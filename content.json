{"meta":{"title":"代码推演录","subtitle":"分享运维开发相关技术，另外好想下班","description":"运维开发相关技术","author":"Aquarius","url":"https://AquaPluto.github.io","root":"/"},"pages":[{"title":"","date":"2025-08-28T12:33:05.420Z","updated":"2025-08-28T12:33:05.420Z","comments":true,"path":"css/wave.css","permalink":"https://aquapluto.github.io/css/wave.css","excerpt":"","text":"/* 波浪css */ .main-hero-waves-area { width: 100%; position: absolute; left: 0; bottom: -11px; z-index: 5; } .waves-area .waves-svg { width: 100%; height: 5rem; } /* Animation */ .parallax > use { animation: move-forever 25s cubic-bezier(0.55, 0.5, 0.45, 0.5) infinite; } .parallax > use:nth-child(1) { animation-delay: -2s; animation-duration: 7s; fill: #f7f9febd; } .parallax > use:nth-child(2) { animation-delay: -3s; animation-duration: 10s; fill: #f7f9fe82; } .parallax > use:nth-child(3) { animation-delay: -4s; animation-duration: 13s; fill: #f7f9fe36; } .parallax > use:nth-child(4) { animation-delay: -5s; animation-duration: 20s; fill: #f7f9fe; } /* 黑色模式背景 */ [data-theme=\"dark\"] .parallax > use:nth-child(1) { animation-delay: -2s; animation-duration: 7s; fill: #18171dc8; } [data-theme=\"dark\"] .parallax > use:nth-child(2) { animation-delay: -3s; animation-duration: 10s; fill: #18171d80; } [data-theme=\"dark\"] .parallax > use:nth-child(3) { animation-delay: -4s; animation-duration: 13s; fill: #18171d3e; } [data-theme=\"dark\"] .parallax > use:nth-child(4) { animation-delay: -5s; animation-duration: 20s; fill: #18171d; } @keyframes move-forever { 0% { transform: translate3d(-90px, 0, 0); } 100% { transform: translate3d(85px, 0, 0); } } /*Shrinking for mobile*/ @media (max-width: 768px) { .waves-area .waves-svg { height: 40px; min-height: 40px; } }"},{"title":"tags","date":"2025-08-18T06:48:32.000Z","updated":"2025-08-28T12:33:05.455Z","comments":true,"path":"tags/index.html","permalink":"https://aquapluto.github.io/tags/","excerpt":"","text":""},{"title":"home","date":"2025-08-15T08:19:44.000Z","updated":"2025-08-28T12:33:05.420Z","comments":true,"path":"home/index.html","permalink":"https://aquapluto.github.io/home/","excerpt":"","text":""},{"title":"categories","date":"2025-08-15T08:20:20.000Z","updated":"2025-08-28T12:33:05.419Z","comments":true,"path":"categories/index.html","permalink":"https://aquapluto.github.io/categories/","excerpt":"","text":""}],"posts":[{"title":"role","slug":"CICD/ansible/role","date":"2025-08-27T10:49:36.000Z","updated":"2025-08-28T12:33:05.184Z","comments":true,"path":"CICD/ansible/role/","permalink":"https://aquapluto.github.io/CICD/ansible/role/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"playbook","slug":"CICD/ansible/playbook","date":"2025-08-27T10:49:30.000Z","updated":"2025-08-28T12:33:05.184Z","comments":true,"path":"CICD/ansible/playbook/","permalink":"https://aquapluto.github.io/CICD/ansible/playbook/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"module","slug":"CICD/ansible/module","date":"2025-08-27T10:49:25.000Z","updated":"2025-08-28T12:33:05.184Z","comments":true,"path":"CICD/ansible/module/","permalink":"https://aquapluto.github.io/CICD/ansible/module/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"command","slug":"CICD/ansible/command","date":"2025-08-27T10:49:19.000Z","updated":"2025-08-28T12:33:05.182Z","comments":true,"path":"CICD/ansible/command/","permalink":"https://aquapluto.github.io/CICD/ansible/command/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"deploy","slug":"CICD/ansible/deploy","date":"2025-08-27T10:49:09.000Z","updated":"2025-08-28T12:33:05.183Z","comments":true,"path":"CICD/ansible/deploy/","permalink":"https://aquapluto.github.io/CICD/ansible/deploy/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"introduce","slug":"CICD/ansible/introduce","date":"2025-08-27T10:48:59.000Z","updated":"2025-08-28T12:33:05.183Z","comments":true,"path":"CICD/ansible/introduce/","permalink":"https://aquapluto.github.io/CICD/ansible/introduce/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"charts","slug":"monitor/grafana/charts","date":"2025-08-27T10:35:49.000Z","updated":"2025-08-28T12:33:05.417Z","comments":true,"path":"monitor/grafana/charts/","permalink":"https://aquapluto.github.io/monitor/grafana/charts/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"https://aquapluto.github.io/tags/Grafana/"}]},{"title":"data-source","slug":"monitor/grafana/data-source","date":"2025-08-27T10:35:42.000Z","updated":"2025-08-28T12:33:05.417Z","comments":true,"path":"monitor/grafana/data-source/","permalink":"https://aquapluto.github.io/monitor/grafana/data-source/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"https://aquapluto.github.io/tags/Grafana/"}]},{"title":"deploy","slug":"monitor/grafana/deploy","date":"2025-08-27T10:35:34.000Z","updated":"2025-08-28T12:33:05.418Z","comments":true,"path":"monitor/grafana/deploy/","permalink":"https://aquapluto.github.io/monitor/grafana/deploy/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"https://aquapluto.github.io/tags/Grafana/"}]},{"title":"alarm","slug":"monitor/alertmanager/alarm","date":"2025-08-27T10:29:44.000Z","updated":"2025-08-28T12:33:05.416Z","comments":true,"path":"monitor/alertmanager/alarm/","permalink":"https://aquapluto.github.io/monitor/alertmanager/alarm/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Alertmanager","slug":"Alertmanager","permalink":"https://aquapluto.github.io/tags/Alertmanager/"}]},{"title":"deploy","slug":"monitor/alertmanager/deploy","date":"2025-08-27T10:29:08.000Z","updated":"2025-08-28T12:33:05.417Z","comments":true,"path":"monitor/alertmanager/deploy/","permalink":"https://aquapluto.github.io/monitor/alertmanager/deploy/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Alertmanager","slug":"Alertmanager","permalink":"https://aquapluto.github.io/tags/Alertmanager/"}]},{"title":"introduce","slug":"monitor/alertmanager/introduce","date":"2025-08-27T10:28:57.000Z","updated":"2025-08-28T12:33:05.417Z","comments":true,"path":"monitor/alertmanager/introduce/","permalink":"https://aquapluto.github.io/monitor/alertmanager/introduce/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Alertmanager","slug":"Alertmanager","permalink":"https://aquapluto.github.io/tags/Alertmanager/"}]},{"title":"indicators-re-marked","slug":"monitor/prometheus/indicators-re-marked","date":"2025-08-27T10:18:07.000Z","updated":"2025-08-28T12:33:05.418Z","comments":true,"path":"monitor/prometheus/indicators-re-marked/","permalink":"https://aquapluto.github.io/monitor/prometheus/indicators-re-marked/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"service-discovery","slug":"monitor/prometheus/service-discovery","date":"2025-08-27T10:17:40.000Z","updated":"2025-08-28T12:33:05.419Z","comments":true,"path":"monitor/prometheus/service-discovery/","permalink":"https://aquapluto.github.io/monitor/prometheus/service-discovery/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"query-results-persist","slug":"monitor/prometheus/query-results-persist","date":"2025-08-27T10:17:21.000Z","updated":"2025-08-28T12:33:05.419Z","comments":true,"path":"monitor/prometheus/query-results-persist/","permalink":"https://aquapluto.github.io/monitor/prometheus/query-results-persist/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"promql","slug":"monitor/prometheus/promql","date":"2025-08-27T10:16:50.000Z","updated":"2025-08-28T12:33:05.419Z","comments":true,"path":"monitor/prometheus/promql/","permalink":"https://aquapluto.github.io/monitor/prometheus/promql/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"exporter","slug":"monitor/prometheus/exporter","date":"2025-08-27T10:16:32.000Z","updated":"2025-08-28T12:33:05.418Z","comments":true,"path":"monitor/prometheus/exporter/","permalink":"https://aquapluto.github.io/monitor/prometheus/exporter/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"deploy","slug":"monitor/prometheus/deploy","date":"2025-08-27T10:16:18.000Z","updated":"2025-08-28T12:33:05.418Z","comments":true,"path":"monitor/prometheus/deploy/","permalink":"https://aquapluto.github.io/monitor/prometheus/deploy/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"conspect","slug":"monitor/conspect","date":"2025-08-27T10:15:50.000Z","updated":"2025-08-28T12:33:05.417Z","comments":true,"path":"monitor/conspect/","permalink":"https://aquapluto.github.io/monitor/conspect/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[]},{"title":"introduce","slug":"monitor/prometheus/introduce","date":"2025-08-27T10:14:47.000Z","updated":"2025-08-28T12:33:05.419Z","comments":true,"path":"monitor/prometheus/introduce/","permalink":"https://aquapluto.github.io/monitor/prometheus/introduce/","excerpt":"","text":"","categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"}]},{"title":"文本处理三剑客","slug":"Linux/linux-basics/GSA","date":"2025-08-21T03:38:34.000Z","updated":"2025-08-28T12:33:05.240Z","comments":true,"path":"Linux/linux-basics/GSA/","permalink":"https://aquapluto.github.io/Linux/linux-basics/GSA/","excerpt":"","text":"一、grep作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行，即过滤文本或者过滤命令的结果 模式：由正则表达式字符及文本字符所编写的过滤条件 123456789101112131415161718192021222324grep [OPTIONS] PATTERN [FILE...]--color=auto #对匹配到的文本着色显示-m N #匹配N次后停止-v #显示不被pattern匹配到的行,即取反-i #忽略字符大小写-n #显示匹配的行号-c #统计匹配的行数-o #仅显示匹配到的字符串-q #静默模式，不输出任何信息-A N #显示匹配到的字符串所在的行及其后n行-B N #显示匹配到的字符串所在的行及其前N行-C N #显示匹配到的字符串所在的行及其前后各N行-e #实现多个选项间的逻辑or关系-w #匹配整个单词-x #整行匹配，即仅选择完全匹配整行的模式。换句话说，只有当模式与整行内容完全匹配时，该行才会被选中-E #使用ERE，相当于egrep-F #不支持正则表达式，相当于fgrep，将模式视为固定字符串而不是正则表达式。通常用于搜索不包含正则表达式特殊字符的模式-P #支持Perl格式的正则表达式-f file #从文件中读取匹配规则，每行一条-r #递归目录，但不处理软链接-R #递归目录，但处理软链接-l #显示匹配上的文件名，只显示文件名-H #显示匹配行所在的文件名 grep -qFx 和 grep -qF 的区别 12345grep -qFx:这个命令的含义是使用-q选项表示&quot;quiet&quot;模式，不会输出任何匹配行，仅返回匹配结果的退出状态。-Fx则分别表示使用固定字符串匹配(即精确匹配)和整行匹配。因此，-qFx表示在文件中查找完全匹配给定字符串的行，并且在匹配时不输出任何内容，只返回匹配结果的退出状态。grep -qF:与上述相似，这个命令也使用了-q选项表示&quot;quiet&quot;模式，不会输出任何匹配行，仅返回匹配结果的退出状态。但是，-F表示使用固定字符串匹配(即精确匹配)，但并不要求完全整行匹配，而是只要匹配到给定字符串即可总的来说，区别在于-Fx要求完全整行匹配，而-F则只要求匹配到给定字符串即可，不要求整行完全匹配 范例 12345678910111213141516171819202122232425262728293031323334353637383940#取前三行[root@ubuntu2204 ~]# grep -m 3 bin /etc/passwd#显示匹配的行数[root@ubuntu2204 ~]# grep -c bash /etc/passwd#仅显示匹配到的字符串[root@ubuntu2204 ~]# grep -o root /etc/passwd#显示匹配root的行或匹配 bash 的行[root@ubuntu2204 ~]# grep -e root -e bash /etc/passwd#显示匹配root的行且匹配 bash 的行[root@ubuntu2204 ~]# grep root /etc/passwd | grep bash#从文件读取匹配规则[root@ubuntu2204 ~]# cat test.txtrootbash#匹配有root或者bash的行[root@ubuntu2204 ~]# grep -f test.txt /etc/passwd #只显示有匹配到的文件的文件名，不显示具体内容[root@ubuntu2204 ~]# grep root -l /etc/passwd /etc/sudoers /etc/my.cnf#显示内容来自于哪个文件[root@ubuntu2204 ~]# grep -H root /etc/passwd /etc/sudoers /etc/my.cnf#命令行展开[root@ubuntu2204 ~]# grep `whoami` /etc/passwdroot:x:0:0:root:/root:/bin/bash[root@ubuntu2204 ~]# echo Linux123 | grep $(uname)Linux123#变量展开[root@ubuntu2204 ~]# grep &quot;$USER&quot; /etc/passwd#取CPU核数[root@ubuntu2204 ~]# grep -c processor /proc/cpuinfo 过滤以#开头的注释行和空行123456[root@centos8 ~]#grep -v &quot;^#&quot; /etc/profile | grep -v &#x27;^$&#x27;[root@centos8 ~]#grep -v &quot;^#\\|^$&quot; /etc/profile[root@centos8 ~]#grep -v &quot;^\\(#\\|$\\)&quot; /etc/profile[root@centos8 ~]#grep -Ev &quot;^(#|$)&quot; /etc/profile[root@centos8 ~]#egrep -v &quot;^(#|$)&quot; /etc/profile[root@centos6 ~]#egrep -v &#x27;^(#|$)&#x27; /etc/httpd/conf/httpd.conf 取两个文件的相同行123456789101112131415[11:40:48 root@10 data[]#cat a.txtaefd gh[11:40:56 root@10 data[]#cat a.txt.orig abcd[11:41:16 root@10 data[]#grep -f a.txt a.txt.orig ad 分区利用率最大的值12345[root@centos8 ~]#df | grep &#x27;^/dev/sd&#x27; | tr -s &#x27; &#x27; % | cut -d% -f5 | sort -n | tail -1[root@centos8 ~]#df | grep &#x27;^/dev/sd&#x27; | grep -oE &#x27;\\&lt;[0-9]&#123;,3&#125;%&#x27; | tr -d &#x27;%&#x27;|sort -nr|head -n1[root@centos8 ~]#df | grep &#x27;^/dev/sd&#x27; | grep -oE &#x27;\\&lt;[0-9]&#123;,3&#125;%&#x27;|grep -Eo &#x27;[0-9]+&#x27;|sort -nr|head -n1[root@centos8 ~]#df | grep &#x27;^/dev/sd&#x27; | grep -oE [0-9]+% | tr -d % |sort -nr|head -n113 哪个IP和当前主机连接数最多的前三位1234[root@centos8 ~]#ss -nt | grep &quot;^ESTAB&quot; |tr -s &#x27; &#x27; : |cut -d: -f6|sort |uniq -c|sort -nr|head -n3 3 10.0.0.1 1 172.16.4.100 1 172.16.31.188 连接状态的统计12345678[root@wang-liyun-pc ~]# ss -nta | grep -v &#x27;^State&#x27; |cut -d&quot; &quot; -f1|sort |uniq -c 7 ESTAB 4 LISTEN 7 TIME-WAIT[root@wang-liyun-pc ~]# ss -nta | tail -n +2 |cut -d&quot; &quot; -f1|sort |uniq -c 3 ESTAB 4 LISTEN 12 TIME-WAIT 取IP地址1234567[root@centos8 ~]#ifconfig eth0 | grep -Eo &#x27;([0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;&#x27;|head -110.0.0.8[root@ubuntu2204 ~]# cat reg.txt([0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;[root@ubuntu2204 ~]# ifconfig | grep -oEf reg.txt | head -110.0.0.206 匹配字符前后一样的行12345678[root@centos8 ~]#grep &quot;^\\(.*\\)\\&gt;.*\\&lt;\\1$&quot; /etc/passwd[root@centos8 ~]#grep -E &quot;^(.*)\\&gt;.*\\&lt;\\1$&quot; /etc/passwd[root@centos8 ~]#egrep &quot;^(.*)\\&gt;.*\\&lt;\\1$&quot; /etc/passwdsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltbash:x:1008:1008::/home/bash:/bin/bashnologin:x:1011:1011::/home/nologin:/sbin/nologin 二、sedSed是不会一下子把文件内容全部读入内容，而是读一行到内存处理一行，然后再读下一行，一次处理一行的设计模式使得sed性能很高，在读取大文件时不会出现卡顿的现象。支持管道符号 每当处理一行时，把当前处理的行存储在临时缓冲区 模式空间（Pattern Space） 中，接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。 如果使用vi命令打开几十M上百M的文件，明显会出现有卡顿的现象，这是因为vi命令打开文件是一次性将文件加载到内存，然后再打开。Sed就避免了这种情况，一行一行的处理，打开速度非常快，执行速度也很快。 sed 基本用法1234567891011121314151617sed [option]... &#x27;script;script;...&#x27; [file...]-n #不输出模式空间内容到屏幕，即不自动打印-e #多点编辑，多个script，or 的关系-f FILE #从指定文件中读取编辑脚本-r, -E #使用扩展正则表达式-i.bak #-i 直接修改文件，-i.bak 以.bak后缀备份原文件-c #配合i一起使用，保留原文件-s #将多个文件视为独立文件，而不是单个连续的长文件流-e #多个script，or 的关系#说明:-ir #不支持-i -r #支持-ri #支持-ni #危险选项,会清空文件 script格式 1&#x27;定位+命令&#x27; #在哪些行，执行什么操作 定位格式 12345678910111213141516171. 不定位：对全文进行处理2. 行定位，指定行： N #指定的行 $ #最后一行 /pattern/ #被此处模式所能够匹配到的每一行 3. 范围定位： M,N #从M行到第N行，3，6 从第3行到第6行 M,+N #从M行到M+N行，3,+4 表示从3行到第7行 /pat1/,/pat2/ #从第一个匹配行开始，到第二个匹配行中间的行 M,/pat/ #行号开始，匹配结束 /pat/,N #匹配开始，行号结束 4. 步进：~ 1~2 #奇数行 2~2 #偶数行 命令格式 1234567891011121314151617181920212223p #打印当前模式空间内容，追加到默认输出之后Ip #忽略大小写输出d #删除模式空间匹配的行，并立即启用下一轮循环= #为模式空间中的行打印行号! #模式空间中匹配行取反处理q #结束或退出seda [\\]text #在指定行后面追加文本，支持使用\\n实现多行追加i [\\]text #在行前面插入文本c [\\]text #替换行为单行或多行文本w file #保存模式匹配的行至指定文件r file #读取指定文件的文本至模式空间中匹配到的行后s/pattern/string/修饰符 #查找替换,支持使用其它分隔符，可以是其它形式：s@@@，s### #修饰符 g #行内全局替换 p #显示替换成功的行 w /PATH/FILE #将替换成功的行保存至文件中 I,i #忽略大小写 #后向引用 \\1 #第一个分组 \\2 #第二个分组 \\N #第N个分组 &amp; #所有搜索内容 范例 12345678[root@centos7 ~]#cat &gt; test.logport=3306^C[root@centos7 ~]#sed &#x27;s/3306/3307/&#x27; test.log &gt; test2.log [root@centos7 ~]#cat test2.log port=3307[root@centos7 ~]#cat test.log port=3306 范例 123456789101112#script 中执行p命令，再加上默认输出，所有每行都显示了两次[root@ubuntu2204 ~]# sed &#x27;p&#x27; /etc/issueUbuntu 22.04 LTS \\n \\lUbuntu 22.04 LTS \\n \\l#关闭默认输出，script 为空，则无任何输出[root@ubuntu2204 ~]# sed -n &#x27;&#x27; /etc/issue[root@ubuntu2204 ~]##用 -n 选项关闭默认输出，script 中执行p命令[root@ubuntu2204 ~]# sed -n &#x27;p&#x27; /etc/issueUbuntu 22.04 LTS \\n \\l 范例：\\ 的作用 123456789101112[root@ubuntu2204 ~]# sed &#x27;2a *******&#x27; test.txtaaabbb*******cccbbb[root@ubuntu2204 ~]# sed &#x27;2a\\ *******&#x27; test.txtaaabbb *******cccbbb 范例：取第几行的问题 123456[15:36:26 root@10 ~[]#seq 10 | sed -n &#x27;3,5p&#x27;345[20:00:38 root@10 ~[]#seq 10 | sed -n &#x27;3p&#x27;3 范例：给特定的行过滤掉 1234567[20:03:22 root@10 ~[]#seq 10 | sed &#x27;3,6d&#x27;1278910 范例：追加内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[20:31:16 root@10 ~[]#seq 10 | sed &#x27;2~2ahello&#x27;12hello34hello56hello78hello910hello[20:31:23 root@10 ~[]#cat .bashrc# .bashrc# User specific aliases and functionsalias rm=&#x27;rm -i&#x27;alias cp=&#x27;cp -i&#x27;alias mv=&#x27;mv -i&#x27;# Source global definitionsif [ -f /etc/bashrc ]; then . /etc/bashrcfi[20:34:26 root@10 ~[]#sed &#x27;User specificaalias text=ls&#x27; .bashrcsed：-e 表达式 #1，字符 1：未知的命令：“U”[20:35:11 root@10 ~[]#sed &#x27;/User specific/aalias text=ls&#x27; .bashrc# .bashrc# User specific aliases and functionsalias text=lsalias rm=&#x27;rm -i&#x27;alias cp=&#x27;cp -i&#x27;alias mv=&#x27;mv -i&#x27;# Source global definitionsif [ -f /etc/bashrc ]; then . /etc/bashrcfi#加-i.bak可修改文件，改过的在.bashrc，原来的在.bashrc.bak 范例：将内容保存到指定文件 12345678910111213[21:01:35 root@10 ~[]#seq 10 | sed &#x27;3w c.txt&#x27;12345678910[21:02:02 root@10 ~[]#cat c.txt 3 范例：追加文件内容到指定的行后 12345678910111213141516171819202122232425[21:02:07 root@10 ~[]#seq 10 | sed &#x27;2~2r /etc/issue&#x27;12\\SKernel \\r on an \\m34\\SKernel \\r on an \\m56\\SKernel \\r on an \\m78\\SKernel \\r on an \\m910\\SKernel \\r on an \\m 命令行和变量展开123456789[root@centos7 ~]#sed &quot;s/3306/`id -u wu`/&quot; test.log[root@centos7 ~]#sed &#x27;s/3306/&#x27;`id -u wu`&#x27;/&#x27; test.logport=1000[root@centos7 ~]#echo $UID0[root@centos7 ~]#sed &quot;s/3306/$UID/&quot; test.log[root@centos7 ~]#sed &#x27;s/3306/&#x27;$UID&#x27;/&#x27; test.logport=0 只要#号开头的行12345678910111213[20:07:48 root@10 ~[]#sed -n &#x27;/^#/p&#x27; /etc/profile# /etc/profile# System wide environment and startup programs, for login setup# Functions and aliases go in /etc/bashrc# It&#x27;s NOT a good idea to change this file unless you know what you# are doing. It&#x27;s much better to create a custom.sh shell script in# /etc/profile.d/ to make custom changes to your environment, as this# will prevent the need for merging in future updates.# Path manipulation# By default, we want umask to get set. This sets it for login shell# Current threshold for system reserved uid/gids is 200# You could check uidgid reservation validity in# /usr/share/doc/setup-*/uidgid file 不要#号开头的行12345[20:08:15 root@10 ~[]#sed -n &#x27;/^[^#]/p&#x27; /etc/profile[root@centos8 ~]#sed -n &#x27;/^#/!p&#x27; fstab[20:11:18 root@10 ~[]#sed &#x27;/^#/d&#x27; /etc/profile 将#开头的行删除#1[root@centos8 ~]#sed -ri.bak &#x27;/^#/s/^#//&#x27; /etc/fstab #先读取#开头的行，然后将#替换成空 将非#开头的行加#123[root@centos8 ~]#sed -rn &quot;s/^[^#]/#&amp;/p&quot; /etc/fstab[root@centos8 ~]#sed -rn &#x27;s/^[^#](.*)/#\\1/p&#x27; /etc/fstab[root@centos8 ~]#sed -rn &#x27;/^#/!s@^@#@p&#x27; /etc/fstab 不显示注释行和空行12[root@centos6 ~]#sed &#x27;/^#/d;/^$/d&#x27; /etc/httpd/conf/httpd.conf[root@centos6 ~]#grep -Ev &#x27;^#|^$&#x27; /etc/httpd/conf/httpd.conf 在&#x2F;etc&#x2F;passwd需要b开头和s开头的行123456[20:15:39 root@10 ~[]#sed -n &#x27;/^b/,/^s/p&#x27; /etc/passwdbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/sync 获取分区利用率123456[root@centos8 ~]#df | sed -En &#x27;/^\\/dev\\/sd/s@.* ([0-9]+)%.*@\\1@p&#x27;3113[root@centos8 ~]#df | sed -rn &#x27;/^\\/dev\\/sd/ s#([^[:space:]]+[[:space:]]+)&#123;4&#125;(.*)%.*#\\2#p&#x27;[root@centos8 ~]#df | sed -rn &#x27;/^\\/dev\\/sd/ s#(\\S+\\s+)&#123;4&#125;(.*)%.*#\\2#p&#x27; 取 IP 地址123456789101112[root@centos8 ~]#ifconfig eth0 |sed -nr &quot;2s/[^0-9]+([0-9.]+).*/\\1/p&quot; 10.0.0.8[root@centos6 ~]#ifconfig eth0 | sed -En &#x27;2s/^[^0-9]+([0-9.]&#123;7,15&#125;).*/\\1/p&#x27;10.0.0.6[root@centos8 ~]#ifconfig eth0 | sed -rn &#x27;2s/^[^0-9]+([0-9.]+) .*$/\\1/p&#x27;10.0.0.8[root@centos8 ~]#ifconfig eth0 | sed -n &#x27;2s/^.*inet //p&#x27; | sed -n &#x27;s/netmask.*//p&#x27;10.0.0.8[root@centos8 ~]#ifconfig eth0 | sed -n &#x27;2s/^.*inet //;s/ netmask.*//p&#x27;10.0.0.8[root@centos8 ~]#ifconfig eth0 | sed -rn &#x27;2s/(.*inet )([0-9].*)(netmask.*)/\\2/p&#x27;10.0.0.8 取目录名和基名123456789echo &quot;/etc/sysconfig/network-scripts/&quot; |sed -r &#x27;s#(^/.*/)([^/]+/?)#\\2#&#x27; 取基名echo &quot;/etc/sysconfig/network-scripts/&quot; |sed -r &#x27;s#(^/.*/)([^/]+/?)#\\1#&#x27; 取目录#取目录名[root@centos8 ~]#echo /etc/sysconfig/ | sed -rn &#x27;s#(.*)/([^/]+)/?#\\1#p&#x27;/etc#取基名[root@centos8 ~]#echo /etc/sysconfig/ | sed -rn &#x27;s#(.*)/([^/]+)/?#\\2#p&#x27;sysconfig 取文件的前缀和后缀12345678910[root@centos8 data]#echo a.b.c.gz |sed -En &#x27;s/(.*)\\.([^.]+)$/\\1/p&#x27;a.b.c[root@centos8 data]#echo a.b.c.gz |sed -En &#x27;s/(.*)\\.([^.]+)$/\\2/p&#x27;gz[root@centos8 data]#echo a.b.c.gz |grep -Eo &#x27;.*\\.&#x27;a.b.c[root@centos8 data]#echo a.b.c.gz |grep -Eo &#x27;[^.]+$&#x27;gz[root@centos8 ~]#echo a.b.tar.gz | sed -rn &#x27;s@.*\\.([^.]+)\\.([^.]+)$@\\1.\\2@p&#x27;tar.gz 修改网卡配置1[root@centos8 ~]#sed -Ei.bak &#x27;/^GRUB_CMDLINE_LINUX/s/(.*)(&quot;)$/\\1net.ifnames=0\\2/&#x27; /etc/default/grub 修改内核参数12345[root@centos8 ~]#sed -nr &#x27;/^GRUB_CMDLINE_LINUX/s/&quot;$/ net.ifnames=0&quot;/p&#x27;/etc/default/grub[root@centos8 ~]#sed -rn &#x27;/^GRUB_CMDLINE_LINUX=/s@(.*)&quot;$@\\1 net.ifnames=0&quot;@p&#x27;/etc/default/grub[root@centos8 ~]#sed -rn &#x27;/^GRUB_CMDLINE_LINUX=/s@&quot;$@ net.ifnames=0&quot;@p&#x27;/etc/default/grub 修改网卡名称123456#centos7,8[root@centos8 ~]#sed -i &#x27;/GRUB_CMDLINE_LINUX=/s#quiet#&amp; net.ifnames=0#&#x27;/etc/default/grub[root@centos8 ~]#sed -ri &#x27;/^GRUB_CMDLINE_LINUX=/s@&quot;$@ net.ifnames=0&quot;@&#x27;/etc/default/grub[root@centos8 ~]#grub2-mkconfig -o /boot/grub2/grub.cfg#ubuntu[root@ubuntu ~]#grub-mkconfig -o /boot/grub/grub.cfg 后项引用将需要的内容用()分组，然后后续引用它，命令为 \\1;\\2;\\3 \\1 表示第一个分组 \\0 表示正则表达式匹配的所有字符 范例：要把123456789换成以下三种情况 12345678[10:58:07 root@10 ~[]#echo 123456789 | sed -n &#x27;s/\\(123\\)\\(456\\)\\(789\\)/\\2\\1\\3/p&#x27;456123789[10:58:19 root@10 ~[]#echo 123456789 | sed -n &#x27;s/\\(123\\)\\(456\\)\\(789\\)/\\1\\3/p&#x27;123789[10:59:20 root@10 ~[]#echo 123456789 | sed -n &#x27;s/\\(123\\)\\(456\\)\\(789\\)/\\1xyx\\3/p&#x27;123xyx789 范例：取ip地址 12[13:36:02 root@10 ~[]#ifconfig ens160 | sed -r -n &#x27;2s/^(.*inet +)([0-9.]+)( +netmask.*)$/\\2/p&#x27;10.0.0.131 sed 高级用法sed 中除了模式空间，还另外还支持保持空间（Hold Space）,利用此空间，可以将模式空间中的数据，临时保存至保持空间，从而后续接着处理，实现更为强大的功能 常见的高级命令 12345678910P #打印模式空间开端至\\n内容，并追加到默认输出之前h #把模式空间中的内容覆盖至保持空间中H #把模式空间中的内容追加至保持空间中g #从保持空间取出数据覆盖至模式空间G #从保持空间取出内容追加至模式空间x #把模式空间中的内容与保持空间中的内容进行互换n #读取匹配到的行的下一行覆盖至模式空间N #读取匹配到的行的下一行追加至模式空间d #删除模式空间中的行D #如果模式空间包含换行符，则删除直到第一个换行符的模式空间中的文本，并不会读取新的输入行，而使用合成的模式空间重新启动循环。如果模式空间不包含换行符，则会像发出d命令那样启动正常的新循环 范例 1234567891011121314sed -n &#x27;n;p&#x27; FILEseq 10 | sed &#x27;N;s/\\n//&#x27;sed &#x27;1!G;h;$!d&#x27; FILEseq 10 | sed -n &#x27;/3/&#123;g;1!p;&#125;;h&#x27; #前一行seq 10 | sed -nr &#x27;/3/&#123;n;p&#125;&#x27; #后一行sed &#x27;N;D&#x27;FILEseq 10 |sed &#x27;3h;9G;9!d&#x27;sed &#x27;$!N;$!D&#x27; FILEsed &#x27;$!d&#x27; FILEsed &#x27;G&#x27; FILEsed &#x27;g&#x27; FILEsed &#x27;/^$/d;G&#x27; FILEsed &#x27;n;d&#x27; FILEsed -n &#x27;1!G;h;$p&#x27; FILE 范例: 打印偶数行 123456789101112131415161718192021222324[root@centos8 ~]#seq 10 | sed -n &#x27;n;p&#x27;246810[root@centos8 ~]#seq 10 | sed -n &#x27;2~2p&#x27;246810[root@centos8 ~]#seq 10 | sed &#x27;1~2d&#x27;246810[root@centos8 ~]#seq 10 | sed -n &#x27;1~2!p&#x27;246810 三、awkawk工作原理和基本用法格式化输出，针对的是有规律的文本文件，支持管道符号 执行BEGIN&#123;action;… &#125;语句块中的语句 读入文本的一行内容，进行处理 先把这行内容整体赋值给一个变量$0 以冒号为分隔符对该行进行分割 第一段内容 –赋值给—》$1 第二段内容 –赋值给—》$2 把行号赋值NR变量 把这一行分的总段数赋值给变量NF 执行规则&#39;NR&gt;=1 &amp;&amp; NR&lt;=3&#123;print $1&#125;&#39; 后续就是重复2，3步直到处理完文件的所有行 读取完所有的行之后执行END&#123;action;… &#125;语句块中的语句 格式 1234567awk [options] &#x27;program&#x27; var=value file…awk [options] -f programfile var=value file…#常用选项-f progfile #从文件中读入program-F fs #指定分隔符，默认的分隔符是若干个连续空白符,可以指定多个-v var=val #设置变量 program格式 12345678910&#x27;pattern&#123;action statements;..&#125;&#x27;pattern：定位 行号：NR==5或NR&gt;=1 &amp;&amp; NR&lt;=3或NR&lt;=3 || NR &gt;= 5（可以运用各种操作符） 正则定位：/正则表达式/action statements：对数据进行处理 &#123;print $1&#125; 算术，比较表达式 if, while等 组合语句 说明：program通常是被放在单引号中，并可以由三种部分组成 BEGIN语句块，BEGIN&#123;&#125; 模式匹配的通用语句块，[pattern]&#123;COMMAND&#125; END语句块，END&#123;&#125; 分割符、域和记录 由分隔符分隔的字段（列column,域field）标记的$1,$2...$n称为域标识，$0为所有域 文件的每一行称为记录record 如果省略action，则默认执行print $0的操作 范例 1234567[root@centos7 ~]#awk &#x27;BEGIN&#123;print strftime(&quot;%Y-%m-%dT%H:%M&quot;,systime()-3600)&#125;&#x27;2023-10-04T15:10[root@centos7 ~]#cat a.awkBEGIN&#123;print strftime(&quot;%Y-%m-%dT%H:%M&quot;,systime()-3600)&#125;[root@centos7 ~]#awk -f a.awk2023-10-04T15:09 范例：awk打印列很简单，$1表示第一列 12345678910111213141516171819202122232425[root@centos7 ~]#df | awk &#x27;&#123;print $5&#125;&#x27;Use%0%0%3%0%13%15%0%0%#指定分隔符[root@centos7 ~]#df | awk &#x27;&#123;print $5&#125;&#x27; | awk -F&quot;%&quot; &#x27;&#123;print $1&#125;&#x27;Use0030131500[root@centos7 ~]#getent passwd | awk -F&quot;:&quot; &#x27;&#123;print $1,$3&#125;&#x27;[root@centos7 ~]#getent passwd | awk -F&quot;:&quot; &#x27;&#123;print $1&quot;=&quot;$3&#125;&#x27; 范例 123456789101112131415#指定多个分隔符[root@centos7 ~]#df | awk -F&quot; +|%&quot; &#x27;&#123;print $5&#125;&#x27; #多个空格和%作为分隔符Use0030131500#但是这种写法中，会多出一列空行，即第6列是空行，因为%这里分割的时候，会分割成两列，前面是数字，但是后面原来啥也没有，所以自动补充了一列空格#这种写法不会出现以上情况[root@centos8 ~]#df | awk -F&quot;[ %]+&quot; &#x27;&#123;print $5&#125;&#x27; #表示多个空格和多个%作为分隔符 原因的话，我们用下列例子来分析 123456789101112131415161718[root@ubuntu2004 ~]#cat a.txt1 2% 41 2%3 4Avail Use% MountedFilesystem Size Used Avail Use% Mounted on[root@ubuntu2004 ~]#awk -F&quot;[ %]+&quot; &#x27;&#123;print NF&#125;&#x27; a.txt3437[root@ubuntu2004 ~]#awk -F&quot; +|%&quot; &#x27;&#123;print NF&#125;&#x27; a.txt4448#解析如下 123456789总的来说，跟离散数学的逻辑相似p：使用空格作为分隔符q：使用%作为分隔符awk -F&quot;[ %]+&quot;的逻辑就是(p∧¬q)V(¬p∧q) #这表示使用空格作为分隔符或者使用%作为分隔符awk -F&quot; +|%&quot;的逻辑就是pVq #这表示使用空格作为分隔符或者使用%作为分隔符，或者两者都可能发生这里的“∨”是逻辑或的意思，通常对应于集合的并集。它涵盖了所有满足至少一个条件的情况。然而，在经典逻辑中，如果p和q不能同时为真，即它们是互斥的情况，那么“p ∨ q”实际上只会有两种可能性，即p为真或q为真，但不会同时为真。这是因为在经典逻辑中，“∨”通常被解释为包含性的或（inclusive or），意味着如果p和q都是真的，那么“p ∨ q”也是真的。 动作print和printfprint123456print item1, item2, ...逗号分隔符输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式如省略item，相当于print $0固定字符符需要用“ ” 引起来，而变量和数字不需要 范例 123456789101112131415161718192021222324252627282930313233[root@centos7 ~]#awk &#x27;&#123;print &quot;hello&quot;&#125;&#x27; 123helloabchello^C[root@centos7 ~]#awk &#x27;&#123;print &quot;hello&quot;&#125;&#x27; &lt; /etc/issuehellohellohello[root@centos7 ~]#cat /etc/issue | awk &#x27;&#123;print &quot;hello&quot;&#125;&#x27; &lt; /etc/issuehellohellohello[root@centos8 ~]#seq 10 | awk &#x27;&#123;print &quot;hello,awk&quot;&#125;&#x27;hello,awkhello,awkhello,awkhello,awkhello,awkhello,awkhello,awkhello,awkhello,awkhello,awk[root@centos8 ~]#seq 3 | awk &#x27;&#123;print 2*3&#125;&#x27;666[root@centos7 etc]#awk &#x27;&#123;print &quot;2*3&quot;&#125;&#x27; &lt; /etc/issue2*32*32*3 面试题：取出网站访问量最大的前3个IP1[root@VM_0_10_centos logs]# awk &#x27;&#123;print $1&#125;&#x27; nginx.access.log-20200428|sort |uniq -c |sort -nr|head -3 面试题：取出分区利用率123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@centos8 ~]#df | awk &#x27;&#123;print $1,$5&#125;&#x27;Filesystem Use%devtmpfs 0%tmpfs 0%tmpfs 2%tmpfs 0%/dev/sda2 3%/dev/sda3 1%/dev/sda1 15%tmpfs 0%#使用扩展的正则表达式[root@centos8 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &#x27;&#123;print $5&#125;&#x27;Use001051921[root@centos8 ~]#df | awk -F&quot;[ %]+&quot; &#x27;&#123;print $5&#125;&#x27;Use001031190[root@rocky8 ~]#df | awk -F&quot; +|%&quot; &#x27;&#123;print $5&#125;&#x27;Use001031170[root@centos8 ~]#df | grep &quot;^/dev/sd&quot; | awk -F&quot;[[:space:]]+|%&quot; &#x27;&#123;print $5&#125;&#x27;5192[root@centos8 ~]#df | grep &#x27;^/dev/sd&#x27;| awk -F&#x27;[[:space:]]+|%&#x27; &#x27;&#123;print $1,$5&#125;&#x27; /dev/sda2 3/dev/sda3 1/dev/sda1 15[root@centos8 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &#x27;/^\\/dev\\/sd/&#123;print $5&#125;&#x27;5192[root@centos8 ~]#df | awk -F&#x27;[[:space:]]+|%&#x27; &#x27;/^\\/dev\\/sd/&#123;print $1,$5&#125;&#x27; /dev/sda2 3/dev/sda3 1/dev/sda1 15[root@centos8 ~]#df|awk -F&#x27; +|%&#x27; &#x27;/^\\/dev\\/sd/&#123;print $1,$5&#125;&#x27;/dev/sda2 3/dev/sda3 2/dev/sda1 100 取nginx的访问日志的中IP和时间123456789101112[root@VM_0_10_centos ~]# head -n 3 /apps/nginx/logs/nginx.access.log58.87.87.99 - - [09/Jun/2020:03:42:43 +0800] &quot;POST /wp-cron.php?doing_wp_cron=1591645363.2316548824310302734375 HTTP/1.1&quot; &quot;&quot;sendfileon128.14.209.154 - - [09/Jun/2020:03:42:43 +0800] &quot;GET / HTTP/1.1&quot; &quot;&quot;sendfileon64.90.40.100 - - [09/Jun/2020:03:43:11 +0800] &quot;GET /wp-login.php HTTP/1.1&quot;&quot;&quot;sendfileon[root@VM_0_10_centos ~]# awk -F&#x27;[[ ]&#x27; &#x27;&#123;print $1,$5&#125;&#x27;/apps/nginx/logs/nginx.access.log|head -358.87.87.99 09/Jun/2020:03:42:43128.14.209.154 09/Jun/2020:03:42:4364.90.40.100 09/Jun/2020:03:43:11 面试题：取 ifconfig 输出结果中的IP地址123456789101112[root@centos8 ~]#ifconfig eth0|sed -n &#x27;2p&#x27; |awk &#x27;&#123;print $2&#125;&#x27;|cat -A10.0.0.8$[root@centos8 ~]#ifconfig eth0 | awk &#x27;/netmask/&#123;print $2&#125;&#x27;10.0.0.8[root@centos6 ~]#ifconfig eth0 |awk -F &quot; +|:&quot; &#x27;/Mask/&#123;print $4&#125;&#x27;10.0.0.6[root@centos6 ~]#ip a show eth0 |awk -F&#x27; +|\\/&#x27; &#x27;/\\&lt;inet\\&gt;/&#123;print $3&#125;&#x27; 2&gt;/dev/null10.0.0.6[root@centos8 ~]#ifconfig eth0| sed -rn &#x27;2s/^[^0-9]+([0-9.]+) .*$/\\1/p&#x27;10.0.0.8[root@centos6 ~]#ifconfig eth0| sed -rn &#x27;2s/^[^0-9]+([0-9.]+) .*$/\\1/p&#x27;10.0.0.6 面试题：文件host_list.log如下格式，请提取”.magedu.com”前面的主机名部分并写入到回到该文件中1234567891011121314151617181920212223242526[root@centos8 ~]#cat host_list.log1 www.magedu.com2 blog.magedu.com3 study.magedu.com4 linux.magedu.com5 python.magedu.com[root@centos8 ~]#awk -F&quot;[ .]&quot; &#x27;&#123;print $2&#125;&#x27; host_list.logwwwblogstudylinuxpython[root@centos8 ~]#awk -F&quot;[ .]&quot; &#x27;&#123;print $2&#125;&#x27; host_list.log &gt;&gt; host_list.log[root@centos8 ~]#cat host_list.log1 www.magedu.com2 blog.magedu.com3 study.magedu.com4 linux.magedu.com5 python.magedu.comwwwblogstudylinuxpython printfprintf 可以实现格式化输出 12345printf “FORMAT”, item1, item2, ...必须指定FORMAT不会自动换行，需要显式给出换行控制符 \\nFORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 12345678%s：显示字符串%d, %i：显示十进制整数%f：显示为浮点数%e, %E：显示科学计数法数值%c：显示字符的ASCII码%g, %G：以科学计数法或浮点形式显示数值%u：无符号整数%%：显示%自身 修饰符 123#[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，如：%3.1f- 左对齐（默认右对齐） 如：%-15s+ 显示数值的正负符号 如：%+d 范例 123456789awk -F: &#x27;&#123;printf &quot;%s&quot;,$1&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;%s\\n&quot;,$1&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;%20s\\n&quot;,$1&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;%-20s\\n&quot;,$1&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;%-20s %10d\\n&quot;,$1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;Username: %s\\n&quot;,$1&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf “Username: %sUID:%d\\n&quot;,$1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;Username: %25sUID:%d\\n&quot;,$1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;&#123;printf &quot;Username: %-25sUID:%d\\n&quot;,$1,$3&#125;&#x27; /etc/passwd awk 变量常见的内置变量 FS：输入字段分隔符，默认为空白字符，功能相当于 -F -F 和 FS 变量功能一样，同时使用，-F优先级高 12345678[root@centos8 ~]#awk -v FS=&quot;:&quot; &#x27;&#123;print $1FS$3&#125;&#x27; /etc/passwd |head -n3root:0bin:1daemon:2[root@centos8 ~]#S=:;awk -F$S &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd|head -n3root 0bin 1daemon 2 OFS：输出字段分隔符，默认为空白字符 1234[root@centos8 ~]#awk -v FS=&#x27;:&#x27; &#x27;&#123;print $1,$3,$7&#125;&#x27; /etc/passwd|head -n1root 0 /bin/bash[root@centos8 ~]#awk -v FS=&#x27;:&#x27; -v OFS=&#x27;:&#x27; &#x27;&#123;print $1,$3,$7&#125;&#x27; /etc/passwd|head -n1root:0:/bin/bash RS：换行符，用于分割指定文件的行，默认是换行符 12345678910[root@centos7 ~]#cat b.txt a,b,c;1,2,3;x,y,z[root@centos7 ~]#awk -v RS=&quot;;&quot; &#x27;&#123;print $1&#125;&#x27; b.txt a,b,c1,2,3x,y,z[root@centos7 ~]#awk -v RS=&quot;;&quot; -v FS=&quot;,&quot; &#x27;&#123;print $1&#125;&#x27; b.txt a1x ORS：输出换行符，输出时用指定符号代替换行符 12[root@centos7 ~]#awk -v RS=&quot;;&quot; -v FS=&quot;,&quot; -v ORS=&quot;-&quot; &#x27;&#123;print $1&#125;&#x27; b.txt a-1-x- NF：统计一条记录的字段数量 1234567#引用变量时，变量前不需加$[root@centos8 ~]#awk -F: &#x27;&#123;print NF&#125;&#x27; /etc/fstab[root@centos8 ~]#awk -F: &#x27;&#123;print $(NF-1)&#125;&#x27; /etc/passwd #打印倒数第二列[root@centos8 ~]#ls /misc/cd/BaseOS/Packages/*.rpm |awk -F&quot;.&quot; &#x27;&#123;print $(NF-1)&#125;&#x27;|sort |uniq -c 389 i686 208 noarch 1060 x86_64 面试题：连接数最多的前3个IP1234567891011121314151617[root@centos8 ~]#awk -F&quot; +|:&quot; &#x27;&#123;print $(NF-2)&#125;&#x27; ss.log |sort |uniq -c|sort -nr|head -n3 12 223.88.255.148 11 119.250.197.118 10 183.202.63.36[root@centos8 ~]#awk -F&quot; +|:&quot; &#x27;/^ESTAB/&#123;print $(NF-2)&#125;&#x27; ss.log |sort |uniq -c|sort -nr|head -n3 12 223.88.255.148 10 183.202.63.36 9 117.152.155.119[root@centos8 ~]#ss -nt |grep &quot;^ESTAB&quot; | awk -F&quot;[[:space:]]+|:&quot; &#x27;&#123;print $(NF-2)&#125;&#x27;10.0.0.110.0.0.710.0.0.1[root@centos8 ~]#ss -nt |awk -F&quot;[[:space:]]+|:&quot; &#x27;/^ESTAB/&#123;print $(NF-2)&#125;&#x27;[root@centos8 ~]#ss -nt|awk -F: &#x27;&#123;print $(NF-1)&#125;&#x27; |awk &#x27;/^[0-9]/&#123;print $NF&#125;&#x27;|sort |uniq -c |head -n 3[root@wang-liyun-pc ~]# awk -F&#x27; +|:&#x27; &#x27;NR!=1&#123;print $(NF-2)&#125;&#x27; ss.log|sort |uniq -c 1 100.100.30.25 86 39.164.140.134 每十分钟检查将连接数超过100个以上的IP放入黑名单拒绝访问12345678910111213[root@centos8 ~]#cat deny_dos.shLINK=100while true;doss -nt | awk -F&quot;[[:space:]]+|:&quot; &#x27;/^ESTAB/&#123;print $(NF-2)&#125;&#x27;|sort |uniq -c|while read count ip;doif [ $count -gt $LINK ];then iptables -A INPUT -s $ip -j REJECTfidonedone[root@centos8 ~]#chmod +x /root/deny_dos.sh[root@centos8 ~]#crontab -e[root@centos8 ~]#crontab -l*/10 * * * * /root/deny_dos.sh NR：记录的编号（行号） 1234567891011121314[root@centos7 ~]#awk &#x27;&#123;print NR&#125;&#x27; /etc/passwd1234.....129[root@centos7 ~]#awk &#x27;END&#123;print NR&#125;&#x27; /etc/passwd129[root@centos7 ~]#awk &#x27;BEGIN&#123;print NR&#125;&#x27; /etc/passwd0[root@centos8 ~]#ifconfig eth0 | awk &#x27;NR==2&#123;print $2&#125;&#x27; #根据行号筛选想要的行10.0.0.8 取ifconfig输出结果中的IP地址1234[root@centos8 ~]#ifconfig eth0 | awk &#x27;/netmask/&#123;print $2&#125;&#x27;10.0.0.8[root@centos8 ~]#ifconfig eth0 | awk &#x27;NR==2&#123;print $2&#125;&#x27;10.0.0.8 FNR：各文件分别计数，记录的编号 1[root@centos7 ~]#awk &#x27;&#123;print FNR&#125;&#x27; /etc/passwd /etc/issue FILENAME：当前文件名 123456789101112[root@centos7 ~]#awk &#x27;&#123;print FNR,FILENAME&#125;&#x27; /etc/issue /etc/hosts1 /etc/issue2 /etc/issue3 /etc/issue1 /etc/hosts2 /etc/hosts[root@centos7 ~]#awk &#x27;&#123;print FILENAME&#125;&#x27; /etc/issue /etc/hosts/etc/issue/etc/issue/etc/issue/etc/hosts/etc/hosts ARGC：命令行参数的个数 1234567root@centos8 ~]#awk &#x27;&#123;print ARGC&#125;&#x27; /etc/issue /etc/redhat-release3333[root@centos8 ~]#awk &#x27;BEGIN&#123;print ARGC&#125;&#x27; /etc/issue /etc/redhat-release3 ARGV：数组，保存的是命令行所给定的各参数，每一个参数：ARGV[0]，…… 123456789[root@centos8 ~]#awk &#x27;BEGIN&#123;print ARGV[0]&#125;&#x27; /etc/issue /etc/redhat-releaseawk[root@centos8 ~]#awk &#x27;BEGIN&#123;print ARGV[1]&#125;&#x27; /etc/issue /etc/redhat-release/etc/issue[root@centos8 ~]#awk &#x27;BEGIN&#123;print ARGV[2]&#125;&#x27; /etc/issue /etc/redhat-release/etc/redhat-release[root@centos8 ~]#awk &#x27;BEGIN&#123;print ARGV[3]&#125;&#x27; /etc/issue /etc/redhat-release[root@centos8 ~]# 自定义变量自定义变量是区分字符大小写的,使用下面方式进行赋值 -v var&#x3D;value 在program中直接定义（要加BEGIN，不然会让你在屏幕输入内容） awk和shell赋值的区别 awk 赋值，a&#x3D;b&#x3D;1，这个表示先赋值 b&#x3D;1，之后将 b&#x3D;1返回值赋值给a shell中 -v k1=k2=v 这个是赋值一个字符串 范例 12345678910[root@centos7 ~]#awk -v test1=&quot;hello,gawk&quot; &#x27;BEGIN&#123;print test1&#125;&#x27;hello,gawk[root@centos7 ~]#awk -v test1=&quot;hello,gawk&quot; &#x27;BEGIN&#123;print test1;test1=&quot;hello,awk&quot;;print test1&#125;&#x27;hello,gawkhello,awk[root@centos8 ~]#awk -v test1=test2=&quot;hello,gawk&quot; &#x27;BEGIN&#123;print test1,test2&#125;&#x27; #test1是后面字符串，test2为空test2=hello,gawk[root@centos8 ~]#awk -v test1=test2=&quot;hello1,gawk&quot;&#x27;BEGIN&#123;test1=test2=&quot;hello2,gawk&quot;;print test1,test2&#125;&#x27; hello2,gawk hello2,gawk 操作符算术操作符：x+y, x-y, x*y, x/y, x^y, x%y -x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符：=, +=, -=, *=, /=, %=, ^=，++, -- 1234[root@centos8 ~]#awk &#x27;BEGIN&#123;i=0;print i++,i&#125;&#x27;0 1[root@centos8 ~]#awk &#x27;BEGIN&#123;i=0;print ++i,i&#125;&#x27;1 1 比较操作符：==, !=, &gt;, &gt;=, &lt;, &lt;= 1234[root@centos8 ~]#awk -F: &#x27;$3&gt;=1000&#x27; /etc/passwdnobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologinwang:x:1000:1000:wang:/home/wang:/bin/bashmage:x:1001:1001::/home/mage:/bin/bash 范例：取奇，偶数行 123456789101112131415161718[root@centos8 ~]#seq 10 | awk &#x27;NR%2==0&#x27;246810[root@centos8 ~]#seq 10 | awk &#x27;NR%2==1&#x27;13579[root@centos8 ~]#seq 10 | awk &#x27;NR%2!=0&#x27;13579 模式匹配符： ~ 左边是否和右边匹配，包含关系 !~ 是否不匹配 12345678[root@centos8 ~]#awk -F: &#x27;$0 ~ /root/&#123;print $1&#125;&#x27; /etc/passwd[root@centos8 ~]#awk -F: &#x27;$0 ~ &quot;^root&quot;&#123;print $1&#125;&#x27; /etc/passwd[root@centos8 ~]#awk &#x27;$0 !~ /root/&#x27; /etc/passwd[root@centos8 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &#x27;$0 ~ /^\\/dev\\/sd/&#123;print $5&#125;&#x27;5192 逻辑操作符： 与：&amp;&amp;，并且关系 或：||，或者关系 非：!，取反 1234awk -F: &#x27;$3&gt;=0 &amp;&amp; $3&lt;=1000 &#123;print $1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;$3==0 || $3&gt;=1000 &#123;print $1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;!($3==0) &#123;print $1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;!($3&gt;=500) &#123;print $1,$3&#125;&#x27; /etc/passwd 条件表达式（三目表达式） 1234567selector?if-true-expression:if-false-expression[root@centos8 ~]#awk -F: &#x27;&#123;$3&gt;=1000?usertype=&quot;Common User&quot;:usertype=&quot;SysUser&quot;;printf&quot;%-20s:%12s\\n&quot;,$1,usertype&#125;&#x27; /etc/passwd[root@centos8 ~]#df | awk -F&quot;[ %]+&quot; &#x27;/^\\/dev\\/sd/&#123;$(NF-1)&gt;10?disk=&quot;full&quot;:disk=&quot;OK&quot;;print $(NF-1),disk&#125;&#x27;3 OK1 OK13 full 范例 123456789101112[root@rocky8 ~]#cat scores.txtwang 100li 90zhang 50zhao 80han 70[root@rocky8 ~]#awk &#x27;$2&gt;=60?type=&quot;pass&quot;:type=&quot;nopass&quot;&#123;print $1,type&#125;&#x27; scores.txtwang passli passzhang nopasszhao passhan pass 模式PATTERNPATTERN：根据pattern条件，过滤匹配的行，再做处理 如果未指定：空模式，匹配每一行 1[root@centos8 ~]#awk -F: &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd &#x2F;regular expression&#x2F;：仅处理能够模式匹配到的行，需要用&#x2F; &#x2F;括起来 12345678910111213141516[root@centos8 ~]#df | awk &#x27;/^\\/dev\\/sd/&#x27;/dev/sda2 104806400 4935924 99870476 5% //dev/sda3 52403200 398876 52004324 1% /data/dev/sda1 999320 848572 81936 92% /boot[root@centos7 ~]#df | awk -F&quot;[ %]&quot; &#x27;/^\\/dev\\//&#123;print $(NF-2)&#125;&#x27;1315[root@centos7 ~]#ifconfig eth0 | awk &#x27;/netmask/&#123;print $2&#125;&#x27;10.0.0.183[root@centos7 ~]#awk &#x27;!/^#|^$/&#x27; /etc/fstab/dev/mapper/centos_10-root / xfs defaults 0 0UUID=263ab425-76cc-48bf-952f-b5958e7d325d /boot xfs defaults 0 0/dev/mapper/centos_10-swap swap swap defaults 0 0 relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@centos8 ~]#seq 10 | awk &#x27;i=0&#x27; #0为假，不输出任何东西[root@centos8 ~]#seq 10 | awk &#x27;i=1&#x27;12345678910[root@centos8 ~]#seq 10 | awk &#x27;i=!i&#x27; #首先i没赋值为假，取反为真，打印1，接着取反为假，2不打印，接着取反为真，打印3...13579[root@centos8 ~]#seq 10 | awk &#x27;!(i=!i)&#x27;246810[root@centos8 ~]#seq 10 | awk -v i=1 &#x27;i=!i&#x27;246810[root@centos8 ~]#seq 10 | awk -v i=0 &#x27;i=!i&#x27;13579[root@centos8 ~]#seq 10 | awk &#x27;&#123;i=!i;print i&#125;&#x27;1010101010 范例 1234567891011121314awk -F: &#x27;i=1;j=1&#123;print i,j&#125;&#x27; /etc/passwdAwk -F: &#x27;$3&gt;=1000&#123;print $1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;$3&lt;1000&#123;print $1,$3&#125;&#x27; /etc/passwdawk -F: &#x27;$NF==&quot;/bin/bash&quot;&#123;print $1,$NF&#125;&#x27; /etc/passwd[root@centos8 ~]#awk -F: &#x27;$NF==&quot;/bin/bash&quot;&#123;print $1,$NF&#125;&#x27; /etc/passwdroot /bin/bashwang /bin/bashmage /bin/bash[root@centos8 ~]#awk -F: &#x27;$NF ~ /bash$/&#123;print $1,$NF&#125;&#x27; /etc/passwdroot /bin/bashwang /bin/bashmage /bin/bash line ranges：行范围 不支持直接用行号，但可以使用变量NR间接指定行号 &#x2F;pat1&#x2F;,&#x2F;pat2&#x2F; 不支持直接给出数字格式 12345678910111213141516171819202122232425[root@centos8 ~]#seq 10 | awk &#x27;NR&gt;=3 &amp;&amp; NR&lt;=6&#x27;3456[root@centos8 ~]#awk &#x27;NR&gt;=3 &amp;&amp; NR&lt;=6&#123;print NR,$0&#125;&#x27; /etc/passwd3 daemon:x:2:2:daemon:/sbin:/sbin/nologin4 adm:x:3:4:adm:/var/adm:/sbin/nologin5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin6 sync:x:5:0:sync:/sbin:/bin/sync[root@centos8 ~]#sed -n &#x27;3,6p&#x27; /etc/passwddaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/sync[root@centos8 ~]#awk &#x27;/^bin/,/^adm/&#x27; /etc/passwdbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologin[root@centos8 ~]#sed -n &#x27;/^bin/,/^adm/p&#x27; /etc/passwdbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologin BEGIN&#x2F;END模式 BEGIN&#123;&#125;：仅在开始处理文件中的文本之前执行一次 END&#123;&#125;：仅在文本处理完成之后执行一次 范例：打印表格 123456789[root@centos8 ~]#awk -F: &#x27;BEGIN&#123;printf &quot;--------------------------------\\n%-20s|%10s|\\n--------------------------------\\n&quot;,&quot;username&quot;,&quot;uid&quot;&#125;&#123;printf&quot;%-20s|%10d|\\n--------------------------------\\n&quot;,$1,$3&#125;&#x27; /etc/passwd--------------------------------username | uid |--------------------------------root | 0 |bin | 1 |daemon | 2 |adm | 3 |lp | 4 | 条件判断 if-else12if(condition)&#123;statement;…&#125;[else statement]if(condition1)&#123;statement1&#125;else if(condition2)&#123;statement2&#125;else if(condition3)&#123;statement3&#125;...... else &#123;statementN&#125; 使用场景：对awk取得的整行或某个字段做条件判断 123456789101112[root@centos7 ~]#cat score.txtname scorehuang 90wu 80 zhao 70opan 50[root@centos7 ~]#awk &#x27;NR!=1&#123;score=$2;if(score&gt;=80)&#123;print $1,&quot;good&quot;&#125;else if(score&gt;=60)&#123;print $1,&quot;pass&quot;&#125;else &#123;print $1,&quot;no pass&quot;&#125;&#125;&#x27; score.txthuang goodwu goodzhao passopan no pass 条件判断 switchawk 中的switch分支语句功能较弱，只能进行等值比较或正则匹配 各分支结尾需使用break来终止 12switch(expression) &#123;case VALUE1 or /REGEXP/: statement1; case VALUE2 or/REGEXP2/: statement2; ...; default: statementn&#125; 循环 while语法：while (condition) &#123;statement;…&#125; 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 12root@ubuntu2004:~# awk -v i=1 -v sum=0 &#x27;BEGIN&#123;while(i&lt;=100)&#123;sum+=i;i++&#125;;print sum&#125;&#x27;5050 循环 do-while语法：do &#123;statement;…&#125;while(condition) 12[root@centos8 ~]#awk &#x27;BEGIN&#123; total=0;i=1;do&#123; total+=i;i++;&#125;while(i&lt;=100);print total&#125;&#x27;5050 循环 for语法：for(expr1;expr2;expr3) &#123;statement;…&#125; 常见用法：for(variable assignment;condition;iteration process) &#123;for-body&#125; 特殊用法：能够遍历数组中的元素，for(var in array) &#123;for-body&#125; 范例 123456root@ubuntu2004:~# awk &#x27;BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++)&#123;sum+=i&#125;;print sum&#125;&#x27;5050#shell实现root@ubuntu2004:~# for((i=1,sum=0;i&lt;=100;i++));do let sum+=i;done;echo $sum5050 面试题：文件abc.txt只有一行数字，计算其总和12345678[root@centos8 ~]#cat abc.txt1 2 3 4 5[root@centos8 ~]#cat abc.txt |awk &#x27;&#123;for(i=1;i&lt;=NF;i++)&#123;sum+=i&#125;;print sum&#125;&#x27;15[root@centos8 ~]#cat abc.txt|tr &#x27; &#x27; + |bc15[root@centos8 ~]#sum=0;for i in `cat abc.txt`;do let sum+=i;done;echo $sum15 性能比较 1234time (awk &#x27;BEGIN&#123; total=0;for(i=0;i&lt;=10000;i++)&#123;total+=i;&#125;;print total;&#125;&#x27;)time (total=0;for i in &#123;1..10000&#125;;do total=$(($total+i));done;echo $total)time (for ((i=0;i&lt;=10000;i++));do let total+=i;done;echo $total)time (seq –s ”+” 10000|bc) 取出字符串中的数字123456789101112[root@ubuntu2204 ~]# echo &#x27;dsFUs34tg*fs5a%8ar%$#@&#x27; |awk -F &quot;&quot; &#x27;&gt; &#123;&gt; for(i=1;i&lt;=NF;i++)&gt; &#123; &gt; if ($i ~ /[0-9]/) &gt; &#123;&gt; str=(str $i) #连字符，字符串拼接&gt; &#125; &gt; &#125;&gt; print str&gt; &#125;&#x27;3458 continue 和 breakcontinue 中断本次循环 break 中断整个循环 123456continue [n]break [n][root@centos8 ~]#awk &#x27;BEGIN&#123;for(i=1;i&lt;=100;i++)&#123;if(i==50)continue;sum+=i&#125;;print sum&#125;&#x27;5000[root@centos8 ~]#awk &#x27;BEGIN&#123;for(i=1;i&lt;=100;i++)&#123;if(i==50)break;sum+=i&#125;;print sum&#125;&#x27;1225 nextnext 可以提前结束对本行处理而直接进入下一行处理（awk自身循环） 1234567891011121314151617181920212223242526#奇数行不处理[root@centos8 ~]#awk -F: &#x27;&#123;if($3%2!=0) next; print $1,$3&#125;&#x27; /etc/passwd root 0daemon 2lp 4shutdown 6mail 8games 12ftp 14nobody 65534polkitd 998gluster 996rtkit 172rpc 32chrony 994saslauth 992clevis 984pegasus 66colord 982setroubleshoot 980gdm 42gnome-initial-setup 978sshd 74avahi 70tcpdump 72wang 1000 数组awk的数组为关联数组 123array_name[index-expression]weekdays[&quot;mon&quot;]=&quot;Monday&quot; index-expression 利用数组，实现 k&#x2F;v 功能 可使用任意字符串；字符串要使用双引号括起来 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串” 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 范例 12[root@centos8 ~]#awk &#x27;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;Tuesday&quot;;print weekdays[&quot;mon&quot;]&#125;&#x27;Monday 范例：去重 123456789101112131415[root@centos7 ~]#cat c.txtabcabcd[root@centos7 ~]#awk &#x27;!line[$0]++&#x27; c.txt abcd首先是line[‘a’]=“”，a空值，为假，取反后为真，++后a=1；同理b和c一样，接着又是a，line[&#x27;a&#x27;]=1，取反后为假，b和c同理 范例：判断数组索引是否存在 123456[root@centos8 ~]# awk &#x27;BEGIN&#123;array[&quot;i&quot;]=&quot;x&quot;; array[&quot;j&quot;]=&quot;y&quot; ; print &quot;i&quot; in array, &quot;y&quot; in array &#125;&#x27;1 0[root@centos8 ~]#awk &#x27;BEGIN&#123;array[&quot;i&quot;]=&quot;x&quot;; array[&quot;j&quot;]=&quot;y&quot; ;if (&quot;i&quot; in array )&#123;print &quot;存在&quot;&#125;else&#123;print &quot;不存在&quot;&#125;&#125;&#x27;存在[root@centos8 ~]#awk &#x27;BEGIN&#123;array[&quot;i&quot;]=&quot;x&quot;; array[&quot;j&quot;]=&quot;y&quot; ;if (&quot;abc&quot; in array )&#123;print &quot;存在&quot;&#125;else&#123;print &quot;不存在&quot;&#125;&#125;&#x27;不存在 若要遍历数组中的每个元素，要使用 for 循环 1for(var in array) &#123;for-body&#125; #var 会遍历array的每个索引 范例：遍历数组 12345678910111213141516171819202122232425[root@ubuntu2204 ~]# awk &#x27;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;Tuesday&quot;;for(i in weekdays)&#123;print i,weekdays[i]&#125;&#125;&#x27;tue Tuesdaymon Monday[root@ubuntu2204 ~]# awk &#x27;BEGIN&#123;students[1]=&quot;user1&quot;;students[2]=&quot;user2&quot;;students[3]=&quot;user3&quot;;for(x in students)&#123;print x&quot;:&quot;students[x]&#125;&#125;&#x27;1:user12:user23:user3[root@centos8 ~]#awk &#x27;BEGIN &#123;a[&quot;x&quot;] = &quot;welcome&quot;a[&quot;y&quot;] = &quot;to&quot;a[&quot;z&quot;] = &quot;Magedu&quot;for (i in a) &#123; print i,a[i]&#125;&#125;&#x27;x welcomey toz Magedu[root@ubuntu2204 ~]#awk -F: &#x27;&#123;user[$1]=$3&#125;END&#123;for(i in user)&#123;print &quot;username:&quot;i,&quot;uid: &quot;user[i]&#125;&#125;&#x27; /etc/passwdusername: adm uid: 3username: rpc uid: 32username: dnsmasq uid: 985 范例：显示主机的连接状态出现的次数 1234567[root@centos7 ~]#ss -ant | awk &#x27;NR&gt;=2&#123;print $1&#125;&#x27; | sort | uniq -c 1 ESTAB 4 LISTEN[root@centos7 ~]#ss -ant | awk &#x27;NR&gt;=2&#123;state[$1]++&#125;END&#123;for(i in state)&#123;print state[i],i&#125;&#125;&#x27;4 LISTEN1 ESTAB 范例 1234567891011121314151617181920[root@ubuntu2204 ~]# awk &#x27;&#123;ip[$1]++&#125;END&#123;for(i in ip)&#123;print i,ip[i]&#125;&#125;&#x27; /var/log/httpd/access_log172.20.0.200 1482172.20.21.121 2172.20.30.91 29172.16.102.29 864172.20.0.76 1565172.20.9.9 15172.20.1.125 463172.20.61.11 2172.20.73.73 198[root@ubuntu2204 ~]# awk &#x27;&#123;ip[$1]++&#125;END&#123;for(i in ip)&#123;print ip[i],i&#125;&#125;&#x27; access_log|sort -nr| head -34870 172.20.116.2283429 172.20.116.2082834 172.20.0.222[root@ubuntu2204 ~]# wk &#x27;&#123;ip[$1]++&#125;END&#123;for(i in ip)&#123;print i,ip[i]&#125;&#125;&#x27; access_log|sort -k2 -nr|head -3172.20.116.228 4870172.20.116.208 3429172.20.0.222 2834 范例：封掉查看访问日志中连接次数超过1000次的IP 1[root@centos8 ~]#awk &#x27;&#123;ip[$1]++&#125;END&#123;for(i in ip)&#123;if(ip[i]&gt;=1000)&#123;system(&quot;iptables -A INPUT -s &quot;i&quot; -j REJECT&quot;)&#125;&#125;&#125;&#x27; nginx.access.log-20200428 范例：多维数组 1234567891011121314151617[root@centos8 ~]#awk &#x27;BEGIN&#123;&gt; array[1][1]=11&gt; array[1][2]=12&gt; array[1][3]=13&gt; array[2][1]=21&gt; array[2][2]=22&gt; array[2][3]=23&gt; for (i in array)&gt; for (j in array[i])&gt; print array[i][j]&gt; &#125;&#x27;111213212223 awk函数官方文档：https://www.gnu.org/software/gawk/manual/gawk.html 常见内置函数数值处理： 123rand()：返回0和1之间一个随机数srand()：配合rand() 函数,生成随机数的种子int()：返回整数 范例 1234567891011121314151617[root@centos8 ~]#awk &#x27;BEGIN&#123;srand();print rand()&#125;&#x27;0.790437[root@centos8 ~]#awk &#x27;BEGIN&#123;srand();print rand()&#125;&#x27;0.283736[root@centos8 ~]#awk &#x27;BEGIN&#123;srand(); for (i=1;i&lt;=10;i++)print int(rand()*100)&#125;&#x27;35173595191570544693 字符串处理： 12345str1=(str2,str3)：连字符，字符串拼接length([s])：返回指定字符串的长度sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s（懒惰模式）gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容（贪婪模式）split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中，第一个索引值为1,第二个索引值为2,… 范例: 统计用户名的长度 12root@ubuntu2004:~# cut -d: -f1 /etc/passwd | awk &#x27;&#123;print length()&#125;&#x27;root@ubuntu2004:~# awk -F: &#x27;&#123;print length($1)&#125;&#x27; /etc/passwd 范例 12345#内置函数length()返回字符数，而非字节数[root@centos8 ~]#awk &#x27;BEGIN&#123;print length(&quot;hello&quot;)&#125;&#x27;5[root@centos8 ~]#awk &#x27;BEGIN&#123;print length(&quot;你好&quot;)&#125;&#x27;2 范例 123456[root@centos8 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &#x27;sub(/:/,&quot;-&quot;,$1)&#x27;2008-08:08 08:08:08[root@centos8 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &#x27;gsub(/:/,&quot;-&quot;,$1)&#x27;2008-08-08 08:08:08[root@centos8 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &#x27;gsub(/:/,&quot;-&quot;,$0)&#x27;2008-08-08 08-08-08 范例 12345678[root@centos7 ~]#head -n1 /etc/passwd | awk &#x27;&#123;split($0,array,&quot;:&quot;)&#125;END&#123;print array[1]&#125;&#x27;root[root@centos7 ~]#head -n1 /etc/passwd | awk &#x27;&#123;split($0,array,&quot;:&quot;)&#125;END&#123;print array[4]&#125;&#x27;0[root@centos8 ~]#netstat -tn | awk &#x27;/^tcp/&#123;split($5,ip,&quot;:&quot;);count[ip[1]]++&#125;END&#123;for(i in count)&#123;print i,count[i]&#125;&#125;&#x27;10.0.0.1 110.0.0.6 110.0.0.7 673 调用shell命令 123system(&#x27;cmd&#x27;)空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来 范例 12awk &#x27;BEGIN&#123;system(&quot;hostname&quot;)&#125;&#x27;awk &#x27;BEGIN&#123;score=100; system(&quot;echo your score is &quot; score) &#125;&#x27; 时间函数 12systime() 当前时间到1970年1月1日的秒数strftime() 指定时间格式 范例 1234[root@centos8 ~]#awk &#x27;BEGIN&#123;print systime()&#125;&#x27;1609917829[root@centos8 ~]#awk &#x27;BEGIN&#123;print strftime(&quot;%Y-%m-%dT%H:%M&quot;,systime()-3600)&#125;&#x27;2021-01-06T14:24 自定义函数自定义函数格式： 1234function name ( parameter, parameter, ... ) &#123; statements return expression&#125; 范例 1234567[root@ubuntu2204 ~]# awk &#x27;function test()&#123;print &quot;hello test func&quot;&#125;BEGIN&#123;test()&#125;&#x27;hello test func[root@ubuntu2204 ~]# awk -F: &#x27;function test(uname,uid)&#123;print uname&quot; id is &quot;uid&#125;&#123;test($1,$3)&#125;&#x27; /etc/passwdroot id is 0bin id is 1daemon id is 2 范例 123456789[root@centos8 ~]#cat func.awkfunction max(x,y) &#123;x&gt;y?var=x:var=yreturn var&#125;BEGIN&#123;print max(a,b)&#125;[root@centos8 ~]#awk -v a=30 -v b=20 -f func.awk30 awk 脚本将awk程序写成脚本，直接调用或执行 12345678910[root@centos8 ~]#cat test.awk#!/bin/awk -f#this is a awk script&#123;if($3&gt;=1000)print $1,$3&#125;[root@centos8 ~]#chmod +x test.awk[root@centos8 ~]#./test.awk -F: /etc/passwdnobody 65534wang 1000mage 1001 向awk脚本传递参数 格式：awkfile var=value var2=value2... Inputfile 注意： 上面格式变量在BEGIN过程中不可用。直到首行输入完成以后，变量才可用 可以通过 -v 参数，让awk在执行BEGIN之前得到变量的值 命令行中每一个指定的变量都需要一个 -v 参数 范例 123456789101112131415161718192021[root@ubuntu2204 ~]# awk -v x=100 &#x27;BEGIN&#123;print x&#125;&#123;print x+100&#125;&#x27; /etc/hosts100200200[root@ubuntu2204 ~]# awk &#x27;BEGIN&#123;print x&#125;&#123;print x+100&#125;&#x27; x=200 /etc/hosts300300[root@centos8 ~]#cat test2.awk#!/bin/awk -f&#123;if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3&#125;[root@centos8 ~]#chmod +x test2.awk[root@centos8 ~]#./test2.awk -F: min=100 max=200 /etc/passwdsystemd-resolve 193rtkit 172pulse 171qemu 107usbmuxd 113abrt 173 范例: 检查出最近一小时内访问nginx服务次数超过3次的客户端IP 12345678910111213141516171819202122232425262728[root@VM_0_10_centos ~]# cat check_nginx_log.awk#!/usr/bin/awk -fBEGIN &#123; beg=strftime(&quot;%Y-%m-%dT%H:%M&quot;,systime()-3600) ; #定义一个小时前的时间，并格式化日期格式 end=strftime( &quot;%Y-%m-%dT%H:%M&quot;,systime()-60) ; #定义结束时间 #print beg; #print end;&#125;$4 &gt; beg &amp;&amp; $4 &lt; end &#123;#定义取这个时间段内的日志 count[$12]+=1;#利用ip当做数组下标，次数当做数组内容&#125;END &#123; for(i in count)&#123;#结束从数组取数据代表数组的下标，也就是ip if(count[i]&gt;3) &#123; #如果次数大于3次，做操作 print count [i]&quot; &quot;i; #system(&quot;iptables -I INPUT -S”i”j DROP&quot; ) &#125; &#125;&#125;#awk -F&#x27;&quot;&#x27; -f check_nginx_log.awk /apps/nginx/logs/access.log[root@VM_0_10_centos ~]# awk -F&#x27;&quot;&#x27; -f check_nginx_log.awk /apps/nginx/logs/access_json.log4 127.0.0.156 172.105.120.925 58.87.87.9911 111.199.184.16","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"PAM认证机制","slug":"Linux/encryption-security/PAM","date":"2025-08-21T03:03:21.000Z","updated":"2025-08-28T12:33:05.210Z","comments":true,"path":"Linux/encryption-security/PAM/","permalink":"https://aquapluto.github.io/Linux/encryption-security/PAM/","excerpt":"","text":"1 PAM介绍PAM：Pluggable Authentication Modules，插件式的验证模块，Sun公司于1995 年开发的一种与认证相关的通用框架机制。PAM 只关注如何为服务验证用户的 API，通过提供一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证 方式而无需更改服务程序一种认证框架，自身不做认证 官网：http://www.linux-pam.org/ 2 PAM架构 PAM提供了对所有服务进行认证的中央机制，适用于本地登录，远程登录，如：telnet,rlogin,fsh,ftp,点对点协议PPP，su等应用程序中，系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略；应用程序开发者通过在服务程序中使用PAM API(pam_xxxx( ))来实现对认证方法的调用；而PAM服务模块的开发者则利用PAM SPI来编写模块（主要调用函数pam_sm_xxxx( )供PAM接口库调用，将不同的认证机制加入到系统中；PAM接口库（libpam）则读取配置文件，将应用程序和相应的PAM服务模块联系起来 3 PAM相关文件包名: pam 模块文件目录：&#x2F;lib64&#x2F;security&#x2F;*.so（放各种模块） 特定模块相关的设置文件：&#x2F;etc&#x2F;security&#x2F;（复杂模块的专有配置文件） 应用程序调用PAM模块的配置文件 主配置文件：&#x2F;etc&#x2F;pam.conf，默认不存在，一般不使用主配置 为每种应用模块提供一个专用的配置文件：&#x2F;etc&#x2F;pam.d&#x2F;APP_NAME（哪些服务调用&#x2F;lib64&#x2F;security&#x2F;里哪些模块的配置文件） 注意：如&#x2F;etc&#x2F;pam.d存在，&#x2F;etc&#x2F;pam.conf将失效 范例：查看程序是否支持PAM 123456789[root@centos8 ~]#ldd `which sshd` |grep libpamlibpam.so.0 =&gt; /lib64/libpam.so.0 (0x00007fea8e70d000)[root@centos8 ~]#ldd `which passwd` |grep pamlibpam.so.0 =&gt; /lib64/libpam.so.0 (0x00007f045b805000)libpam_misc.so.0 =&gt; /lib64/libpam_misc.so.0 (0x00007f045b601000)#不支持PAM[root@centos6 ~]#ldd /usr/sbin/httpd |grep pam[root@centos6 ~]# 4 PAM工作原理PAM认证一般遵循这样的顺序：Service(服务)→PAM(配置文件)→pam_*.so PAM认证首先要确定那一项服务，然后加载相应的PAM的配置文件(位于&#x2F;etc&#x2F;pam.d下)，最后调用认证文件(位于&#x2F;lib64&#x2F;security下)进行安全认证 PAM认证过程示例： 使用者执行&#x2F;usr&#x2F;bin&#x2F;passwd 程序，并输入密码 passwd开始调用PAM模块，PAM模块会搜寻passwd程序的PAM相关设置文件，这个设置文件一般是在&#x2F;etc&#x2F;pam.d&#x2F;里边的与程序同名的文件，即PAM会搜寻&#x2F;etc&#x2F;pam.d&#x2F;passwd此设置文件 经由&#x2F;etc&#x2F;pam.d&#x2F;passwd设定文件的数据，取用PAM所提供的相关模块来进行验证 将验证结果回传给passwd这个程序，而passwd这个程序会根据PAM回传的结果决定下一个动作（重新输入密码或者通过验证） 5 PAM配置文件格式说明通用配置文件&#x2F;etc&#x2F;pam.conf格式,此格式不使用 1application type control module-path arguments 专用配置文件&#x2F;etc&#x2F;pam.d&#x2F; 格式 1234567type control module-path argumentsapplication #指服务名，如：telnet、login、ftp等，服务名字“OTHER”代表所有没有在该文件中明确配置的其它服务type #指模块类型，即功能control #PAM库该如何处理与该服务相关的PAM模块的成功或失败情况，一个关健词实现module-path #用来指明本模块对应的程序文件的路径名Arguments #用来传递给该模块的参数 模块类型（module-type） Auth：账号的认证和授权 Account：帐户的有效性，与账号管理相关的非认证类的功能，如：用来限制&#x2F;允许用户对某个服务的访问时间，限制用户的位置(例如：root用户只能从控制台登录) Password：用户修改密码时密码复杂度检查机制等功能 Session：用户会话期间的控制，如：最多打开的文件数，最多的进程数等 -type：表示因为缺失而不能加载的模块将不记录到系统日志,对于那些不总是安装在系统上的模块有用 Control required ：一票否决，表示本模块必须返回成功才能通过认证，但是如果该模块返回失败，失败结果也不会立即通知用户，而是要等到同一type中的所有模块全部执行完毕，再将失败结果返回给应用程序，即为必要条件 requisite ：一票否决，该模块必须返回成功才能通过认证，但是一旦该模块返回失败，将不再执行同一type内的任何模块，而是直接将控制权返回给应用程序。是一个必要条件 sufficient ：一票通过，表明本模块返回成功则通过身份认证的要求，不必再执行同一type内的其它模块，但如果本模块返回失败可忽略，即为充分条件，优先于前面的required和requisite optional ：表明本模块是可选的，它的成功与否不会对身份认证起关键作用，其返回值一般被忽略 include： 调用其他的配置文件中定义的配置信息 在 control 列中，对于更复杂的语法，可以写成如下格式 1234[value1=action1 value2=action2 ...]valueN对应于在为其定义行的模块中调用的函数的返回代码,取值如下success, open_err, symbol_err, service_err, system_err, buf_err, perm_denied,auth_err, cred_insufficient, authinfo_unavail, user_unknown,maxtries,new_authtok_reqd, acct_expired, session_err, cred_unavail, cred_expired,cred_err, no_module_data, conv_err, authtok_err,authtok_recover_err,authtok_lock_busy, authtok_disable_aging, try_again, ignore, abort,authtok_expired, module_unknown, bad_item, conv_again,incomplete, and default module-path: 模块文件所在绝对路径：&#x2F;path&#x2F;XYZ.so 模块文件所在相对路径：&#x2F;lib64&#x2F;security目录下的模块可使用相对路径，如：pam_shells.so、pam_limits.so，表示 so 文件在 &#x2F;lib64&#x2F;security&#x2F; 目录下 有些模块有自已的专有配置文件，在&#x2F;etc&#x2F;security&#x2F;*.conf目 录下，这种写法表示直接使用另一个配置，例如postlogin Arguments debug ：该模块应当用syslog( )将调试信息写入到系统日志文件中 no_warn ：表明该模块不应把警告信息发送给应用程序 use_first_pass ：该模块不能提示用户输入密码，只能从前一个模块得到输入密码 try_first_pass ：该模块首先用前一个模块从用户得到密码，如果该密码验证不通过，再提示用户输入新密码 use_mapped_pass 该模块不能提示用户输入密码，而是使用映射过的密码 expose_account 允许该模块显示用户的帐号名等信息，一般只能在安全的环境下使用，因为泄漏用户名会对安全造成一定程度的威胁 注意：修改PAM配置文件将马上生效 建议：编辑pam规则时，保持至少打开一个root会话，以防止root身份验证错误 6 PAM模块帮助在线文档：http://www.linux-pam.org/Linux-PAM-html/ 离线文档：http://www.linux-pam.org/documentation/ 12345678910man pam#查询模块在哪一个man 章节man -k 模块名[root@ubuntu ~]# man -k pam_nologinpam_nologin (8) - Prevent non-root users from login#在指定章节查询模块man N 模块名[root@ubuntu ~]# man 8 pam_nologin 7 常用PAM模块7.1 pam_nologin.so模块功能：如果&#x2F;etc&#x2F;nologin文件存在，将导致非root用户不能登陆,当该用户登陆时，会显示&#x2F;etc&#x2F;nologin文件内容，并拒绝登陆，前提是相应的服务使用了该模块，此规则才会生效 查询有哪些服务使用了该模块 1234[root@ubuntu ~]# grep pam_nologin /etc/pam.d/*/etc/pam.d/login:auth requisite pam_nologin.so/etc/pam.d/ppp:auth required pam_nologin.so/etc/pam.d/sshd:account required pam_nologin.so 默认此模块可以对ssh等登录有效，由于 su 服务没有使用该模块，所以使用 su 切换账号，不受影响 1234[root@centos8 pam.d]#grep pam_nologin *login:account required pam_nologin.soremote:account required pam_nologin.sosshd:account required pam_nologin.so 范例 123456789101112131415161718#创建/etc/nologin文件，普通用户立即无法远程登录[root@ubuntu ~]# touch /etc/nologin[root@ubuntu ~]# ll /etc/nologin-rw-r--r-- 1 root root 0 May 28 22:01 /etc/nologin#普通用户远程登录的拒绝日志，可以在 /var/log/secure 文件中查询，明确说明是pam account 配置拒绝登录[root@ubuntu ~]# tail -2 /var/log/secureMay 28 22:03:15 ubuntu sshd[25125]: Failed password for mage from 10.0.0.1 port52961 ssh2May 28 22:03:15 ubuntu sshd[25125]: fatal: Access denied for user mage by PAM account configuration [preauth]#写入内容到文件[root@ubuntu ~]# echo &quot;pam deny user login&quot; &gt; /etc/nologin#普通用户远程登录，被拒绝时能看到 &quot;pam deny user login&quot; 的提示C:\\Users\\44301&gt;ssh mage@10.0.0.206mage@10.0.0.206&#x27;s password:pam deny user loginConnection closed by 10.0.0.206 port 22 7.2 pam_limits.so模块功能：在用户级别实现对其可使用的资源的限制，例如：可打开的文件数量，可运行的进程数量，可用内存空间 查看有哪些服务使用了该模块 123456789[root@ubuntu ~]# grep pam_limits /etc/pam.d/*/etc/pam.d/atd:session required pam_limits.so/etc/pam.d/cron:session required pam_limits.so/etc/pam.d/login:session required pam_limits.so/etc/pam.d/runuser:session required pam_limits.so/etc/pam.d/sshd:session required pam_limits.so/etc/pam.d/su:session required pam_limits.so/etc/pam.d/sudo:session required pam_limits.so/etc/pam.d/sudo-i:session required pam_limits.so 修改限制的实现方式： （1）ulimit命令 用于对shell进程及其子进程进行资源限制，使用ulimit进行修改，立即生效，limit只影响shell进程及其子进程，用户登出后失效 可以在profile中加入ulimit的设置，变相的做到永久生效 ulimit的设定值是 per-process 的，也就是说，每个进程有自己的limits值 使用ulimit进行修改，立即生效 12345678910111213141516171819-H 设置硬件资源限制.-S 设置软件资源限制.-a 显示当前所有的资源限制.-c size:设置core文件的最大值.单位:blocks-d size:设置数据段的最大值.单位:kbytes-f size:设置创建文件的最大值.单位:blocks-l size:设置在内存中锁定进程的最大值.单位:kbytes-m size:设置可以使用的常驻内存的最大值.单位:kbytes-n size:设置内核可以同时打开的文件描述符的最大值.单位:n，最大是1048576-p size:设置管道缓冲区的最大值.单位:kbytes-s size:设置堆栈的最大值.单位:kbytes-t size:设置CPU使用时间的最大上限.单位:seconds-u size:最大用户进程数-v size:设置虚拟内存的最大值.单位:kbytesunlimited 是一个特殊值，用于表示不限制#说明查询时，若不加H或S参数，默认显示的是软限制修改时，若不加H或S参数，两个参数一起改变 案例：查看各种默认资源限制 1[root@centos8 ~]#ulimit -a 案例： 查看指定进程的资源限制 12#cat /proc/PID/limits[root@wang-liyun-pc ~]# cat /proc/`pidof nginx | xargs -n1 | sort -n|head -1`/limits 案例：ulimit 命令修改用户可同时打开的最大文件个数 123456789[root@centos8 ~]#ulimit -n1024[root@centos8 ~]#ulimit -n 1048577-bash: ulimit: open files: cannot modify limit: Operation not permitted[root@centos8 ~]#ulimit -n 1048576[root@centos8 ~]#ulimit -a#测试[root@ubuntu ~]# ab -c 1100 -n 10000 http://www.magedu.com/ (2) 使用 pam_limits 模块来配置相关参数 配置文件：pam_limits的设定值是基于 per-process 的 12/etc/security/limits.conf #需要重启机器才能生效/etc/security/limits.d/*.conf #无需重启系统，退出当前终端重新进入即可生效 配置文件格式： 123#每行一个定义&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;应用对象 限制类型 限制的资源 指定具体值 格式说明： 应用于哪些对象 1234Username #单个用户@group #组内所有用户* #所有用户% #仅用于限制 maxlogins limit , 可以使用 %group 语法. 只用 % 相当于 * ，表示对所有用户的maxsyslogins limit限制. %group 表示限制此组中的所有用户总的最大登录数 限制的类型 123Soft #软限制,普通用户自己可以修改Hard #硬限制,由root用户设定，且通过kernel强制生效- #二者同时限定 软限制（soft limit）： 这是用户可以自行调整的最大限制值（只要不超过硬限制）。当软限制被达到时，进程或用户可能会收到警告消息，但允许继续使用资源，除非资源的使用量达到了硬限制。 硬限制（hard limit）： 这是由管理员设定的最大限制值，普通用户不能更改硬限制，超过硬限制后，系统将采取强制措施，通常是拒绝进一步的资源分配或者终止进程，防止用户过度消耗系统资源。 限制的资源 123456789101112131415161718nofile #所能够同时打开的最大文件数量,默认为1024nproc #所能够同时运行的进程的最大数量,默认为1024core #控制进程生成核心转储文件的大小限制。data #控制进程数据段（data segment）的大小限制。fsize #控制进程可以创建的文件的最大大小限制。memlock #控制进程可以锁定在内存中的物理内存量的限制。rss #控制进程的常驻集大小（resident set size）的限制。stack #控制进程堆栈大小的限制。cpu #控制进程可以使用的 CPU 时间量的限制。as #控制进程的地址空间大小的限制。maxlogins #控制用户可以同时拥有的最大登录会话数量的限制。maxsyslogins #控制系统可以同时拥有的最大登录会话数量的限制。priority #控制进程的优先级限制。locks #控制进程可以锁定的文件数量的限制。sigpending #控制进程可以排队等待处理的挂起信号的数量限制。msgqueue #控制进程可以拥有的 POSIX 消息队列的最大数量限制。nice #控制进程可以调整的优先级范围的限制。rtprio #控制进程可以设置的实时优先级的范围限制。 案例：限制用户最多打开的文件数和运行进程数，并持久保存 1234567891011121314151617181920cat /etc/pam.d/system-authsession required pam_limits.sovim /etc/security/limits.conf #用户apache可打开10240个文件apache - nofile 10240#用户student不能运行超过20个进程student hard nproc 10#用student登录多次运行bash，观察结果[root@centos8 ~]#vim /etc/security/limits.confwang - nofile 66666wang - nproc 5mage - nofile 88888[root@centos8 ~]#su - wangLast login: Mon May 25 14:40:38 CST 2020 on pts/0[wang@centos8 ~]$ulimit -n66666 案例：限制mage用户最大的同时登录次数 1234567891011121314[root@centos8 ~]#tail -n1 /etc/security/limits.confmage - maxlogins 2[root@centos8 ~]#whomage tty1 2021-04-28 09:27root pts/0 2021-04-28 08:50 (10.0.0.1)root pts/1 2021-04-28 09:09 (10.0.0.1)root pts/2 2021-04-28 09:19 (10.0.0.1)mage tty3 2021-04-28 09:27[root@centos8 ~]#tail /var/log/secure -fApr 28 09:28:06 centos8 login[23278]: pam_limits(login:session): Too many logins (max 2) for mageApr 28 09:28:06 centos8 login[23278]: pam_unix(login:session): session opened for user mage by LOGIN(uid=0)Apr 28 09:28:06 centos8 login[23278]: Permission denied 生产环境下常用的调优选项 123456vim /etc/security/limits.conf * - core unlimited* - nproc 1000000* - nofile 1000000* - memlock 32000* - msgqueue 8192000 注意：systemd 的service 资源设置需要单独配置 在Centos7以上版本中，使用Systemd替代了之前的SysV。&#x2F;etc&#x2F;security&#x2F;limits.conf文件的配置作用域缩小了，其作用范围是针对普通用户和用户组，而不是针对系统服务或进程。 /etc/security/limits.conf的配置，只适用于通过PAM认证登录用户的资源限制，它对systemd的service的资源限制不生效。因此登录用户的限制，通过/etc/security/limits.conf与/etc/security/limits.d下的文件设置即可 对于systemd service的资源设置，则需修改全局配置，全局配置文件放在/etc/systemd/system.conf和/etc/systemd/user.conf，同时也会加载两个对应目录中的所有.conf文件/etc/systemd/system.conf.d/*.conf和/etc/systemd/user.conf.d/*.conf。 system.conf是系统实例使用的，user.conf是用户实例使用的。 123456789vim /etc/systemd/system.confDefaultLimitNOFILE=100000DefaultLimitNPROC=65535#或者针对指定的service添加下面行[root@ubuntu ~]## vim /usr/lib/systemd/system/nginx.service[Service]LimitNOFILE=100000 #设置服务进程可以打开的文件描述符数量限制LimitNPROC=65535 #设置服务进程可以创建的子进程数量限制","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"加密和安全","slug":"加密和安全","permalink":"https://aquapluto.github.io/tags/%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8/"}]},{"title":"sudo实现授权","slug":"Linux/encryption-security/sudo","date":"2025-08-21T03:03:05.000Z","updated":"2025-08-28T12:33:05.224Z","comments":true,"path":"Linux/encryption-security/sudo/","permalink":"https://aquapluto.github.io/Linux/encryption-security/sudo/","excerpt":"","text":"1 sudo 介绍允许系统管理员让普通用户执行一些或者全部的root命令的一个工具，如halt，reboot，su等等。这样不仅减少了root用户的登录 和管理时间，同样也提高了安全性 一般用户管理系统的方式是利用su切换为超级用户。但是使用su的缺点之一在于必须要先告知超级用户的密码。sudo使一般用户不需要知道超级用户的密码即可获得权限。首先超级用户将普通用户的名字、可以执行的特定命令、按照哪种用户或用户组的身份执行等信息，登记在特殊的文件中（通常是&#x2F;etc&#x2F;sudoers），即完成对该用户的授权（此时该用户称为“sudoer”）；在一般用户需要取得特殊权限时，其可在命令前加上“sudo”，此时sudo将会询问该用户自己的密码（以确认终端机前的是该用户本人），回答后系统即会将该命令的进程以超级用户的权限运行。之后的一段时间内（默认为5分钟，可在&#x2F;etc&#x2F;sudoers自定义），使用sudo不需要再次输入密码 由于不需要超级用户的密码，部分Unix系统甚至利用sudo使一般用户取代超级用户作为管理帐号 sudo特性 sudo能够授权指定用户在指定主机上运行某些命令。如果未授权用户尝试使用 sudo，会提示联系管理员 sudo提供了丰富的日志，详细地记录了每个用户干了什么。它能够将日志传到中心主机或者日志服务器 sudo使用时间戳文件来执行类似的“检票”系统。当用户调用sudo并且输入它的密码时，用户获得了一张存活期为5分钟的票 sudo的配置文件是sudoers文件，它允许系统管理员集中的管理用户的使用权限和使用的主机。它所存放的位置默认是在&#x2F;etc&#x2F;sudoers，属性必须为0440 2 sudo 组成包：sudo 主配置文件： 1/etc/sudo.conf 授权规则配置文件： 12/etc/sudoers #重点/etc/sudoers.d 工具命令 12345678#安全编辑授权规则文件和语法检查工具/usr/sbin/visudo#授权编辑规则文件的工具/usr/bin/sudoedit#执行授权命令/usr/bin/sudo 范例：由于&#x2F;etc&#x2F;sudoers不建议用vim直接改，所以用下面方式来修改文件 123456#检查语法visudo -c#检查指定配置文件语法visudo -f /etc/sudoers.d/test#visudo缺点是没有带颜色 范例：修改visudo的默认编辑器 12root@ubuntu1804:~# export EDITOR=vimroot@ubuntu1804:~# visudo 授权编辑规则文件的工具： 1/usr/bin/sudoedit 时间戳文件： 1/var/db/sudo 日志文件： 1/var/log/secure 3 sudo 命令1234567891011121314sudo命令ls -l /usr/bin/sudosudo -i -u wang 切换身份功能和 su 相似,但不一样,sudo必须提前授权,而且要输入自已的密码sudo [-u user] COMMAND-V 显示版本信息等配置信息-u user 指定代表的用户，默认为root-l,ll 列出用户在主机上可用的和被禁止的命令-v 再延长密码有效期限5分钟,更新时间戳-k 清除时间戳（1970-01-01），下次需要重新输密码-K 与-k类似，还要删除时间戳文件-b 在后台执行指令-p 改变询问密码的提示符号示例：-p &quot;password on %h for user %p: &quot; 4 sudo 授权规则配置配置文件格式说明：&#x2F;etc&#x2F;sudoers,，&#x2F;etc&#x2F;sudoers.d&#x2F; 配置文件中支持使用通配符 glob 123456? 任意单一字符* 匹配任意长度字符[wxc] 匹配其中一个字符[!wxc] 除了这三个字符的其它字符\\x 转义[[alpha]] 字母 范例： 1/bin/ls [[alpha]]* 配置文件规则有两类 1、别名定义：不是必须的 2、授权规则：必须的 sudoers 授权规则格式： 1234567用户 登入主机=(代表用户) 命令user host=(runas) command #授权user用户可以在host主机上以runas的身份执行commanduser: 运行命令者的身份host: 登入哪些主机(runas)：以哪个用户的身份command: 运行哪些命令，要带路径 范例 1root ALL=(ALL) ALL sudoers的别名 123456789101112131415User和runas: username #uid %group_name %#gid user_alias|runas_aliashost: ip或hostname #ip地址,主机名 network(/netmask) #网段/子网掩码 host_alias #别名command: command name directory/* #某个目录下所有命令 sudoedit #授权其可以修改sudo文件 Cmnd_Alias #命令别名 sudo别名有四种类型： User_Alias Runas_Alias Host_Alias Cmnd_Alias 别名格式： 12#由大写字母开始，后面接大写字母，数字，下划线[A-Z]([A-Z][0-9]_)* 别名定义： 1Alias_Type NAME1 = item1,item2,item3 : NAME2 = item4, item5 配置范例 1234#指定IP或网段的写法，要求在对应主机上也有该配置jose 10.0.0.158=(root) /bin/ls /root/jose 10.0.0.0/24=(root) /bin/touch /root/from-josejose 10.0.0.157=(root) /sbin/shutdown -h now 范例：授权wu身份去运行mount和umount命令 123456789101112[root@centos7 ~]#su wu[wu@centos7 root]$mount /dev/cdrom /mnt/mount: only root can do that[root@centos7 ~]#visudowu ALL=(root) /usr/bin/mount /dev/cdrom /mnt/,/usr/bin/umount /mnt/[wu@centos7 root]$sudo mount /dev/cdrom /mnt/[sudo] password for wu: mount: /dev/sr0 is write-protected, mounting read-only[wu@centos7 root]$sudo umount /mnt/ 5 实战案例案例：授权写法 1234567Student ALL=(ALL) ALL%wheel ALL=(ALL) ALLstudent ALL=(root) /sbin/pidof,/sbin/ifconfig%wheel ALL=(ALL) NOPASSWD: ALL #NOPASSWD可以让授权账号不需要输密码执行操作wang 192.168.1.6,192.168.1.8=(root) /usr/sbin/,!/usr/sbin/useradd 案例：别名授权 12345678#授权netuser1和netuser2可以执行ip和ifconfig命令User_Alias NETADMIN= netuser1,netuser2Cmnd_Alias NETCMD = /usr/sbin/ip,/usr/sbin/ifconfigNETADMIN ALL=（root） NETCMD#授权adminuser1和adminuser2可以执行useradd,usermod,passwd命令，但是passwd命令只可以修改别人密码，不可以修改root密码User_Alias ADMINUSER = adminuser1,adminuser2Cmnd_Alias ADMINCMD = /usr/sbin/useradd，/usr/sbin/usermod, /usr/bin/passwd [a-zA-Z]*, !/usr/bin/passwd rootADMINUSER ALL=(root) NOPASSWD:ADMINCMD，PASSWD:/usr/sbin/userdel 案例：默认指定授权用户 12345Defaults:wang runas_default=tom #指定了用户 wang 在使用 sudo 执行命令时，默认以 tom 用户的身份来执行wang ALL=(tom,jerry) ALLwang$ sudo cmd #默认以tom的身份执行cmdwang$ sudo -u jerry cmd #以 jerry 用户的身份来执行命令 cmd 案例：解决通配符带来的安全风险 1234#这样子写，可以让wang访问/var/log/messages.1，也可以访问/var/log/messages /etc/shadow两文件wang ALL=(ALL) /bin/cat /var/log/messages*#解决方法wang ALL=(ALL) /bin/cat /var/log/messages*,!/bin/cat /var/log/messages* * 案例：授权可以放在新建在sudoers.d目录下的文件（生产中配置如果比较复杂，此方法可以让每一个项目写一个单独的文件，互相不干扰） 123456[root@centos8 ~]#vim /etc/sudoers.d/testWang ALL=(ALL) sudoedit#wang 可以执行下面命令[root@centos8 ~]#sudoedit /etc/sudoers[root@centos8 ~]#sudoedit /etc/sudoers.d/test 案例：修改验证密码间隔为2分钟 1234[root@centos8 ~]#vim /etc/sudoersDefaults env_reset , timestamp_timeout=2[root@centos8 ~]#sudo -V 范例：ubuntu 默认用户具有sudo权限 1234567root@ubuntu1804:~# grep %sudo /etc/sudoers%sudo ALL=(ALL:ALL) ALLroot@ubuntu1804:~# id wanguid=1000(wang) gid=1000(wang)groups=1000(wang),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),108(lxd),113(lpadmin),114(sambashare)#默认的用户wang 属于此sudo组，所以wang有所有权限 范例：修改sudo 提示符格式 1234[wang@centos8 ~]$sudo cat /var/log/messages[sudo] password for wang:[wang@centos8 ~]$sudo -p &quot;password on %h for user %p: &quot; cat /var/log/messagespassword on centos8 for user wang: 范例：删除时间戳文件 12345678910[root@centos8 ~]#su - wangLast login: Mon May 25 10:28:14 CST 2020 on pts/1[wang@centos8 ~]$sudo -K[wang@centos8 ~]$exitlogout[root@centos8 ~]#ll /run/sudo/tstotal 4-rw------- 1 root mage 112 May 25 10:11 mage[root@centos8 ~]#file /run/sudo/ts/mage/run/sudo/ts/mage: data 案例：禁止git用户执行wget命令 1234[root@centos8 ~]#vim /etc/sudoers.d/testgit ALL=(ALL) /usr/bin/wget,!/usr/bin/wget[root@centos8 ~]#alias wget=&#x27;echo &quot;wget is disabled for this user&quot;&#x27;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"加密和安全","slug":"加密和安全","permalink":"https://aquapluto.github.io/tags/%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8/"}]},{"title":"OpenSSL","slug":"Linux/encryption-security/OpenSSL","date":"2025-08-21T03:02:59.000Z","updated":"2025-08-28T12:33:05.201Z","comments":true,"path":"Linux/encryption-security/OpenSSL/","permalink":"https://aquapluto.github.io/Linux/encryption-security/OpenSSL/","excerpt":"","text":"OpenSSL是一个开放源代码的软件库包，应用程序可以使用这个包来进行安全通信，避免窃听，同时确认另一端连线者的身份。这个包广泛被应用在互联网的网页服务器上，实现了基本的加密功能，实现了SSL与TLS协议 包括三个组件： libcrypto：用于实现加密和解密的库 libssl：用于实现ssl通信协议的安全库 openssl：多用途命令行工具 1 Base64 编码Base64就是一种基于64个可打印字符来表示二进制数据的方法（不是加密，只是系统数据由base64的方式保存） 范例： 1234[root@centos8 ~]#echo -n ab | base64YWI=[root@centos8 ~]#echo -n ab | base64 | base64 -dab[root@centos8 ~]# 2 openssl 命令两种运行模式： 交互模式 批处理模式 三种子命令： 标准命令 消息摘要命令（配合不同算法） 加密命令（配合不同算法） 范例: openssl的交互和非交互式查看版本 12345678910111213root@ubuntu2004:~# openssl versionOpenSSL 1.1.1f 31 Mar 2020[root@centos8 ~]#openssl versionOpenSSL 1.1.1c FIPS 28 May 2019[root@ubuntu1804 ~]#opensslOpenSSL&gt; versionOpenSSL 1.1.1 11 Sep 2018[root@centos7 ~]#opensslOpenSSL&gt; versionOpenSSL 1.0.2k-fips 26 Jan 2017 分类列出所有命令与算法 1234567891011121314#列出所有标准命令[root@ubuntu ~]# openssl list --commands#列出所有摘要命令[root@ubuntu ~]# openssl list -digest-commands#列出所有摘要算法[root@ubuntu ~]# openssl list -digest-algorithms#列出所有加密命令[root@ubuntu ~]# openssl list -cipher-commands#列出所有加密算法[root@ubuntu ~]# openssl list -cipher-algorithms 2.1 单向哈希加密工具：openssl dgst 算法：md5sum, sha1sum, sha224sum,sha256sum… 范例 12345[root@centos8 data]#openssl md5 fstabMD5(fstab)= 8f8e3b0d0c17f1b29d404544c7b310da[root@centos8 data]#openssl sha512 fstabSHA512(fstab)=81f67107026a43bf60fff2cdd6ebe93f49ad3bf48e3645912aa0e8d27eec8d9647121f608c7b6ad194856318f0381db21f6961db862e99644126b64c38a5eeb6 补充知识 12MAC: Message Authentication Code，单向加密的一种延伸应用，用于实现网络通信中保证所传输数据的完整性机制HMAC：hash-based MAC，使用哈希算法 2.2 生成用户密码格式 1234567891011121314151617openssl passwd [options...] STRING-help #获取帮助信息-in infile #从文件读取要加密的内容-noverify #从标准输入接收密码时，不用输两次-quiet #不输出告警信息-table #以表格形式输出-salt val #手动指定盐值，默认每次自动随机生成-stdin #从标准输入接收要加密的内容-6 #使用SHA512 算法加密-5 #使用SHA256 算法加密-apr1 #使用 apache 特有的MD5算法加密-1 #使用MD5 加密算法-aixmd5 #使用AIX MD5 加密算法-rand val #将文件加到随机数生成器-writerand outfile #将此过程中产生的随机数写到指定文件-crypt #标准unix密码加密算法，旧版中默认项 范例：从标准输入读取 12[root@ubuntu ~]# echo 123456 | openssl passwd -stdin$1$2b626GRH$mY5SAZYhOMadVjJyY52.n. 两个$之间的是盐，加盐的目的就是为了让你不能根据这个加密的结果来判断俩密码一样不一样，就算是相同的密码，盐不一样，加密后的结果会不同，只有盐一样，加密的结果才会相同 指定盐值 12345#-1和$1相对应[root@ubuntu ~]# openssl passwd -1 -salt abcd1234 123456$1$abcd1234$flW8OGJjRMMEgtyb4lbLN0[root@ubuntu ~]# openssl passwd -1 -salt abcd1234 123456$1$abcd1234$flW8OGJjRMMEgtyb4lbLN0 &#x2F;etc&#x2F;shadow 文件中的密码字段说明 123456[root@Rocky8 ~]#getent shadow wuwu:$6$8fvMk.Ge4CHdKb0l$a/MiQroCDB7sHYYGqnpQUk6xzNiohkdQAfXGBHBlu7zk7qeMT4AcJ8xyQhnsFPM6IhEgXZLRlqcMrTxlwGikB0::0:99999:7:::$6：使用SHA512 算法加密8fvMk.Ge4CHdKb0l：盐值$a/MiQroCDB7sHYYGqnpQUk6xzNiohkdQAfXGBHBlu7zk7qeMT4AcJ8xyQhnsFPM6IhEgXZLRlqcMrTxlwGikB：真正的加密后密文 相同加密算法，相同内容相同盐值的情况下，加密后的内容也相同 1234[root@Rocky8 ~]#getent shadow wuwu:$6$8fvMk.Ge4CHdKb0l$a/MiQroCDB7sHYYGqnpQUk6xzNiohkdQAfXGBHBlu7zk7qeMT4AcJ8xyQhnsFPM6IhEgXZLRlqcMrTxlwGikB0::0:99999:7:::[root@Rocky8 ~]#openssl passwd -6 -salt &quot;8fvMk.Ge4CHdKb0l&quot; zjwjl2004$6$8fvMk.Ge4CHdKb0l$a/MiQroCDB7sHYYGqnpQUk6xzNiohkdQAfXGBHBlu7zk7qeMT4AcJ8xyQhnsFPM6IhEgXZLRlqcMrTxlwGikB0 不指定盐值，每次都会随机生成 12345[root@Rocky8 ~]#openssl passwd -6 zjwjl2004$6$t9hIpHGtEOs8mjHs$XV5/TTsbdxxyMCnbo5NpxSu6MoQMr1MZx.XKbv.ckqQXv1HImi/H7W7g00yXrGZH.QdjjeaFGVKldAxz8cVNr/[root@rocky8 ~]#openssl passwd -6 zjwjl2004$6$nhk.wwXsRt1JviHf$TeS9MFeW6VzZR0SICF0fqca140pcgVXGjNz2uH/sU6Sm6KdjrM9E079fPi/YNc9S7CyiicPrshIBNoyrjQ7TY. 范例: 利用Python程序在CentOS7 生成sha512加密密码 1234[root@centos7 ~]#python -c &#x27;importcrypt,getpass;pw=&quot;magedu&quot;;print(crypt.crypt(pw))&#x27;$6$pt0SFMf6YqKea3mh$.7Hkslg17uI.Wu7BcMJStVVtkzrwktXrOC8DxcMFC4JO1igrqR7VAi87H5PHOuLTUEjl7eJqKUhMT1e9ixojn1 范例：创建新用户同时指定密码，在CentOS8和Ubuntu都通用 12345678910[root@centos8 ~]#useradd -p `echo magedu | openssl passwd -6 -saltY16DiwuVQtL6XCQK -stdin` zhang[root@centos8 ~]#getent shadow zhangzhang:$6$Y16DiwuVQtL6XCQK$DAQO4BhVbfQmaUMFWKR61hVwFvxk7J9U4pZaFcwf6nBwERUN6bL3wALPonDRebk3CgooupeXHfRuFKRciUe6q.:18402:0:99999:7:::[root@centos8 ~]#getent shadow zhang wangzhang:$6$Y16DiwuVQtL6XCQK$DAQO4BhVbfQmaUMFWKR61hVwFvxk7J9U4pZaFcwf6nBwERUN6bL3wALPonDRebk3CgooupeXHfRuFKRciUe6q.:18402:0:99999:7:::wang:$6$Y16DiwuVQtL6XCQK$DAQO4BhVbfQmaUMFWKR61hVwFvxk7J9U4pZaFcwf6nBwERUN6bL3wALPonDRebk3CgooupeXHfRuFKRciUe6q.:18373:0:99999:7::: 2.3 生成随机数随机数生成器：伪随机数字，利用键盘和鼠标，块设备中断生成随机数 12345678910/dev/random #仅从熵池返回随机数；随机数用尽，阻塞/dev/urandom #从熵池返回随机数；随机数用尽，会利用软件生成伪随机数，非阻塞openssl rand [options...] NUMNUM #字符个数-out outfile #输出到指定文件-rand val #将文件加到随机数生成器-writerand outfile #将此过程中产生的随机数写到指定文件-base64 #base64编码后显示-hex #16进制显示，每个字符为十六进制，相当于4位二进制，出现的字符数为NUM*2，一个字节占8位 范例：生成随机10位长度密码 123456789[root@centos8 ~]#openssl rand -base64 9 |head -c10 #9*8=72,72/6=12位；除不尽时用=代替（不是3的整数倍）ip97t6qQes[root@centos8 ~]#[root@centos8 ~]#tr -dc &#x27;[:alnum:]&#x27; &lt; /dev/urandom |head -c10DO2mDp3eZu[root@centos8 ~]##16进制显示，一个字节可表示8个二进制，一个16进制可表示4个二进制，所以一个字节可以表示2个16进制[root@ubuntu ~]# openssl rand -hex 1015e0b3882859424f6d4f 2.4 实现密钥对PKI生成私钥，再从私钥中提取公钥 1234567891011#私钥文件-----BEGIN RSA PRIVATE KEY----------END RSA PRIVATE KEY-----#公钥文件-----BEGIN PUBLIC KEY----------END PUBLIC KEY-----#RSA公钥文件-----BEGIN RSA PUBLIC KEY----------END RSA PUBLIC KEY----- 格式 123456789101112131415161718192021222324252627282930313233#生成私钥，私钥包含公钥信息openssl genrsa [options...] [NUM]NUM #指定密钥长度,单位bit,默认2048-help #获取帮助信息-out outfile #输出到指定文件-rand val #以文件作随机数种子-writerand outfile #将此过程中产生的随机数写到指定文件-passout val #输出文件的保护口令-* #加密算法#从私钥提取公钥openssl rsa [options...]-help #获取帮助信息 -inform format #显示指定输入文件格式DEM|PEM,默认PEM-outform format #指定输出文件模式DER|PEM，默认PEM-in val #指定输入的文件，通常是私钥-out outfile #指定要输出的文件,不指定就是标准输出-pubin #从输入文件中读取公钥值，默认是读取私钥值-pubout #指定导出公钥，默认输出私钥-passout val #输出文件的保护口令-passin val #输入文件的保护口令-RSAPublicKey_in #输入文件格式为RSAPublicKey-RSAPublicKey_out #输出文件格式为RSAPublicKey-noout #不输出任何内容-text #输出所有信息-modulus #输出公钥信息-check #检查公钥是否匹配-* #指定私钥的保护加密算法#加密算法aes128|aes192|aes256|aria128|aria192|aria256|camellia128|camellia192|camellia256|des|des3|idea 公钥加密： 算法：RSA, ELGamal 工具：gpg, openssl rsautl（man rsautl） 数字签名： 算法：RSA, DSA, ELGamal 密钥交换： 算法：dh，DSA，DSS，RSA openssl命令生成密钥对儿：man genrsa 生成私钥 1openssl genrsa -out /PATH/TO/PRIVATEKEY.FILE [-aes128] [-aes192] [-aes256] [-des3] [NUM_BITS,默认2048] 解密加密的私钥 1openssl rsa -in /PATH/TO/PRIVATEKEY.FILE -out /PATH/TO/PRIVATEKEY2.FILE 范例 123456789#生成私钥及其存放文件[root@ubuntu ~]# openssl genrsa -out test.key#从指定私钥提取出公钥[root@ubuntu ~]# openssl rsa -in test.key -pubout -out test.pubkeywriting RSA key[root@ubuntu ~]# ls -al test*-rw------- 1 root root 1704 May 21 16:03 test.key-rw-r--r-- 1 root root 451 May 21 16:07 test.pubkey 范例：生成私钥时加密 1234567891011121314151617#指定加密算法，指定口令[root@ubuntu ~]# openssl genrsa -out test2.key -des3 -passout pass:&quot;123456&quot;#解密加密的私钥[root@ubuntu ~]# openssl rsa -in test2.key -out test2.key2Enter pass phrase for test2.key:writing RSA key#提取公钥要求输入密码[root@ubuntu ~]# openssl rsa -in test2.key -pubout -out test2.pubkeyEnter pass phrase for test2.key:writing RSA key[root@ubuntu ~]# ll test2*-rw------- 1 root root 1854 May 21 16:09 test2.key-rw------- 1 root root 1704 May 21 16:09 test2.key2-rw-r--r-- 1 root root 451 May 21 16:12 test2.pubkey 范例: 密钥文件要保证权限，生成的私钥设置权限保证安装 1234567#对私钥通过设置严格的权限实现安全，应用更广泛[root@centos8 ~]#(umask 077; openssl genrsa -out /data/app1.key 2048)[root@centos8 ~]#cat /data/app1.key#用加密对称密钥加密私钥,此方式更安全，但是不方便[root@centos8 ~]#openssl genrsa -out /data/app2.key -des3 2048[root@centos8 ~]#cat /data/app2.key 从私钥中提取出公钥 1234openssl rsa -in PRIVATEKEYFILE -pubout -out PUBLICKEYFILE范例openssl rsa -in test.key -pubout -out test.pubkey 范例 1234567891011121314151617[root@centos7 ~]#(umask 066;openssl genrsa -out /data/app.key)Generating RSA private key, 2048 bit long modulus........................+++.+++e is 65537 (0x10001)[root@centos7 ~]#ls -l /data/total 4-rw------- 1 root root 1679 Feb 3 15:26 app.key[root@centos8 ~]#openssl genrsa -out /data/app.key 1024Generating RSA private key, 1024 bit long modulus (2 primes).............................................................................+++++..........+++++e is 65537 (0x010001)[root@centos8 ~]#ll /data/app.key-rw------- 1 root root 891 Feb 3 14:52 /data/app.key 范例：利用私钥提取公钥 1234567891011121314[root@centos8 ~]#(umask 066;openssl genrsa -out /data/app.key)[root@centos8 ~]#openssl rsa -in /data/app.key -pubout -out /data/app.key.pubwriting RSA key[root@centos8 ~]#ls -l /data/total 8-rw------- 1 root root 887 Feb 3 15:28 app.key-rw-r--r-- 1 root root 272 Feb 3 15:32 app.key.pub[root@centos8 ~]#cat /data/app.key.pub-----BEGIN PUBLIC KEY-----MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCvkS+Z4NWAMoXEwNUyn58J0oI+ZjXotZUJLfbVHvGd3Ug6Rk52imHp1J629edUn0Cw7KoPfQLegmWsldG4v931HCdlELT2vj+QE7KJhc1tGFomzCnX8Q41tRrVVbHPxQYvNmMRXRqIdqXGxFpR758EngxFzAGcnLTrDz/I2GocrQIDAQAB-----END PUBLIC KEY----- 范例：利用加密的私钥提取公钥 1234567891011121314[root@centos8 ~]#openssl genrsa -out /data/app2.key -des3 2048[root@centos8 ~]#openssl rsa -in /data/app2.key -pubout -out /data/app2.pubkeyEnter pass phrase for /data/app2.key:writing RSA key[root@centos8 ~]#cat /data/app2.pubkey-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2VXLcmClBWiqL8u3f1vOmjCEV+9c6S0qDXNiZrCRiYUyIMKLhyXnVLw+k6uGmC4bdATFgxDU2zjdJF3bptS6dNZzMQJ5uAQOxQ1KHKm3O+s+Isg+H/LTHUDyc4szQZ3gjJCTKculS60qsWV7lcGPPNSzXr3/F/TlLMRxv/9GrEjYXDgCAJt2lxWgvgXqX8Y1mc1FFkBRXVZr/CnXaij5JIA89/OHIJoX+mQIuQEjmwFMCX/6cm64iks2obgmzluvm6fM6dkvlHDGpZicNZI15vaQcO7sJ4YTUGwJrDShC9R++vrAvfahvTDV3n/MLmfwS+8nhUA0Dr7M7I0GOYMpEQIDAQAB-----END PUBLIC KEY----- 范例：生成加密的私钥，并解密 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@centos8 ~]#openssl genrsa -out /data/app.key -des3 1024Generating RSA private key, 1024 bit long modulus (2 primes)......+++++...........+++++e is 65537 (0x010001)Enter pass phrase for /data/app.key:Verifying - Enter pass phrase for /data/app.key:[root@centos8 ~]#ls -l /datatotal 4-rw------- 1 root root 963 Feb 3 15:27 app.key[root@centos8 ~]#cat /data/app.key-----BEGIN RSA PRIVATE KEY-----Proc-Type: 4,ENCRYPTEDDEK-Info: DES-EDE3-CBC,577C3B861BAD86B6VM8P7vx1UUcSJyXCB0pDO9xgmdNgsMOcl6NitdUvBA9Jx2oLyxsT6TYbbvZvlF55aQB0bq43atECDBz2+v1ghacPp78S2wuGuTR1hdWwfFKJNr6d/5yXO4y1ZOt3RLvRE4K6TCeSwZTIUNeQyuh+vstarQmaLQmdObb3lsMG+WipQj3hb0oGdZcWjuQ0gi1BRKN1duhsWFQbdXZamBqWQqCbvigmqRwjk7S6GE3YwVhys1T4N0BFX/edNCMnzb796/mR+LJ2Wz/ecJXB5250rVby3h88ZNsgARg7jUM9zI6jf7G4t1etRlCJ8A9TvDe8J/5lkDUSWEh1dnB+xw5uamDY7f3GanuKTEe54DxuBwmbBpphV1QTTefSJ01Q6l9KwS0zV6WE+vCt99dE9J8+GXGD77twRcbmjDWfaoibvwMu00crB9K5dbxdSX50jlD9Mj+bVr9tcwQW/WzA+V05Ndb74e8OE97pEFjTX8DeIxcZomDUcpNGpQ0eWvyE+A2xSrux9nN8z9dUF963V4NjQGUg1owQPAlfO6zBGObXnynOqKDmBj+8FfWrnHnZUVt53HTV+uSkLuA+8lGoNoxH4/6ZLfvY0Y5+WSg3st2EvwGT74SNNrsNYD0qGt1LujQxIiwfCI0uv8rqgtLtsYmJmYI0t7hWUVmb6QgX1Qh0Kvzc0A34IMDjY6dhXTKnxeF3LGkrFAgl3+6tKXxMuQDLB6Jy9m3SOwW/JoXMVVcYHrSPzTgAl2sgAkgEq8nf4yfmZP9WHrDe10yXY+5K2h8UiFhvrnQ+YnH4BcTrKuEa9T7pxToo0cTdqg==-----END RSA PRIVATE KEY-----[root@centos8 ~]#openssl rsa -in /data/app.key -out /data/app.keyEnter pass phrase for /data/app.key:writing RSA key[root@centos8 ~]#ls -l /datatotal 4-rw------- 1 root root 887 Feb 3 15:28 app.key[root@centos8 ~]#cat /data/app.key-----BEGIN RSA PRIVATE KEY-----MIICXQIBAAKBgQCvkS+Z4NWAMoXEwNUyn58J0oI+ZjXotZUJLfbVHvGd3Ug6Rk52imHp1J629edUn0Cw7KoPfQLegmWsldG4v931HCdlELT2vj+QE7KJhc1tGFomzCnX8Q41tRrVVbHPxQYvNmMRXRqIdqXGxFpR758EngxFzAGcnLTrDz/I2GocrQIDAQABAoGAQ/uDJCGkanSlya8lnumiKqqB1mm7nDWb1ScgOhw2UPubeT06Krqg+WtkXdJQVjsoUJoDq+WrU7/IYRDOWayp5Be3EXCdyldSrWu1+wqJ1Vnpk2oUAEyr+lzcHhW1FNQ/5rb8kIUjR7DZpwnsYJxDygnaKaNKiUiF2FsMX8JcS8ECQQDoZt3zSsXYeR4tY9kPPA19npQXx9K4Wv2wsCR904pznzoaJ9Kj+6E/3AdxtXcTD0GiZe8vW+H6WCmWgB1NpGiRAkEAwWTwO9ZncQnA+X2PYTkizBp/JdEdRjcL/D2g+g3rpL2nLChI56C5zA4NsJFmblE2uY1OLIJBGExiZP/XS74gXQJBAISTOgYyH48P+OEX1plUPrXsorq2KUU10wbaVNbauF6g9Lo7AXS+dQxC7pQ1Wsoqp9yGnd28Yrs3U/Ig/5ZtNaECQG+/kKUy3bDOjwhbCjeGmVnQ0bmbXMwO0MkfH15+HrShtfBpEr9s+w8y66wkSEjkere7M/m6Bj0xHgX4Y4JryS0CQQChBua8JXCCUGLle7+IEEcgQZSF4PdLrmnhrRG7Qrrgyd6pPuvd2jAGv5fMhjROmf9MWc4DFiRK0B6dz7OyF9j/-----END RSA PRIVATE KEY----- 3 建立私有CA实现证书申请颁发建立私有CA： OpenCA：OpenCA开源组织使用Perl对OpenSSL进行二次开发而成的一套完善的PKI免费软件 openssl：相关包 openssl和openssl-libs 证书申请及签署步骤： 生成证书申请请求 RA核验 CA签署 获取证书 123456789#安装包[root@rocky86 ~]# yum install openssl-libs#查看配置文件[root@rocky86 ~]# cat /etc/pki/tls/openssl.cnf#安装包[root@ubuntu ~]# apt install libssl-dev#查看配置文件[root@ubuntu ~]# cat /etc/ssl/openssl.cnf 三种策略：match匹配、optional可选、supplied提供 123match：要求用户申请填写的信息跟CA设置信息必须一致optional：可有可无，跟CA设置信息可不一致supplied：必须填写这项申请信息 CA证书配置规范 1234567891011121314151617181920212223242526272829303132[root@centos8 ~]#cat /etc/pki/tls/openssl.cnf[ ca ]default_ca = CA_default # The default ca section[ CA_default ]dir = /etc/pki/CA #存放CA数据的目录，即所有与证书相关的文件目录（centos7默认有，8没有） certs = $dir/certs #颁发的证书文件crl_dir = $dir/crl #吊销的证书文件database = $dir/index.txt #证书索引文件new_certs_dir = $dir/newcerts #新颁发的证书存放路径certificate = $dir/cacert.pem #CA机构自己的证书serial = $dir/serial #证书编号文件，里面的编号给下一个颁发的证书使用crlnumber = $dir/crlnumber #证书吊销列表编号，即存放当前CRL编号的文件 crl = $dir/crl.pem #证书吊销列表文件private_key = $dir/private/cakey.pem #CA证书自己的私钥RANDFILE = $dir/private/.rand #私有随机数文件x509_extensions = usr_cert #要添加到证书的扩展name_opt = ca_default #“使用者名称”选项cert_opt = ca_default #证书字段选项default_days = 365 #认证多长时间default_crl_days= 30 #距离下一次 CRL 还有多久default_md = sha256 #默认使用 SHA-256preserve = no #保持传递DN排序policy = policy_match[ policy_match ]countryName = match #国家stateOrProvinceName = match #省organizationName = match #组织（公司名）organizationalUnitName = optional #部门commonName = supplied #通用名（哪个服务使用这个证书）emailAddress = optional #邮箱bash 格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566openssl req-new #生成新证书签署请求-x509 #专用于CA生成自签证书标准规范-key #生成请求时用到的私钥文件-days n #证书的有效期限-out /PATH/TO/SOMECERTFILE #证书的保存路径-keyout #指明创建的新的私有密钥文件的文件名-nodes #如果指定-newkey自动生成秘钥，那么-nodes选项说明生成的秘钥不需要加密，即不需要输入passphase-newkey #指在生成证书请求或者自签名证书的时候自动生成密钥，然后生成的密钥名称由-keyout参数指定。当指定newkey选项时，后面指定rsa:bits说明产生rsa密钥，位数由bits指定。 如果没有指定选项-key和-newkey，默认自动生成秘钥-subj args #替换或自定义证书请求时需要输入的信息，并输出修改后的请求信息。args的格式为&quot;/type0=value0/type1=value1...&quot;，如果value为空，则表示使用配置文件中指定的默认值，如果value值为&quot;.&quot;，则表示该项留空。其中可识别type有：C是Country、ST是state、L是localcity、O是Organization、OU是Organization Unit、CN是common name等-set_serial n #指定生成自签名证书时的证书序列号，该序列号将写入配置文件中serial指定的文件中，这样就不需要手动更新该序列号文件openssl ca-cert ca_cert.pem #指定 CA 证书文件。-keyfile ca_key.pem #指定 CA 私钥文件。-in file #输入的证书签署请求文件。-out file #输出的签署证书文件。-key file #签署证书时使用的私钥文件。-revoke file #吊销证书。-days arg #设置证书的有效期天数。-status serial|hex #检查证书状态。-config ca_config.cnf #指定 OpenSSL 配置文件。-outdir dir #指定输出目录。-infiles file ... #输入的多个证书签署请求文件。-spkac file #输入的 Netscape SPKAC 文件。-extensions section #指定证书扩展字段。-extfile file #从文件中读取扩展字段配置。-subj arg #自定义证书主题字段。-utf8 #使用 UTF8 编码。-nameopt option #指定证书主题名称选项。-enddate YYMMDDHHMMSSZ #设置证书的截止日期。-md arg #指定摘要算法（如 sha256）。-batch #批量模式，无需确认。-preserveDN #保留原始主题名称。-include file #包含其它 CA 配置文件。-rand file(s) #指定随机数种子文件。-engine id #指定加密引擎。-updatedb #更新证书数据库。-crldays arg #设置 CRL 的有效期天数。-crlhours arg #设置 CRL 的有效期小时数。-crlsec arg #设置 CRL 的有效期秒数。-crlexts section #指定 CRL 扩展字段。-createdb #创建证书数据库。-msie_hack #使用 MSIE 兼容模式。-noemailDN #不使用电子邮件字段。-selfsign #自签名 CA 证书。-separate #对每个输入文件生成单独的证书。-crlexts section #指定 CRL 扩展字段。openssl x509in #指定输入文件，默认是标准输入。out #指定输出文件，默认是标准输出。noout #不向控制台输出证书信息days #设置证书的有效期时间，默认30天req #输入是一个证书请求，签名和输出CA #设置CA证书，必须是PEM格式的CAkey #设置CA的key，必须是PEM格式set_serial #使用序列号text #以文本格式输出证书-in cert.der #指定输入的 DER 格式证书文件-outform PEM #指定输出格式为 PEM-out cert.pem #指定输出的 PEM 格式证书文件-in cert.pem #指定输入的 PEM 格式证书文件。-outform DER #指定输出格式为 DER。-out cert.der #指定输出的 DER 格式证书文件。 3.1 创建私有CA1、创建私有CA所需要的文件 12345678#创建相关目录mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts,private&#125; #生成证书索引数据库文件touch /etc/pki/CA/index.txt#指定第一个颁发证书的序列号echo 01 &gt; /etc/pki/CA/serial 2、 生成私有CA的私钥 12cd /etc/pki/CA/(umask 066; openssl genrsa -out private/cakey.pem 2048) 3、生成私有CA的自签名证书 1234567891011121314151617openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pem....Country Name (2 letter code) [AU]:CN #国家代码State or Province Name (full name) [Some-State]:beijing #省/州Locality Name (eg, city) []:beijing #城市Organization Name (eg, company) [Internet Widgits Pty Ltd]:magedu #公司/单位Organizational Unit Name (eg, section) []:m54 #部门Common Name (e.g. server FQDN or YOUR name) []:www.magedu.org #域名Email Address []: #邮箱选项说明：openssl req：#申请-new：#生成新证书签署请求-x509：#专用于CA生成自签证书标准规范-key：#生成请求时用到的私钥文件-days n：#证书的有效期限-out /PATH/TO/SOMECERTFILE: #证书的保存路径 国家代码： https://country-code.cl/ 范例：查看证书信息 12345[root@centos8 ~]#openssl x509 -in /etc/pki/CA/cacert.pem -noout -text-text：以文本方式展示如果传到Windows，把文件后缀改成crt就能看了 范例：生成自签名证书 1234567891011121314[root@centos8 ~]#openssl req -utf8 -newkey rsa:1024 -subj &quot;/CN=www.magedu.org&quot; -keyout app.key -nodes -x509 -out app.crtGenerating a RSA private key...........................+++++...+++++writing new private key to &#x27;app.key&#x27;-----选项说明：-newkey：#指在生成证书请求或者自签名证书的时候自动生成密钥，然后生成的密钥名称由-keyout参数指定。当指定newkey选项时，后面指定rsa:bits说明产生rsa密钥，位数由bits指定。 如果没有指定选项-key和-newkey，默认自动生成秘钥-keyout：#指明创建的新的私有密钥文件的文件名-subj args ：#替换或自定义证书请求时需要输入的信息，并输出修改后的请求信息。args的格式为&quot;/type0=value0/type1=value1...&quot;，如果value为空，则表示使用配置文件中指定的默认值，如果value值为&quot;.&quot;，则表示该项留空。其中可识别type有：C是Country、ST是state、L是localcity、O是Organization、OU是Organization Unit、CN是common name等-nodes：#如果指定-newkey自动生成秘钥，那么-nodes选项说明生成的秘钥不需要加密，即不需要输入passphase[root@centos8 ~]#openssl x509 -in app.crt -noout -text 3.2 申请证书并颁发证书1、为需要使用证书的用户生成他自己的私钥 12#/data/test.key可以改，将来给网站或者服务申请证书可换路径(umask 066; openssl genrsa -out /data/test.key 2048) 2、为需要使用证书的主机利用他的私钥生成证书申请文件 12#/data/test.csr是证书申请文件openssl req -new -key /data/test.key -out /data/test.csr 3、在CA签署证书并将证书颁发给请求者 12#/etc/pki/CA/certs/test.crt为证书文件openssl ca -in /data/test.csr -out /etc/pki/CA/certs/test.crt -days 100 注意：默认要求 国家，省，公司名称三项必须和CA一致，如果证书申请文件中的配置项与CA机构的匹配规则不一致，将无法签发证书，要是想不一致，就去OpenSSL配置文件将match改成optional 4、查看证书中的信息 123456789101112openssl x509 -in /PATH/FROM/CERT_FILE -noout -text|issuer|subject|serial|dates#查看指定编号的证书状态openssl ca -status 0F#原来是0F，加1后变成10[root@ubuntu CA]# cat /etc/pki/CA/serial10#V 表示有效，230830 表示2023年8月30日过期，0F 表示证书编号[root@ubuntu CA]# cat /etc/pki/CA/index.txtV 230830135623Z 0F unknown /C=CN/ST=beijing/O=magedu/OU=m54-class/CN=www.m54.magedu.com 3.3 吊销证书在客户端获取要吊销的证书的serial 1openssl x509 -in /PATH/FROM/CERT_FILE -noout -serial -subject 在CA上，根据客户提交的serial与subject信息，对比检验是否与index.txt文件中的信息一致，吊销证书： 1openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem 指定第一个吊销证书的编号,注意：第一次更新证书吊销列表前，才需要执行 1echo 01 &gt; /etc/pki/CA/crlnumber 生成证书吊销列表 1openssl ca -gencrl -out /etc/pki/CA/crl.pem 查看crl文件： 123openssl crl -in /etc/pki/CA/crl.pem -noout -text如果传到Windows，把文件后缀改成crl就能看了 3.4 CentOS 7创建自签名证书因为centos7上有Makefile文件，可以方便快捷生成证书，不用敲上面很长的命令，要是想centos8上也可以这样，将centos7的Makefile文件传到centos8上 123456789101112[root@centos7 ~]#cd /etc/pki/tls/certs[root@centos7 certs]#make[root@centos7 certs]#make /data/test.key #生成私钥文件，需要输入口令，可以编辑Makefile文件删除[root@centos7 certs]#lsca-bundle.crt ca-bundle.trust.crt make-dummy-cert Makefile renew-dummy-cert[root@centos7 certs]#cat Makefile.....%.key:umask 77 ; \\/usr/bin/openssl genrsa -aes128 $(KEYLEN) &gt; $@ #将-aes12删除......[root@centos7 certs]#make /data mysql.crt #生成自签名证书 3.5 实战案例：在CentOS 8上实现私有CA和证书申请3.5.1 创建CA相关目录和文件1234[root@centos8 ~]#mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts,private&#125;[root@centos8 ~]#tree /etc/pki/CA/[root@centos8 ~]#touch /etc/pki/CA/index.txt[root@centos8 ~]#echo 0F &gt; /etc/pki/CA/serial index.txt和serial文件在颁发证书时需要使用，如果不存在，会出现以下错误提示 1234567891011121314151617[root@centos8 ~]#openssl ca -in /data/app1/app1.csr -out/etc/pki/CA/certs/app1.crt -days 1000Using configuration from /etc/pki/tls/openssl.cnf140040142845760:error:02001002:system library:fopen:No such file ordirectory:crypto/bio/bss_file.c:72:fopen(&#x27;/etc/pki/CA/index.txt&#x27;,&#x27;r&#x27;)140040142845760:error:2006D080:BIO routines:BIO_new_file:no suchfile:crypto/bio/bss_file.c:79:[root@centos8 ~]#openssl ca -in /data/app1/app1.csr -out/etc/pki/CA/certs/app1.crt -days 1000Using configuration from /etc/pki/tls/openssl.cnf/etc/pki/CA/serial: No such file or directoryerror while loading serial number140240559408960:error:02001002:system library:fopen:No such file ordirectory:crypto/bio/bss_file.c:72:fopen(&#x27;/etc/pki/CA/serial&#x27;,&#x27;r&#x27;)140240559408960:error:2006D080:BIO routines:BIO_new_file:no suchfile:crypto/bio/bss_file.c:79: 3.5.2 创建CA的私钥123456789101112[root@centos8 ~]#cd /etc/pki/CA/[root@centos8 CA]#(umask 066; openssl genrsa -out private/cakey.pem 2048)Generating RSA private key, 2048 bit long modulus (2 primes)..........................................................................+++++.............................+++++e is 65537 (0x010001)[root@centos8 CA]#tree[root@centos8 CA]#ll private/total 4-rw------- 1 root root 1679 May 20 11:55 cakey.pem[root@centos8 CA]#cat private/cakey.pem 3.5.3 给CA颁发自签名证书123456789[root@centos8 ~]#openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pem[root@centos8 ~]#tree /etc/pki/CA[root@centos8 ~]#cat /etc/pki/CA/cacert.pem[root@centos8 ~]#openssl x509 -in /etc/pki/CA/cacert.pem -noout -text[root@centos8 ~]#sz /etc/pki/CA/cacert.pem#将文件cacert.pem传到windows上，修改文件名为cacert.pem.crt，双击可以看到下面显示 3.5.4 用户生成私钥和证书申请1234567[root@centos8 ~]#mkdir /data/app1#生成私钥文件[root@centos8 ~]#(umask 066; openssl genrsa -out /data/app1/app1.key 2048)[root@centos8 ~]#cat /data/app1/app1.key#生成证书申请文件[root@centos8 ~]#openssl req -new -key /data/app1/app1.key -out /data/app1/app1.csr 3.5.5 CA颁发证书12[root@centos8 ~]#openssl ca -in /data/app1/app1.csr -out /etc/pki/CA/certs/app1.crt -days 1000[root@centos8 ~]#tree /etc/pki/CA 默认有三项内容必须和CA一致：国家，省份，组织，如果不同，会出现下面的提示 123456[root@centos8 ~]#openssl ca -in /data/app2/app2.csr -out /etc/pki/CA/certs/app2.crtUsing configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okThe stateOrProvinceName field is different betweenCA certificate (beijing) and the request (hubei) 3.5.6 查看证书1234567891011121314[root@centos8 ~]#cat /etc/pki/CA/certs/app1.crt[root@centos8 ~]#openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -text[root@centos8 ~]#openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -issuer[root@centos8 ~]#openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -subject[root@centos8 ~]#openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -dates[root@centos8 ~]#openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -serial#验证指定编号对应证书的有效性[root@centos8 ~]#openssl ca -status 0F[root@centos8 ~]#cat /etc/pki/CA/index.txt[root@centos8 ~]#cat /etc/pki/CA/index.txt.old[root@centos8 ~]#cat /etc/pki/CA/serial[root@centos8 ~]#cat /etc/pki/CA/serial.old 3.5.7 将证书相关文件发送到用户端使用12[root@centos8 ~]#cp /etc/pki/CA/certs/app1.crt /data/app1/[root@centos8 ~]#tree /data/app1/ 3.5.8 证书的信任默认生成的证书，在windows上是不被信任的，可以通过下面的操作实现信任 打开internet属性 3.5.9 证书的吊销123[root@centos8 ~]#openssl ca -revoke /etc/pki/CA/newcerts/11.pem[root@centos8 ~]#openssl ca -status 11[root@centos8 ~]#cat /etc/pki/CA/index.txt 3.5.10 生成证书吊销列表文件123456789101112131415161718192021[root@centos8 ~]#openssl ca -gencrl -out /etc/pki/CA/crl.pemUsing configuration from /etc/pki/tls/openssl.cnf/etc/pki/CA/crlnumber: No such file or directoryerror while loading CRL number140511895181120:error:02001002:system library:fopen:No such file ordirectory:crypto/bio/bss_file.c:72:fopen(&#x27;/etc/pki/CA/crlnumber&#x27;,&#x27;r&#x27;)140511895181120:error:2006D080:BIO routines:BIO_new_file:no suchfile:crypto/bio/bss_file.c:79:[root@centos8 ~]#echo 01 &gt; /etc/pki/CA/crlnumber[root@centos8 ~]#openssl ca -gencrl -out /etc/pki/CA/crl.pemUsing configuration from /etc/pki/tls/openssl.cnf[root@centos8 ~]#cat /etc/pki/CA/crlnumber02[root@centos8 ~]#cat /etc/pki/CA/crl.pem[root@centos8 ~]#openssl crl -in /etc/pki/CA/crl.pem -noout -text[root@centos8 ~]#sz /etc/pki/CA/crl.pem#将此文件crl.pem传到windows上并改后缀为crl.pem.crl，双击可以查看以下显示 4 gpg 命令GPG是一个完全免费的开源实现，用于OpenPGP标准的数据加密和解密。这种加密方式可以用于保护敏感数据，确保其在传输过程中不被截获或篡改 安装gpg 1sudo apt-get install gnupg 语法 1gpg [参数] 文件名 选项 123456789--import #导入或合并密钥--verify #验证签名--output #输出信息到文件--decrypt #解密数据-c #设置加密文件 -o #设置解密文件--export #导出密钥信息--gen-key #生成密钥对--encrypt #加密数据 范例 1234567891011#基于对称加密方式，加密指定文件gpg -c File #基于对称加密方式，解密指定文件gpg -o mydecrypt -d File.gpg #生成密钥对文件gpg --gen-key #查看已有密钥列表gpg --list-keys 范例 12345678#导入公钥gpg --import public.key#验证签名gpg --verify zzyenv-5.3.1-x64.tar.gz.asc#解密文件并输出到指定文件gpg --output zzyenv-5.3.1-x64.tar.gz --decrypt zzyenv-5.3.1-x64.tar.gz.asc","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"加密和安全","slug":"加密和安全","permalink":"https://aquapluto.github.io/tags/%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8/"}]},{"title":"安全机制","slug":"Linux/encryption-security/security-mechanisms","date":"2025-08-21T03:02:54.000Z","updated":"2025-08-28T12:33:05.214Z","comments":true,"path":"Linux/encryption-security/security-mechanisms/","permalink":"https://aquapluto.github.io/Linux/encryption-security/security-mechanisms/","excerpt":"","text":"1 常见的安全攻击 STRIDE Spoofing 假冒，与真实网站界面相同，欺骗浏览者提交敏感信息 123456789101112131415161718192021发送邮件服务yum info postfix25端口发送邮件telnet 127.0.0.1 25内容+域名hello magedu.com指定发送人和收件人mail from:jack.ma@alibaba.comrcpt to:wang@xxx.com（有邮箱写邮箱）内容datasubject:hellowelcome to alibaba.（以.结束内容）quit切换用户查看邮件su -wangmail Tampering 篡改，修改网络中的数据包以达到某种目的 Repudiation 否认 Information Disclosure 信息泄漏 12345678910yum -y install telnet.serversystemctl enable --now telnet.socket端口号是23远程登陆telnet 10.0.0.8输用户，密码敲命令wireshark抓包 TCP追踪流 Denial of Service 拒绝服务，使计算机或网络无法提供正常的服务 Elevation of Privilege 提升权限，将用户权限通过非法手段提高，以到达执行敏感操作的目的 2 加密算法和协议对称加密 非对称（公钥）加密 单向加密 认证协议 2.1 对称加密算法 对称加密：加密和解密使用同一个密钥 特性： 加密、解密使用同一个密钥，效率高 将原始数据分割成固定大小的块，逐个进行加密 缺陷： 密钥过多 密钥分发 数据来源无法确认 常见对称加密算法: DES：Data Encryption Standard，56bits 3DES AES：Advanced (128, 192, 256bits) Blowfish，Twofish IDEA，RC6，CAST5 123Alice ---Bob 对称算法 key1=key2data -- 加密(key1) -- data&#x27; ---解密（key2）---data 2.2 非对称加密算法2.2.1 非对称加密算法介绍非对称加密：密钥是成对出现 公钥：public key，公开给所有人，主要给别人加密使用 私钥：secret key，private key 自己留存，必须保证其私密性，用于自已加密签名 特点：用公钥加密数据，只能使用与之配对的私钥解密；反之亦然 功能： 数据加密：适合加密较小数据,比如: 加密对称密钥 数字签名：主要在于让接收方确认发送方身份 缺点： 密钥长,算法复杂 加密解密效率低下 常见算法： RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的,可实现加密和数字签名 DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准） ECC（Elliptic Curves Cryptography）：椭圆曲线密码编码学，比RSA加密算法使用更小的密钥，提供相当的或更高等级的安全 2.2.2 非对称加密实现加密 接收者公钥加密，接收者私钥解密 数据加密是为了保证信息的机密性，任何知道接收方的公钥的都可以向接收方发送信息，但是只有拥有私钥的才能解密出来 接收者 生成公钥&#x2F;密钥对：P和S 公开公钥P，保密密钥S 发送者 使用接收者的公钥来加密消息M 将P(M)发送给接收者 接收者 使用密钥S来解密：M&#x3D;S(P(M)) 12345678910111213141516171819Alice ---Bob 非对称算法 key1&lt;&gt;key2data -- 加密(key1) -- data&#x27; ---解密（key2）---dataAlicePublic key 公开 PaSecret private key 不公开 SaBobPublic key PbSecret private key Sb 用任何一个密钥加密，只能用对应另一把密钥解密Alice ---&gt; Bob 加密data -- 加密(key1=Pb) -- data&#x27; ---解密（key2=Sb）---dataAlice ---&gt; Bob 来源确认 ---&gt; jack data -- 加密(key1=Sa) -- data&#x27; ---解密（key2=Pa）---data 2.2.3 非对称加密实现数字签名 发送者私钥加密，发送者公钥加密 数字签名是为了保证信息的完整性、真实性、不可否认性，任何接收方都可以用公钥解密，验证数据的正确性 得到文件之后，用相同的算法获取文件摘要，再跟官方提供的摘要值对比，就能判断文件是否被篡改过 发送者 生成公钥&#x2F;密钥对：P和S 公开公钥P，保密密钥S 使用密钥S来加密消息M 发送给接收者S(M) 接收者 使用发送者的公钥来解密M&#x3D;P(S(M)) 2.2.4 RSA和DSARSA：RSA是目前最有影响力的公钥加密算法，它能够抵抗到目前为止已知的所有密码攻击，已被ISO推荐为公钥数据加密标准。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥 DSA：DSA是基于整数有限域离散对数难题的，其安全性与RSA相比差不多。DSA只是一种算法，和RSA不同之处在于它不能用作加密和解密，也不能进行密钥交换，只用于签名,它比RSA要快很多 2.3 单向哈希算法哈希算法：也称为散列算法，将任意数据缩小成固定大小的“指纹”，称为digest，即摘要 特性： 任意长度输入，固定长度输出 若修改数据，指纹也会改变，且有雪崩效应，数据的一点微小改变，生成的指纹值变化非常大。 无法从指纹中重新生成数据，即不要逆，具有单向性 功能：数据完整性 常见算法 md5: 128bits、sha1: 160bits、sha224 、sha256、sha384、sha512 常用工具 md5sum | sha1sum [ –check ] file openssl、gpg rpm -V 123456hash(data)--&gt;digest摘要,相当于指纹1 单向2 data 相同，digest必相同3 data不相同，digest必不相同4 hash算法固定，则digest的长度固定5 data发生轻微变化，而digest会发生巨大的变化 查看文件的哈希值 123#md5 以16进制显示, 32*4=128[root@centos7 ~]#md5sum /etc/hosts54fb6627dbaa37721048e4549db3224d /etc/hosts 2.4 综合应用多种加密算法2.4.1 实现数据加密对称加密和非对称加密 无法验证数据完整性和来源 123A--&gt;B加密：Key(data)+Pb(key) 解密：Sb(key)+Key(data) 2.4.2 实现数字签名不加密数据，可以保证数据来源的可靠性、数据的完整性和一致性 1data+Sa(hash(data)) #先哈希加密数据，再用A的私钥接着加密 2.4.3 综合加密和签名即实现数据加密，又可以保证数据来源的可靠性、数据的完整性和一致性 12#方法一Pb&#123;Sa[hash(data)]+data&#125; 12#方法二对称key&#123;Sa[hash(data)]+data&#125;+Pb(对称key) 2.5 密码交换密钥交换：IKE（ Internet Key Exchange ） 公钥加密：用目标的公钥加密对称密钥 DH (Deffie-Hellman)：生成对称（会话）密钥 DH 介绍 这个密钥交换方法，由惠特菲尔德·迪菲（Bailey Whitfield Diffie）和马丁·赫尔曼（MartinEdward Hellman）在1976年发表 它是一种安全协议，让双方在完全没有对方任何预先信息的条件下通过不安全信道建立起一个密钥，这个密钥一般作为“对称加密”的密钥而被双方在后续数据传输中使用。 DH数学原理是base离散对数问题。做类似事情的还有非对称加密类算法，如：RSA。 其应用非常广泛，在SSH、VPN、Https…都有应用，勘称现代密码基石 DH 实现过程： 123456A: g,p 协商生成公开的整数g, 大素数pB: g,pA:生成隐私数据:a (a&lt;p)，计算得出 g^a%p，发送给BB:生成隐私数据:b,(b&lt;p)，计算得出 g^b%p，发送给AA:计算得出 [(g^b%p)^a]%p = g^ab%p，生成为密钥B:计算得出 [(g^a%p)^b]%p = g^ab%p，生成为密钥 DH 特点 泄密风险：私密数据a，b在生成K后将被丢弃，因此不存在a，b过长时间存在导致增加泄密风险。 中间人攻击：由于DH在传输p，g时并无身份验证，所以有机会被实施中间人攻击，替换双方传输时的数据 范例 12345678910111213141516171819202122g=23p=5A:a=6g^a%p=23^6%5=4[(g^b%p)^a]%p=2^6%5=4B:b=15g^b%p=23^15%5=2[(g^a%p)^b]%p=4^15%5=4[root@centos8 ~]#echo 23^15%5|bc2[root@centos8 ~]#echo 23^6%5|bc4[root@centos8 ~]#echo 2^6%5|bc4[root@centos8 ~]#echo 4^15%5|bc4 3 CA和证书3.1 中间人攻击中间人截获服务器向客户端发送的真正公钥，将假公钥发送给客户端，让客户端用假公钥加密数据，从而中间人可以利用自己的私钥解密 并查看加密的数据，并篡改数据利用真公钥发送给服务器 3.2 CA和证书CA证书代表信息的真伪，通过CA证书，可以确定客户端收到的公钥是否是真的公钥，从而防止中间人攻击，实现公钥的安全交换 子CA证书由根CA证书颁发，根CA证书由自己给自己颁发 PKI：Public Key Infrastructure 公共密钥加密体系 签证机构：CA（Certificate Authority） 注册机构：RA 证书吊销列表：CRL 证书存取库： X.509：定义了证书的结构以及认证协议标准 版本号 序列号 签名算法 颁发者 有效期限 主体名称 证书类型： 证书授权机构的证书 服务器证书 用户证书 获取证书两种方法： 自签名的证书： 自已签发自己的公钥 使用证书授权机构：生成证书请求（csr）将证书请求csr发送给CACA签名颁发证书 自签名证书和根证书的区别 根证书（Root Certificate）就是自签名证书，不过签发机构不同，他有就有区别，它们之间有以下区别： 自签名证书（Self-Signed Certificate） 颁发者和使用者是同一个实体： 自签名证书是由实际使用该证书的实体（通常是个人、组织或设备）自行创建和签名的证书。颁发者和使用者是同一个实体，没有第三方 CA 参与。 信任度较低： 自签名证书在公共网络中信任度较低，因为它们没有受到受信任的第三方 CA 的验证。当客户端连接到使用自签名证书的服务时，通常会收到安全警告，用户需要手动确认是否信任该证书。 用途有限： 自签名证书通常用于内部测试、开发环境或局域网中，而不是在公共网络中使用。它们提供了加密通信的能力，但没有得到广泛信任。 根证书（Root Certificate） 由受信任的 CA 颁发： 根证书是由受信任的证书颁发机构（CA）签名并颁发的证书。CA 是一个受信任的实体，它通过验证证书请求者的身份，并签发数字证书。根证书是 CA 的根证书，它本身是自签名证书。 信任度高： 根证书由操作系统、浏览器等软件内置，因此被广泛信任。当使用者收到由受信任 CA 签发的证书时，不会收到安全警告，因为这些证书是受信任的。 广泛用于公共网络： 根证书和由它签发的中间证书（Intermediate Certificate）通常用于公共网络中，例如用于加密网站的 HTTPS 通信。这些证书能够建立安全的、受信任的通信连接。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"加密和安全","slug":"加密和安全","permalink":"https://aquapluto.github.io/tags/%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8/"}]},{"title":"nft","slug":"Linux/firewall/nft","date":"2025-08-21T03:02:22.000Z","updated":"2025-08-28T12:33:05.240Z","comments":true,"path":"Linux/firewall/nft/","permalink":"https://aquapluto.github.io/Linux/firewall/nft/","excerpt":"","text":"1 nft介绍nftables 是一个 netfilter 项目，旨在替换现有的 {ip,ip6,arp,eb}tables 框架，为 {ip,ip6}tables 提供一个新的包过滤框架、一个新的用户空间实用程序（nft）和一个兼容层。它使用现有的钩子、链接跟踪系统、用户空间排队组件和 netfilter 日志子系统。 nftables 主要由三个组件组成：内核实现、libnl netlink 通信和 nftables 用户空间。 其中内核提供了一个 netlink 配置接口以及运行时规则集，libnl 包含了与内核通信的基本函数，用户空间可以通过 nft 和用户进行交互。 2 nft相关概念nftables 和 iptables 一样，由表（table）、链（chain）和规则（rule）组成，其中表包含链，链包含规则，规则是真正的 action，规则由地址，接口，端口或包含当前处理数据包中的其他数据等表达式以及诸如drop, queue, continue等声明组成。 与 iptables 相比，nftables 主要有以下几个变化： iptables 规则的布局是基于连续的大块内存的，即数组式布局；而 nftables 的规则采用链式布局，即数组和链表的区别 iptables 大部分工作在内核态完成，如果要添加新功能，只能重新编译内核；而 nftables 的大部分工作是在用户态完成的，添加新功能更加容易，不需要改内核 nftables不包含任何内置表和链 拥有使用额外脚本的能力, 拥有一些高级的类似编程语言的能力，例如定义变量和包含外部文件 iptables 有内置的链，即使只需要一条链，其他的链也会跟着注册；而 nftables 不存在内置的链，可以按需注册。由于 iptables 内置了一个数据包计数器，所以即使这些内置的链是空的，也会带来性能损耗 简化了 IPv4&#x2F;IPv6 双栈管理 原生支持集合、字典和映射 nftables 的每个表只有一个地址簇，并且只适用于该簇的数据包。表可以指定五个簇中的一个： nftables簇 iptables命令行工具 ip IPv4 地址 iptables ip6 IPv6 地址 ip6tables inet IPv4 和 IPv6 地址 iptables和ip6tables arp 地址解析协议(ARP)地址 arptables bridge 处理桥接数据包 ebtables inet 同时适用于 IPv4 和 IPv6 的数据包，即统一了 ip 和 ip6 簇，可以更容易地定义规则，注：当没有指定地址簇时，默认为ip 链是用来保存规则的，和表一样，链也需要被显示创建，因为 nftables 没有内置的链。链有以下两种类型： 基本链 : 数据包的入口点，需要指定钩子类型和优先级，相当于内置链 常规链 : 不需要指定钩子类型和优先级，可以用来做跳转，从逻辑上对规则进行分类，类似于自定义链 3 nft常见用法3.1 nft命令格式1234567891011121314151617[root@centos8 ~]#nft --helpUsage: nft [ options ] [ cmds... ]选项说明-h, --help 显示帮书-v, --version 显示版本信息-c, --check 检查命令的有效性，而不实际应用更改。-f, --file &lt;filename&gt; 包含文件内容&lt;filename&gt;-i, --interactive 从命令行读取输入-j, --json 以JSON格式化输出-n, --numeric 指定一次后，以数字方式显示网络地址（默认行为）。指定两次以数字方式显示Internet服务（端口号）。指定三次以数字方式显示协议，用户ID和组ID。-s, --stateless 省略规则集的有状态信息-N 将IP地址转换为名称。-a, --handle 显示规则句柄handle-e, --echo Echo what has been added, inserted or replaced.-I, --includepath &lt;directory&gt; 添加&lt;directory&gt;目录到包含文件的搜索路径中。默认为: /etc--debug &lt;level [,level...]&gt; 添加调试,在level处(scanner, parser, eval, netlink, mnl,proto-ctx, segtree, all) nft 命令基本格式 nft 操作符 操作目标 操作内容 123456789101 操作符: 增,删,改,查,清除,插入,创建表操作：add,delete,list,flush链操作：add,delete,rename,list,flush,create规则：add,delete,insert2 操作目标: 簇,表,链,规则链类型：filter,route,nat链钩子：hook3 操作内容：... 规则选项 12345678910accept 接受 接受包 停止处理drop 丢弃 丢弃包 停止处理reject 拒绝 驳回包 停止处理queue 队列 发送包到用户空间程序 停止处理continue 继续 继续处理包 return 返回 发送到调用的规则链进行处理jump 跳跃 发送到指定的规则链进行处理 当完成时或执行了返回的声明，返回到调用的规则链goto 转到 发送到指定的规则链进行处理 不返回到调用的规则链limit limit 达到接收包的匹配限制 则根据规则处理包log log 日志记录包 继续处理 3.2 查看1234567nft list ruleset # 列出所有规则nft list tables # 列出所有表nft list table filter # 列出ip簇的filter表nft list table inet filter # 列出inet簇的filter表nft list chain filter INPUT # 列出filter表input链以上命令后面也可以加 -nn 用于不解析ip地址和端口加 -a 用于显示 handles 范例：CentOS8.1版才支持以下操作,CentOS8.2以后版本默认无任何规则 1234567891011121314151617181920212223242526272829303132333435363738394041[root@centos8 ~]#nft list tables[root@centos8 ~]#vim /etc/sysconfig/nftables.conf#删除此行前的注释include &quot;/etc/nftables/inet-filter.nft&quot; [root@centos8 ~]#systemctl restart nftables.service[root@centos8 ~]#nft list tablestable inet filter#默认为ip簇，无规则[root@centos8 ~]#nft list table filterError: Could not process rule: No such file or directorylist table filter ^^^^^^ #指定inet簇才有规则[root@centos8 ~]#nft list table inet filtertable inet filter &#123; chain input &#123; type filter hook input priority 0; policy accept; &#125; chain forward &#123; type filter hook forward priority 0; policy accept; &#125; chain output &#123; type filter hook output priority 0; policy accept; &#125;&#125;[root@centos8 ~]#nft list rulesettable inet filter &#123; chain input &#123; type filter hook input priority 0; policy accept; &#125; chain forward &#123; type filter hook forward priority 0; policy accept; &#125; chain output &#123; type filter hook output priority 0; policy accept; &#125;&#125; 3.3 增加 增加表：nft add table fillter 增加链：nft add chain filter input &#123; type filter hook input priority 0 ; &#125; # 要和hook（钩子）相关连 增加规则：nft add rule filter input tcp dport 22 accept 3.4 删 只需要把上面的 add 改为 delete 即可 3.5 改 更改链名用rename 更改规则用replace 4 nft实战案例4.1 创建表和删除表12345678[root@centos8 ~]#nft add table inet test_table[root@centos8 ~]#nft list tablestable inet filtertable inet test_table[root@centos8 ~]#nft delete table inet test_table[root@centos8 ~]#nft list tablestable inet filter[root@centos8 ~]#nft add table inet test_table 列出所有的规则 1[root@centos8 ~]#nft list ruleset 4.2 创建链现在表中还没有任何规则，需要创建一个链来保存规则 4.2.1 创建基本链1[root@centos8 ~]#nft add chain inet test_table test_filter_input_chain &#123; type filter hook input priority 0 \\; &#125; 反斜线（ \\ ）用来转义，这样 shell 就不会将分号解释为命令的结尾。 priority 采用整数值，可以是负数，值较小的链优先处理 4.2.2 创建常规链1[root@centos8 ~]#nft add chain inet test_table test_chain 4.2.3 列出链1234567[root@centos8 ~]#nft list table inet test_table[root@centos8 ~]#nft list chain inet test_table test_filter_input_chain[root@centos8 ~]#nft list chain inet test_table test_chain[root@centos8 ~]#nft list ruleset 4.3 创建规则4.3.1 创建常规链规则有了表和链之后，就可以创建规则了，规则由语句或表达式构成，包含在链中 123456789101112#创建常规链的规则[root@centos8 ~]#nft add rule inet test_table test_chain tcp dport http reject[root@centos8 ~]#nft list chain inet test_table test_chaintable inet test_table &#123; chain test_chain &#123; tcp dport http reject &#125;&#125;#常规链规则默认不生效[root@centos7 ~]#curl 10.0.0.8rft Http Server add 表示将规则添加到链的末尾，如果想将规则添加到链的开头，可以使用 insert 1[root@centos8 ~]# nft insert rule inet test_table test_chain tcp dport mysql reject 列出规则 123[root@centos8 ~]#nft list chain inet test_table test_chain[root@centos8 ~]#nft list table inet test_table 4.3.2 创建基本链规则12345678910111213141516[root@centos8 ~]#nft add rule inet test_table test_filter_input_chain tcp dporthttp reject[root@centos8 ~]#nft add rule inet test_table test_filter_input_chain ip saddr10.0.0.6 reject[root@centos8 ~]#nft list chain inet test_table test_filter_input_chaintable inet test_table &#123; chain test_filter_input_chain &#123; type filter hook input priority 0; policy accept; tcp dport http reject ip saddr 10.0.0.6 reject &#125;&#125;[root@centos7 ~]#curl 10.0.0.8curl: (7) Failed connect to 10.0.0.8:80; Connection refused 4.4 插入链的指定位置将规则插入到链的指定位置，有两种方法： 4.4.1 使用 index 来指定规则的索引index 类似于 iptables 的 -I 选项， index 的值是从 0 开始表示第一条rule index 必须指向一个存在的规则，比如 nft insert rule … index 0 就是非法的。 add 表示新规则添加在索引位置的规则后面 insert 表示新规则添加在索引位置的规则前面 12345[root@centos8 ~]#nft insert rule inet test_table test_filter_input_chain index 0 tcp dport mysql reject[root@centos8 ~]#nft list chain inet test_table test_filter_input_chain[root@centos8 ~]#nft insert rule inet test_table test_filter_input_chain index 1 udp dport 123 accept[root@centos8 ~]#nft list chain inet test_table test_filter_input_chain 4.4.2 使用 handle 来指定规则的句柄在 nftables 中，句柄值是固定不变的，除非规则被删除，这就为规则提供了稳定的索引。而 index 的值是可变的，只要有新规则插入，就有可能发生变化。一般建议使用 handle 来插入新规则。 add 表示新规则添加在索引位置的规则后面， insert 表示新规则添加在索引位置的规则前面。 handle 的值可以通过参数 –handle 或者 -a 获取 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@centos8 ~]#nft -a list chain inet test_table test_filter_input_chaintable inet test_table &#123; chain test_filter_input_chain &#123; # handle 2 type filter hook input priority 0; policy accept; tcp dport mysql reject # handle 7 udp dport ntp accept # handle 8 tcp dport http reject # handle 6 &#125;&#125;[root@centos8 ~]#nft add rule inet test_table test_filter_input_chain handle 7 tcp dport ftp reject[root@centos8 ~]#nft -a list chain inet test_table test_filter_input_chaintable inet test_table &#123; chain test_filter_input_chain &#123; # handle 2 type filter hook input priority 0; policy accept; tcp dport mysql reject # handle 7 tcp dport ftp reject # handle 9 udp dport ntp accept # handle 8 tcp dport http reject # handle 6 &#125;&#125;[root@centos8 ~]#nft insert rule inet test_table test_filter_input_chain handle 8 udp dport 8080 reject[root@centos8 ~]#nft -a -nn list rulesettable inet filter &#123; # handle 4 chain input &#123; # handle 1 type filter hook input priority 0; policy accept; &#125; chain forward &#123; # handle 2 type filter hook forward priority 0; policy accept; &#125; chain output &#123; # handle 3 type filter hook output priority 0; policy accept; &#125;&#125;table inet test_table &#123; # handle 7 chain test_chain &#123; # handle 1 tcp dport 3306 reject # handle 5 tcp dport 80 reject # handle 4 &#125; chain test_filter_input_chain &#123; # handle 2 type filter hook input priority 0; policy accept; tcp dport 3306 reject # handle 7 tcp dport 21 reject # handle 9 udp dport 8080 reject # handle 10 udp dport 123 accept # handle 8 tcp dport 80 reject # handle 6 &#125;&#125; 可以在创建规则时就获取到规则的句柄值，在创建规则时同时加上参数 –echo或者-e 和 –handle 123456789101112131415[root@centos8 ~]#nft -a -e add rule inet test_table test_filter_input_chain tcp dport 6379 rejectadd rule inet test_table test_filter_input_chain tcp dport 6379 reject # handle11[root@centos8 ~]#nft -a list chain inet test_table test_filter_input_chaintable inet test_table &#123; chain test_filter_input_chain &#123; # handle 2 type filter hook input priority 0; policy accept; tcp dport mysql reject # handle 7 tcp dport ftp reject # handle 9 udp dport http-alt reject # handle 10 udp dport ntp accept # handle 8 tcp dport http reject # handle 6 tcp dport 6379 reject # handle 11 &#125;&#125; 4.5 删除规则4.5.1 删除单个规则单个规则只能通过其句柄删除，首先需要找到想删除的规则句柄 1[root@centos8 ~]#nft --handle list ruleset 然后使用句柄值来删除该规则 1[root@centos8 ~]#nft delete rule inet test_table test_filter_input_chain handle8 4.5.2 删除所有规则12[root@centos8 ~]#nft flush ruleset[root@centos8 ~]#nft list ruleset 4.5 列出规则可以列出所有规则，也可以列出规则的一部分 4.5.1 列出所有规则1[root@centos8 ~]#nft list ruleset 4.5.2 列出指定表中的所有规则1[root@centos8 ~]#nft list table inet test_table 4.5.3 列出指定链中的所有规则1[root@centos8 ~]#nft list chain inet test_table test_filter_input_chain 5 备份还原规则都是临时的，要想永久生效，可以将规则备份，重启后自动加载恢复 查看service文件 1[root@centos8 ~]#cat /lib/systemd/system/nftables.service 备份配置并还原 1234567891011#备份至文件中[root@centos8 ~]#nft list ruleset[root@centos8 ~]#nft list ruleset &gt; /etc/sysconfig/nftables.conf#删除所有规则[root@centos8 ~]#nft flush ruleset[root@centos8 ~]#nft list ruleset#重新启动后全部还原[root@centos8 ~]#systemctl restart nftables.service[root@centos8 ~]#nft list ruleset 启用指定的配置文件 12345[root@centos8 ~]#cat nftables2.conf#-f 指定规则配置文件，如果已经有规则，是追加至现有规则后[root@centos8 ~]#nft -f nftables2.conf[root@centos8 ~]#nft list ruleset 6 迁移iptables规则到nft1.若要将现有规则保存到文件，请运行以下命令 1# iptables-save &gt; rules.iptables 2.通过 scp 或 ftp 将 step1 文件移动到 CentOS&#x2F;RHEL 8 服务器。也可以使用 vi 编辑器来从 CentOS&#x2F;RHEL 6 或 7 计算机复制内容。 3.运行以下命令，在 CentOS&#x2F;RHEL 8 上使用 iptables 规则生成 nft rules 文件文件 1# iptables-restore-translate -f rules.iptables &gt; rules.nft 4.在 CentOS&#x2F;RHEL 8 机器中加载规则，确保 nftables 服务在系统 1# nft -f rules.nft # load the rule via nft to nftables. 5.在 CentOS&#x2F;RHEL 8 Server 中显示规则 1# nft list ruleset 也可以看到规则已从 CentOS&#x2F;RHEL 6 或 7 迁移到 CentOS&#x2F;RHEL 8 服务器并且也可以测试它们","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"防火墙","slug":"防火墙","permalink":"https://aquapluto.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"firewalld","slug":"Linux/firewall/firewalld","date":"2025-08-21T03:02:14.000Z","updated":"2025-08-28T12:33:05.225Z","comments":true,"path":"Linux/firewall/firewalld/","permalink":"https://aquapluto.github.io/Linux/firewall/firewalld/","excerpt":"","text":"1 firewalld介绍firewalld是CentOS 7.0新推出的管理netfilter的用户空间软件工具,也被ubuntu18.04版以上所支持(aptinstall firewalld安装即可) firewalld是配置和监控防火墙规则的系统守护进程。可以实iptables,ip6tables,ebtables的功能 firewalld服务由firewalld包提供 firewalld支持划分区域zone,每个zone可以设置独立的防火墙规则 归入zone顺序： 先根据数据包中源地址，将其纳为某个zone 纳为网络接口所属zone 纳入默认zone，默认为public zone,管理员可以改为其它zone 网卡默认属于public zone,lo网络接口属于trusted zone firewalld zone 分类 zone名称 默认配置 trusted 允许所有流量 home 拒绝除和传出流量相关的，以及ssh,mdsn,ipp-client,samba-client,dhcpv6-client预定义服务之外其它所有传入流量 internal 和home相同 work 拒绝除和传出流量相关的，以及ssh,ipp-client,dhcpv6-client预定义服务之外的其它所有传入流量 public 拒绝除和传出流量相关的，以及ssh,dhcpv6-client预定义服务之外的其它所有传入流量，新加的网卡默认属于public zone external 拒绝除和传出流量相关的，以及ssh预定义服务之外的其它所有传入流量，属于external zone的传出ipv4流量的源地址将被伪装为传出网卡的地址。 dmz 拒绝除和传出流量相关的，以及ssh预定义服务之外的其它所有传入流量 block 拒绝除和传出流量相关的所有传入流量 drop 拒绝除和传出流量相关的所有传入流量（甚至不以ICMP错误进行回应） 预定义服务 服务名称 配置 ssh Local SSH server. Traffic to 22&#x2F;tcp dhcpv6-client Local DHCPv6 client. Traffic to 546&#x2F;udp on the fe80::&#x2F;64 IPv6 network ipp-client Local IPP printing. Traffic to 631&#x2F;udp. samba-client Local Windows file and print sharing client. Traffic to 137&#x2F;udp and 138&#x2F;udp. mdns Multicast DNS (mDNS) local-link name resolution. Traffic to 5353&#x2F;udp to the224.0.0.251 (IPv4) or ff02::fb (IPv6) multicast addresses. firewalld预定义服务配置 firewall-cmd –get-services 查看预定义服务列表 &#x2F;usr&#x2F;lib&#x2F;firewalld&#x2F;services&#x2F;*.xml预定义服务的配置 firewalld 三种配置方法 firewall-config 图形工具: 需安装 firewall-config包 firewall-cmd 命令行工具: firewalld包,默认安装 &#x2F;etc&#x2F;firewalld&#x2F; 配置文件，一般不建议,如:&#x2F;etc&#x2F;firewalld&#x2F;zones&#x2F;public.xml 2 firewall-cmd命令firewall-cmd 格式 1firewall-cmd [OPTIONS...] 常见选项 123456789101112131415161718192021222324252627282930313233343536373839404142434445--state #查看服务运行状态 --reload #重载，修改后只是在当前运行环境下生效，如果想还原回去之前的配置，可以使用此选项；删除当前运行时配置，应用加载永久配置--complete-reload #完全重载--runtime-to-permanent #将当前运行状态的配置永久保存--check-config #检查规则配置是否出错--get-log-denied #显示日记记录规则--set-log-denied= #设置日志记录规则 all|unicast|broadcast|multicast|off--permanent #设置永久生效规则时加上此项，如果没有此项，则更改的都是临时生效规则--get-zones #列出所有可用区域--get-default-zone #查询默认区域--set-default-zone=&lt;ZONE&gt; #设置默认区域--get-active-zones #列出当前正使用的区域--get-services #显示所有己定义的 services,每一个 services 对应一个或多个端口规则，多个 service 组成 zone--get-icmptypes #显示icmp协议类型--get-zone-of-interface= #显示指定设备的 zone--list-all-zones #列出每个zone中的所有规则--new-zone= #添加一个新的zone--new-zone-from-file= #从指定文件中读取规则，添加新zone--delete-zone= #删除指定zone--zone= #指定zone,配合其它选项--info-zone= #查看指定zone运行情况--add-service=&lt;SERVICE&gt; [--zone=&lt;ZONE&gt;] #允许服务的流量通过，如果无--zone= 选项，使用默认区域--remove-service=&lt;SERVICE&gt; [--zone=&lt;ZONE&gt;] #从区域中删除指定服务，禁止该服务流量，如果无--zone= 选项，使用默认区域--new-service= #添加一个新的 service--new-service-from-file= #从文件中添加一个新的 serivce--list-services #查看开放的服务--delete-service= #删除 service--info-service= #输出 info 相关信息--add-source=&lt;CIDR&gt;[--zone=&lt;ZONE&gt;] #添加源地址的流量到指定区域，如果无--zone= 选项，使用默认区域--remove-source=&lt;CIDR&gt; [--zone=&lt;ZONE&gt;] #从指定区域删除源地址的流量，如无--zone= 选项，使用默认区域--add-interface=&lt;INTERFACE&gt;[--zone=&lt;ZONE&gt;] #添加来自于指定接口的流量到特定区域，如果无--zone= 选项，使用默认区域--change-interface=&lt;INTERFACE&gt;[--zone=&lt;ZONE&gt;] #改变指定接口至新的区域，如果无--zone=选项，使用默认区域--add-port=&lt;PORT/PROTOCOL&gt;[--zone=&lt;ZONE&gt;] #允许指定端口和协议的流量，如果无--zone= 选项，使用默认区域--remove-port=&lt;PORT/PROTOCOL&gt;[--zone=&lt;ZONE&gt;] #从区域中删除指定端口和协议，禁止该端口的流量，如果无--zone= 选项，使用默认区域--list-ports #查看开放的端口--list-all [--zone=&lt;ZONE&gt;] #列出指定区域的所有配置信息，包括接口，源地址，端口，服务等，如果无--zone= 选项，使用默认区域 启动firewall 1syscemctl start firewall 范例： 1234567891011121314#查看默认zonefirewall-cmd --get-default-zone#默认zone设为dmzfirewall-cmd --set-default-zone=dmz#在internal zone中增加源地址192.168.0.0/24的永久规则firewall-cmd --permanent --zone=internal --add-source=192.168.0.0/24#在internal zone中增加协议mysql的永久规则firewall-cmd --permanent --zone=internal --add-service=mysql#加载新规则以生效firewall-cmd --reload 范例：查看 12345678910111213141516171819202122232425262728293031323334353637383940#查看服务当前运行状态[root@rocky86 ~]# firewall-cmd --staterunning#检查配置[root@rocky86 ~]# firewall-cmd --check-configsuccess#查看默认 Zone[root@rocky86 ~]# firewall-cmd --get-default-zonepublic#显示当前默认的zone中的 service[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client ssh#结果同上一条[root@rocky86 ~]# firewall-cmd --zone=public --list-servicescockpit dhcpv6-client ssh#显示指定zone中的 service[root@rocky86 ~]# firewall-cmd --zone=home --list-servicescockpit dhcpv6-client mdns samba-client ssh#显示所有 zones[root@rocky86 ~]# firewall-cmd --get-zonesblock dmz drop external home internal libvirt nm-shared public trusted work#显示当前正在使用的 zone[root@rocky86 ~]# firewall-cmd --get-active-zonesblock interfaces: eth0 eth1 #生效的网络设备 #显示zone中的自定义规则[root@rocky86 ~]# firewall-cmd --zone=block --list-ports8080/tcp#显示工作在指定设备上的 zone[root@rocky86 ~]# firewall-cmd --get-zone-of-interface=eth0block 范例：查看 services 12345678910111213141516#查看所有可用 services[root@rocky86 ~]# firewall-cmd --get-services#查看 service 详细信息[root@rocky86 ~]# firewall-cmd --info-service=ssh#查看 service 描述信息 [root@rocky86 ~]# firewall-cmd --permanent --service=ssh --get-description#查看 service 简略描述[root@rocky86 ~]# firewall-cmd --permanent --service=ssh --get-short SSH#查看 service 端口[root@rocky86 ~]# firewall-cmd --permanent --service=ssh --get-ports 22/tcp 范例：查看详细信息 12345678910111213141516171819202122#查看默认Zone中的所有内容[root@rocky86 ~]# firewall-cmd --list-allblock (active) target: %%REJECT%% #目标 icmp-block-inversion: no #决定 icmp-blocks interfaces: eth0 eth1 #生效的网络设备 sources: #来源，IP或MAC services: http ssh #放行的服务 ports: #允许的目标端口，即本地开放的端口 protocols: #允许通过的协议 forward: no #允许转发的端口 masquerade: no #是否允许伪装（yes/no），可改写来源IP地址及mac地址 forward-ports: #允许转发的端口 source-ports: #允许的源端口 icmp-blocks: #ICMP类型，配合 icmp-block-inversion=no/yes一起使用 rich rules: #富规则 #查看指定zone中的所有内容 [root@rocky86 ~]# firewall-cmd --list-all --zone=block#查看所有 zone 的详细规则[root@rocky86 ~]# firewall-cmd --list-all-zones 范例：修改默认 Zone 123456789101112131415161718192021222324#查看默认 zone[root@rocky86 ~]# firewall-cmd --get-default-zonepublic#修改默认zone[root@rocky86 ~]# firewall-cmd --set-default-zone=blocksuccess#再次查看，修改成功[root@rocky86 ~]# firewall-cmd --get-default-zoneblock#block Zone 中没有任何开启的服务[root@rocky86 ~]# firewall-cmd --list-services[root@rocky86 ~]##在Windows下测试，SSH无法连接，但己连接的不受影响[C:\\~]$ ssh root@10.0.0.157Connecting to 10.0.0.157:22...Could not connect to &#x27;10.0.0.157&#x27; (port 22): Connection failed.#WEB服务不可用C:\\Users\\44301&gt;curl 10.0.0.157curl: (28) Failed to connect to 10.0.0.157 port 80 after 21022 ms: Timed out 范例：修改指定设备的zone 12345678[root@rocky86 ~]# firewall-cmd --get-zone-of-interface=eth0public[root@rocky86 ~]# firewall-cmd --change-interface=eth0 --zone=blocksuccess[root@rocky86 ~]# firewall-cmd --get-zone-of-interface=eth0block 范例：修改 Zone 中的 Service 12345678910111213141516171819202122232425#查看默认 zone[root@rocky86 ~]# firewall-cmd --get-default-zoneblock#添加 ssh 服务，不指定 zone，表示加到默认zone中[root@rocky86 ~]# firewall-cmd --add-service=sshsuccess#查看zone中的 service[root@rocky86 ~]# firewall-cmd --list-servicessh#再次测试，SSH服务可用，但WEB服务不通#添加 web 服务放行规则[root@rocky86 ~]# firewall-cmd --zone=block --add-service=httpsuccess#再次查看[root@rocky86 ~]# firewall-cmd --list-servicehttp ssh#测试，WEB服务可用C:\\Users\\44301&gt;curl 10.0.0.157&lt;h1&gt;test page from 10.0.0.157&lt;/h1&gt; 范例：增加非 service 规则 1234[root@rocky86 ~]# firewall-cmd --zone=block --add-port=8080/tcpsuccess[root@rocky86 ~]# firewall-cmd --zone=block --list-ports 8080/tcp 范例：自定义 zones 12345678910111213141516171819#自定义zone必须要加 --permanent 选项[root@rocky86 ~]# firewall-cmd --permanent --new-zone=test-zonesuccess#往zone 中添加 service[root@rocky86 ~]# firewall-cmd --zone=test-zone --add-service=sshError: INVALID_ZONE: test-zone#需要先 reload[root@rocky86 ~]# firewall-cmd --reloadsuccess#往 zone 中增加 service[root@rocky86 ~]# firewall-cmd --zone=test-zone --add-service=sshsuccess#查看[root@rocky86 ~]# firewall-cmd --zone=test-zone --list-servicesssh 范例：自定义 service 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@rocky86 ~]# firewall-cmd --new-service=test-serviceusage: see firewall-cmd man pageOption can be used only with --permanent.#添加 service[root@rocky86 ~]# firewall-cmd --permanent --new-service=test-servicesuccess#查看[root@rocky86 ~]# firewall-cmd --get-services | grep test-service[root@rocky86 ~]# firewall-cmd --permanent --get-services | grep test-servicetest-service#重载[root@rocky86 ~]# firewall-cmd --reloadsuccess#设置service的desc[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --set-description=&quot;test desc&quot;success#添加port[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --add-port=8080/tcpsuccess[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --add-port=8081/tcpsuccess#查看 port[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-ports8080/tcp 8081/tcp#查看 ports[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-port8080/tcp 8081/tcp#添加 protocol[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --add-protocol=stpsuccess#查看[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-protocolstp 范例：删除 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#删除protocol[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-protocolstp[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --remove-protocol=stpsuccess[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-protocol#删除ports[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-ports8080/tcp 8081/tcp[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --remove-port=8080/tcpsuccess[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --remove-port=8081/tcpsuccess[root@rocky86 ~]# firewall-cmd --permanent --service=test-service --get-ports#删除 services[root@rocky86 ~]# firewall-cmd --permanent --delete-service=test-servicesuccess[root@rocky86 ~]# firewall-cmd --permanent --info-service=test-serviceError: INVALID_SERVICE: test-service[root@rocky86 ~]# firewall-cmd --info-service=test-servicetest-serviceports: 8080/tcp 8081/tcpprotocols:source-ports:modules:destination:includes:helpers:#reload[root@rocky86 ~]# firewall-cmd --reloadsuccess[root@rocky86 ~]# firewall-cmd --info-service=test-serviceError: INVALID_SERVICE: test-service#删除zone[root@rocky86 ~]# firewall-cmd --permanent --delete-zone=test-zonesuccess[root@rocky86 ~]# firewall-cmd --permanent --get-zonesblock dmz drop external home internal libvirt nm-shared public trusted work[root@rocky86 ~]# firewall-cmd --get-zonesblock dmz drop external home internal libvirt nm-shared public test-zone trusted work#需要 reload[root@rocky86 ~]# firewall-cmd --get-zonesblock dmz drop external home internal libvirt nm-shared public trusted work#己删除[root@rocky86 ~]# firewall-cmd --get-zonesblock dmz drop external home internal libvirt nm-shared public trusted work 范例：持久化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@rocky86 ~]# firewall-cmd --add-service=httpsuccess[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client http ssh#重启服务[root@rocky86 ~]# systemctl restart firewalld.service#http service 丢失[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client ssh#添加的时候使用 --permanent 选项，只保存，但当前不生效[root@rocky86 ~]# firewall-cmd --permanent --add-service=httpsuccess#添加成功[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client ssh#但当前状态看不到[root@rocky86 ~]# firewall-cmd --permanent --list-servicescockpit dhcpv6-client http ssh#reload 或 重启服务[root@rocky86 ~]# systemctl restart firewalld.service[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client http ssh#添加 https[root@rocky86 ~]# firewall-cmd --add-service=httpssuccess#当前可见[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client http https ssh#永久状态不可见[root@rocky86 ~]# firewall-cmd --permanent --list-servicescockpit dhcpv6-client http ssh#将当前状态永久保存[root@rocky86 ~]# firewall-cmd --runtime-to-permanentsuccess#查看[root@rocky86 ~]# firewall-cmd --permanent --list-servicescockpit dhcpv6-client http https ssh#重启[root@rocky86 ~]# systemctl restart firewalld.service#查看[root@rocky86 ~]# firewall-cmd --list-servicescockpit dhcpv6-client http https ssh 范例：配置firewalld 12345678910systemctl mask iptablessystemctl mask ip6tablessystemctl status firewalldsystemctl enable firewalldsystemctl start firewalldfirewall-cmd --get-default-zonefirewall-cmd --set-default-zone=publicfirewall-cmd --permanent --zone=public --list-allfirewall-cmd --permanent --zone=public --add-port 8080/tcpfirewall-cmd ---reload 3 其它规则当基本firewalld语法规则不能满足要求时，可以使用以下更复杂的规则 rich-rules 富规则，功能强,表达性语言 Direct configuration rules 直接规则，灵活性差, 帮助：man 5 firewalld.direct 3.1 管理rich规则rich规则比基本的firewalld语法实现更强的功能，不仅实现允许&#x2F;拒绝，还可以实现日志syslog和auditd，也可以实现端口转发，伪装和限制速率 规则实施顺序： 该区域的端口转发，伪装规则 该区域的日志规则 该区域的允许规则 该区域的拒绝规则 每个匹配的规则生效，所有规则都不匹配，该区域默认规则生效 rich语法 1234567891011121314151617181920rule [source]源地址 source [not] address=&quot;address[/mask]&quot;|mac=&quot;mac-address&quot;|ipset=&quot;ipset&quot; [destination]目标 destination [not] address=&quot;address[/mask]&quot; service|port|......过滤规则service|port|protocol|icmp-block|icmp-type|masquerade|forward-port|source-port#service name=&quot;service name&quot;#port port=&quot;port value&quot; protocol=&quot;tcp|udp&quot;#protocol value=&quot;protocol value&quot;，支持的 protocol 见/etc/protocols#icmp-block name=&quot;icmptype name&quot;，支持的值可用 firewall-cmd --get-icmptypes 命令查看#icmp-type name=&quot;icmptype name&quot;，支持的值可用 firewall-cmd --get-icmptypes 命令查看#masquerade#forward-port port=&quot;port&quot; protocol=&quot;tcp|udp&quot; to-port=&quot;port&quot; to-addr=&quot;address&quot;#source-port port=&quot;port value&quot; protocol=&quot;tcp|udp&quot; [log]将被匹配到的数据记录到日志 log [prefix=&quot;prefix text&quot;] [level=&quot;log level&quot;][limit value=&quot;rate/duration&quot;] [audit]audit [limit value=&quot;rate/duration&quot;] [accept|reject|drop] 格式 12345firewall-cmd [OPTIONS...]--list-rich-rules #列出 rich rule--add-rich-rule= #添加 rich rule--remove-rich-rule= #移除 rich rule--query-rich-rule= #查询 rich rule 3.2 rich规则实现拒绝从192.168.0.100的所有流量，当address 选项使用source 或 destination时，必须用family&#x3D; ipv4|ipv6 1firewall-cmd --permanent --zone=public --add-rich-rule=&#x27;rule family=ipv4 source address=192.168.0.100/32 reject&#x27; 限制每分钟只有两个连接到ftp服务 1firewall-cmd --add-rich-rule=‘rule service name=ftp limit value=2/m accept’ 抛弃esp（ IPsec 体系中的一种主要协议）协议的所有数据包 1firewall-cmd --permanent --add-rich-rule=&#x27;rule protocol value=esp drop&#x27; 接受所有192.168.1.0&#x2F;24子网端口5900-5905范围的TCP流量 1firewall-cmd --permanent --zone=vnc --add-rich-rule=&#x27;rule family=ipv4 source address=192.168.1.0/24 port port=5900-5905 protocol=tcp accept&#x27; 限制来自10.0.0.150 的 PING 1[root@rocky86 ~]# firewall-cmd --add-rich-rule=&#x27;rule family=ipv4 source address=10.0.0.150/32 protocol value=icmp limit value=3/m accept&#x27; rich日志规则 12345log [prefix=&quot;&lt;PREFIX TEXT&gt;&quot; [level=&lt;LOGLEVEL&gt;] [limit value=&quot;&lt;RATE/DURATION&gt;&quot;]&lt;LOGLEVEL&gt; 可以是emerg,alert, crit, error, warning, notice, info, debug.&lt;DURATION&gt; s：秒, m：分钟, h：小时, d：天audit [limit value=&quot;&lt;RATE/DURATION&gt;&quot;] 范例 1234567891011#接受ssh新连接，记录日志到syslog的notice级别，每分钟最多三条信息firewall-cmd --permanent --zone=work --add-rich-rule=&#x27;rule service name=&quot;ssh&quot;log prefix=&quot;ssh &quot; level=&quot;notice&quot; limit value=&quot;3/m&quot; accept#从2001:db8::/64子网的DNS连接在5分钟内被拒绝，并记录到日志到audit,每小时最大记录一条信息firewall-cmd --add-rich-rule=&#x27;rule family=ipv6 source address=&quot;2001:db8::/64&quot;service name=&quot;dns&quot; audit limit value=&quot;1/h&quot; reject&#x27; --timeout=300firewall-cmd --permanent --add-rich-rule=&#x27;rule family=ipv4 source address=172.25.X.10/32 service name=&quot;http&quot; log level=notice prefix=&quot;NEW HTTP &quot; limit value=&quot;3/s&quot; accept&#x27;firewall-cmd --reloadtail -f /var/log/messagescurl http://serverX.example.com 3.3 伪装和端口转发NAT网络地址转换，firewalld支持伪装和端口转发两种NAT方式 伪装NAT 1234firewall-cmd --permanent --zone=&lt;ZONE&gt; --add-masqueradefirewall-cmd --query-masquerade #检查是否允许伪装firewall-cmd --add-masquerade #允许防火墙伪装IPfirewall-cmd --remove-masquerade #禁止防火墙伪装IP 范例 123firewall-cmd --add-rich-rule=&#x27;rule family=ipv4 source address=192.168.0.0/24 masquerade&#x27;等价于iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE 端口转发：将发往本机的特定端口的流量转发到本机或不同机器的另一个端口。通常要配合地址伪装才能实现 1firewall-cmd --permanent --zone=&lt;ZONE&gt; --add-forward-port=port=&lt;PORTNUMBER&gt;:proto=&lt;PROTOCOL&gt;[:toport=&lt;PORTNUMBER&gt;][:toaddr=] 说明：toport= 和 &#96;toaddr&#x3D; 至少要指定一个 范例： 1234#转发传入的连接9527/TCP，到防火墙的80/TCP到public zone 的192.168.0.254firewall-cmd --add-masquerade 启用伪装firewall-cmd --zone=public --add-forward-port=port=9527:proto=tcp:toport=80:toaddr=192.168.0.254 rich规则的port转发语法 1forward-port port=&lt;PORTNUM&gt; protocol=tcp|udp [to-port=&lt;PORTNUM&gt;] [to-addr=&lt;ADDRESS&gt;] 范例 1234567#转发从192.168.0.0/24来的，发往80/TCP的流量到防火墙的端口8080/TCPfirewall-cmd --zone=work --add-rich-rule=&#x27;rule family=ipv4 source address=192.168.0.0/24 forward-port port=80 protocol=tcp to-port=8080&#x27;firewall-cmd --permanent --add-rich-rule &#x27;rule family=ipv4 source address=172.25.X.10/32 forward-port port=443 protocol=tcp to-port=22&#x27;firewall-cmd --reloadssh -p 443 serverX.example.com 范例：限制ssh服务非标准端口访问 1234567891011121314151617cp /usr/lib/firewalld/services/ssh.xml /etc/firewalld/services/ssh.xmlvim /etc/firewalld/services/ssh.xml&lt;port protocol=&quot;tcp&quot; port=&quot;999&quot;/&gt;systemctl restart sshd.servicesystemctl status -l sshd.servicesealert -a /var/log/audit/audit.logsemanage port -a -t ssh_port_t -p tcp 999systemctl restart sshd.servicess -tulpn | grep sshdfirewall-cmd --permanent --zone=work --add-source=172.25.X.0/24firewall-cmd --permanent --zone=work --add-port=999/tcpfirewall-cmd --reload","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"防火墙","slug":"防火墙","permalink":"https://aquapluto.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"iptables","slug":"Linux/firewall/iptables","date":"2025-08-21T03:02:08.000Z","updated":"2025-08-28T12:33:05.228Z","comments":true,"path":"Linux/firewall/iptables/","permalink":"https://aquapluto.github.io/Linux/firewall/iptables/","excerpt":"","text":"1 iptables的组成iptables由五个表table和五个链chain以及一些规则组成 链 chain： 内置链：对应内核中的每一个勾子函数 （INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING） 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制；只有Hook钩子调用自定义链时，才生效 五个表table：filter、nat、mangle、raw、security filter：过滤规则表，根据预定义的规则过滤符合条件的数据包，默认表，实现防火墙功能 nat：network address translation 地址转换规则表，实现共享上网，端口和IP映射 mangle：修改数据标记位规则表，即对数据包进行重构或修改，比如服务类型、TTL（生存时间）等字段 raw：关闭启用的数据连接跟踪机制，加快封包穿越防火墙速度，决定了数据包是否应被状态跟踪机制（如连接跟踪）处理 security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现 表的优先级由高到低的顺序为 1security --&gt;raw--&gt;mangle--&gt;nat--&gt;filter 表和链对应关系 filter表 INPUT：负责过滤所有目标地址是本机地址的数据包，通俗来讲，就是过滤进入主机的数据包（能否让数据包进入服务器） FORWARD：路过，负责转发流经主机的数据包，起转发的作用，和NAT关系大，在LVS NAT模式中，net.ipv4.ip_forward&#x3D;0 OUTPUT：处理所有源地址是本机地址的数据包，通俗来讲，就是处理从主机发出去的数据包，当数据包从本地主机发送至外部网络时，确定哪些本地系统发出的数据包可以被发送到外部网络 nat表 OUTPUT：和主机放出去的数据包有关，改变主机发出数据包的目的地址 PREROUTING：在数据包到达防火墙时，进行路由判断之前执行的规则，作用是改变数据包的目的地址、目的端口等 POSTROUTING：在数据包离开防火墙时进行路由判断之后执行的规则，作用是改变数据包的源地址、源端口等 数据包过滤匹配流程 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去 如果数据包是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过OUTPUT链，然后到达POSTROUTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到达POSTROUTING链输出 范例：查看表匹配哪些链 12345678[root@centos8 ~]#iptables -vnL -t filter[root@centos8 ~]#iptables -vnL -t nat[root@centos8 ~]#iptables -vnL -t mangle[root@centos8 ~]#iptables -vnL -t raw[root@centos8 ~]#iptables -vnL -t security#CentOS 6 nat表不支持INPUT链[root@centos6 ~]#iptables -vnL -t nat 2 iptables规则说明2.1 iptables规则组成规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动作作出处理，规则在链接上的次序即为其检查时的生效次序 匹配条件：默认为与条件，同时满足 基本匹配：IP，端口，TCP的Flags（SYN,ACK等） 扩展匹配：通过复杂高级功能匹配 处理动作：称为target，跳转目标 内建处理动作：ACCEPT,DROP,REJECT,SNAT,DNAT,MASQUERADE,MARK,LOG… 自定义处理动作：自定义chain，利用分类管理复杂情形 规则要添加在链上，才生效；添加在自定义链上不会自动生效 白名单:只有指定的特定主机可以访问,其它全拒绝 黑名单:只有指定的特定主机拒绝访问,其它全允许，默认方式 2.2 iptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 2.3 本章学习环境准备CentOS 7，8： 12345systemctl stop firewalld.servicesystemctl disable firewalld. service#或者systemctl disable --now firewalld. service CentOS 6： 12service iptables stopchkconfig iptables off 注意：如果不是最小化安装，在禁用 frewalld 之后，再次重启还是能看到防火墙规则，这是由KVM启动的 12#卸载kvm功能[root@rocky86 ~]# yum remove qemu-kvm Ubuntu 1systemctl disable --now ufw 2.4 规则说明iptables 防火墙中的规则，在生效时会按照顺序，从上往下生效，当前一条规则命中后，不再继续往下匹配。 如果多条规则里面，匹配条件中有交集，或者有包含关系，则这些规则，要注意前后顺序，范围小的，需要精确匹配的，要往前放，范围大的，往后放，负责兜底的，放在最后。 如果多条规则里面，匹配条件没有交集，彼此不会互相影响，则无所谓前后顺序，但是从效率上来讲，更容易命中，范围大的放在前面。 3 iptables用法说明 格式 1234567891011121314iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specificationiptables [-t table] -I chain [rulenum] rule-specificationiptables [-t table] -R chain rulenum rule-specificationiptables [-t table] -D chain rulenumiptables [-t table] -S [chain [rulenum]]iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...]iptables [-t table] -N chainiptables [-t table] -X [chain]iptables [-t table] -P chain targetiptables [-t table] -E old-chain-name new-chain-namerule-specification = [matches...] [target]match = -m matchname [per-match-options]target = -j targetname [per-target-options] iptables命令格式详解 1iptables [-t table] SUBCOMMAND chain [-m matchname [per-match-options]] -j targetname [per-target-options] 3.1 table指定表：raw, mangle, nat, [filter]默认 3.2 COMMAND3.2.1 链管理类12345-N：new, 自定义一条新的规则链-E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除-X：delete，删除自定义的空的规则链-P：Policy，设置默认策略；对filter表中的链而言，其默认策略有：ACCEPT：接受, DROP：丢弃-C：检查链上的规则是否正确 3.2.2 查看类1234567891011-L：list, 列出指定鏈上的所有规则，本选项须置后-n：numberic，以数字格式显示地址和端口号-v：verbose，详细信息-vv 更详细-x：exactly，显示计数器结果的精确值,而非单位转换后的易读值--line-numbers：显示规则的序号-S selected,以iptables-save命令格式显示链上规则常用组合-vnL-vvnxL --line-numbers 范例：查看表匹配哪些链 在使用 -L 选项查看规则时，如果规则不为空，单独 -L 选项显示时有可能会很慢，这是因为需要对主机名和服务名进行反解导致的，可以加 -n 选项来规避 默认 filter 表，可以不指定 12345678910111213141516171819[root@centos8 ~]#iptables -vnL -t filterChain INPUT (policy ACCEPT 0 packets, 0 bytes)pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)pkts bytes target prot opt in out source destinationpkts：在当前规则中，被命中的数据包数量bytes：在当前规则中，被命中的总流量大小target：动作，目标，DROP 表示丢弃prot：具体协议opt：选项in：数据从哪个网络设备进来out：数据从哪个网络设备上出去source：源，可以是主机IP，网段，anywhere 表示不受限 destination：目标，可以是主机IP，网段，anywherer 表示不受限 范例：指定表和链 1[root@ubuntu ~]# iptables -t filter -vnL INPUT 3.2.3 规则管理类1234567891011-A：append，往链上追加规则-I：insert, 插入，要指明插入至的规则编号，默认为第一条-D：delete，删除 (1) 指明规则序号 (2) 指明规则本身-R：replace，替换指定链上的指定规则编号-F：flush，清空指定的规则链-Z：zero，置零 iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和 范例 1234567#这条命令指定了来自源地址为 10.0.0.1 的数据包将被接受（ACCEPT）。换句话说，它允许了从地址为 10.0.0.1 的主机发送到你的主机的数据包通过防火墙。iptables -t filter -A INPUT -s 10.0.0.1 -j ACCEPT#这条命令指定了目标地址为 10.0.0.1 的数据包将被接受（ACCEPT）。换句话说，它允许了发送到地址为 10.0.0.1 的主机的数据包通过防火墙。iptables -t filter -A INPUT -d 10.0.0.1 -j ACCEPT#因此，这两条命令的区别在于它们是针对数据包的不同方向进行匹配的。第一条命令是匹配从指定源地址发送到你的主机的数据包，而第二条命令是匹配发送到指定目标地址的数据包。 范例 1234567891011121314151617181920212223242526#在INPUT 链的 filter 表上设置过滤规则，将来自 10.0.0.150 的数据包丢弃掉[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.150 -j DROP#将来自10网段的数据包丢弃掉[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.0/24 -j DROP#删除第3条规则，根据规则编号删除[root@ubuntu ~] iptables -t filter -D INPUT 3#在最前面插入 127.1 的ACCEPT 规则[root@ubuntu ~]# iptables -t filter -I INPUT -s 127.0.0.1 -j ACCEPT#指定入口设备是本地回环网卡[root@ubuntu ~]# iptables -t filter -I INPUT -i lo -j ACCEPT#替换第一条规则[root@ubuntu ~]# iptables -t filter -R INPUT 1 -s 127.0.0.1 -j ACCEPT#清空INPUT链上的第一条规则统计数据 [root@ubuntu ~]# iptables -t filter -Z INPUT 1#清空表上的所有统计数据[root@ubuntu ~]# iptables -t filter -Z#修改默认规则[root@ubuntu ~]# iptables -P FORWARD DROP 范例：黑名单和白名单 12345678910111213141516#只允许 10.0.0.1 连接[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.1 -j ACCEPT#其它机器数据全部拒绝，不指定匹配条件，则全部拒绝[root@ubuntu ~]# iptables -t filter -A INPUT -j REJECT#这种情况下，ACCEPT规则一定要写在前面[root@ubuntu ~]# iptables -t filter -nL INPUT --line-numberChain INPUT (policy ACCEPT)num target prot opt source destination 1 ACCEPT all -- 10.0.0.1 0.0.0.0/0 2 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachable#由于拒绝了10.0.0.1 之外的主机，本机也无法使用[root@ubuntu ~]# ping 127.1PING 127.1 (127.0.0.1) 56(84) bytes of data. 3.3 chain指定链：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING 3.4 parameter匹配条件 基本：通用的，PARAMETERS 扩展：需加载模块，MATCH EXTENTIONS 3.4.1 基本匹配条件基本匹配条件：无需加载模块，由iptables&#x2F;netfilter自行提供 1234567[!] -s, --source address[/mask][,...]：源IP地址或者不连续的IP地址[!] -d, --destination address[/mask][,...]：目标IP地址或者不连续的IP地址[!] -p, --protocol protocol：指定协议，可使用数字如0（all） protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or“all“ 参看：/etc/protocols[!] -i, --in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于INPUT、FORWARD、PREROUTING链[!] -o, --out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用于FORWARD、OUTPUT、POSTROUTING链 范例 123456[root@centos8 ~]#iptables -A INPUT -s 10.0.0.6,10.0.0.10 -j REJECT[root@centos8 ~]#iptables -I INPUT -i lo -j ACCEPT[root@centos8 ~]#curl 127.0.0.110.0.0.8[root@centos8 ~]#curl 10.0.0.810.0.0.8 范例：根据协议过滤 12#接受10.0.0.6上的除icmp协议的其他协议[root@centos8 ~]#iptables -I INPUT 2 -s 10.0.0.6 ! -p icmp -j ACCEPT 范例：规则取反 12#设置取反规则，除了 10.0.0.150 来的数据，其它都拒绝[root@ubuntu ~]# iptables -t filter -R INPUT 2 ! -s 10.0.0.150 -j REJECT 范例：根据目标地址匹配（目标地址是机器上有多网卡或者一网卡有多个地址时才使用） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@rocky8 ~]#ip a a 10.0.0.10/24 dev eth0 label eth0:1[root@rocky8 ~]#ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:d2:a3:ac brd ff:ff:ff:ff:ff:ff inet 10.0.0.179/24 brd 10.0.0.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet 10.0.0.10/24 scope global secondary eth0:1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fed2:a3ac/64 scope link valid_lft forever preferred_lft forever#现在能访问10[root@centos8 ~]#ping 10.0.0.10PING 10.0.0.10 (10.0.0.10) 56(84) bytes of data.64 bytes from 10.0.0.10: icmp_seq=1 ttl=64 time=1.23 ms64 bytes from 10.0.0.10: icmp_seq=2 ttl=64 time=10.8 ms#任何来访问10的IP地址都拒绝，不管什么协议[root@rocky8 ~]#iptables -A INPUT -d 10.0.0.10 -j REJECT[root@rocky8 ~]#iptables -vnLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 REJECT all -- * * 0.0.0.0/0 10.0.0.10 reject-with i #现在不能ping了[root@centos8 ~]#ping 10.0.0.10PING 10.0.0.10 (10.0.0.10) 56(84) bytes of data.From 10.0.0.10 icmp_seq=1 Destination Port UnreachableFrom 10.0.0.10 icmp_seq=2 Destination Port Unreachable#远程也不能链接[root@centos8 ~]#ssh 10.0.0.10^C#来自icmp协议的拒绝。其他协议可以访问[root@rocky8 ~]#iptables -R INPUT 1 -d 10.0.0.10 -p icmp -j REJECT#还是不能ping[root@centos8 ~]#ping 10.0.0.10[root@centos8 ~]#ping 10.0.0.10PING 10.0.0.10 (10.0.0.10) 56(84) bytes of data.From 10.0.0.10 icmp_seq=1 Destination Port UnreachableFrom 10.0.0.10 icmp_seq=2 Destination Port Unreachable#可以远程连接[root@centos8 ~]#ssh 10.0.0.10The authenticity of host &#x27;10.0.0.10 (10.0.0.10)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:LjI4Fn8mPxXYJjqouGvxROkMgF9Nv5fDZpHKfzM8hRs.Are you sure you want to continue connecting (yes/no/[fingerprint])? 3.4.2 扩展匹配条件扩展匹配条件：需要加载扩展模块（&#x2F;usr&#x2F;lib64&#x2F;xtables&#x2F;*.so），方可生效 扩展模块的查看帮助 ：man iptables-extensions 扩展匹配条件： 隐式扩展 显式扩展 3.4.2.1 隐式扩展iptables 在使用 -p 选项指明了特定的协议时，无需再用 -m 选项指明扩展模块的扩展机制，不需要手动加载扩展模块 tcp，upd，icmp 这三个协议是可以用 -m 指定的模块，但同时，也可以在基本匹配里面用 -p 来指定这几个协议 3.4.2.1.1 tcp协议1234567891011[!] --source-port, --sport port[:port]：匹配报文源端口,可为端口连续范围[!] --destination-port,--dport port[:port]：匹配报文目标端口,可为连续范围[!] --tcp-flags mask comp mask 需检查的标志位列表，用,分隔 , 例如 SYN,ACK,FIN,RST comp 在mask列表中必须为1的标志位列表，无指定则必须为0，用,分隔tcp协议的扩展选项--tcp-flags SYN,ACK,FIN,RST SYN #检查SYN,ACK,FIN,RST四个标志位，其中SYN值为1，其它值为0，表示第一次握手--tcp-flags SYN,ACK,FIN,RST SYN,ACK #第二次握手[!] --syn：用于匹配第一次握手, 相当于：--tcp-flags SYN,ACK,FIN,RST SYN#错误包--tcp-flags ALL ALL --tcp_flags ALL NONE 范例：用tcp 协议和目标端口拒绝ssh服务 12#拒绝来自于150 的，其目标IP是110，目标端口是 21 到 23 的 tcp协议数据包[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.150 -d 10.0.0.110 -p tcp --dport 21:23 -j REJECT 范例：拒绝ssh服务，接受http服务 12345678910111213141516171819202122232425[root@rocky8 ~]#yum -y install nginx[root@rocky8 ~]#systemctl start nginx[root@rocky8 ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:80 0.0.0.0:* LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 [::]:80 [::]:* LISTEN 0 128 [::]:22 [::]:*[root@rocky8 ~]#iptables -A INPUT -s 10.0.0.1 -j ACCEPT[root@rocky8 ~]#iptables -A INPUT -p tcp --dport 80 -j ACCEPT[root@rocky8 ~]#iptables -A INPUT -p tcp -d 10.0.0.179 -j REJECT(iptables -A INPUT -j REJECT)[root@rocky8 ~]#iptables -vnLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 288 17760 ACCEPT all -- * * 10.0.0.1 0.0.0.0/0 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 0 0 REJECT tcp -- * * 0.0.0.0/0 10.0.0.179 reject-with icmp-port-unreachable( 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachable )[root@centos8 ~]#ssh 10.0.0.179ssh: connect to host 10.0.0.179 port 22: Connection refused[root@centos8 ~]#curl 10.0.0.179&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.1//EN&quot; &quot;http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd&quot;&gt;.......... 范例：根据TCP标志位过滤 12#拒绝第一次握手[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.150 -d 10.0.0.110 -p tcp --tcp-flags SYN,ACK,FIN,RST SYN -j REJECT 范例：TCP隐式扩展 1iptables -A INPUT -p tcp --dport 80 -j ACCEPT 3.4.2.1.2 udp协议12[!] --source-port, --sport port[:port]：匹配报文的源端口或端口范围[!] --destination-port,--dport port[:port]：匹配报文的目标端口或端口范围 3.4.2.1.3 icmp协议1234[!] --icmp-type &#123;type[/code]|typename&#125; type/code 0/0 echo-reply #icmp应答 8/0 echo-request #icmp请求 范例 123[root@centos8 ~]#iptables -A INPUT -s 10.0.0.6 -p tcp --dport 21:23 -j REJECT[root@centos8 ~]#iptables -A INPUT -p tcp --syn -j REJECT[root@centos8 ~]#iptables -A INPUT -s 10.0.0.6 -p icmp --icmp-type 8 -j REJECT 范例：我能ping对方，对方不能ping我 1234iptables -A INPUT -s 10.0.0.0/24 -j REJECTiptables -A INPUT -p icmp --icmp-type 0 -j ACCEP#对方主机发出的 ICMP Echo Request 报文将被第一条规则拒绝，而你的本地主机发出的 ICMP Echo Reply 报文（响应对方的 ping 请求）将被第二条规则接受。 范例：拒绝ICMP的请求包 1[root@ubuntu ~]# iptables -t filter -A INPUT -s 10.0.0.150 -p icmp --icmp-type 8 -j REJECT 3.4.2.2 显式扩展及相关模块显示扩展即必须使用-m选项指明要调用的扩展模块名称，需要手动加载扩展模块 1[-m matchname [per-match-options]] 扩展模块的使用帮助： CentOS 7,8: man iptables-extensions CentOS 6: man iptables 3.4.2.2.1 multiport扩展以离散方式定义多端口匹配,最多指定15个端口 12345678#指定多个源端口[!] --source-ports,--sports port[,port|,port:port]...# 指定多个目标端口[!] --destination-ports,--dports port[,port|,port:port]...#多个源或目标端[!] --ports port[,port|,port:port]... 范例 12[root@centos8 ~]#iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp -m multiport --dports 20:22,80 -j ACCEPT[root@centos8 ~]#iptables -A INPUT -s 10.0.0.6 -p tcp -m multiport --dports 445,139 -j REJECT 3.4.2.2.2 iprange扩展指明连续的（但一般不是整个网络）ip地址范围 12[!] --src-range from[-to] 源IP地址范围[!] --dst-range from[-to] 目标IP地址范围 范例： 1iptables -A INPUT -d 172.16.1.100 -p tcp --dport 80 -m iprange --src-range 172.16.1.5-172.16.1.10 -j DROP 3.4.2.2.3 mac扩展mac 模块可以指明源MAC地址,，适用于：PREROUTING, FORWARD，INPUT chains 1[!] --mac-source XX:XX:XX:XX:XX:XX 范例 1234#仅有 mac 地址是 00:0c:29:f3:44:9a 的主机才能访问[root@ubuntu ~]# iptables -t filter -A INPUT -d 10.0.0.110 -m mac --mac-source 00:0c:29:f3:44:9a -j ACCEPT#其它主机拒绝[root@ubuntu ~]# iptables -t filter -A INPUT -d 10.0.0.110 -j REJECT 3.4.2.2.4 string扩展对报文中的应用层数据做字符串模式匹配检测 1234567--algo &#123;bm|kmp&#125; 字符串匹配检测算法 bm：Boyer-Moore kmp：Knuth-Pratt-Morris--from offset 开始偏移--to offset 结束偏移[!] --string pattern 要检测的字符串模式[!] --hex-string pattern 要检测字符串模式，16进制格式 范例：数据报文结构中，前62位都是报文头(22位），IP（10位)和TCP(20位)，不会有敏感词汇，所以从第62位开始检查 请求报文中（INPUT）访问的形式是index.html，不会带有敏感词汇，是回来的报文带有（OUTPUT） 12345678910111213141516[root@rocky ~]# curl 10.0.0.206/bd.htmlbaidu[root@rocky ~]# curl 10.0.0.206/gg.htmlgoogle#设置出口规则，在返回的数据包中，跳过前62字节的报文头，如果内容中出现 google，则拒绝返回[root@ubuntu ~]# iptables -t filter -A OUTPUT -m string --algo kmp --from 62 --string &quot;google&quot; -j REJECT#再次测试[root@rocky ~]# curl 10.0.0.110/bd.htmlbaidu#google 无法返回[root@rocky ~]# curl 10.0.0.110/gg.html#区分大小写，大写不会被命中[root@rocky ~]# curl 10.0.0.110/GG.htmlGOOGLE 3.4.2.2.5 time扩展注意：CentOS 8 此模块有问题 根据将报文到达的时间与指定的时间范围进行匹配 123456789--datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期--datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]--timestart hh:mm[:ss] 时间--timestop hh:mm[:ss][!] --monthdays day[,day...] 每个月的几号[!] --weekdays day[,day...] 星期几，1 – 7 分别表示星期一到星期日--kerneltz：内核时区（当地时间），不建议使用，CentOS 7版本以上系统默认为 UTC注意： centos6 不支持kerneltz ，--localtz指定本地时区(默认)说明：UTC时间在原来时间上减8 范例: CentOS 8 的 time模块问题 1234[root@centos8 ~]#rpm -ql iptables |grep time/usr/lib64/xtables/libxt_time.so[root@centos8 ~]#iptables -A INPUT -m time --timestart 12:30 --timestop 13:30 -j ACCEPTiptables v1.8.4 (nf_tables): Couldn&#x27;t load match `time&#x27;:No such file or directory 范例 123456789101112131415161718#在ubuntu中设置[root@ubuntu ~]# iptables -t filter -A INPUT -m time --timestart 01:00 --timestop 14:00 -s 10.0.0.150 -j REJECT#在150上PING 主机，被拒绝[root@rocky ~]# ping 10.0.0.206 -c1PING 10.0.0.206 (10.0.0.206) 56(84) bytes of data.From 10.0.0.206 icmp_seq=1 Destination Port Unreachable#修改主机上的时间，让当前时间不在iptables 规则范围内[root@ubuntu ~]# date +&quot;%F %T&quot;2023-06-10 21:02:46[root@ubuntu ~]# date -s &quot;+1 hour&quot;Sat Jun 10 10:03:09 PM CST 2023[root@ubuntu ~]# date +&quot;%F %T&quot;2023-06-10 22:03:11[root@rocky ~]# ping 10.0.0.206 -c1PING 10.0.0.206 (10.0.0.206) 56(84) bytes of data.64 bytes from 10.0.0.206: icmp_seq=1 ttl=64 time=0.573 ms 3.4.2.2.6 connlimit扩展根据每客户端IP做并发连接数数量匹配 可防止Dos(Denial of Service，拒绝服务)攻击 12--connlimit-upto N #连接的数量小于等于N时匹配--connlimit-above N #连接的数量大于N时匹配 范例 12#如果并发连接数超过2个，则拒绝连接iptables -A INPUT -d 172.16.100.10 -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT 3.4.2.2.7 limit扩展基于收发报文的速率做匹配 , 令牌桶过滤器（限制流量） connlimit 扩展是限制单个客户端对服务器的并发连接数，limit 扩展是限制服务器上所有的连接数 12--limit-burst number #前多少个包不限制--limit #[/second|/minute|/hour|/day] #在一个时间区间内能接收的连接数# 范例 1234567891011121314151617181920212223242526272829#添加 icmp 放行规则，前10个不处理，后面每分钟放行20个[root@centos8 ~]#iptables -A INPUT -p icmp -m limit --limit-burst 10 --limit 20/minute -j ACCEPT#兜底的拒绝规则[root@centos8 ~]#iptables -A INPUT -p icmp -j REJECT[root@centos6 ~]#ping 10.0.0.8PING 192.168.39.8 (192.168.39.8) 56(84) bytes of data.64 bytes from 192.168.39.8: icmp_seq=1 ttl=64 time=0.779 ms64 bytes from 192.168.39.8: icmp_seq=2 ttl=64 time=0.436 ms64 bytes from 192.168.39.8: icmp_seq=3 ttl=64 time=0.774 ms64 bytes from 192.168.39.8: icmp_seq=4 ttl=64 time=0.391 ms64 bytes from 192.168.39.8: icmp_seq=5 ttl=64 time=0.441 ms64 bytes from 192.168.39.8: icmp_seq=6 ttl=64 time=0.356 ms64 bytes from 192.168.39.8: icmp_seq=7 ttl=64 time=0.553 ms64 bytes from 192.168.39.8: icmp_seq=8 ttl=64 time=0.458 ms64 bytes from 192.168.39.8: icmp_seq=9 ttl=64 time=0.459 ms64 bytes from 192.168.39.8: icmp_seq=10 ttl=64 time=0.479 ms64 bytes from 192.168.39.8: icmp_seq=11 ttl=64 time=0.450 ms64 bytes from 192.168.39.8: icmp_seq=12 ttl=64 time=0.471 ms64 bytes from 192.168.39.8: icmp_seq=13 ttl=64 time=0.531 ms64 bytes from 192.168.39.8: icmp_seq=14 ttl=64 time=0.444 msFrom 192.168.39.8 icmp_seq=15 Destination Port Unreachable64 bytes from 192.168.39.8: icmp_seq=16 ttl=64 time=0.668 msFrom 192.168.39.8 icmp_seq=17 Destination Port UnreachableFrom 192.168.39.8 icmp_seq=18 Destination Port Unreachable64 bytes from 192.168.39.8: icmp_seq=19 ttl=64 time=0.692 msFrom 192.168.39.8 icmp_seq=20 Destination Port UnreachableFrom 192.168.39.8 icmp_seq=21 Destination Port Unreachable64 bytes from 192.168.39.8: icmp_seq=22 ttl=64 time=0.651 ms 3.4.2.2.8 state扩展state 扩展模块，可以根据”连接追踪机制“去检查连接的状态，较耗资源 conntrack机制：追踪本机上的请求和响应之间的关系 格式 1[!] --state state state状态类型： NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求 ESTABLISHED：NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通信状态 RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连接与命令连接之间的关系 INVALID：无效的连接，如flag标记不正确 UNTRACKED：未进行追踪的连接，如：raw表中关闭追踪 查看是否启用了连接追踪机制 1234567#当前还没有启用[root@rocky ~]# lsmod | grep nf_conntrack#启用连接跟踪机制后，会自动生成此文件，[root@rocky ~]# cat /proc/net/nf_conntrack#只要系统中某处要使用到连接追踪机制，连接追踪机制相关模块会自动加载 已经追踪到的并记录下来的连接信息库 1234567891011[root@centos8 ~]#cat /proc/net/nf_conntrackipv4 2 icmp 1 29 src=10.0.0.206 dst=10.0.0.150 type=8 code=0 id=1 src=10.0.0.150 dst=10.0.0.206 type=0 code=0 id=1 mark=0 zone=0 use=2ipv4 2 tcp 6 299 ESTABLISHED src=10.0.0.150 dst=10.0.0.1 sport=22 dport=51848 src=10.0.0.1 dst=10.0.0.150 sport=51848 dport=22 [ASSURED] mark=0 zone=0 use=2ipv4 #第一列 网络层协议名称2 #第二列 网络层协议号icmp #第三列 传输层协议名称1 #第四列 传输层协议号29 #第五列 无后续包进入时无效的秒数，即老化时间ESTABLISHED #第六列 该连接的连接状态，不是所有协议都有此列值 #后续都是k=v 格式的连接参数和选项 连接追踪功能所能够容纳的最大连接数量 12345#两文件，不管修改哪个，没改的会随之改变[root@centos8 ~]#cat /proc/sys/net/netfilter/nf_conntrack_max26624[root@centos8 ~]#cat /proc/sys/net/nf_conntrack_max26624 己追踪的连接数量 12[root@centos8 ~]#cat /proc/sys/net/netfilter/nf_conntrack_count10 不同的协议的连接追踪时长，单位为秒，超时后会踢出己监控的队列 1[root@centos8 ~]#ll /proc/sys/net/netfilter/*_timeout_* 说明： 连接跟踪，需要加载模块： modprobe nf_conntrack_ipv4 当服务器连接多于最大连接数时dmesg 可以观察到 ：kernel: ip_conntrack: table full, dropping packet错误,并且导致建立TCP连接很慢。 各种状态的超时后，链接会从表中删除 范例: 不允许远程主机 10.0.0.7 访问本机,但本机可以访问10.0.0.7 12345678[root@centos8 ~]#iptables -S-P INPUT ACCEPT-P FORWARD ACCEPT-P OUTPUT ACCEPT-A INPUT -s 10.0.0.1/32 -j ACCEPT-A INPUT -m state --state ESTABLISHED -j ACCEPT-A INPUT ! -s 10.0.0.7/32 -m state --state NEW -j ACCEPT-A INPUT -j REJECT --reject-with icmp-port-unreachable 范例 12iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT 范例：新用户不能连，老用户可以连 123456789101112#老用户（不能断开，断开就不是已经建立联机的用户了）[root@centos7 ~]#ping 10.0.0.176PING 10.0.0.176 (10.0.0.176) 56(84) bytes of data.64 bytes from 10.0.0.176: icmp_seq=1 ttl=64 time=0.830 ms[root@centos8 ~]#iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT[root@centos8 ~]#iptables -A INPUT -m state --state NEW -j REJECT#新用户[root@rocky8 ~]#ping 10.0.0.176PING 10.0.0.176 (10.0.0.176) 56(84) bytes of data.From 10.0.0.176 icmp_seq=1 Destination Port Unreachable 案例：开放被动模式的ftp服务 CentOS 8 此模块有bug (1) 装载ftp连接追踪的专用模块： 跟踪模块路径： &#x2F;lib&#x2F;modules&#x2F;kernelversion&#x2F;kernel&#x2F;net&#x2F;netfilter 123vim /etc/sysconfig/iptables-configIPTABLES_MODULES=“nf_conntrack_ftp&quot;modprobe nf_conntrack_ftp (2) 放行请求报文： 命令连接：NEW, ESTABLISHED 数据连接：RELATED, ESTABLISHED 12iptables -I INPUT -d LocalIP -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -d LocalIP -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行响应报文： 范例：开放被动模式的ftp服务示例 1iptables -I OUTPUT -s LocalIP -p tcp -m state --state ESTABLISHED -j ACCEPT 范例：开放被动模式的ftp服务示例 12345678910yum install vsftpdsystemctl start vsftpdmodprobe nf_conntrack_ftpiptables -Fiptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp --dport 21 -m state --state NEW -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT DROPiptables -vnL 3.5 Target处理动作1-j targetname [per-target-options] （1）简单动作 Target 说明 ACCEPT 接受，命中此规则后，不再对比当前链的其它规则，进入下一个链 DROP 抛弃，不回应，命中此规则后，该连接直接中断，发送方收不到任何回应 REJECT 拒绝，有回应，命中此规则后，该连接直接中断，发送方能收到拒绝回应 （2）扩展动作 Target 说明 REJECT --reject-with：icmp-port-unreachable默认 RETURN 返回调用链，在当前链中不再继续匹配，返回到主链，一般用于自定义规则链中，假如input链定义了第一条和第二条和第四条规则 第三条是自定义链 自定义链有三条规则 如果自定义链中第二条规则加了return 数据报文碰到return并满足 就不会执行自定义链的第三条规则 而是执行input链的第四条规则 REDIRECT 端口重定向 LOG 记录日志，dmesg，非中断target，本身不拒绝和允许，放在拒绝和允许规则前，将被命中的数据的日志记录在&#x2F;var&#x2F;log&#x2F;messages系统日志中- --log-level level：debug, info, notice, warning, error, crit, alert, emerg- --log-prefix prefix：日志前缀，用于区别不同的日志，最多29个字符 MARK 做防火墙标记 DNAT 目标IP地址转换 SNAT 源IP地址转换 MASQUERADE 地址伪装（源IP地址动态转换） 自定义链 见第4节 制定规则时先把本机访问和自身访问开了，免得后续制定其他规则时本机不能访问和自己不能访问自己 12iptables -A INPUT -s windowsip -j ACCEPTiptables -A INPUT -i lo -j ACCEPT 范例：记录日志 1234567[root@centos8 ~]#iptables -I INPUT -s 10.0.0.0/24 -p tcp -m multiport --dports 80,21,22,23 -m state --state NEW -j LOG --log-prefix &quot;new connections: &quot;[root@centos8 ~]#tail -f /var/log/messagesMar 19 18:41:07 centos8 kernel: iptables tcp connection: IN=eth0 OUT=MAC=00:0c:29:f8:5d:b7:00:50:56:c0:00:08:08:00 SRC=10.0.0.1 DST=10.0.0.8 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=43974 DF PROTO=TCP SPT=9844 DPT=22 WINDOW=4102 RES=0x00 ACK URGP=0Mar 19 18:41:07 centos8 kernel: new connections: IN=eth0 OUT=MAC=00:0c:29:f8:5d:b7:00:50:56:c0:00:08:08:00 SRC=10.0.0.1 DST=10.0.0.8 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=43975 DF PROTO=TCP SPT=9844 DPT=22 WINDOW=4102 RES=0x00 ACK URGP=0 范例：记录日志 12345[root@centos8 ~]#iptables -R INPUT 2 -p tcp --dport 21 -m state --state NEW -j LOG --log-prefix &quot;ftp new link: &quot;[root@centos8 ~]#tail -f /var/log/messagesDec 21 10:02:31 centos8 kernel: ftp new link: IN=eth0 OUT=MAC=00:0c:29:f9:8d:90:00:0c:29:10:8a:b1:08:00 SRC=192.168.39.6 DST=192.168.39.8LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=15556 DF PROTO=TCP SPT=53706 DPT=21 WINDOW=14600 RES=0x00 SYN URGP=0 4 iptables自定义链iptables 中除了系统自带的五个链之外，还可以自定义链，来实现将规则进行分组，重复调用的目的。自定义链添加规则之后，要作为系统链的 target 与之关联，才能起到作用 生产中频繁要改的规则可以放在自定义链中，不需要放在主链中，防止修改时出错误，修改时直接修改自定义链，不用修改主链 项目 说明 作用 组织和复用规则，提高可读性和管理效率 创建 iptables -N &lt;chain-name&gt; 删除 iptables -X &lt;chain-name&gt; 调用 在内置链中使用 -j &lt;chain-name&gt; 跳转 RETURN 行为 在自定义链中遇到 RETURN，将返回主链的下一条规则，不再执行该自定义链后续规则 范例：拒绝http和https服务 123iptables -N WEB_CHAINiptables -A WEB_CHAIN -s 10.0.0.6 -p tcp -m multiport --dports80,443 -j REJECTiptables -A INPUT -j WEB_CHAIN 范例: 创建自定义链实现WEB的访问控制 12345678910111213141516171819202122232425262728293031323334[root@centos8 ~]#iptables -N web_chain#改名[root@centos8 ~]#iptables -E web_chain WEB_CHAIN[root@centos8 ~]#iptables -A WEB_CHAIN -p tcp -m multiport --dports 80,443,8080 -j ACCEPT[root@centos8 ~]#iptables -I INPUT 3 -s 10.0.0.0/24 -j WEB_CHAIN[root@centos8 ~]#iptables -A WEB_CHAIN -p icmp -j ACCEPT[root@centos8 ~]#iptables -I WEB_CHAIN 2 -s 10.0.0.6 -j RETURN[root@centos8 ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 10 867 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 2 5637 423K ACCEPT all -- * * 10.0.0.1 0.0.0.0/0 3 248 20427 WEB_CHAIN all -- * * 10.0.0.0/24 0.0.0.0/0 4 4278 248K REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain WEB_CHAIN (1 references)num pkts bytes target prot opt in out source destination 1 36 2619 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 multiport dports 80,443,80802 16 1344 RETURN all -- * * 10.0.0.6 0.0.0.0/0 3 184 15456 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 [root@centos6 ~]#curl 10.0.0.8centos8 website[root@centos6 ~]#curl 10.0.0.8centos8 website[root@centos6 ~]#ping -c1 10.0.0.8 范例: 删除自定义链 123456789101112131415161718192021222324252627#无法直接删除自定义链,删除自定义链和创建的顺序相反[root@centos8 ~]#iptables -X WEB_CHAINiptables v1.8.4 (nf_tables): CHAIN_USER_DEL failed (Device or resource busy):chain WEB_CHAIN[root@centos8 ~]#iptables -D INPUT 3[root@centos8 ~]#iptables -X WEB_CHAINiptables v1.8.4 (nf_tables): CHAIN_USER_DEL failed (Device or resource busy):chain WEB_CHAIN#先清除规则再删[root@centos8 ~]#iptables -F WEB_CHAIN[root@centos8 ~]#iptables -L WEB_CHAINChain WEB_CHAIN (0 references)target prot opt source destination [root@centos8 ~]#iptables -X WEB_CHAIN[root@centos8 ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 10 867 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 2 5824 437K ACCEPT all -- * * 10.0.0.1 0.0.0.0/0 3 4279 248K REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 5 规则优化最佳实践 安全放行所有入站和出站的状态为ESTABLISHED状态连接,建议放在第一条，效率更高 谨慎放行入站的新请求 有特殊目的限制访问功能，要在放行规则之前加以拒绝 同类规则（访问同一应用，比如：http ），匹配范围小的放在前面，用于特殊处理 不同类的规则（访问不同应用，一个是http，另一个是mysql ），匹配范围大的放在前面，效率更高 12-s 10.0.0.6 -p tcp --dport 3306 -j REJECT-s 172.16.0.0/16 -p tcp --dport 80 -j REJECT 应该将那些可由一条规则能够描述的多个规则合并为一条,减少规则数量,提高检查效率 设置默认策略，建议白名单（只放行特定连接）iptables -P，不建议，容易出现“自杀现象”规则的最后定义规则做为默认策略，推荐使用，放在最后一条 6 iptables规则保存使用iptables命令定义的规则，手动删除之前，其生效期限为kernel存活期限，当系统重启之后，定义的规则会消失。 6.1 持久保存规则121 iptables-save &gt; /PATH/TO/SOME_RULES_FILE2 rc.local 1234567891011[root@centos8 ~]#iptables -A INPUT -s 10.0.0.1 -j ACCEPT[root@centos8 ~]#iptables-save &gt; iptables.rule[root@centos8 ~]#cat iptables.rule# Generated by iptables-save v1.8.4 on Tue Nov 21 15:47:34 2023*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -s 10.0.0.1/32 -j ACCEPTCOMMIT# Completed on Tue Nov 21 15:47:34 2023 6.2 加载规则CentOS 7,8 重新载入预存规则文件中规则： 1iptables-restore &lt; /PATH/FROM/SOME_RULES_FILE iptables-restore选项 12-n, --noflush：不清除原有规则-t, --test：仅分析生成规则集，但不提交 范例 12345678910111213141516171819202122[root@centos8 ~]#iptables -F[root@centos8 ~]#iptables -vnLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination [root@centos8 ~]#iptables-restore &lt; iptables.rule [root@centos8 ~]#iptables -vnLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 6 364 ACCEPT all -- * * 10.0.0.1 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 4 packets, 416 bytes) pkts bytes target prot opt in out source destination 6.3 开机自动重载规则 用脚本保存各个iptables命令；让此脚本开机后自动运行&#x2F;etc&#x2F;rc.d&#x2F;rc.local文件中添加脚本路径 &#x2F;PATH&#x2F;TO&#x2F;SOME_SCRIPT_FILE 用规则文件保存各个规则，开机时自动载入此规则文件中的规则在&#x2F;etc&#x2F;rc.d&#x2F;rc.local文件添加 12345iptables-restore &lt; /PATH/FROM/IPTABLES_RULES_FILE#ubuntu中没有该文件，要自行创建[root@ubuntu ~]# vim /etc/rc.local#!/bin/bash 定义Unit File, CentOS 7，8 可以安装 iptables-services 实现iptables.service 范例: CentOS 7，8 使用 iptables-services 123456789101112131415[root@centos8 ~]#yum -y install iptables-services[root@rocky ~]# systemctl start iptables#这些规则是启动iptables 服务后加载的规则，其保存文件为 /etc/sysconfig/iptables[root@centos8 ~]#cp /etc/sysconfig/iptables&#123;,.bak&#125;#保存现在的规则到文件中方法1[root@centos8 ~]#/usr/libexec/iptables/iptables.init save#保存现在的规则到文件中方法2[root@centos8 ~]#iptables-save &gt; /etc/sysconfig/iptables#开机启动[root@centos8 ~]#systemctl enable iptables.service [root@centos8 ~]#systemctl mask firewalld.service nftables.service 7 网络防火墙iptables&#x2F;netfilter 利用filter表的FORWARD链,可以充当网络防火墙： 注意的问题： (1) 请求-响应报文均会经由FORWARD链，要注意规则的方向性 (2) 如果要启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行 7.1 NAT表NAT: 网络地址转换，支持PREROUTING，INPUT，OUTPUT，POSTROUTING四个链 局域网中的主机都是分配的私有IP地址，这些IP地址在互联网上是不可达的，局域网中的主机，在与互联网通讯时，要经过网络地址转换，去到互联网时，变成公网IP地址对外发送数据。服务器返回数据时，也是返回到这个公网地址，再经由网络地址转换返回给局域网中的主机 一个局域网中的主机，想要访问互联网，在出口处，应该有一个公网可达的IP地址，应该能将局域网中的IP地址通过NAT转换成公网IP NAT的实现分为下面类型： SNAT：source NAT ，支持POSTROUTING, INPUT，让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装（源地址转换，将请求报文中的源IP地址转换为公网地址） DNAT：destination NAT ，支持PREROUTING , OUTPUT，把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)，但隐藏真实IP（目标地址转换，将响应报文中的目标IP地址转换为私网地址） PNAT: port nat，端口转换，IP地址和端口都进行转换 NAT 网络转换原理 当我们从运营商接入宽带之后，经过路由器，防火墙，交换机等各种设备，后面再接入终端机，包括打印机，手机，电脑等，在大多数情况下，我们在接入运营商的宽带后，会在使用（公司，学校，工厂，家庭）范围内组建一个局域网。 以我现在的工作机为例。 物理机的IP地址是 192.168.1.101，在物理机上运行着两台虚拟机，它们的IP 分别是 10.0.0.150 和10.0.0.151。 但是这三台主机，在访问互联网时，互联网上得到的这三台主机的IP都是 219.143.130.7 我们知道，两台主机之间通讯，是需要经过路由表的，路由表中保存了去到下一个IP地址的路由记录，但是 192.168.0.101 和 10.0.0.150 这两个IP地址都是私有地址，在网路上是不可达的，也就是说，在互联网上，是没有一个去到 192.168.0.101 这个网段的路由记录的(10.0.0.150 同理)，那么，我的物理机和虚拟机，是怎么访问互联网的，互联网上的主机，又是怎么回传数据给我的物理机和虚拟机的呢 根据我们前面学过的识知，两台主机之间通讯，是客户端主机启一个随机端口，去连接服务器的IP地址和固定端口，连接成功后，客户端发送数据，服务端根据客户端发送的数据，做出响应，再返回给客户端。 思考题 12在单位内部使用未经申请的公网地址,如:6.0.0.0/8网段,进行内部网络通讯,并利用SNAT连接Internet,是否可以?答：不可以，万一使用的恰好是公网中有的地址，就会连不上 7.2 SNATSNAT：源地址转换，基于nat表的target，适用于固定的公网IP，工作在 POSTROUTING 链上，支持专线 具体是指将经过当前主机转发的请求报文的源IP地址转换成根据防火墙规则指定的IP地址，解决私网访问公网的问题 局域网内所有设备要上外网，如果每个设备都分配一个公网ip成本太大，可以在路由器出口分配一个公网ip，局域网内的设备访问外网时统一走路由器出口，路由器此时需要做两件事： 数据包从出口出去之前，将数据包的源地址和源端口改成公网ip和随机端口 同时将转换关系记录保存，响应数据包返回时根据记录转发给局域网内的设备 SNAT选项： 12--to-source [ipaddr[-ipaddr]][:port[-port]] #转换成指定IP，或指定范围内的IP，端口可选--random #端口映射基于hash算法随机化 范例 1iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j SNAT --to-source ExtIP 注意: 需要开启 ip_forward 12[root@ubuntu ~]# sysctl -a | grep ip_forwardnet.ipv4.ip_forward = 1 范例 12345678#在防火墙主机上添加规则，如果源IP是 10.0.0.0/24网段的IP，则出去的时候，替换成192.168.10.123[root@ubuntu ~]# iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -d 10.0.0.0/24 -j SNAT --to-source 192.168.10.123#替换成172.18.1.6-172.18.1.9范围内的地址[root@ubuntu ~]#iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! –d 10.0.0.0/24 -j SNAT --to-source 172.18.1.6-172.18.1.9#只转换tcp协议 目标端口为80的报文，且通过12345 端口向外访问[root@ubuntu ~]# iptables -t nat -R POSTROUTING 1 -s 10.0.0.0/24 ! -d 10.0.0.0/24 -o ens37 -p tcp --dport 80 -j SNAT --to-source 192.168.10.123:12345 MASQUERADE：基于nat表的target，适用于动态的公网IP，既支持拨号网络，也支持专线 如果我们内网的出口设备上有固定IP，则直接指定 –to-source IP 没有任何问题，但是如果是使用拨号上网，出口网络设备上的IP地址会发生变化，这种情况下，我们的出口IP不能写成固定的。 这种场景下，我们需要使用 MASQUERADE 进行地址转换，MASOUERADE 可以从主机网卡上自动获取IP地址当作出口IP地址 MASQUERADE选项： 12--to-ports port[-port] #指定端口--random #端口映射基于hash算法随机化 范例 12345#从本地内网地址发出，只要不是到达本地地址的都转换为公网地址iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE#从10网段发出，只要不是到达10网段的都转换为公网地址iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -d 10.0.0.0/24 -j MASQUERADE 范例：查看本地主机访问公网时使用的IP 123456789101112131415161718192021222324252627[root@centos8 ~]#curl http://ip.sb111.199.191.204#Windows10 支持curlC:\\Users\\Wang&gt;curl ip.sb111.199.184.218[root@centos8 ~]#curl http://ipinfo.io/ip/111.199.191.204[root@centos8 ~]#curl http://ifconfig.me111.199.191.204[root@centos8 ~]#curl -L http://tool.lu/ip当前IP: 111.199.191.204归属地: 中国 北京 北京[root@centos8 ~]#curl -sS --connect-timeout 10 -m 60https://www.bt.cn/Api/getIpAddress111.199.189.164[root@centos8 ~]#curl &quot;https://api.ipify.org?format=string&quot;111.199.184.218[root@firewall ~]#curl cip.ccIP : 39.164.140.134地址 : 中国 河南 鹤壁运营商 : 移动数据二 : 河南省郑州市 | 移动数据三 :URL : http://www.cip.cc/39.164.140.134 范例: SNAT 客户端端口随机，http的端口为80 由于10.0.0.8占用了12345端口，所以假如10.0.0.18同时向外网连接的话，端口号就要转换为192.168.10.7这个公网地址没人用的端口号 序号 源地址 目的地址 1 10.0.0.8:12345 192.168.10.100:80 2 192.168.10.7:12345 192.168.0.100:80 3 192.168.0.100:80 192.168.10.7:12345 4 192.168.0.100:80 10.0.0.:12345 1 10.0.0.18:12345 192.168.10.100:80 2 192.168.10.7:12346 192.168.10.100:80 3 192.168.10.100:80 192.168.0.7:12346 4 192.168.10.100:80 10.0.0.1:12345 实现内网两机器可以访问外网 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#做好测试服务，注意先做好再去配置地址和网关和网络模式[root@lanserver1 ~]#yum -y install httpd[root@lanserver2 ~]#yum -y install httpd[root@internet ~]#yum -y install httpd[root@lanserver1 ~]#hostname -I &gt; /var/www/html/index.html[root@lanserver2 ~]#hostname -I &gt; /var/www/html/index.html[root@Internet ~]#hostname -I &gt; /var/www/html/index.html[root@lanserver1 ~]#systemctl start httpd[root@lanserver2 ~]#systemctl start httpd[root@internet ~]#systemctl start httpd#配置地址和网关#lanserver1DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.179PREFIX=24GATEWAY=10.0.0.176ONBOOT=yes#lanserver2DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.180PREFIX=24GATEWAY=10.0.0.176ONBOOT=yes #firewallDEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.176PREFIX=24ONBOOT=yesDEVICE=eth1NAME=eth1BOOTPROTO=noneIPADDR=192.168.10.8PREFIX=24#internetDEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=192.168.10.6PREFIX=24ONBOOT=yes#测试连接状态[root@firewall ~]#curl 192.168.10.6192.168.10.6#启用路由转发（只要数据包经过forward链就要开启）[root@firewall ~]#vim /etc/sysctl.confnet.ipv4.ip_forward=1[root@firewall ~]#sysctl -p#配置规则（两种方法，因为现在192.168.10.8假设是专线IP）1 针对专线静态公共IP#对于来自 10.0.0.0/24 子网的数据包，只有当它们不要访问 10.0.0.0/24 子网时才进行 SNAT 转换[root@firewall ~]#iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -d 10.0.0.0/24 -j SNAT --to-source 192.168.10.82 针对拨号网络和专线静态公共IP[root@firewall ~]#iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -d 10.0.0.0/24 -j MASQUERADE#10.0.0.179转换为192.168.10.8去ping192.168.10.6[root@lanserver1 ~]#ping 192.168.10.6PING 192.168.10.6 (192.168.10.6) 56(84) bytes of data.64 bytes from 192.168.10.6: icmp_seq=9 ttl=63 time=6.18 ms64 bytes from 192.168.10.6: icmp_seq=10 ttl=63 time=6.12 ms[root@internet ~]#tcpdump -i eth0 -nn icmpdropped privs to tcpdumptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes21:14:43.283872 IP 192.168.10.8 &gt; 192.168.10.6: ICMP echo request, id 3, seq 28, length 6421:14:43.283948 IP 192.168.10.6 &gt; 192.168.10.8: ICMP echo reply, id 3, seq 28, length 6421:14:44.294611 IP 192.168.10.8 &gt; 192.168.10.6: ICMP echo request, id 3, seq 29, length 6421:14:44.294695 IP 192.168.10.6 &gt; 192.168.10.8: ICMP echo reply, id 3, seq 29, length 64#10.0.0.179转换为192.168.10.8去访问192.168.10.6[root@lanserver1 ~]#curl 192.168.10.6192.168.10.6 [root@internet ~]#tail -f /var/log/httpd/access_log 192.168.10.8 - - [21/Nov/2023:21:16:14 +0800] &quot;GET / HTTP/1.1&quot; 200 14 &quot;-&quot; &quot;curl/7.61.1&quot;#查看转换状态信息[root@firewall ~]#cat /proc/net/nf_conntrackipv4 2 tcp 6 117 TIME_WAIT src=10.0.0.179 dst=192.168.10.6 sport=47724 dport=80 src=192.168.10.6 dst=192.168.10.8 sport=80 dport=47724 [ASSURED] mark=0 zone=0 use=2#查看监听端口[root@firewall ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 [::]:22 [::]:* #会发现监听不到80端口，原因是ss命令监听的是应用程序打开的端口，而iptables是属于内核参数的，内核不属于应用程序空间#外网不可以访问内网[root@internet ~]#curl 10.0.0.179curl: (7) Couldn&#x27;t connect to server#解决办法是使用DNAT技术 7.3 DNATDNAT：目标地址转换，nat表的target，适用于端口映射，即可重定向到本机，也可以支持重定向至不同主机的不同端口，但不支持多目标，即不支持负载均衡功能，工作在 PREROUTING 链上 在内网环境中，使用私有IP地址的设备要与互联网进行通讯时，需要借助出口设备将源内网IP地址转换成公网可达的IP地址再进行通讯。 在内网环境中，只有在出口设备上才有一个(或数个)公网可达的IP，所以在互联网上，是不能路由至内网主机的。如果要让内网主机上的服务在公网上可见，我们需要使用 DNAT 实现目标IP地址转换，解决公网访问私网的问题 修改端口号：重定向端口 DNAT选项 12--to-destination [ipaddr[-ipaddr]][:port[-port]] #转换成指定IP，或指定范围内的IP，端口可选-d ExtIP #指公网可达的IP地址，必须是固定IP，不可以是拨号网络 DNAT 格式 1iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination InterSeverIP[:PORT] 范例 123456#在防火墙主机上设置DNAT转发规则，在访问 192.168.10.123 的 web 服务时，转发到 10.0.0.150上[root@ubuntu ~]# iptables -t nat -A PREROUTING -d 192.168.10.123 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.150:80[root@ubuntu ~]#iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 22 -j DNAT --to-destination 10.0.1.22[root@ubuntu ~]#iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 80 -j DNAT --to-destination 10.0.1.22:8080 注意: 需要开启 ip_forward 范例: DNAT 序号 源地址 目的地址 1 192.168.10.100:12345 192.168.10.7:80 2 192.168.10.100:12345 10.0.0.8:80 3 10.0.0.8:80 192.168.10.100:12345 4 192.168.10.7:80 192.168.10.100:12345 实现外网访问内网 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#配置规则[root@firewall ~]#iptables -t nat -A PREROUTING -d 192.168.10.8 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.179:80#外网通过将防火墙IP地址转换为内网地址去访问内网10.0.0.179[root@internet ~]#curl 192.168.10.810.0.0.179 [root@lanserver1 ~]#tail /var/log/httpd/access_log 192.168.10.6 - - [21/Nov/2023:21:46:22 +0800] &quot;GET / HTTP/1.1&quot; 200 12 &quot;-&quot; &quot;curl/7.61.1&quot;[root@firewall ~]#cat /proc/net/nf_conntrackipv4 2 tcp 6 28 TIME_WAIT src=192.168.10.6 dst=192.168.10.8 sport=53096 dport=80 src=10.0.0.179 dst=192.168.10.6 sport=80 dport=53096 [ASSURED] mark=0 zone=0 use=2#注意不能直接访问内网地址，因为没有设置路由表[root@internet ~]#curl 10.0.0.179curl: (7) Couldn&#x27;t connect to server#外网不能通过将防火墙IP地址转换为内网地址去访问内网10.0.0.180[root@firewall ~]#iptables -t nat -A PREROUTING -d 192.168.10.8 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.180:80[root@firewall ~]#iptables -t nat -vnLChain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 2 120 DNAT tcp -- * * 0.0.0.0/0 192.168.10.8 tcp dpt:80 to:10.0.0.179:80 0 0 DNAT tcp -- * * 0.0.0.0/0 192.168.10.8 tcp dpt:80 to:10.0.0.180:80 [root@internet ~]#curl 192.168.10.810.0.0.179 #原因是iptables规则是有先后次序的，匹配了第一条，也就是访问192.168.10.8是去访问10.0.0.179:80的，就不会去匹配第二条，解决方法是重新指定端口，不能是80端口了，因为已经被10.0.0.179占了[root@firewall ~]#iptables -t nat -R PREROUTING 2 -d 192.168.10.8 -p tcp --dport 81 -j DNAT --to-destination 10.0.0.180:80[root@internet ~]#curl 192.168.10.8:8110.0.0.180[root@internet ~]#curl 192.168.10.8:8010.0.0.179#修改内网httpd服务自身的端口号[root@lanserver2 ~]#vim /etc/httpd/conf/httpd.confListen 8080[root@lanserver2 ~]#systemctl restart httpd#现在拒绝连接了root@internet ~]#curl 192.168.10.8:81curl: (7) Failed to connect to 192.168.10.8 port 81: 拒绝连接#解决办法是使用REDIRECT来重定向端口 7.4 REDIRECT转发REDIRECT，是NAT表的 target，通过改变目标IP和端口，将接受的包转发至同一个主机的不同端口，可用于PREROUTING，OUTPUT链 REDIRECT 功能无需开启内核 ip_forward 转发 REDIRECT选项 1--to-ports port[-port] 范例：继续根据上面案例 1234567891011[root@lanserver2 ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 *:8080 *:* LISTEN 0 128 [::]:22 [::]:* #当我本机（10.0.0.180）80端口收到请求后通过REDIRECT转发到我本机的8080端口[root@lanserver2 ~]#iptables -t nat -A PREROUTING -d 10.0.0.180 -p tcp --dport 80 -j REDIRECT --to-ports 8080[root@internet ~]#curl 192.168.10.8:8110.0.0.180 7.5 FORWARD链实现内外网络的流量控制范例: 实现内网访问可以访问外网,反之禁止 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168#环境准备[root@internet ~]#hostname -I192.168.0.6[root@internet ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 192.168.0.8 0.0.0.0 UG 0 0 0 eth0[root@firewall ~]#hostname -I10.0.0.8 192.168.0.8[root@firewall ~]#vim /etc/sysctl.confnet.ipv4.ip_forward=1[root@firewall ~]#sysctl -p[root@lanserver1 ~]#hostname -I10.0.0.7[root@lanserver1 ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.8 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0[root@lanserver2 ~]#hostname -I10.0.0.17[root@lanserver2 ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.8 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0#方法1 通过标准模块实现内网访问外网特定服务http和icmp,反之禁止[root@firewall ~]#iptables -A FORWARD -j REJECT[root@firewall ~]#iptables -I FORWARD -s 10.0.0.0/24 -p tcp --dport 80 -j ACCEPT[root@firewall ~]#iptables -I FORWARD -d 10.0.0.0/24 -p tcp --sport 80 -j ACCEPT[root@firewall ~]#iptables -I FORWARD -s 10.0.0.0/24 -p icmp --icmp-type 8 -j ACCEPT[root@firewall ~]#iptables -I FORWARD -d 10.0.0.0/24 -p icmp --icmp-type 0 -j ACCEPT[root@firewall ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 174 14616 ACCEPT icmp -- * * 0.0.0.0/0 10.0.0.0/24 icmptype 02 218 18312 ACCEPT icmp -- * * 10.0.0.0/24 0.0.0.0/0 icmptype 83 10 1084 ACCEPT tcp -- * * 0.0.0.0/0 10.0.0.0/24 tcp spt:804 31 1938 ACCEPT tcp -- * * 10.0.0.0/24 0.0.0.0/0 tcp dpt:805 312 25632 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination #方法2 利用state模块实现内网访问可以访问外网,反之禁止[root@firewall ~]#iptables -D FORWARD 1[root@firewall ~]#iptables -D FORWARD 2[root@firewall ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 342 28728 ACCEPT icmp -- * * 10.0.0.0/24 0.0.0.0/0 icmptype 82 47 2898 ACCEPT tcp -- * * 10.0.0.0/24 0.0.0.0/0 tcp dpt:803 462 37608 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination [root@firewall ~]#iptables -I FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT[root@firewall ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 40 3429 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED2 443 37212 ACCEPT icmp -- * * 10.0.0.0/24 0.0.0.0/0 icmptype 83 49 3018 ACCEPT tcp -- * * 10.0.0.0/24 0.0.0.0/0 tcp dpt:804 563 46068 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination [root@lanserver1 ~]#ping 192.168.0.6 -c1PING 192.168.0.6 (192.168.0.6) 56(84) bytes of data.64 bytes from 192.168.0.6: icmp_seq=1 ttl=63 time=2.20 ms[root@lanserver2 ~]#curl 192.168.0.6internet[root@internet ~]#ping 10.0.0.7 -c1PING 10.0.0.7 (10.0.0.7) 56(84) bytes of data.From 192.168.0.8 icmp_seq=1 Destination Port Unreachable[root@internet ~]#curl 10.0.0.7curl: (7) couldn&#x27;t connect to host#利用state模块实现允许内网可以访问外网所有资源[root@firewall ~]#iptables -D FORWARD 2[root@firewall ~]#iptables -D FORWARD 2[root@firewall ~]#iptables -I FORWARD 2 -s 10.0.0.0/24 -m state --state NEW -j ACCEPT[root@firewall ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 134 15209 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED2 3 204 ACCEPT all -- * * 10.0.0.0/24 0.0.0.0/0 state NEW 3 572 46680 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination [root@lanserver1 ~]#ping 192.168.0.6 -c1PING 192.168.0.6 (192.168.0.6) 56(84) bytes of data.64 bytes from 192.168.0.6: icmp_seq=1 ttl=63 time=2.26 ms[root@lanserver2 ~]#curl 192.168.0.6internet[root@lanserver2 ~]#ssh 192.168.0.6The authenticity of host &#x27;192.168.0.6 (192.168.0.6)&#x27; can&#x27;t be established.RSA key fingerprint is SHA256:ldHMw3UFehPuE3bgtMHIX5IxRRTM7fwC4iZ0Qqglcys.RSA key fingerprint is MD5:8c:44:d9:3d:22:54:62:d8:27:77:d5:06:09:58:76:92.Are you sure you want to continue connecting (yes/no)?[root@internet ~]#curl 10.0.0.7curl: (7) couldn&#x27;t connect to host[root@internet ~]#ping 10.0.0.7 -c1PING 10.0.0.7 (10.0.0.7) 56(84) bytes of data.From 192.168.0.8 icmp_seq=1 Destination Port Unreachable[root@internet ~]#ssh 10.0.0.7ssh: connect to host 10.0.0.7 port 22: Connection refused#允许内网指定主机被外网访问[root@firewall ~]#iptables -I FORWARD 3 -d 10.0.0.7 -p tcp --dport 80 -j ACCEPT[root@firewall ~]#iptables -vnL --line-numbersChain INPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 63 12862 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED2 9 612 ACCEPT all -- * * 10.0.0.0/24 0.0.0.0/0 state NEW3 1 60 ACCEPT tcp -- * * 0.0.0.0/0 10.0.0.7 tcp dpt:804 586 47464 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachableChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination [root@internet ~]#curl 10.0.0.7lanserver1[root@internet ~]#ping 10.0.0.7 -c1PING 10.0.0.7 (10.0.0.7) 56(84) bytes of data.From 192.168.0.8 icmp_seq=1 Destination Port Unreachable[root@internet ~]#curl 10.0.0.17curl: (7) couldn&#x27;t connect to host 范例：内部可以访问外部，外部禁止访问内部 12345678910111213141516171819202122[root@internet-host ~]#hostname -I10.0.0.6[root@internet-host ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.0.0.0 0.0.0.0 255.255.255.0 U 1 0 0 eth00.0.0.0 10.0.0.8 0.0.0.0 UG 0 0 0 eth0[root@firewall-host ~]#hostname -I10.0.0.8 192.168.100.8[root@lan-host ~]#hostname -I192.168.100.7[root@lan-host ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.100.8 0.0.0.0 UG 100 0 0 eth0192.168.100.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0[root@firewall-host ~]#vim /etc/sysctl.confnet.ipv4.ip_forward=1[root@firewall-host ~]#sysctl -p[root@firewall-host ~]#iptables -A FORWARD -d 192.168.100.0/24 -m state --state NEW -j REJECT 范例：针对内部的特定服务可以允许外部访问，其它服务禁止访问 12345678[root@firewall-host ~]#iptables -I FORWARD -d 192.168.100.0/24 -p tcp --dport 80 -j ACCEPT[root@firewall-host ~]#iptables -vnL FORWARD --line-numbersChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 6 486 ACCEPT tcp -- * * 0.0.0.0/0 192.168.100.0/24 tcp dpt:802 3 228 REJECT all -- * * 0.0.0.0/0 192.168.100.0/24 state NEW reject-with icmp-port-unreachable 范例：针对内网不能访问外网的某一地址 123456789101112131415161718192021[root@internet ~]#ip a a 192.168.10.200 dev eth0 label eth0:1[root@internet ~]#ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:9c:0d:3c brd ff:ff:ff:ff:ff:ff inet 192.168.10.6/24 brd 192.168.10.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet 192.168.10.200/32 scope global eth0:1 valid_lft forever preferred_lft forever [root@firewall ~]#iptables -A FORWARD -s 10.0.0.0/24 -d 192.168.10.200 -j REJECT[root@lanserver1 ~]#curl 192.168.10.6192.168.10.6 [root@lanserver1 ~]#curl 192.168.10.200curl: (7) Failed to connect to 192.168.10.200 port 80: Connection refused 8 综合案例: 两个私有网络的互相通迅 12345#192.168.10.6访问172.16.0.7192.168.10.6（SNAT）-10.0.0.18（DNAT）-172.16.0.7#172.16.0.7访问192.168.10.6172.16.0.7（SNAT）-10.0.0.8（DNAT）-192.168.10.6 9 iptables常见操作替换系统防火墙在Centos7系统中默认防火墙管理工具不是iptables,当需要使用时则需要自己安装替换. 1234567[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# systemctl disable firewalld[root@localhost ~]# yum install -y iptables iptables-services[root@localhost ~]# systemctl restart iptables[root@localhost ~]# systemctl enable iptables 查询完整防火墙规则使用 -L -n –line-numbers 参数查看防火墙默认配置规则. 12345678910111213141516[root@localhost ~]# iptables -L -n --line-numbers[root@localhost ~]# iptables -F # 临时清空规则Chain INPUT (policy ACCEPT)num target prot opt source destination 1 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED2 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/0 3 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 4 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:225 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT)num target prot opt source destination 1 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT)num target prot opt source destination 设置防火墙默认拒绝设置默认拒绝规则，把 INPUT 链设置为默认拒绝,也就是拒绝所有连接请求. 1234567891011[root@localhost ~]# iptables -P INPUT DROP[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP) #这里可以看出INPUT链已变成DROPnum target prot opt source destination Chain FORWARD (policy ACCEPT)num target prot opt source destination Chain OUTPUT (policy ACCEPT)num target prot opt source destination 开启防火墙ICMP回显在默认规则拒绝的情况下,设置开启ICMP测试,允许主机ping通. 123456789101112[root@localhost ~]# iptables -I INPUT -p icmp -j ACCEPT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT)num target prot opt source destination Chain OUTPUT (policy ACCEPT)num target prot opt source destination 允许客户SSH远程连接在默认拒绝的情况下,设置开启22号端口,允许远程ssh连接到本机. 12345678910[root@localhost ~]# iptables -I INPUT -p tcp --dport 22 -j ACCEPT[root@localhost ~]# iptables -I OUTPUT -p tcp --sport 22 -j ACCEPT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy ACCEPT)num target prot opt source destination 1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:22Chain OUTPUT (policy ACCEPT)num target prot opt source destination 1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp spt:22 删除指定规则在默认拒绝的情况下,删除INPUT链,第2条数据,删除ICMP规则. 1234567891011[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:222 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/0 [root@localhost ~]# iptables -D INPUT 2[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 指定允许网段访问在默认拒绝的情况下,设置只允许192.168.1.0&#x2F;24网段的主机访问本机的22号端口. 1234567891011[root@localhost ~]# iptables -I INPUT -s 192.168.1.0/24 -p tcp --dport 22 -j ACCEPT[root@localhost ~]# iptables -I OUTPUT -s 192.168.1.0/24 -p tcp --sport 22 -j ACCEPT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 ACCEPT tcp -- 192.168.1.0/24 0.0.0.0/0 tcp dpt:22Chain OUTPUT (policy ACCEPT)num target prot opt source destination 1 ACCEPT tcp -- 192.168.1.0/24 0.0.0.0/0 tcp spt:22 拒绝访问指定端口在INPUT规则链中,添加拒绝所有人访问本机的8888号端口. 123456[root@localhost ~]# iptables -I INPUT -p tcp --dport 8888 -j REJECT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 REJECT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:8888 reject-with icmp-port-unreachable2 ACCEPT tcp -- 192.168.1.0/24 0.0.0.0/0 tcp dpt:22 拒绝访问指定主机网段的端口在INPUT规则链中,添加拒绝192.168.1.20主机访问本机的80端口. 12345678[root@localhost ~]# iptables -I INPUT -p tcp -s 192.168.1.20 --dport 80 -j REJECT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 REJECT tcp -- 192.168.1.20 0.0.0.0/0 tcp dpt:80 reject-with icmp-port-unreachable2 REJECT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:8888 reject-with icmp-port-unreachable3 ACCEPT tcp -- 192.168.1.0/24 0.0.0.0/0 tcp dpt:22 拒绝访问指定端口范围在INPUT规则链中,添加拒绝所有主机访问本机1000-2000端口. 1234567891011[root@localhost ~]# iptables -A INPUT -p tcp --dport 1000:2000 -j REJECT[root@localhost ~]# iptables -A INPUT -p udp --dport 1000:2000 -j REJECT[root@localhost ~]# iptables -L -n --line-numbersChain INPUT (policy DROP)num target prot opt source destination 1 REJECT tcp -- 192.168.1.20 0.0.0.0/0 tcp dpt:80 reject-with icmp-port-unreachable2 REJECT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:8888 reject-with icmp-port-unreachable3 ACCEPT tcp -- 192.168.1.0/24 0.0.0.0/0 tcp dpt:224 REJECT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpts:1000:2000 reject-with icmp-port-unreachable5 REJECT udp -- 0.0.0.0/0 0.0.0.0/0 udp dpts:1000:2000 reject-with icmp-port-unreachable SNAT-源地址转换&lt;内网映射到公网&gt;从本地发出的数据包,经过SNAT后,会自动伪装成公网的IP,并以公网IP访问指定服务. 123456#例：将本地 192.168.1.1 的请求自动伪装成外网地址 59.110.167.234[root@localhost ~]# iptables -t nat -A POSTROUTING -o ens32 -s 192.168.1.1 -j SNAT --to-source 59.110.167.234 -o #指定外网接口,此处为ens32 -s #指定内网口地址,此处为192.168.1.1 --to-source #外网口的地址 DNAT-目标地址转换&lt;公网映射到内网&gt;从公网接收的数据包,经过DNAT后,会自动将数据包转到指定的内网主机. 1234567#例：将请求 59.110.167.234 且端口为 80 的数据包,自动映射到内网 192.168.1.10[root@localhost ~]# iptables -t nat -A PREROUTING -i ens32 -d 59.110.167.234 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.10 --to-destination #内网口地址,此处为192.168.1.1 -i #绑定外网接口,此处为ens32 -d #外网地址,此处为8.8.8.8 -dport #内网端口,此处为80 限制物理请求连接数iptables可以利用connlimit模块实现限制同一IP针对某个端口的连接数. 允许限制每个客户端IP的并发连接数,即每个IP同时连接到一个服务器个数,还可以限制内网用户的网络使用,对服务器而言则可以限制每个IP发起的连接数. 12345678910111213141516# 限制同一IP同时最多100个http连接[root@localhost ~]# iptables -I INPUT -p tcp --syn --dport 80 -m connlimit --connlimit-above 100 -j REJECT[root@localhost ~]# iptables -I INPUT -p tcp --syn --dport 80 -m connlimit ! --connlimit-above 100 -j ACCEPT# 只允许每组C类IP同时100个http连接[root@localhost ~]# iptables -p tcp --syn --dport 80 -m connlimit --connlimit-above 100 --connlimit-mask 24 -j REJECT# 只允许每个IP同时5个80端口转发,超过的丢弃[root@localhost ~]# iptables -I FORWARD -p tcp --syn --dport 80 -m connlimit --connlimit-above 5 -j DROP# 限制某IP最多同时100个http连接[root@localhost ~]# iptables -A INPUT -s 192.168.1.100 -p tcp --syn --dport 80 -m connlimit --connlimit-above 100 -j REJECT# 限制每IP在一定的时间(比如60秒)内允许新建立最多100个http连接数[root@localhost ~]# iptables -A INPUT -p tcp --dport 80 -m recent --name BAD_HTTP_ACCESS --update --seconds 60 --hitcount 100 -j REJECT[root@localhost ~]# iptables -A INPUT -p tcp --dport 80 -m recent --name BAD_HTTP_ACCESS --set -j ACCEPT 配置基本防火墙规则我们可以在新安装的系统中依次执行下方代码,来配置一个基本的防火墙规则. 12345678910111213141516171819202122232425262728293031323334353637383940# 删除已有规则iptables --delete-chainiptables --flush# 默认禁止进,允许出,允许回环网卡iptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT ACCEPTiptables -A INPUT -i lo -j ACCEPT# 允许已建立的或相关连接的通行iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPTiptables -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT# 限制80端口443端口的单个IP的最大连接数为10iptables -I INPUT -p tcp --dport 80 -m connlimit --connlimit-above 10 -j DROPiptables -I INPUT -p tcp --dport 443 -m connlimit --connlimit-above 10 -j DROP# 允许80(HTTP)/873(RSYNC)/443(HTTPS)/20,21(FTP)/25(SMTP)端口的连接iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 20 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 21 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 25 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 873 -j ACCEPT# 允许SSH端口的连接,放行SSH端口iptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPTiptables -A OUTPUT -p tcp -m tcp --dport 22 -j ACCEPT# 允许pingiptables -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 11 -j ACCEPT# 放行允许DNS解析端口iptables -A OUTPUT -p udp -m udp -d 8.8.8.8 --dport 53 -j ACCEPTiptables -A OUTPUT -p udp -m udp -d 114.114.114.114 --dport 53 -j ACCEPT# 保存规则iptables-save 生产常用配置规则下面是收藏的一些生成环境下常用规则的配置,一般情况下配置这些规则足够使用. 1234567891011121314151617181920iptables -t filter -P INPUT DROP #设置默认规则,拒绝所有iptables -t filter -A INPUT -p tcp --dport 80 -j ACCEPT #放行80口iptables -t filter -A INPUT -p tcp --dport 443 -j ACCEPT #放行22口iptables -t filter -A INPUT -p tcp --dport 22 -j ACCEPT #放行22口iptables -t filter -A INPUT -p tcp --dport 80 -j ACCEPT #放行80端口iptables -t filter -I INPUT -p tcp --dport 443-j ACCEPT #插入在顶端一条放行443端口的规则iptables -t filter -I INPUT 2 -p tcp --dport 443 -j ACCEPT #在第二列插入一条443放行规则iptables -t filter -A INPUT -p tcp --dport 80 -j DROP #丢弃80端口的请求iptables -I INPUT 2 -p icmp -j DROP #丢弃ICMP请求iptables -t filter -D INPUT 3 #删除第三条规则iptables -A FORWARD -s 192.168.1.10 -j REJECT #拒绝IP的转发请求iptables -I INPUT -s 10.20.30.0/24 -j DROP #丢弃IP网段的入站请求iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP #丢弃从eth1网卡流入,且地址匹配的数据包iptables -A INPUT -o eth0 -s 192.168.1.0/24 -j DROP #丢弃从eth0网卡流出,且地址匹配的数据包iptables -A INPUT -p tcp --dport 20:21 -j ACCEPT #放行20-21端口的数据包iptables -I INPUT -p tcp -m multiport --dport 80-90,85 -j ACCEPTiptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.10-192.168.1.100 -j ACCEPT 防止常见网络攻击什么是syn，ddos，ping 12345SYN (Synchronize)：在 TCP（传输控制协议）中，SYN 是握手过程的一部分。当客户端尝试与服务器建立连接时，它发送一个带有 SYN 标志的数据包。服务器收到 SYN 数据包后，通常会回复一个带有 SYN 和 ACK（确认）标志的数据包，表示接受连接。最后，客户端再发送一个带有 ACK 标志的数据包，表示握手完成。这个过程通常称为三次握手。DDoS (Distributed Denial of Service)：DDoS 攻击是一种网络攻击，通过在短时间内向目标服务器发送大量的请求，使其超负荷，无法正常响应合法用户的请求。这些请求可以是来自多个分布式计算机的，使得攻击者能够利用分布式网络资源来发动攻击，使攻击更难以阻止。 配置防火墙防止syn，ddos攻击 123456# vim /etc/sysconfig/iptables在iptables中加入下面几行#anti syn，ddos-A FORWARD -p tcp --syn -m limit --limit 1/s --limit-burst 5 -j ACCEPT-A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j ACCEPT-A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT 说明：第一行：每秒中最多允许5个新连接 第二行：防止各种端口扫描 第三行：Ping洪水攻击（Ping of Death），可以根据需要调整或关闭 重启防火墙 1# /etc/init.d/iptables restart 屏蔽一个IP 1# iptables -I INPUT -s 192.168.0.1 -j DROP 怎么防止别人ping我 1# iptables -A INPUT -p icmp -j DROP 防止同步包洪水（Sync Flood） 1# iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT 防止各种端口扫描 1# iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j ACCEPT Ping洪水攻击（Ping of Death） 123456789101112131415161718# iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPTNMAP FIN/URG/PSH# iptables -A INPUT -i eth0 -p tcp --tcp-flags ALL FIN,URG,PSH -j DROPXmas Tree# iptables -A INPUT -i eth0 -p tcp --tcp-flags ALL ALL -j DROPAnother Xmas Tree# iptables -A INPUT -i eth0 -p tcp --tcp-flags ALL SYN,RST,ACK,FIN,URG -j DROPNull Scan(possibly)iptables -A INPUT -i eth0 -p tcp --tcp-flags ALL NONE -j DROPSYN/RST# iptables -A INPUT -i eth0 -p tcp --tcp-flags SYN,RST SYN,RST -j DROPSYN/FIN -- Scan(possibly)# iptables -A INPUT -i eth0 -p tcp --tcp-flags SYN,FIN SYN,FIN -j DROP 限制对内部封包的发送速度 1# iptables -A INPUT -f -m limit --limit 100/s --limit-burst 100 -j ACCEPT 限制建立联机的转发 1# iptables -A FORWARD -f -m limit --limit 100/s --limit-burst 100 -j ACCEPT","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"防火墙","slug":"防火墙","permalink":"https://aquapluto.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"安全技术和防火墙","slug":"Linux/firewall/introduce","date":"2025-08-21T03:02:00.000Z","updated":"2025-08-28T12:33:05.225Z","comments":true,"path":"Linux/firewall/introduce/","permalink":"https://aquapluto.github.io/Linux/firewall/introduce/","excerpt":"","text":"1 安全技术和防火墙1.1 安全技术 入侵检测系统（Intrusion Detection Systems）：特点是不阻断任何网络访问，量化、定位来自内外网络的威胁情况，主要以提供报警和事后监督为主，提供有针对性的指导措施和安全决策依据,类似于监控系统一般采用旁路部署方式 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式 防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略,会将希望外网访问的主机放在DMZ(demilitarized zone)网络中 防水墙（Waterwall）：与防火墙相对，防水墙是一种防止内部信息泄漏的安全产品。它利用透明加解密，身份认证，访问控制和审计跟踪等技术手段，对涉密信息，重要业务数据和技术专利等敏感信息的存储，传播和处理过程，实施安全保护；最大限度地防止敏感信息泄漏、被破坏和违规外传，并完整记录涉及敏感信息的操作日志，以便日后审计。 1.2 防火墙的分类按保护范围划分： 主机防火墙：服务范围为当前一台主机 网络防火墙：服务范围为防火墙一侧的局域网 按实现方式划分: 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件实现 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件，Windows 防火墙 ISA –&gt; ForefrontTMG 按网络协议划分： 网络层防火墙：OSI模型下四层，又称为包过滤防火墙 应用层防火墙&#x2F;代理服务器：proxy 代理网关，OSI模型七层 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议状态等因素，或他们的组合来确定是否允许该数据包通过优点：对用户来说透明，处理速度快且易于维护缺点：无法检查应用层数据，如病毒等 应用层防火墙 应用层防火墙&#x2F;代理服务型防火墙，也称为代理服务器（Proxy Server)将所有跨越防火墙的网络通信链路分为两段内外网用户的访问都是通过代理服务器上的“链接”来实现优点：在应用层对数据进行检查，比较安全缺点：增加防火墙的负载 提示：现实生产环境中所使用的防火墙一般都是二者结合体，即先检查网络数据，通过之后再送到应用层去检查 1.3 防火墙的作用防火墙的基本功能是监控和控制进出网络的数据流。它根据预先定义的安全规则来审查每一个数据包，这些规则可能基于IP地址、端口号、协议类型甚至是具体的内容。任何不符合规则的数据包都会被防火墙拦截，从而防止潜在的攻击和未经授权的访问。 除了基本的包过滤功能，现代防火墙还具备更高级的安全特性，如入侵检测系统（IDS）、入侵防御系统（IPS）和虚拟专用网络（VPN）等。这些功能使得防火墙成为了网络安全的第一道防线。 2 Linux防火墙的基本认识2.1 NetfilterLinux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中 Netfilter 是Linux 2.4.x之后新一代的Linux防火墙机制，是linux内核的一个子系统。Netfilter采用模块化设计，具有良好的可扩充性，提供扩展各种网络服务的结构化底层框架。Netfilter与IP协议栈是无缝契合，并允许对数据报进行过滤、地址转换、处理等操作 内核中netfilter相关的模块 12345[root@centos8 ~]#grep -m 10 NETFILTER /boot/config-4.18.0-193.el8.x86_64[root@centos7 ~]#grep -m 10 NETFILTER /boot/config-3.10.0-1127.el7.x86_64[root@centos6 ~]#grep -m 10 NETFILTER /boot/config-2.6.32-754.el6.x86_64[root@ubuntu2004 ~]#grep -m 10 NETFILTER /boot/config-5.4.0-33-generic[root@ubuntu1804 ~]#grep -m 10 NETFILTER /boot/config-4.15.0-29-generic 2.2 防火墙工具介绍2.2.1 iptables由软件包iptables提供的命令行工具，工作在用户空间，用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包 范例：安装iptables的service包 123456789101112131415[root@centos8 ~]#dnf -y install iptables-services#rocky中己默认安装[root@rocky86 ~]# rpm -q iptablesiptables-1.8.4-22.el8.x86_64#ubuntu中己默认安装root@ubuntu22:~# dpkg -l iptablesDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-==============-==============-============-=================================================ii iptables 1.8.7-1ubuntu5 amd64 administration tools for packet filtering and NAT 2.2.2 firewalld从CentOS 7 版开始引入了新的前端管理工具 软件包： firewalld firewalld-config 管理工具： firewall-cmd 命令行工具 firewall-config 图形工作 123456789101112#rocky默认安装[root@rocky86 ~]# rpm -q firewalldfirewalld-0.9.3-13.el8.noarch#ubuntu中没有安装root@ubuntu22:~# dpkg -l firewalldDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-==============-============-============-=================================un firewalld &lt;none&gt; &lt;none&gt; (no description available) 2.2.3 nftables此软件是CentOS 8 新特性,Nftables最初在法国巴黎的Netfilter Workshop 2008上发表，然后由长期的netfilter核心团队成员和项目负责人Patrick McHardy于2009年3月发布。它在2013年末合并到Linux内核中，自2014年以来已在内核3.13中可用。 它重用了netfilter框架的许多部分，例如连接跟踪和NAT功能。它还保留了命名法和基本iptables设计的几个部分，例如表，链和规则。就像iptables一样，表充当链的容器，并且链包含单独的规则，这些规则可以执行操作，例如丢弃数据包，移至下一个规则或跳至新链。 从用户的角度来看，nftables添加了一个名为nft的新工具，该工具替代了iptables，arptables和ebtables中的所有其他工具。从体系结构的角度来看，它还替换了内核中处理数据包过滤规则集运行时评估的那些部分 1234567891011[root@rocky86 ~]# rpm -q nftablesnftables-0.9.3-25.el8.x86_64[root@ubuntu ~]# dpkg -l nftablesDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-==============-==============-============-==============================================================ii nftables 1.0.2-1ubuntu2 amd64 Program to control packet filtering rules by Netfilter project CentOS 8 支持三种防火墙服务 123[root@centos8 ~]#systemctl status iptables.service[root@centos8 ~]#systemctl status firewalld.service[root@centos8 ~]#systemctl status nftables.service ubuntu 中的防火墙工具 12345678910111213141516171819202122232425262728#系统层面状态[root@ubuntu ~]# systemctl status ufw● ufw.service - Uncomplicated firewall Loaded: loaded (/lib/systemd/system/ufw.service; enabled; vendor preset:enabled) Active: active (exited) since Thu 2023-06-08 08:51:58 CST; 5h 6min ago Docs: man:ufw(8) Process: 734 ExecStart=/lib/ufw/ufw-init start quiet (code=exited,status=0/SUCCESS) Main PID: 734 (code=exited, status=0/SUCCESS) CPU: 2msJun 08 08:51:58 ubuntu systemd[1]: Starting Uncomplicated firewall...Jun 08 08:51:58 ubuntu systemd[1]: Finished Uncomplicated firewall.#应用层面状态[root@ubuntu ~]# ufw statusStatus: inactive[root@ubuntu ~]# ufw enableCommand may disrupt existing ssh connections. Proceed with operation (y|n)? nAborted[root@ubuntu ~]# systemctl status nftables.service○ nftables.service - nftables Loaded: loaded (/lib/systemd/system/nftables.service; disabled; vendorpreset: enabled) Active: inactive (dead) Docs: man:nft(8) http://wiki.nftables.org 2.3 netfilter 中五个勾子函数和报文流向Netfilter在内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一个命令工具（iptables）向其写入规则，内核中的勾子函数根据预设的规则进行工作，达到对流经的数据包进行过滤，拒绝，转发等功能。 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上 特别说明 从 Linux kernel 4.2 版以后，netfilter 在prerouting 前加了一个 ingress 勾子函数。可以使用这个新的入口挂钩来过滤来自第2层的流量，这个新挂钩比预路由要早，基本上是 tc 命令（流量控制工具）的替代品。 三种报文流向 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING INPUT 链 该链用于处理进入本地系统的流量（即目标是本机的流量）。 所有到达本机的流量都会经过 INPUT 链进行检查 适用于例如 SSH、HTTP 等服务的连接请求 OUTPUT 链 该链用于处理从本地系统发出的流量（即源是本机的流量）。 所有由本机发出的流量都会经过 OUTPUT 链 适用于例如从本机访问外部网站的请求 FORWARD 链 该链用于处理被路由通过本机的流量（即流量不会到达本机，而是转发到其他网络）。 此链仅适用于做路由的机器 适用于例如路由器转发的流量 PREROUTING 链 该链用于在路由决策之前处理流量。 通常用于目标地址转换（DNAT），在数据包到达路由前修改其目标地址 适用于例如网络地址转换（NAT）时，修改目标地址的规则 POSTROUTING 链 该链用于在路由决策之后处理流量。 通常用于源地址转换（SNAT），在数据包离开本机前修改源地址 例如 NAT 中修改源地址的规则","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"防火墙","slug":"防火墙","permalink":"https://aquapluto.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"ssh远程连接服务","slug":"Linux/service-manage/ssh","date":"2025-08-21T03:01:35.000Z","updated":"2025-08-28T12:33:05.353Z","comments":true,"path":"Linux/service-manage/ssh/","permalink":"https://aquapluto.github.io/Linux/service-manage/ssh/","excerpt":"","text":"1 ssh服务介绍ssh: secure shell protocol, 22&#x2F;tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议，生产中要改端口号 具体的软件实现： OpenSSH：ssh协议的开源实现，CentOS 默认安装 dropbear：另一个ssh协议的开源项目的实现 ssh和telnet的区别 telnet： 不支持root用户登录，只允许普通用户登录 数据传输过程中明文的 ssh： 支持root用户登录 数据传输过程中时加密码 1.1 公钥交换原理 客户端发起链接请求 服务端返回自己的公钥，以及一个会话ID（这一步客户端得到服务端公钥）客户端生成密钥对 客户端用自己的公钥异或会话ID，计算出一个值Res，并用服务端的公钥加密 客户端发送加密后的值到服务端，服务端用私钥解密，得到Res 服务端用解密后的值Res异或会话ID，计算出客户端的公钥（这一步服务端得到客户端公钥） 最终：双方各自持有三个秘钥，分别为自己的一对公、私钥，以及对方的公钥，之后的所有通讯都会被加密 1.2 ssh加密通讯原理 2 openssh软件Openssh软件相关包： openssh openssh-clients openssh-server 服务器端程序：&#x2F;usr&#x2F;sbin&#x2F;sshd Unit 文件：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;sshd.service 2.1 ssh命令ssh命令是ssh客户端，允许实现对远程系统经验证地加密安全访问 当用户远程连接ssh服务器时，会复制ssh服务器 /etc/ssh/ssh_host*key.pub 文件中的公钥到客户机的~/.ssh/know_hosts 中。下次连接时，会自动匹配相对应的私钥，不能匹配，将拒绝连接 ssh客户端配置文件： /etc/ssh/ssh_config 主要配置 12345678#StrictHostKeyChecking ask#首次登录不显示检查提示StrictHostKeyChecking no# IdentityFile ~/.ssh/id_rsa# IdentityFile ~/.ssh/id_dsa# IdentityFile ~/.ssh/id_ecdsa# IdentityFile ~/.ssh/id_ed25519# Port 22 首次连接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#首次连接，会显示目标主机的指纹信息（唯一标识），并提示是否继续#敲yes后会将目标主机的公钥保存在当前用户的~/.ssh/know_hosts 文件中root@ubuntu2204:~# ssh root@10.0.0.206The authenticity of host &#x27;10.0.0.206 (10.0.0.206)&#x27; can&#x27;t be established.ED25519 key fingerprint is SHA256:+CC49Sra7GzLnNYn4QqcT0QyDEwS+osEpcbQ5e1zCc8.This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added &#x27;10.0.0.206&#x27; (ED25519) to the list of known hosts.root@10.0.0.206&#x27;s password: #在客户端机器上可以看到远端主机的公钥root@ubuntu2204:~# ls -l .ssh/total 8-rw------- 1 root root 978 May 23 02:08 known_hosts-rw-r--r-- 1 root root 142 May 23 02:08 known_hosts.old#该文件中保存的内容，在远程主机上都能找到对应的root@ubuntu2204:~# cat .ssh/known_hosts#在10.0.0.206上查看[root@ubuntu ~]# ls -l /etc/ssh/*pub-rw-r--r-- 1 root root 605 May 4 17:02 /etc/ssh/ssh_host_dsa_key.pub-rw-r--r-- 1 root root 177 May 4 17:02 /etc/ssh/ssh_host_ecdsa_key.pub #公钥-rw-r--r-- 1 root root 97 May 4 17:02 /etc/ssh/ssh_host_ed25519_key.pub-rw-r--r-- 1 root root 569 May 4 17:02 /etc/ssh/ssh_host_rsa_key.pub#首次连接时并不能确定远端主机公钥的真伪,为了确定真伪，可以进行以下操作#在连接前，在准备要连接的机器上自己连自己，查看一下指纹，比对一下指纹[root@ubuntu ~]# ssh 127.1The authenticity of host &#x27;127.0.0.1 (127.0.0.1)&#x27; can&#x27;t be established.ED25519 key fingerprint is SHA256:+CC49Sra7GzLnNYn4QqcT0QyDEwS+osEpcbQ5e1zCc8.This key is not known by any other namesAre you sure you want to continue connecting (yes/no/[fingerprint])? #首次连接之后，保存了远程主机的公钥，后续如果有冒充这个IP地址的主机，连接到这个假冒的主机，发现公钥不一样，则会提示#如果远程主机确实发生了改变，则可以删除本地~.ssh/know_host中的对应的公钥root@ubuntu2204:~# ssh root@10.0.0.206@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ED25519 key sent by the remote host isSHA256:1eOK9Aygq1kbA+smlYjwRwRsx+ZdSRkDnNy5AFp3aPE.Please contact your system administrator.Add correct host key in /root/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /root/.ssh/known_hosts:3remove with:ssh-keygen -f &quot;/root/.ssh/known_hosts&quot; -R &quot;10.0.0.206&quot;Host key for 10.0.0.206 has changed and you have requested strict checking.Host key verification failed. 范例：修改客户端配置，首次连接自动回答为yes 1[root@centos7 ~]#sed -i.bak &#x27;/StrictHostKeyChecking/s/.*/StrictHostKeyChecking no/&#x27; /etc/ssh/ssh_config 格式： 12ssh [user@]host [COMMAND]ssh [-l user] host [COMMAND] 常见选项 12345678-p port #远程服务器监听的端口-b #指定连接的源IP-v #调试模式-C #压缩方式-X #支持x11转发-t #强制伪tty分配，如：ssh -t remoteserver1 ssh -t remoteserver2 ssh remoteserver3-o option 如：-o StrictHostKeyChecking=no-i &lt;file&gt; #指定私钥文件路径，实现基于key验证，默认使用文件： ~/.ssh/id_dsa,~/.ssh/id_ecdsa, ~/.ssh/id_ed25519，~/.ssh/id_rsa等 范例：通过多个跳板登录远程主机10.0.0.6 123456[root@centos8 ~]#ssh -t 10.0.0.8 ssh -t 10.0.0.7 ssh 10.0.0.6root@10.0.0.8&#x27;s password:root@10.0.0.7&#x27;s password:root@10.0.0.6&#x27;s password:Last login: Fri May 22 09:10:28 2020 from 10.0.0.7[root@centos6 ~]# 范例：远程执行命令 1234[root@centos6 ~]#ssh 10.0.0.8 &quot;sed -i.bak&#x27;/StrictHostKeyChecking/s/.*/StrictHostKeyChecking no/&#x27; /etc/ssh/ssh_config&quot;root@10.0.0.8&#x27;s password:[root@centos6 ~]# 范例：在远程主机运行本地shell脚本 12345678[root@centos8 ~]#hostname -I10.0.0.8[root@centos8 ~]#cat test.sh#!/bin/bashhostname -I[root@centos8 ~]#ssh 10.0.0.18 /bin/bash &lt; test.shroot@10.0.0.18&#x27;s password:10.0.0.18 范例：加选项，首次连接时自动回答yes 123[root@ubuntu ~]# ssh -o StrictHostKeyChecking=no 10.0.0.210Warning: Permanently added &#x27;10.0.0.210&#x27; (ED25519) to the list of known hosts.root@10.0.0.210&#x27;s password: 2.2 scp命令1234567scp [options] SRC... DEST/-C #压缩数据流-r #递归复制-p #保持原文件的属性信息-q #静默模式-P PORT #指定远程服务器的端口,默认22 方式 123scp [options] [user@]host:/sourcefile /destpathscp [options] /sourcefile [user@]host:/destpathscp [options] [user@]host1:/sourcetpath [user@]host2:/destpath 范例：将本地文件复制到远程 123456789#将当前主机/root/test.sh 复制到远程主机 mage 的家目录下[root@ubuntu ~]# scp /root/test.sh mage@10.0.0.210:mage@10.0.0.210&#x27;s password:test.sh 100% 25 2.6KB/s 00:00#远程主机上查看root@ubuntu2204:~# ls -l /home/mage/total 4-rwxr-xr-x 1 mage mage 25 May 23 07:17 test.sh 范例：将远程主机文件复制到本地 1234[root@rocky86 ~]# scp root@10.0.0.157:/home/jose/test.sh .root@10.0.0.157&#x27;s password:test.sh 100% 25 10.0KB/s 00:00 范例：源和目标都不是本机 123456[root@rocky86 ~]# scp jose@10.0.0.157:test.sh root@10.0.0.154:jose@10.0.0.157&#x27;s password:root@10.0.0.154&#x27;s password:test.sh 100% 25 12.9KB/s 00:00 Connection to 10.0.0.157 closed. 范例：复制目录 12345678910[root@ubuntu ~]# scp -r /var/log/ root@10.0.0.161:/tmp/root@10.0.0.161&#x27;s password:syslog 100% 1575KB 15.4MB/s 00:00 sysinfo.log 100% 0 0.0KB/s 00:00 kern.log.2.gz 100% 281KB 45.9MB/s 00:00 ......scp -r dir dest/ #复制整个目录scp -r dir/ dest/ #复制整个目录scp -r dir/* dest/ #复制目录下所有文件 2.3 rsync命令rsync工具可以基于ssh和rsync协议实现高效率的远程系统之间复制文件，使用安全的shell连接做为传输方式，比scp更快，基于增量数据同步，即只复制两方不同的文件，此工具来自于rsync包 注意：通信两端主机都需要安装 rsync 软件 12rsync -av /etc server1:/tmp/ #复制目录和目录下文件rsync -av /etc/ server1:/tmp/ #只复制目录下文件 常用选项 123456789101112131415-n 模拟复制过程-v 显示详细过程-r 递归复制目录树-p 保留权限-t 保留修改时间戳-g 保留组信息-o 保留所有者信息-l 将软链接文件本身进行复制（默认）-L 将软链接文件指向的文件复制-u 如果接收者的文件比发送者的文件较新，将忽略同步-z 压缩，节约网络带宽-a 保留属性，相当于-rlptgoD，但不保留ACL（-A）和SELinux属性（-X）--delete 源数据删除，目标数据也自动同步删除--progress 显示进度--bwlimit=5120 #限速以KB为单位,5120表示5MB 范例 12345678910[root@centos8 ~]#rsync -auv --delete /data/test 10.0.0.7:/data[root@centos8 ~]#rsync -auv --progress --bwlimit=5120 --delete /data/test 10.0.0.7:/datasending incremental file listtest/test/a.img 104,857,600 100% 5.01MB/s 0:00:19 (xfr#1, to-chk=0/2)sent 104,883,319 bytes received 39 bytes 4,463,121.62 bytes/sectotal size is 104,857,600 speedup is 1.00[root@rocky8 ~]# 范例：增量复制 1234567891011121314151617181920212223[root@ubuntu ~]# cp /var/log/syslog ./0525[root@ubuntu ~]# ls -l ./0525total 1584-rw-r--r-- 1 123 456 657 May 25 15:46 fstab-rw-r--r-- 1 123 456 24 May 25 15:46 issue-rw-r----- 1 root root 1612718 May 25 15:55 syslog#这次只复制了新增的syslog 文件[root@ubuntu ~]# rsync -av /root/0525 root@10.0.0.161:/tmp/root@10.0.0.161&#x27;s password:sending incremental file list0525/0525/syslogsent 1,613,291 bytes received 39 bytes 460,951.43 bytes/sectotal size is 1,613,399 speedup is 1.00#查看目标机，0918这个目录属性更新了root@ubuntu:~# ls -l /tmp/0525/total 1584-rw-r--r-- 1 123 456 657 May 25 15:46 fstab-rw-r--r-- 1 123 456 24 May 25 15:46 issue-rw-r----- 1 root root 1612718 May 25 15:55 syslog 2.4 sftp命令交互式文件传输工具，用法和传统的ftp工具相似，利用ssh服务实现安全的文件上传和下载 使用ls cd mkdir rmdir pwd get put等指令，可用？或help获取帮助信息 12sftp [user@]hostsftp&gt; help 2.5 自动登录ssh工具sshpass由EPEL源提供，ssh登陆不能在命令行中指定密码。sshpass的出现，解决了这一问题。sshpass用于非交互SSH的密码验证，一般用在sh脚本中，无须再次输入密码（本机known_hosts文件中有的主机才能生效）。它允许你用 -p 参数指定明文密码，然后直接登录远程服务器，它支持密码从命令行、文件、环境变量中读取。 格式 12345sshpass [option] command parameters-p password #后跟密码它允许你用 -p 参数指定明文密码，然后直接登录远程服务器-f filename #后跟保存密码的文件名，密码是文件内容的第一行-e #将环境变量SSHPASS作为密码 范例 12345[root@centos7 ~]#sshpass -p zjwjl2004 ssh -o StrictHostKeyChecking=no 10.0.0.129 hostname -I10.0.0.129 [root@ubuntu ~]# sshpass -p 123456 ssh 10.0.0.161 hostname -I10.0.0.161 范例 1234[root@ubuntu ~]# cat pwd.txt123456[root@ubuntu ~]# sshpass -f pwd.txt ssh 10.0.0.161 hostname -I10.0.0.161 范例 123[root@ubuntu ~]# export SSHPASS=123456[root@ubuntu ~]# sshpass -e ssh 10.0.0.161 hostname -I10.0.0.161 范例：批量修改主机密码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@ubuntu ~]# cat pwd.sh#!/bin/bashIPLIST=&quot;10.0.0.16110.0.0.210&quot;PASS=123456. /etc/os-releasepre_os () &#123; if [[ $ID =~ ubuntu ]];then dpkg -l sshpass &amp;&gt; /dev/null || &#123; apt update; apt -y install sshpass; &#125; elif [[ $ID =~ rocky|centos|rhel ]];then rpm -q sshpass &amp;&gt;/dev/null || yum -y install sshpass else echo &quot;不支持当前操作系统&quot; exit fi&#125;change_root_pass () &#123; [ -f ip_pass.txt ] &amp;&amp; mv ip_pass.txt ip_pass.txt.bak for ip in $IPLIST;do pass=`openssl rand -base64 9` sshpass -p $PASS ssh -o StrictHostKeyChecking=no $ip &quot;echo root:$pass | chpasswd&quot; if [ $? -eq 0 ];then echo &quot;$ip:root:$pass&quot; &gt;&gt; ip_pass.txt echo &quot;change root password is successfull on $ip&quot; else echo &quot;change root password is failed on $ip&quot; fi done&#125;pre_oschange_root_pass[root@ubuntu ~]# chmod a+x pwd.sh[root@ubuntu ~]# ./pwd.sh[root@ubuntu ~]# ./pwd.shchange root password is successfull on 10.0.0.161change root password is successfull on 10.0.0.210#记录执行结果[root@ubuntu ~]# cat ip_pass.txt10.0.0.161:root:uOihK+VaW54C10.0.0.210:root:aSQdPL57FHaX 2.6 lastb命令lastb 命令用于列出登入系统失败的用户相关信息。 单独执行 lastb 指令，它会读取位于 &#x2F;var&#x2F;log 目录下，名称为 btmp 的文件，并把该文件记录登入失败的用户名，全部显示出来 12345678910lastb [-adRx][-f &lt;记录文件&gt;][-n &lt;显示行数&gt;][帐号名称...][终端机编号...]参数说明：-R #省略主机名 hostname 的列-a #把从何处登入系统的主机名称或IP地址显示在最后一行。-d #将IP地址转换成主机名称。-f&lt;记录文件&gt; #指定记录文件。-n&lt;显示行数&gt;或-&lt;显示行数&gt; #显示名单的行数。-R #不显示登入系统的主机名称或IP地址。-x #显示系统关机，重新开机，以及执行等级的改变等信息。 范例：统计ssh登录失败次数最多的前十个远程IP 1234567891011121314151617181920212223[root@centos8 ~]#lastb -f btmp-test | awk &#x27;&#123;print $3&#125;&#x27;|sort |uniq -c|sort -nr|head 86294 58.218.92.37 43148 58.218.92.26 18036 112.85.42.201 10501 111.26.195.101 10501 111.231.235.49 10501 111.204.186.207 10501 111.11.29.199 10499 118.26.23.225 6288 42.7.26.142 4236 58.218.92.30 [root@centos8 ~]#lastb -f btmp-test | awk &#x27;&#123;ip[$3]++&#125;END&#123;for(i in ip)&#123;print ip[i],i&#125;&#125;&#x27;|sort -nr|head86294 58.218.92.3743148 58.218.92.2618036 112.85.42.20110501 111.26.195.10110501 111.231.235.4910501 111.204.186.20710501 111.11.29.19910499 118.26.23.2256288 42.7.26.1424236 58.218.92.30 3 ssh登录验证方式介绍基于用户和口令登录验证 客户端发起ssh请求，服务器会把自己的公钥发送给用户 用户会根据服务器发来的公钥对密码进行加密 加密后的信息回传给服务器，服务器用自己的私钥解密，如果密码正确，则用户登录成功 基于密钥的登录方式 首先在客户端生成一对密钥（ssh-keygen） 并将客户端的公钥ssh-copy-id 拷贝到服务端 当客户端再次发送一个连接请求，包括ip、用户名 服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，就会随机生成一个字符串，例如：magedu 服务端将使用客户端拷贝过来的公钥进行加密，然后发送给客户端 得到服务端发来的消息后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端 服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录 3.1 实现基于密钥的登录方式在客户端生成密钥对 1ssh-keygen -t rsa [-P &#x27;password&#x27;] [-f “~/.ssh/id_rsa&quot;] [-C &quot;your_email@example.com&quot;] 命令释义说明： 使用 ssh-keygen 用于生成 RSA 密钥和公钥，-t 指定密钥类型，就是生成 RSA 加密的钥匙，-p指定密码，-C 添加注释，一般用邮箱地址，-f 指定密钥对存放路径 RSA 也是默认的加密类型，所以可以只输入 ssh-keygen，默认的 RSA 长度是 2048 位，如果你非常注重安全，那么可以指定 4096 位的长度，指令如下： 1ssh-keygen -b 4096 -t rsa 生成密钥对后，你可以选择将其存储在默认位置（~/.ssh/ 目录下）或选择其他位置。 生成的密钥对包括两个文件：私钥文件（id_rsa）和公钥文件（id_rsa.pub）。私钥文件存储在本地，而公钥文件则需要被复制到远程服务器上。 把公钥文件传输至要免密登录的远程服务器对应用户的家目录 123456ssh-copy-id [-i [identity_file]] [user@]host选项-p：指定ssh端口号-i &lt;identity_file&gt;：指定复制到远程主机的公钥认证文件路径-o &lt;ssh_option&gt;：指定其他ssh参数 重设私钥口令： 1ssh-keygen -p 范例：10.0.0.183（centos7）远程免密登陆10.0.0.176（rocky8）和10.0.0.129（Ubuntu2004） 12345678910111213141516171819202122232425262728293031323334353637[root@centos7 ~]#ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #回车，接受默认值Enter passphrase (empty for no passphrase): #回车，接受默认值，空密码Enter same passphrase again: #回车，接受默认值Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #生成私钥存放路径，默认/root/.ssh/id_rsaEnter passphrase (empty for no passphrase): #私钥文件要不要加密Enter same passphrase again: root@centos7 ~]#ls .sshid_rsa id_rsa.pub[root@centos7 ~]#ssh-copy-id 10.0.0.129 #默认是root用户，如果要指定，wu@10.0.0.129[root@ubuntu2023 ~]#cat .ssh/authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwUJnGIjiRoZkFN+RLZdS0/td6mYu9ANZJlNrTp/AbN73JXuMx9CAjhNPfS1NzeD8U0HCDyMBDZPjgiTtwB8rqHIL2TiKdf6gnXjiLbQ15v5fk7ZW2Na7Nh4x3sUY3ZpuZt/w2SEG37yHxwAKRCBBccafEbbo/GW8GOhTdbHEUlONSv5jDLVzQyxNzjAgpBX7Y/LYbtrY3QG6UJOw61gknI8rPWlBN+VuPo11NXqQ5F/mVCy/QgzZIkD5N/MBCBO2jMcLkXD0+kgrOZxx1DY7lC2jyGt27zu9OS/OLPR7ZNmLKKnCMJp+Yp+DHcelVrDEMD8SoAXh1gMAb7Jux04i/ root@centos7[root@centos7 ~]#cat .ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwUJnGIjiRoZkFN+RLZdS0/td6mYu9ANZJlNrTp/AbN73JXuMx9CAjhNPfS1NzeD8U0HCDyMBDZPjgiTtwB8rqHIL2TiKdf6gnXjiLbQ15v5fk7ZW2Na7Nh4x3sUY3ZpuZt/w2SEG37yHxwAKRCBBccafEbbo/GW8GOhTdbHEUlONSv5jDLVzQyxNzjAgpBX7Y/LYbtrY3QG6UJOw61gknI8rPWlBN+VuPo11NXqQ5F/mVCy/QgzZIkD5N/MBCBO2jMcLkXD0+kgrOZxx1DY7lC2jyGt27zu9OS/OLPR7ZNmLKKnCMJp+Yp+DHcelVrDEMD8SoAXh1gMAb7Jux04i/ root@centos7[root@centos7 ~]#ssh 10.0.0.129 #免密登陆[root@ubuntu2023 ~]#[root@centos7 ~]#ssh 10.0.0.129 hostname #也可远程执行命令ubuntu2023[root@centos7 ~]#ssh-copy-id 10.0.0.176[root@Rocky8 ~]#ls .sshauthorized_keys[root@centos7 ~]#ssh 10.0.0.176[root@Rocky8 ~]##如果不想敲yesno[root@centos7 ~]#ssh -o StrictHostKeyChecking=no 10.0.0.176 范例：10.0.0.183（centos7，以该机为主要机器）10.0.0.176（rocky8）和10.0.0.129（Ubuntu2004）互相免密远程登陆 123456789101112[root@centos7 ~]#ssh-keygen [root@centos7 ~]#ssh-copy-id 10.0.0.183[root@centos7 ~]#ls .sshauthorized_keys id_rsa id_rsa.pub known_hosts[root@centos7 ~]#scp -r .ssh 10.0.0.176:/root/[root@Rocky8 ~]#ls .sshauthorized_keys id_rsa id_rsa.pub known_hosts[root@centos7 ~]#scp -r .ssh 10.0.0.129:/root/[root@ubuntu2023 ~]#ls .sshauthorized_keys id_rsa id_rsa.pub known_hosts authorized_keys known_hosts 位置 存在于服务器端（目标主机）。 存在于客户端（发起连接的主机）。 作用 存储允许登录的客户端公钥，用于身份验证。 存储远程主机的公钥，用于验证主机身份。 文件内容 每行一个公钥，对应一个允许登录的用户。 每行一个条目，包含主机名&#x2F;IP 和公钥。 权限要求 必须限制为仅用户可读写（600）。 必须限制为仅用户可读写（600）。 首次连接行为 不涉及。 客户端会提示确认主机公钥，并记录到 known_hosts。 范例：实现基于 key 验证 123456789101112131415161718192021222324252627282930313233343536373839[root@centos8 ~]#ssh-keygen[root@centos8 ~]#ll .ssh/total 8-rw------- 1 root root 2622 May 22 09:51 id_rsa-rw-r--r-- 1 root root 583 May 22 09:51 id_rsa.pub[root@centos8 ~]#ssh-copy-id root@10.0.0.7[root@centos7 ~]#ll .sshtotal 4-rw------- 1 root root 583 May 22 09:52 authorized_keys[root@centos8 ~]#ssh 10.0.0.7Last login: Fri May 22 08:43:50 2020 from 10.0.0.1[root@centos7 ~]#exitlogoutConnection to 10.0.0.7 closed.[root@centos8 ~]#scp /etc/fstab 10.0.0.7:/datafstab#对私钥加密[root@centos8 ~]#ssh-keygen -p[root@centos8 ~]#ssh 10.0.0.7Enter passphrase for key &#x27;/root/.ssh/id_rsa&#x27;: #输入私钥的密码Last login: Fri May 22 08:47:50 2020 from 10.0.0.8[root@centos7 ~]#exitlogoutConnection to 10.0.0.7 closed.#启用ssh代理[root@centos8 ~]#ssh-agent bash[root@centos8 ~]#ps aux|grep agentroot 1972 0.0 0.0 29440 548 ? Ss 10:18 0:00 ssh-agent bashroot 1992 0.0 0.1 12108 964 pts/0 S+ 10:18 0:00 grep --color=auto agent[root@centos8 ~]#ssh-addEnter passphrase for /root/.ssh/id_rsa:Identity added: /root/.ssh/id_rsa (root@centos8.wangxiaochun.com)[root@centos8 ~]#ssh 10.0.0.7Last login: Fri May 22 08:48:55 2020 from 10.0.0.8 范例: 利用expect实现ssh key的批量部署 1234567891011121314151617181920212223242526#!/bin/bashCOLOR=&quot;echo -e \\E[1;32m&quot;END=&quot;\\E[0m&quot;PASSWORD=123456IPLIST=&quot;10.0.0.710.0.0.17&quot;[ ! -f ~/.ssh/id_rsa ] &amp;&amp; ssh-keygen -P &quot;&quot; -f ~/.ssh/id_rsa &amp;&gt;/dev/nullrpm -q expect &amp;&gt; /dev/null || yum -y -q install expect &amp;&gt;/dev/nullfor ip in $IPLIST ;do&#123; expect &lt;&lt;EOF set timeout 60 spawn ssh-copy-id $ip expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\r&quot;;exp_continue &#125; &quot;password:&quot; &#123; send &quot;$PASSWORD\\r&quot; &#125; &#125; expect eof EOF $COLOR&quot;$ip is ready&quot;$END&#125;&amp;donewait$COLOR&quot;Push ssh key is finished!&quot;$END 范例：expect实现批量基于ssh的key部署 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@centos8 ~]#cat push_ssh_key.sh#!/bin/bashPASS=magedurpm -q expect &amp;&gt; /dev/null || yum -y install expect &amp;&gt; /dev/nullif [ ! -e /root/.ssh/id_rsa ];then ssh-keygen -t rsa -P &quot;&quot; -f /root/.ssh/id_rsa &amp;&gt; /dev/null echo &quot;ssh key is created&quot;fiwhile read IP ;do expect &amp;&gt; /dev/null &lt;&lt;EOF #或者expect &lt;&lt;EOF &amp;&gt; /dev/null set timeout 20 spawn ssh-copy-id -i /root/.ssh/id_rsa.pub root@$IP expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$PASS\\n&quot; &#125; &#125; expect eof EOF echo $IP is readydone &lt; hosts.txt[root@centos8 ~]#cat hosts.txt10.0.0.710.0.0.6[root@centos8 ~]#bash push_ssh_key.shssh key is created10.0.0.7 is ready10.0.0.6 is ready[root@centos8 ~]#ssh 10.0.0.7Last login: Fri May 22 10:19:35 2020 from 10.0.0.8[root@centos7 ~]#exitlogoutConnection to 10.0.0.7 closed.[root@centos8 ~]#ssh 10.0.0.6Last login: Fri May 22 10:19:39 2020 from 10.0.0.8[root@centos6 ~]#exitlogoutConnection to 10.0.0.6 closed. 范例：基于key验证实现批量主机管理 123456[root@centos8 ~]#cat hosts.txt10.0.0.710.0.0.6[root@centos8 ~]#for i in `cat hosts.txt`;do ssh $i hostname -I ;done10.0.0.710.0.0.6 范例：批量部署多台主机基于key验证脚本1 123456789101112#!/bin/bashNET=10.0.0PASS=magedussh-keygen -P &quot;&quot; -f /root/.ssh/id_rsa &amp;&gt; /dev/nullrpm -q sshpass &amp;&gt; /dev/null || yum -y install sshpass &amp;&gt; /dev/nullfor i in &#123;1..100&#125;;do&#123; sshpass -p $PASS ssh-copy-id -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa.pub $NET.$i &amp;&gt; /dev/null&#125;&amp;donewait 范例：批量部署多台主机基于key验证脚本2 1234567891011121314151617#!/bin/bashHOSTS=&quot;10.0.0.610.0.0.710.0.0.1810.0.0.28&quot;PASS=magedussh-keygen -P &quot;&quot; -f /root/.ssh/id_rsa &amp;&gt; /dev/nullrpm -q sshpass &amp;&gt; /dev/null || yum -y install sshpass &amp;&gt; /dev/nullfor i in $HOSTS;do&#123; sshpass -p $PASS ssh-copy-id -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa.pub $i &amp;&gt; /dev/null&#125;&amp;donewait 3.2 SSH密钥代理验证代理（authentication agent）保密解密后的密钥，口令就只需要输入一次，在GNOME中，代理被自动提供给root用户 SSH密钥代理是一个可以管理 SSH 私钥的程序，可以在一次登录后将私钥的解密密码缓存起来，以便后续的 SSH 操作无需再次输入密码 这样，你就不需要每次 SSH 登录都输入私钥密码了，提高了使用的便利性和安全性。在实际使用中，你可能会有多个密钥对，用于不同的服务器或用途。为了更好地管理这些密钥对，可以使用 SSH 配置文件或密钥文件的别名。 12345#启用代理ssh-agent bash#添加私钥到代理ssh-add ~/.ssh/id_rsa 在SecureCRT或Xshell实现基于key验证 在SecureCRT工具 —&gt; 创建公钥 —&gt; 生成 Identity.pub 文件 转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文件authorized_keys中,注意权限必须为600，在需登录的ssh主机上执行： 1ssh-keygen -i -f Identity.pub &gt;&gt; .ssh/authorized_keys 4 ssh服务器配置服务器端：sshd 服务器端的配置文件: &#x2F;etc&#x2F;ssh&#x2F;sshd_config 服务器端的配置文件帮助：man 5 sshd_config 常用参数： 1234567891011121314151617181920212223242526272829Port 22 #生产建议修改，不然容易被黑客攻击ListenAddress ip #监听的ip地址LoginGraceTime 2mPermitRootLogin yes #默认ubuntu不允许root远程ssh登录StrictModes yes #检查.ssh/文件的所有者，权限等MaxAuthTries 6 #一次连接，最多可以输错6次密码MaxSessions 10 #同一个连接最大会话PubkeyAuthentication yes #基于key验证PermitEmptyPasswords no #空密码连接PasswordAuthentication yes #基于用户名和密码连接PrintMotd no #是否输出motd信息，改成yes 则motd 会输出两次ChallengeResponseAuthentication yes #改成no，提高登陆速度PrintLastLog yes #是否输出上次登录信息UseDNS yes #是否需要解析主机名，no可加快连接速度GSSAPIAuthentication yes #是否开启客户端对IP反解析，提高速度可改为noBanner /path/file #远程连接时的登录前提示GatewayPorts noClientAliveInterval 10 #单位:秒ClientAliveCountMax 3 #默认3MaxStartups #未认证连接最大值，默认值10#以下可以限制可登录用户的办法：AllowUsers user1 user2 user3 #用户名白名单DenyUsers user1 user2 user3 #用户名黑名单AllowGroups g1 g2 #用户组白名单DenyGroups g1 g2 #用户组黑名单 范例：设置ssh服务超时断开连接 12#10s如果没有互动，则断开链接，永久生效可以写配置文件,例如可以写在 /etc/profile 里面[root@ubuntu ~]# export TMOUT=10 范例：设置 ssh 空闲60s 自动注销 123456Vim /etc/ssh/sshd_configClientAliveInterval 60ClientAliveCountMax 0Service sshd restart#注意：新开一个连接才有效 范例：解决ssh登录缓慢的问题 12345vim /etc/ssh/sshd_configUseDNS no #关闭dns解析选项GSSAPIAuthentication nosystemctl restart sshd 范例：在 ubuntu 上启用 root 远程ssh登录 123456#修改sshd服务配置文件vim /etc/ssh/sshd_config#PermitRootLogin prohibit-password 注释掉此行，修改为下面形式PermitRootLogin yes systemctl restart sshd ssh 服务的最佳实践 123456789101112建议使用非默认端口禁止使用protocol version 1限制可登录用户设定空闲会话超时时长利用防火墙设置ssh访问策略仅监听特定的IP地址基于口令认证时，使用强密码策略，比如：tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 12| xargs使用基于密钥的认证禁止使用空密码禁止root用户直接登录限制ssh的访问频度和并发在线数经常分析日志 5 ssh服务加固安全5.1 限制和加固 SSH 访问禁用密码身份验证 禁用密码身份验证是提高 SSH 安全性的重要步骤之一。这样，用户只能通过密钥身份验证进行访问，而不再依赖弱密码。 在 sshd_config 中禁用密码身份验证： 打开 sshd_config 文件： 1sudo vim /etc/ssh/sshd_config 找到并修改以下行： 1PasswordAuthentication no 保存文件并重新启动 SSH 服务： 1sudo service ssh restart 在 sshd_config 中禁用root身份验证： 1PermitRootLogin no 5.2 使用 sshd_config 文件设置访问限制sshd_config 文件包含了 SSH 服务器的配置选项。通过修改这个文件，你可以设置一些限制，例如限制用户和 IP 地址的访问。 一些常用的 sshd_config 选项： AllowUsers：指定允许登录的用户列表。 DenyUsers：指定禁止登录的用户列表。 AllowGroups：指定允许登录的用户组列表。 DenyGroups：指定禁止登录的用户组列表。 PermitRootLogin：禁用或限制 root 用户的远程登录。 打开 /etc/ssh/sshd_config 文件： 1sudo vim /etc/ssh/sshd_config 限制用户访问： 1AllowUsers username 将 username 替换为允许访问的用户名。你还可以使用逗号分隔的列表允许多个用户。 限制 IP 地址访问： 1AllowUsers username@your_ip 将 username 替换为允许访问的用户名，your_ip 替换为允许访问的 IP 地址。 允许特定 IP 地址段： 1AllowUsers username@192.168.1.* 这样设置将允许来自 192.168.1 网段的所有 IP 地址的用户访问。 保存文件后，重新启动 SSH 服务： 1sudo service ssh restart 示例： 12345AllowUsers alice bobDenyUsers malloryAllowGroups sshusersDenyGroups badusersPermitRootLogin no 以上配置将只允许用户 alice 和 bob 以及属于 sshusers 组的用户登录，同时拒绝用户 mallory 和属于 badusers 组的用户登录。此外，禁止 root 用户通过 SSH 远程登录。 5.3 使用 TCP Wrappers 进行进一步访问控制在 /etc/hosts.allow 和 /etc/hosts.deny 文件中，你可以使用 TCP Wrappers 设置更复杂的主机访问控制规则。例如，在 /etc/hosts.allow 中添加以下行： 1sshd: 192.168.1.0/255.255.255.0 这样将允许来自 192.168.1 网段的所有主机访问 SSH 服务。 5.4 修改 SSH 端口默认情况下，SSH 服务使用 22 端口。为了提高安全性，可以修改为其他非常用端口，比如 2222： 1Port 2222 确保保存修改并重新启动 SSH 服务。 5.5 使用 SSH Agent ForwardingSSH Agent Forwarding 是一种机制，允许你在本地系统上解锁私钥，然后通过安全地转发到远程主机，以在远程主机上进行身份验证。这意味着，如果你已经通过密钥身份验证登录到本地机器，你可以使用相同的身份验证在远程主机上执行操作，而无需再次输入密码或私钥。 在本地机器上启动 SSH Agent： 1eval &quot;$(ssh-agent -s)&quot; 添加私钥到代理： 1ssh-add ~/.ssh/id_rsa 在连接到远程主机时启用 Agent Forwarding： 1ssh -A username@your_server_ip 确保替换 username 为你的用户名，your_server_ip 为目标服务器的 IP 地址。 现在，你可以在远程主机上执行需要私钥身份验证的操作，而无需再次输入密码或私钥。 尽管 SSH Agent Forwarding 提供了便利，但也需要注意一些安全性问题。确保遵循以下最佳实践： 只允许受信任的主机使用 Agent Forwarding：如果你连接到了不受信任的主机，可以通过使用 -A 参数禁用 Agent Forwarding。 定期检查代理并清除不再需要的密钥：使用 ssh-add -L 命令查看当前加载的密钥列表，并使用 ssh-add -D 清除不再需要的密钥。 在不需要 Agent Forwarding 的情况下禁用它：只有在确实需要在远程主机上执行私钥身份验证的操作时才启用 Agent Forwarding。 通过理解和正确配置 SSH Agent Forwarding，你可以在保持安全性的同时提高 SSH 的便利性。 5.6 定期更新密钥对为了增加安全性，定期更新 SSH 密钥对是一个好的实践。可以使用以下步骤生成新的密钥对并替换旧的密钥： 1234567891011# 生成新的密钥对ssh-keygen -t rsa -b 4096 -f ~/.ssh/new_key -C &quot;your_email@example.com&quot;# 复制新的公钥到目标服务器ssh-copy-id username@your_server_ip -i ~/.ssh/new_key.pub# 测试新密钥是否可以成功登录ssh -i ~/.ssh/new_key username@your_server_ip# 如果一切正常，可以删除旧密钥rm ~/.ssh/id_rsa* 5.7 监控和审计 SSH 访问启用 SSH 访问的监控和审计功能可以及时发现潜在的安全问题。可以使用工具如 fail2ban 来监控日志文件，自动封禁恶意的 SSH 连接尝试。 1234567# 安装 fail2bansudo apt install fail2ban # 对于 Debian/Ubuntusudo yum install fail2ban # 对于 Red Hat/CentOS# 启用 SSH 防护sudo systemctl enable fail2bansudo systemctl start fail2ban 通过审查系统日志文件，特别是 /var/log/auth.log（对于 Debian&#x2F;Ubuntu）或 /var/log/secure（对于 Red Hat&#x2F;CentOS），可以查看 SSH 访问的详细信息。 12sudo tail -f /var/log/auth.log # 对于 Debian/Ubuntusudo tail -f /var/log/secure # 对于 Red Hat/CentOS 通过监控和审计 SSH 访问，你可以及时发现异常情况，并采取相应的措施来保护系统安全。 6 优化SSH12UseDNS no # 禁止ssh进行dns反向解析，影响ssh连接效率参数GSSAPIAuthentication no # 禁止GSS认证，减少连接时产生的延迟","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"网络问题排查","slug":"Linux/network-manage/troubleshoot","date":"2025-08-21T03:00:49.000Z","updated":"2025-08-28T12:33:05.274Z","comments":true,"path":"Linux/network-manage/troubleshoot/","permalink":"https://aquapluto.github.io/Linux/network-manage/troubleshoot/","excerpt":"","text":"一、网卡丢包问题linux软硬件中断中断是系统用来影响硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的终端处理程序来影响设备的请求。 中断是一个异步的事件处理机制，可以提高操作系统处理并发的能力。 全双工与半双工全双工模式是指交换机在发送数据的同时也能够接收数据，两者同步进行。 现代多数网络设备，如交换机、路由器、计算机的网卡等，通常支持全双工工作模式，能够提供更好的网络速率和性能。 半双工是指一个时间段内只有一个动作发生，随着技术的不断进步，半双工会逐渐退出历史舞台。 CRCCRC（循环冗余校验码）是数据通信领域中最常用的一种查错校验码，用于数据传输检错，其特征是信息字段和校验字段的长度可以任意选定。它对数据进行多项式计算，并将得到的结果附在帧的后面，接收设备也执行类似的算法，以保证数据传输的正确性和完整性 网卡接收数据的每一帧数据都包含一个CRC值。这个CRC值是基于数据帧中的数据计算得来的。发送数据的设备，如网卡，会在发送数据的时候计算CRC，并将CRC值附加在数据帧的尾部。接收数据的设备则会重新计算接收到的数据帧的CRC值，然后与接收到的CRC值进行比较。如果两个CRC值不相等，则表示数据在传输过程中发生了错误。 网卡进行CRC校验的原理主要有以下几步： 1、发送方网卡在发送数据包时，会首先对数据包进行CRC计算，得出一个CRC值。 2、发送方在数据包的尾部附加CRC值后，就将整个数据包发出。 3、当接收方网卡收到数据包后，会对除CRC值之外的数据重新进行CRC计算，得出一个新的CRC值。 4、接收方网卡会将计算出的新CRC值，和数据包尾部接收到的CRC值进行对比，如果一致则认为此数据没有在传输中被篡改，如果不一致则认为数据在传输中被篡改。 这就是网卡的CRC校验原理。虽然CRC不能完全确保数据的完整性，但是它在很大程度上提高了数据传输的可靠性。 网卡工作流程网卡发包： ip包+14个字节的mac头变成数据帧frame frame拷贝到网卡芯片内部的缓冲区，由网卡处理 网卡芯片为frame添加头部同步信息和CRC校验，此时才是真正可以发送的packet，然后发送该packet 网卡收包： 网络包packet到达网卡，网卡先检查包packet的CRC校验，保证其完整性和正确性，然后去掉它的头得到frame 网卡将frame拷贝到网卡内部的FIFO缓冲区 网卡驱动程序产生硬件中断，把frame从网卡拷贝到内存中，接下来就交给内核处理 网卡丢包 内核通常需要快速的拷贝网络数据包到系统内存！！！ 因为网卡上接收网络数据包的缓存大小固定，而且相比系统内存也要小得多。 所以上述拷贝动作一旦被延迟，必然造成网卡FIFO缓存溢出 - 进入的数据包占满了网卡的缓存，后续的包只能被丢弃，这也应该就是ifconfig里的overrun的来源。 丢包问题解决丢包排查：网卡工作在数据链路层，数据量链路层，会做一些校验，封装成帧。我们可以查看校验是否出错，确定传输是否存在问题。然后从软件层面，是否因为缓冲区太小丢包。 12345678910111213141516171819202122232425262728293031323334353637383940414243# 1 先查看硬件情况一台机器经常收到丢包的报警，先看看最底层的有没有问题:# 1.1 查看工作模式是否正常[root@egon ~]# ethtool ens33 | egrep &#x27;Speed|Duplex&#x27; Speed: 1000Mb/s Duplex: Full # 全双工 # 1.2 查看CRC校验是否正常 [root@egon ~]# ethtool -S ens33 | grep crc # crc错误值大通常是因为服务器外部的网络环境有问题导致的 rx_crc_errors: 0 -----------Speed，Duplex，CRC 之类的都没问题，基本可以排除物理层面的干扰---------- # 2 通过 ifconfig 可以看到 overruns 是否一直增大，如果查看结果是一直增大for i in `seq 1 100`; do ifconfig ens33 | grep RX | grep overruns; sleep 1; done # 3 调整网卡缓冲区[root@egon ~]# ethtool -g ens33Ring parameters for ens33:Pre-set maximums: # 最大可以设置的值RX: 4096RX Mini: 0RX Jumbo: 0TX: 4096Current hardware settings: # 当前设置的值RX: 256RX Mini: 0RX Jumbo: 0TX: 256[root@egon ~]# ethtool -G ens33 rx 2048 # 调大[root@egon ~]# ethtool -G ens33 tx 2048 # 调大[root@egon ~]# ethtool -g ens33Ring parameters for ens33:Pre-set maximums:RX: 4096RX Mini: 0RX Jumbo: 0TX: 4096Current hardware settings:RX: 2048RX Mini: 0RX Jumbo: 0TX: 2048 ethool网卡降速 1234567[root@egon ~]# ethtool -s ens33 speed 100 duplex full[root@egon ~]# ethtool -s ens33 speed 100 duplex full autoneg off # 关闭自适应才能设置成功[root@egon ~]# ethtool ens33 # 查看 若想完成永久设置，可以将上述ethtool设置写入/etc/rc.d/rc.local之中。然后记住必须要加一个x权限[root@egon ~]# chmod +x /etc/rc.d/rc.local 二、解决网络问题排查思路先搞清楚链路 思考清楚 你站在物理量的内部，访问某一台虚拟机，网络流向是什么 你站在某一台虚拟机中，访问另外一台虚拟机，网络流向是什么 你站在你们家其他物理设备上，访问某一台虚拟机，网络流向是什么 检查思路你在进行任何一次网络访问失败的时候，首先在纸上画出来它的链路 然后你就按照这个链路，去检查每一个环节 一遍查的过程，可以一遍google搜一下看看有没有人遇到过同类问题，90%的问题网上都有答案 检查手段定位网络问题工具1234mii-tool eth0 # 判断物理网卡是否接了网线ping命令telnet 目标ip 端口tcpdump + wireshark抓包分析 一些常规查询举例1、检查虚拟网卡与物理网卡 123456789101、ip a 查看网卡运行状态如果网卡处于done或者网卡无显示信息，systemctl restart network重启网卡、停止NetworkManager查看网卡配置文件具体信息2、vm层面检查虚拟网络编辑器 ---&gt; vmnet8 网卡设置 查看子网、掩码、网关等设置3、windows层面检查本地网卡检查 ---&gt; 控制面板\\网络和 Internet\\网络连接本地服务检查 ---&gt; 任务管理器 服务 vmware相关服务重启 2、测试网络连通性 123456789101112131415161718192021222324252627282930313233341、判断网卡是否能识别，是否接了有效的网线mii-tool eth0 # 判断物理网卡是否接了网线有可能明明连接了有效的网线，但是还是看不到link ok,可以先确定网卡配置文件是正确的，并且ONBOOT=yes ，然后重启network服务（systemctl restart network ）2、**ping 127.0.0.1**通，代表系统能够支持tcp/ip通信。不通，原因： 相关驱动损坏或者没有。防火墙iptables拦截了。3、**ping 网卡的ip**假设eth0配置10.1.1.22ping 10.1.1.22通，说明网卡是能够正常工作不通，可能是网卡驱动工作不正常，或iptables防火墙问题。或者是网卡未激活，可以尝试重启网络服务4、**ping 网关**不通原因： 网关有问题，或者IP冲突解决方法：ping 同一个网段中其他IP,或者用其他计算机也ping网关，如果能通，那就是自己机器的原因了5、**ping 外网（IP或域名）**# ping 外网IP通，只能说明通信没问题，网关是ok的。不通，很可能就是网关无法联网# ping 域名如果连域名对应的IP都无法返回，说明域名解析失败，原因：DNS设定有问题。6、**ping的错误类型****network unreachable (网络不可达)： 一般没有设定正确的网关****unknow host xxxx : 设定DNS无效** Ping命令返回错误信息说明123456789101112131415161718192021222324252627282930313233343536373839# 1.Request timed out这是大家经常碰到的提示信息，很多文章中说这是对方机器置了过滤ICMP数据包，从上面工作过程来看，这是不完全正确的，至少有下几种情况。（1） 对方已关机，或者网络上根本没有这个地址：比如在上图中主机A中PING 192.168.0.7 ，或者主机B关机了，在主机A中PING 192.168.0.5 都会得到超时的信息。（2）对方与自己不在同一网段内，通过路由也无法找到对方，但有时对方确实是存在的，当然不存在也是返回超时的信息。（3）对方确实存在，但设置了ICMP数据包过滤（比如防火墙设置）。怎样知道对方是存在，还是不存在呢，可以用带参数 -a 的Ping命令探测对方，如果能得到对方的NETBIOS名称，则说明对方是存在的，是有防火墙设置，如果得不到，多半是对方不存在或关机，或不在同一网段内。（4）错误设置IP地址正常情况下，一台主机应该有一个网卡，一个IP地址，或多个网卡，多个IP地址（这些地址一定要处于不同的IP子网）。但如果一台电脑的“拨号网络适配器”（相当于一块软网卡）的TCP/IP设置中，设置了一个与网卡IP地址处于同一子网的IP地址，这样，在IP层协议看来，这台主机就有两个不同的接口处于同一网段内。当从这台主机Ping其他的机器时，会存在这样的问题： A.主机不知道将数据包发到哪个网络接口，因为有两个网络接口都连接在同一网段。 B.主机不知道用哪个地址作为数据包的源地址。因此，从这台主机去Ping其他机器，IP层协议会无法处理，超时后，Ping 就会给出一个“超时无应答”的错误信息提示。但从其他主机Ping这台主机时，请求包从特定的网卡来，ICMP只须简单地将目的、源地址互换，并更改一些标志即可，ICMP应答包能顺利发出，其他主机也就能成功Ping通这台机器了。# 2.Destination host Unreachable（1） 对方与自己不在同一网段内，而自己又未设置默认的路由，比如上例中A机中不设定默认的路由，运行Ping192.168.0.1.4就会出现“Destination host Unreachable”。（2）网线出了故障这里要说明一下“destination host unreachable”和 “time out”的区别，如果所经过的路由器的路由表中具有到达目标的路由，而目标因为其他原因不可到达，这时候会出现“time out”，如果路由表中连到达目标的路由都没有，那就会出现“destination host unreachable”。# 3.Bad IP address这个信息表示您可能没有连接到DNS服务器，所以无法解析这个IP地址，也可能是IP地址不存在。# 4.Source quench received这个信息比较特殊，它出现的机率很少。它表示对方或中途的服务器繁忙无法回应。# 5.Unknown host——不知名主机这种出错信息的意思是，该远程主机的名字不能被域名服务器（DNS）转换成IP地址。故障原因可能是域名服务器有故障，或者其名字不正确，或者网络管理员的系统与远程主机之间的通信线路有故障。# 6.No answer——无响应这种故障说明本地系统有一条通向中心主机的路由，但却接收不到它发给该中心主机的任何信息。故障原因可能是下列之一：中心主机没有工作；本地或中心主机网络配置不正确；本地或中心的路由器没有工作；通信线路有故障；中心主机存在路由选择问题。# 7.Ping 127.0.0.1127.0.0.1是本地循环地址.如果本地址无法Ping通，则表明本地机TCP/IP协议不能正常工作。# 8.no rout to host网卡工作不正常。# 9.transmit failed，error code：10043网卡驱动不正常。# 10.unknown host nameDNS配置不正确","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"}]},{"title":"网桥配置","slug":"Linux/network-manage/bridge","date":"2025-08-21T03:00:39.000Z","updated":"2025-08-28T12:33:05.265Z","comments":true,"path":"Linux/network-manage/bridge/","permalink":"https://aquapluto.github.io/Linux/network-manage/bridge/","excerpt":"","text":"一、桥接原理桥接：把一台机器上的若干个网络接口“连接”起来。其结果是，其中一个网口收到的报文会被复制给其他网口并发送出去。以使得网口之间的报文能够互相转发。网桥就是这样一个设备，它有若干个网口，并且这些网口是桥接起来的。与网桥相连的主机就能通过交换机的报文转发而互相通信 主机A发送的报文被送到交换机S1的eth0口，由于eth0与eth1、eth2桥接在一起，故而报文被复制到eth1和eth2，并且发送出去，然后被主机B和交换机S2接收到。而S2又会将报文转发给主机C、D CentOS 8 取消brctl 工具,可以用下面方法查看网桥 1234#查看桥接情况[root@centos8 ~]#ip link show master virbr0[root@centos8 ~]#bridge link show 二、配置实现网桥工具包：bridge-utils,目前 CentOS 8 系统光盘里无此包,EPEL源有此包 原理：将centos7这台机器模拟成网桥，实现网桥的功能，使得A和B能够连接通讯 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#临时生效centos7机器准备两个网卡，一个网卡是仅主机模式对应vmnet1，另一个网卡是NAT模式对应vmnet8A主机的网卡是仅主机模式，对应vmnet1，B主机的网卡是NAT模式，对应vmnet8，这个时候A和B想要通就必须把centos7主机配置成交换机配置之前需要安装#yum install bridge-utils#centos7上创建网桥并启用up[root@centos7 ~]#brctl addbr br0[root@centos7 ~]#brctl show #查看[root@centos7 ~]#ip link set br0 up#将两网卡接到交换机上（网桥）[root@centos7 ~]#brctl addif br0 eth0[root@centos7 ~]#brctl addif br0 eth1#之后A和B就能通了,但是配置好后centos7就断了，原因是机器上的两网卡被br0所使用#加地址[root@centos7 ~]#ip a a 10.0.0.20/24 dev br0#如果将centos7上的两网卡删除，也不影响，因为交换机不配IP地址也不影响主机之间的通讯，配ip地址只是为了方便远程操控管理#永久生效第一种方法：nmcli命令#创建网桥nmcli con add type bridge con-name br0 ifname br0nmcli connection modify br0 ipv4.addresses 10.0.0.100/24 ipv4.method manualnmcli con up br0#加入物理网卡nmcli con add type bridge-slave con-name br0-port0 ifname eth0 master br0nmcli con add type bridge-slave con-name br0-port1 ifname eth1 master br0nmcli con up br0-port0nmcli con up br0-port1第二种方法：写配置文件vim /etc/sysconfig/network-scripts/ifcfg-br0DEVICE=br0STP=yesTYPE=Bridge#以下可以不要BOOTPROTO=staticIPADDR=10.0.0.100PREFIX=24vim /etc/sysconfig/network-scripts/ifcfg-br0-eth0TYPE=EthernetNAME=br0-eth0DEVICE=eth0ONBOOT=yesBRIDGE=br0vim /etc/sysconfig/network-scripts/ifcfg-br0-eth1TYPE=EthernetNAME=br0-eth1DEVICE=eth1ONBOOT=yesBRIDGE=br0#查看网桥brctl show#添加和删除网桥brctl addbr | delbr br0#删除之前先禁用：ip link set br0 down#添加和删除网桥中网卡brctl addif | delif br0 eth0 STP 生成树协议 123456正常情况下，三台交换机，连两条网线，但这种情况下，如果断掉了一条线，则网络就会中断，为了解决此问题，三台交换机，连三线网线，这样，如果断了一条线，网络还是可用的，但这样会形成一个环形网络，由于交换机执行广播请求，那这种网络会造成网络风暴，所以需要启用stp规避此问题#开启[root@centos7 ~]#brctl stp br0 on#关闭[root@centos7 ~]#brctl stp br0 off","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"}]},{"title":"网络测试诊断工具","slug":"Linux/network-manage/test-diagnostic","date":"2025-08-21T03:00:33.000Z","updated":"2025-08-28T12:33:05.273Z","comments":true,"path":"Linux/network-manage/test-diagnostic/","permalink":"https://aquapluto.github.io/Linux/network-manage/test-diagnostic/","excerpt":"","text":"一、ping命令用于测试网络连接的常见命令行工具，通常用于检查目标主机是否可达以及测量网络往返时间（RTT）。 1234567891011121314151617-c N #ping N次后停止ping-s N #一个ping包的字节数大小-W N #第一个ping包的响应超时时间，单位S，其余ping包的响应超时时间为1s-w N #执行PING操作的超时时间，单位S-f #极限检测，快速连续ping一台主机[root@ubuntu2004 ~]#ping 10.0.0.179PING 10.0.0.179 (10.0.0.179) 56(84) bytes of data.64 bytes from 10.0.0.179: icmp_seq=1 ttl=64 time=0.809 ms64 bytes from 10.0.0.179: icmp_seq=2 ttl=64 time=4.58 ms64 bytes from 10.0.0.179: icmp_seq=3 ttl=64 time=4.73 ms64 bytes from 10.0.0.179: icmp_seq=4 ttl=64 time=4.44 ms64 bytes from 10.0.0.179: icmp_seq=5 ttl=64 time=2.58 ms^C--- 10.0.0.179 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4047msrtt min/avg/max/mdev = 0.809/3.429/4.733/1.525 ms 字段输出解释： PING：这是 ping 命令的第一行，显示正在执行的 ping 命令以及目标主机的 IP 地址或主机名。 bytes：每个 ICMP 报文的大小，通常默认为 64 字节。 icmp_seq：ICMP 报文的序列号，从 0 开始递增。 ttl：生存时间（Time to Live），表示报文在网络上能够存活的跳数（路由器数量）。 time：每个 ICMP 报文的往返时间（Round-Trip Time，RTT），以毫秒为单位。这是从发送 ICMP 报文到接收响应所经过的时间。 — 10.0.0.179 ping statistics —：表示一个 ICMP 报文的往返时间统计结束并显示 ping 统计信息的标题。 packets transmitted：发送的 ICMP 报文数量，表示发送的次数。 packets received：接收的 ICMP 响应报文数量，表示成功收到的次数。 packet loss：丢失的 ICMP 报文数量，表示未收到响应的次数，通常以百分比形式显示。 time：用于显示 RTT 的统计信息，通常包括最小、最大和平均 RTT 时间。 范例: 利用icmp协议判断网络状态 1234567891011121314151617181920[root@centos7 ~]#ping 10.0.0.8PING 10.0.0.8 (10.0.0.8) 56(84) bytes of data.64 bytes from 10.0.0.8: icmp_seq=1 ttl=64 time=0.307 ms64 bytes from 10.0.0.8: icmp_seq=2 ttl=64 time=0.344 ms[root@centos7 ~]#ping 10.0.0.81 #ping一个不存在地址出现的提示PING 10.0.0.81 (10.0.0.81) 56(84) bytes of data.From 10.0.0.7 icmp_seq=1 Destination Host Unreachable[root@centos7 ~]#iptables -A INPUT -s 10.0.0.8 -j REJECT[root@centos7 ~]#ping 10.0.0.8 #受防火墙规则限制的提示PING 10.0.0.8 (10.0.0.8) 56(84) bytes of data.From 10.0.0.8 icmp_seq=1 Destination Port UnreachableFrom 10.0.0.8 icmp_seq=2 Destination Port Unreachable[root@centos8 ~]#ping -s 65508 10.0.0.8 #指定发送65508大小的包Error: packet size 65508 is too large. Maximum is 65507 #最大只能是65507[root@centos8 ~]#ping -f -s 65507 172.18.0.200 #攻击一个机器，发送大量的包，消耗他的网络带宽PING 172.18.0.200 (172.18.0.200) 65507(65535) bytes of data. 二、mtr命令结合了 traceroute 和 ping 的功能，用于追踪网络路径和测量网络往返时间（RTT）。mtr 不仅可以显示路由路径，还能实时监控网络路径中每个跳的性能指标。 1yum install -y mtr 语法 12345mtr [选项] 目标主机-n：用于禁用域名解析。-c：用于指定发送数据包的次数。-i：用于设置报文发送的时间间隔。 范例：基本 mtr 测试 1mtr www.baidu.com 这会启动 mtr 并追踪到达 www.baidu.com 的网络路径，并实时显示每个路由器的 IP 地址、主机名、以及每个路由器的 RTT 时间。 字段输出解释： Host：显示路由路径上每个跳的主机名或 IP 地址，其中最后一行显示了目标主机（在本例中是 14.119.104.254）。 Loss%：损失率，表示到达每个跳的数据包丢失的百分比。在这个例子中，192.168.* 跳的损失率都是 0%，这意味着我本地没有数据包丢失，我本地网络正常，而中间网络就存在丢包了，说明中间路由网络是有延迟的。 Snt：发送的数据包数量，表示发送给每个跳的数据包总数。 Last：最后一个数据包的往返时间（RTT），以毫秒为单位。这是从源主机到达每个跳的最后一个数据包的时间。 Avg：平均往返时间，以毫秒为单位。这是从源主机到达每个跳的所有数据包的平均时间。 Best：最短往返时间，以毫秒为单位。这是从源主机到达每个跳的最快数据包的时间。 Wrst：最长往返时间，以毫秒为单位。这是从源主机到达每个跳的最慢数据包的时间。 StDev：往返时间的标准差，以毫秒为单位。它表示 RTT 变化的程度，越小越好。 通常网络出问题我们都会使用 ping 命令，但是该命令只是简单的网络连通性测试，却无法确定网络是在哪里出了问题，此时就会使用 traceroute 来查看数据包途径路由，或使用 nslookup 来查看 DNS 解析状态是否正常。而我们的 mtr 命令正好集成了这三个命令的功能，从而实现了我们的需求。 一般情况下 mtr 前几跳都是本地 ISP，后几跳属于服务商（如本次案例的百度），中间跳数则是中间网络互联节点，如果前几跳异常，需联系本地 ISP，如果后几跳出现问题，则需联系服务商（百度），如果中间几跳出现问题，则两边都无完全解决问题。 三、fpingfping是一个程序，用于将ICMP探测发送到网络主机，可以在命令行上定义任意数量的主机，或者指定包含要ping的IP地址或主机列表的文件, 常在shell 脚本中使用 12#-g 选项可以指定网段或地址范围[root@centos8 ~]#fping -g 10.0.0.0/24 四、tcpdump网络数据包截获分析工具。支持针对网络层、协议、主机、网络或端口的过滤。并提供and、or、not等逻辑语句帮助去除无用的信息 1234567891011121314151617181920212223242526272829tcpdump [-adeflnNOpqStvx][-c&lt;数据包数目&gt;][-dd][-ddd][-F&lt;表达文件&gt;][-i&lt;网络界面&gt;][-r&lt;数据包文件&gt;][-s&lt;数据包大小&gt;][-tt][-T&lt;数据包类型&gt;][-vv][-w&lt;数据包文件&gt;][输出数据栏位]参数说明：-a #尝试将网络和广播地址转换成名称。-c&lt;数据包数目&gt; #收到指定的数据包数目后，就停止进行倾倒操作。-d #把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出。-dd #把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出。-ddd #把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出。-e #显示链路层信息,默认不显示链路层-f #用数字显示网际网络地址。-F&lt;表达文件&gt; #指定内含表达方式的文件。-i&lt;网络接口&gt; #使用指定的网络截面送出数据包。-l #使用标准输出列的缓冲区。-n #不把主机的网络地址转换成名字-nn #数字化-N #不列出域名。-O #不将数据包编码最佳化。-p #不让网络界面进入混杂模式。-q #快速输出，仅列出少数的传输协议信息。-r&lt;数据包文件&gt; #从指定的文件读取数据包数据。-s&lt;数据包大小&gt; #设置每个数据包的大小。默认只截取前96个字节,使用-s0可以截取所有报文内容-S #用绝对而非相对数值列出TCP关联数。-t #在每列倾倒资料上不显示时间戳记。-tt #在每列倾倒资料上显示未经格式化的时间戳记。-T&lt;数据包类型&gt; #强制将表达方式所指定的数据包转译成设置的数据包类型。-v #详细显示指令执行过程。-vv #更详细显示指令执行过程。-x #用十六进制字码列出数据包资料。-w&lt;数据包文件&gt; #把数据包数据写入指定的文件。 常规过滤规则基于IP地址过滤：host使用 host 就可以指定 host ip 进行过滤 1$ tcpdump host 192.168.10.100 数据包的 ip 可以再细分为源ip和目标ip两种 12345# 根据源ip进行过滤$ tcpdump -i eth2 src 192.168.10.100# 根据目标ip进行过滤$ tcpdump -i eth2 dst 192.168.10.200 基于网段进行过滤：net若你的ip范围是一个网段，可以直接这样指定 1$ tcpdump net 192.168.10.0/24 网段同样可以再细分为源网段和目标网段 12345# 根据源网段进行过滤$ tcpdump src net 192.168# 根据目标网段进行过滤$ tcpdump dst net 192.168 基于端口进行过滤：port使用 port 就可以指定特定端口进行过滤 1$ tcpdump port 8088 端口同样可以再细分为源端口，目标端口 12345# 根据源端口进行过滤$ tcpdump src port 8088# 根据目标端口进行过滤$ tcpdump dst port 8088 如果你想要同时指定两个端口你可以这样写 1$ tcpdump port 80 or port 8088 但也可以简写成这样 1$ tcpdump port 80 or 8088 如果你的想抓取的不再是一两个端口，而是一个范围，一个一个指定就非常麻烦了，此时你可以这样指定一个端口段。 123$ tcpdump portrange 8000-8080$ tcpdump src portrange 8000-8080$ tcpdump dst portrange 8000-8080 对于一些常见协议的默认端口，我们还可以直接使用协议名，而不用具体的端口号 比如 http &#x3D;&#x3D; 80，https &#x3D;&#x3D; 443 等 1$ tcpdump tcp port http 基于协议进行过滤：proto常见的网络协议有：tcp, udp, icmp, http, ip,ipv6 等 若你只想查看 icmp 的包，可以直接这样写 1$ tcpdump icmp protocol 可选值：ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat, mopdl, moprc, iso, stp, ipx, or netbeui 过滤规则组合 and：所有的条件都需要满足，也可以表示为 &amp;&amp; or：只要有一个条件满足就可以，也可以表示为 || not：取反，也可以使用 ! 举个例子，我想需要抓一个来自10.5.2.3，发往任意主机的3389端口的包 1$ tcpdump src 10.5.2.3 and dst port 3389 当你在使用多个过滤器进行组合时，有可能需要用到括号，而括号在 shell 中是特殊符号，因为你需要使用引号将其包含。例子如下： 1$ tcpdump &#x27;src 10.0.2.4 and (dst port 3389 or 22)&#x27; 而在单个过滤器里，常常会判断一条件是否成立，这时候，就要使用下面两个符号 =：判断二者相等 ==：判断二者相等 !=：判断二者不相等 当你使用这两个符号时，tcpdump 还提供了一些关键字的接口来方便我们进行判断，比如 if：表示网卡接口名、 proc：表示进程名 pid：表示进程 id svc：表示 service class dir：表示方向，in 和 out eproc：表示 effective process name epid：表示 effective process ID 比如我现在要过滤来自进程名为 nc 发出的流经 en0 网卡的数据包，或者不流经 en0 的入方向数据包，可以这样子写 1$ tcpdump &quot;( if=en0 and proc =nc ) || (if != en0 and dir=in)&quot; 范例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#查看网卡[root@centos8 ~]#tcpdump -D#不指定任何参数，监听第一块网卡上经过的数据包。主机上可能有不止一块网卡，所以经常需要指定网卡。tcpdump#监听特定网卡tcpdump -i en0#监听特定主机，监听主机10.0.0.100 的通信包，注意：出、入的包都会被监听。tcpdump host 10.0.0.100#特定来源、目标地址的通信#特定来源tcpdump src host hostname#特定目标地址tcpdump dst host hostname#如果不指定src跟dst，那么来源或者目标是hostname的通信都会被监听tcpdump host hostname#面试题[root@centos8 ~]#tcpdump -i eth0 -nn icmp and src host 10.0.0.6 and dst host 10.0.0.7#特定端口tcpdump port 3000#监听TCP/UDP，服务器上不同服务分别用了TCP、UDP作为传输层，假如只想监听TCP的数据包tcpdump tcp#来源主机+端口+TCP，监听来自主机10.0.0.100在端口22上的TCP数据包tcpdump tcp port 22 and src host 10.0.0.100#监听特定主机之间的通信tcpdump ip host 10.0.0.101 and 10.0.0.102#10.0.0.101和除了10.0.0.1之外的主机之间的通信tcpdump ip host 10.0.0.101 and ! 10.0.0.1#限制抓包的数量，如下，抓到1000个包后，自动退出tcpdump -c 1000#保存到本地，tcpdump默认会将输出写到缓冲区，只有缓冲区内容达到一定的大小，或者tcpdump退出时，才会将输出写到本地磁盘,可以加上-U强制立即写到本地磁盘（一般不建议，性能相对较差）tcpdump -n -vvv -c 1000 -w /tmp/tcpdump_save.cap#详细示例tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型(2)-i eth1 : 只抓经过接口eth1的包(3)-t : 不显示时间戳(4)-s 0 :设置为0表示使用默认值262144字节抓取每个包，以便与tcpdump的旧版本兼容(5)-c 100 : 只抓取100个数据包(6)dst port ! 22 : 不抓取目标端口是22的数据包(7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24(8)-w ./target.cap : 保存成cap文件，方便用wireshark分析 输出内容结构121:26:49.013621 IP 172.20.20.1.15605 &gt; 172.20.20.2.5920: Flags [P.], seq 49:97, ack 106048, win 4723, length 48 从上面的输出来看，可以总结出： 第一列：时分秒毫秒 21:26:49.013621 第二列：网络协议 IP 第三列：发送方的ip地址+端口号，其中172.20.20.1是 ip，而15605 是端口号 第四列：箭头 &gt;， 表示数据流向 第五列：接收方的ip地址+端口号，其中 172.20.20.2 是 ip，而5920 是端口号 第六列：冒号 第七列：数据包内容，包括Flags 标识符，seq 号，ack 号，win 窗口，数据长度 length，其中 [P.] 表示 PUSH 标志位为 1，更多标识符见下面 Flags 标识符 使用 tcpdump 抓包后，会遇到的 TCP 报文 Flags，有以下几种： [S] : SYN（开始连接） [P] : PSH（推送数据） [F] : FIN （结束连接） [R] : RST（重置连接） [.] : 没有 Flag （意思是除上面四种类型外的其他情况，有可能是 ACK 也有可能是 URG） 抓包实战应用例子提取HTTP的User-Agent从 HTTP 请求头中提取 HTTP 的 User-Agent： 1$ tcpdump -nn -A -s1500 -l | grep &quot;User-Agent:&quot; 通过 egrep 可以同时提取User-Agent 和主机名（或其他头文件）： 1$ tcpdump -nn -A -s1500 -l | egrep -i &#x27;User-Agent:|Host:&#x27; 抓取HTTP GET和POST请求抓取 HTTP GET 请求包： 12345$ tcpdump -s 0 -A -vv &#x27;tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x47455420&#x27;# or$ tcpdump -vvAls0 | grep &#x27;GET&#x27; 可以抓取 HTTP POST 请求包： 12345$ tcpdump -s 0 -A -vv &#x27;tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x504f5354&#x27;# or $ tcpdump -vvAls0 | grep &#x27;POST&#x27; 注意：该方法不能保证抓取到 HTTP POST 有效数据流量，因为一个 POST 请求会被分割为多个 TCP 数据包。 找出发包数最多的 IP找出一段时间内发包最多的 IP，或者从一堆报文中找出发包最多的 IP，可以使用下面的命令： 1$ tcpdump -nnn -t -c 200 | cut -f 1,2,3,4 -d &#x27;.&#x27; | sort | uniq -c | sort -nr | head -n 20 cut -f 1,2,3,4 -d ‘.’ : 以 . 为分隔符，打印出每行的前四列。即 IP 地址。 sort | uniq -c : 排序并计数 sort -nr : 按照数值大小逆向排序 抓取DNS请求和响应DNS 的默认端口是 53，因此可以通过端口进行过滤 1$ tcpdump -i any -s0 port 53 切割pcap文件当抓取大量数据并写入文件时，可以自动切割为多个大小相同的文件。例如，下面的命令表示每 3600 秒创建一个新文件 capture-(hour).pcap，每个文件大小不超过 200*1000000 字节： 1$ tcpdump -w /tmp/capture-%H.pcap -G 3600 -C 200 这些文件的命名为 capture-&#123;1-24&#125;.pcap，24 小时之后，之前的文件就会被覆盖。 提取HTTP POST请求中的密码从 HTTP POST 请求中提取密码和主机名： 1$ tcpdump -s 0 -A -n -l | egrep -i &quot;POST /|pwd=|passwd=|password=|Host:&quot; 提取HTTP请求的URL提取 HTTP 请求的主机名和路径： 1$ tcpdump -s 0 -v -n -l | egrep -i &quot;POST /|GET /|Host:&quot; 抓取HTTP有效数据包抓取 80 端口的 HTTP 有效数据包，排除 TCP 连接建立过程的数据包（SYN &#x2F; FIN &#x2F; ACK）： 1$ tcpdump &#x27;tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)&#x27; 五、nmap扫描远程主机工具，比发送 ICMP 报文的 ping 命令的功能要强大很多 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#仅列出指定网段上的每台主机,不发送任何报文到目标主机.[root@centos8 ~]#nmap -sL 10.0.0.0/24#可以指定一个IP地址范围[root@centos8 ~]#nmap -sP 10.0.0.1-10#批量扫描一个网段的主机存活数nmap -sP -v 192.168.1.0/24nmap –v –sn ip/24#有些主机关闭了ping检测,所以可以使用-P0跳过ping的探测,可以加快扫描速度.nmap -P0 192.168.1.100#扫描主机nmap –v –A IP #一次性扫描多台目标主机[root@centos8 ~]#nmap 10.0.0.6 10.0.0.7#探测目标主机开放的端口,可指定一个以逗号分隔的端口列表(如-PS22,443,80)[root@centos8 ~]#nmap -PS22,80,443 10.0.0.1#使用SYN半开放扫描[root@centos8 ~]#nmap -sS 10.0.0.1#扫描开放了TCP端口的设备[root@centos8 ~]#nmap -sT 10.0.0.1#扫描开放了UDP端口的设备[root@centos8 ~]#nmap -sU 10.0.0.1#只扫描UDP端口nmap –e eth1 -sU -O 10.0.0.1 #扫描TCP和UDP端口nmap -sTU -O 10.0.0.1#用于扫描目标主机服务版本号[root@centos8 ~]#nmap -sV 10.0.0.7#查看主机当前开放的端口nmap localhost #查看主机端口（1024-65535）中开放的端口nmap -p 1024-65535 localhost #探测目标主机开放的端口nmap -PS 10.0.0.1 #探测所列出的目标主机端口nmap -PS22,80,3306 10.0.0.1 #探测目标主机操作系统类型nmap -O 10.0.0.1#探测目标主机操作系统类型nmap -A 10.0.0.1 六、nc 实现任意TCP&#x2F;UDP端口的侦听，nc可以作为server以TCP或UDP方式侦听指定端口 端口的扫描，nc可以作为client发起TCP或UDP连接 机器之间传输文件 机器之间网络测速 普通用户不能监听1023以内（包括1023）的端口 12345678910111213141516nc [-hlnruz][-g&lt;网关...&gt;][-G&lt;指向器数目&gt;][-i&lt;延迟秒数&gt;][-o&lt;输出文件&gt;][-p&lt;通信端口&gt;][-s&lt;来源位址&gt;][-v...][-w&lt;超时秒数&gt;][主机名称][通信端口...]-g&lt;网关&gt; 设置路由器跃程通信网关，最多可设置8个。-G&lt;指向器数目&gt; 设置来源路由指向器，其数值为4的倍数。-h 在线帮助。-i&lt;延迟秒数&gt; 设置时间间隔，以便传送信息及扫描通信端口。-l 使用监听模式，管控传入的资料。-n 直接使用IP地址，而不通过域名服务器。-o&lt;输出文件&gt; 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。-p&lt;通信端口&gt; 设置本地主机使用的通信端口。-r 乱数指定本地与远端主机的通信端口。-s&lt;来源位址&gt; 设置本地主机送出数据包的IP地址。-u 使用UDP传输协议-v 显示指令执行过程。-w&lt;超时秒数&gt; 设置等待连线的时间。-z 表示zero，表示扫描时不发送任何数据，只在扫描通信端口时使用 范例 12345678910111213141516#安装nc[root@ubuntu1804 ~]#apt -y install netcat-openbsd[root@centos8 ~]#yum -y install nc#探测TCP协议[root@ubuntu1804 ~]#nc -zv 10.0.0.101 22Connection to 10.0.0.101 22 port [tcp/ssh] succeeded![root@ubuntu1804 ~]#nc -zv 10.0.0.101 2222nc: connect to 10.0.0.101 port 2222 (tcp) failed: Connection refused#探测UDP协议[root@ubuntu1804 ~]#nc -zv -u 10.0.0.101 2049Connection to 10.0.0.101 2049 port [udp/nfs] succeeded![root@ubuntu1804 ~]#nc -zv -u 10.0.0.101 111Connection to 10.0.0.101 111 port [udp/sunrpc] succeeded![root@ubuntu1804 ~]#nc -zv -u 10.0.0.101 123 范例: 扫描远程服务 1234567891011121314151617#!/bin/bashnet=10.0.0port=5900begin=3end=254. /etc/os-releaseif [ $ID_LIKE =~ rhel ]];then rpm -q nc || yum -y install ncelse dpkg -i netcat-openbsd &amp;&gt; /dev/null || apt -y install netcat-openbsdfifor i in `eval echo &#123;$begin..$end&#125;`;do &#123; nc -z -v -w 1 $net.$i $port &amp;&gt; /dev/null &amp;&amp; echo $net.$i &gt; hosts.txt &#125;&amp;donewait","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"}]},{"title":"网络配置命令","slug":"Linux/network-manage/configuration-command","date":"2025-08-21T03:00:28.000Z","updated":"2025-08-28T12:33:05.267Z","comments":true,"path":"Linux/network-manage/configuration-command/","permalink":"https://aquapluto.github.io/Linux/network-manage/configuration-command/","excerpt":"","text":"一、ifconfig命令来自于net-tools包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#启用和禁用网卡[root@centos8 ~]#ifconfig eth0 up[root@centos8 ~]#ifconfig eth0 down#修改ip地址[root@centos8 ~]#ifconfig eth0 10.0.0.111/24#对一个网卡设置多个IP地址[root@centos8 ~]#ifconfig eth0:1 172.16.0.8/24#统计吞吐量[root@centos8 ~]#ifconfig -s [root@centos8 ~]#ifconfig -s eth0#清除eth0上面的IP地址[root@centos8 ~]#ifconfig eth0 0[root@egon ~]# ifconfig ens33ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 # 从flags可知该接口已启用，支持广播、组播，MTU:1500（最大传输单元）：1500字节 # 其他了解知识： // UP：表示“接口已启用”。 // BROADCAST ：表示“主机支持广播”。 // RUNNING：表示“接口在工作中”。 // MULTICAST：表示“主机支持多播”。 // 可以了解一下繁杂模式：https://www.cnblogs.com/linhaifeng/articles/13949611.html inet 192.168.12.42 netmask 255.255.255.0 broadcast 192.168.12.255 # IPv4地址 子网掩码 广播地址 inet6 fe80::499e:c2c1:f5ed:3900 prefixlen 64 scopeid 0x20&lt;link&gt; # IPv6地址 掩码长度 作用域，link表示仅该接口有效 ether 00:0c:29:86:f8:59 txqueuelen 1000 (Ethernet) #网卡接口的MAC地址 传输队列长度 接口类型为Ethernet RX packets 5708 bytes 1061424 (1.0 MiB) # 表示开机后此接口累积接收的报文个数，总字节数 RX errors 0 dropped 833 overruns 0 frame 0 # 表示开机后此接口累积接收报文错误数，丢弃数，溢出数（由于速度过快而丢失的数据包数），冲突的帧数 TX packets 102 bytes 16768 (16.3 KiB) # 表示开机后此接口累积发送的报文个数，总字节数 TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 表示开机后此接口累积发送报文错误数，丢弃数，溢出数（由于速度过快而丢失的数据包数）， # carrier 载荷数(发生carrier错误而丢失的数据包数) # collisions 冲突数 二、route命令路由表管理命令 路由：路径的选择 路由表：导航，地图，但是不仅仅在路由器有，在任何通信的主机都有 路由表构成 Destination：一般来说是到达目标网络的网段地址，即不会精确到一台机器的IP地址，只能是这台机器所在的网段 Genmask:目标网络对应的netmask iface接口： 接口，要到达本路由记录的目标网络，需要从当前设备的哪个出口发送数据报文 gateway网关：如果本机与目标网络不在同一个网段，需要将数据包发送到下一个路由器邻近本机接口的接口的IP，即网关；如果目标网络和本机在同一个网段，则无需配置网关，gateway是0.0.0.0 Metric花费： 此值越小，路由记录的优先级越高 三种路由记录 主机路由：Destination为主机的IP地址，Genmask为255.255.255.255（不常用） 网络路由：Destination为目标网络的网段地址 默认路由：Destination为0.0.0.0，Genmask为0.0.0.0，优先级最低；比如路由表只有10网段和0.0.0.0,10网段的IP地址走10网段配置的路，不属于10网段的IP地址只能走0.0.0.0配置的路 添加路由 1route add [-net|-host|default] target [netmask Nm] [gw GW] [[dev] If] 删除路由 12345678910111213141516171819202122232425262728293031route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If]如果本机eth1这个网卡有172.16.10.0/24这个网段的IP,默认就会产生一条路由条目172.16.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eth1 169.254.0.0/24 是保留网关192.168.100.2 是配置的网关 [root@egon ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.100.2 0.0.0.0 UG 100 0 0 eth0172.16.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eth1192.168.0.0 192.168.100.70 255.255.0.0 UG 0 0 0 eth0192.168.100.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0192.168.100.78 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 各字段含义# 1、Destination：目标网络或目标主机# 2、Gateway：要达到目标所需要经过的网关。如果没有通过网关，这部分将显示为0.0.0.0。# 3、Genmask：和目标IP配对使用的网络掩码# 4、Flags：：表示特定的路由信息，有三个字符U 表示该路由处于up状态、该路由可用G 表示通过网关，路由项指向了一个网关H 表示路由项指向一个主机，而非整个网络 # 5、Metric：Metric用于距离衡量，一般用于路由选择，值越小优先级越高。# 6、Ref：使用/引用这个路由项的活动连接数量 (通常对普通用户没有意义)。# 7、Use：这个路由项被使用的次数。# 8、Iface：该路由所绑定的网络接口名，例如eth0，lo。 对于CentOS 6以上的系统，请忽略Metric和Ref两列，它们已经不被内核使用，只是有些路由软件可能会用上。 范例 123456789101112131415161718192021222324252627282930#查看路由表[root@centos8 ~]#routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault _gateway 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0[root@centos8 ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.2 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0#添加路由#目标：192.168.1.3 网关：172.16.0.1route add -host 192.168.1.3 gw 172.16.0.1 dev eth0#目标：192.168.0.0 网关：172.16.0.1route add -net 192.168.0.0 netmask 255.255.255.0 gw 172.16.0.1 dev eth0route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0route add -net 192.168.8.0/24 dev eth1 metric 200#默认路由，网关：172.16.0.1route add -net 0.0.0.0 netmask 0.0.0.0 gw 172.16.0.1route add -net 0.0.0.0/0 gw 172.16.0.1route add default gw 172.16.0.1#删除路由#目标：192.168.1.3 网关：172.16.0.1route del -host 192.168.1.3#目标：192.168.0.0 网关：172.16.0.1route del -net 192.168.0.0 netmask 255.255.255.0 配置路由表 配置 主机 角色 网卡 IP地址 系统 主机1 路由器R1 NAT 10.0.0.176 rocky86 桥接 10.132.65.73 主机2 路由器R2 NAT 10.0.0.182 rocky86 仅主机 192.168.10.254 主机3 客户端A 桥接 10.132.65.200 ubuntu2004 主机4 客户端B 仅主机 192.168.10.200 ubuntu2004 说明 主机1配置桥接，NAT两块网卡，充当路由 主机2配置仅主机，NAT两块网卡，充当路由 主机3配置一块桥接网卡，路由网关指向主机1桥接网卡上配置的IP地址 主机4配置一块仅主机网卡，路由网关指向主机2仅主机网卡上配置的IP地址 主机1和主机3的桥接网卡为一个网段 主机1和主机2的NAT网卡为一个网段 主机2和主机4的仅主机网卡为一个网段 通过上述配置，让主机3和主机4之间，经由主机1和主机2中转，实现连通 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889901 配置机器#R1DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.176PREFIX=24ONBOOT=yesDEVICE=eth1NAME=eth1BOOTPROTO=staticIPADDR=10.132.65.73PREFIX=21ONBOOT=yes#R2DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.182PREFIX=24ONBOOT=yesDEVICE=eth1NAME=eth1BOOTPROTO=staticIPADDR=192.168.10.254PREFIX=24ONBOOT=yes#Anetwork: version: 2 ethernets: eth0: addresses: - 10.132.65.200/21 gateway4: 10.132.65.73 #Bnetwork: version: 2 ethernets: eth0: addresses: - 192.168.10.200/24 gateway4: 192.168.10.254 2 测试主机A和路由器R1，路由器R1和路由器R2，路由器R2和主机B是否能相互连接[root@A ~]#ping 10.132.65.73[root@R1 ~]#ping 10.0.0.182[root@R2 ~]#ping 192.168.10.2003 配路由#R1和第一个网段和第二个网段直连，所以自动生成了10.132.64.0和10.0.0.0两个路由，就不需要配了，只需要加不直连的第三个网段路由[root@R1 ~]#route add -net 192.168.10.0/24 gw 10.0.0.182 dev eth0#R2和第二个网段和第三个网段直连，所以自动生成了10.0.0.0和192.168.10.0两个路由，就不需要配了，只需要加不直连的第一个网段路由[root@R2 ~]#route add -net 10.132.64.0/21 gw 10.0.0.176 dev eth04 排错第一个网段[root@A ~]#ping 10.132.65.73 #直连的一般能ping通第二个网段[root@A ~]#ping 10.0.0.182 #假如这里ping不通，原因要么是R1发给R2的数据报文失败或者R2返回给R1的数据报文返回失败[root@A ~]#tcpdump -i eth0 -nn icmpdropped privs to tcpdump tcpdump: verbose output suppressed,use -V or -vv for full protoco decodelistening on eth0，link-type EN10MB (Ethernet)，capture size 262144 bytes #发送不了[root@A ~]#ping 10.0.0.176 #假如这里也ping不通，原因是在A机器忘记配置网关了[root@A ~]#ping 10.0.0.176 #假如这里ping通了，而10.0.0.182不行，是因为R1在Linux中不是真正的路由器，Linux是一台电脑，有个默认行为是如果他收到一个数据包，发现这个数据包不是发给他的，就会抛弃掉，也就是A给R2发送数据报文，要经过R1转发给R2，但是由于其原因R1发现这个目标地址不是它，就直接抛弃，不转发给R2，而正常的路由器是会转发给R2的，所以要让R1扮演真正的路由器，就需要开启Linux的内核参数ip_forward，这个内核参数就是实现转发的功能#查看内核参数有无开启[root@R1 ~]#cat /proc/sys/net/ipv4/ip_forward#没开启就开启（临时）[root@R1 ~]#echo 1 &gt; /proc/sys/net/ipv4/ip_forward #永久[root@R1 ~]#vim /etc/sysctl.conf 加上net.ipv4.ip_forward=1[root@R1 ~]#sysctl -p#同理R2也需要开启内核参数[root@A ~]#ping 10.0.0.182 #这时候再ping就可以通了接着[root@A ~]#ping 192.168.10.200 #也成功了#查看经过哪些路由器mtr | tracepath | traceroute 192.168.10.200#如果路由器需要配置的网段只有一条路，只需要写默认路由 实现静态路由 12345678910111213141516171819202122232425262728293031四台主机：A主机：eth0 NAT模式R1主机：eth0 NAT模式,eth1 仅主机模式R2主机：eth0 桥接模式,eth1 仅主机模式B主机：eth0 桥接模式#配置A主机ifconfig eth0 10.0.0.123/8route add -net 10.0.0.0/8 dev eth0route add default gw 10.0.0.200 dev eth0#配置R1ifconfig eth0 10.0.0.200/8ifconfig eth1 192.168.0.200/24route add -net 10.0.0.0/8 dev eth0route add -net 192.168.0.0/24 dev eth1route add -net 172.16.0.0/16 gw 192.168.0.201 dev eth1echo 1 &gt; /proc/sys/net/ipv4/ip_forward#配置R2ifconfig eth0 172.16.0.200/16ifconfig eth1 192.168.0.201/24route add -net 192.168.0.0/24 dev eth1route add -net 172.16.0.0/16 dev eth0route add -net 10.0.0.0/8 gw 10.0.0.200 dev eth1echo 1 &gt; /proc/sys/net/ipv4/ip_forward#配置Bifconfig eth0 172.16.0.123/16route add -net 172.16.0.0/16 dev eth0route add default gw 172.16.0.200 dev eth0 三个路由器配置路由表 三、ip命令来自于iproute包，替代ifconfig 配置Linux网络属性1234567891011121314151617181920212223242526272829303132333435#查看链路层的信息ip link#显示ip地址ip a#禁用网卡ip link set eth1 down#网卡改名ip link set eth1 name wangnet #启用网卡ip link set wangnet up#增加ip地址ip addr add 172.16.100.100/16 dev eth0 #有个问题就是一个网卡名带有两个ip地址，不好分辨，所以加个别名#网卡别名ip addr add 172.16.100.100/16 dev eth0 label eth0:0#删除ipip addr del 172.16.100.100/16 dev eth0 label eth0:0 #先加新IP,再删除旧的IP#清除网络地址ip addr flush dev eth0#过10s后地址消失[root@centos8 ~]#ip addr change 10.0.0.18/24 dev eth0 preferred_lft 10 valid_lft 20#replace 代替现有地址信息[root@centos8 ~]#ip addr replace 10.0.0.18/24 dev eth0 preferred_lft 30 valid_lft 60#replace 也可实现新加IP[root@centos8 ~]#ip addr replace 10.0.0.28/24 dev eth0 preferred_lft 30 valid_lft 60 范例: 增加网卡别名实现一个网卡多个IP 12345678910111213141516171819202122232425262728293031323334[root@centos8 ~]#ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN groupdefault qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UPgroup default qlen 1000 link/ether 00:0c:29:8a:51:21 brd ff:ff:ff:ff:ff:ff inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe8a:5121/64 scope link valid_lft forever preferred_lft forever [root@centos8 ~]#ip address add 10.0.0.18/24 dev eth0 label eth0:1[root@centos8 ~]#ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN groupdefault qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UPgroup default qlen 1000 link/ether 00:0c:29:8a:51:21 brd ff:ff:ff:ff:ff:ff inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet 10.0.0.18/24 scope global secondary eth0:1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe8a:5121/64 scope link valid_lft forever preferred_lft forever 管理路由1234567891011121314151617181920#添加路由：ip route add TARGET via GW dev IFACE src SOURCE_IPTARGET: 主机路由：IP 网络路由：NETWORK/MASK #添加网关：ip route add default via GW dev IFACE#删除路由：ip route del TARGET#显示路由：ip route show|list#清空路由表：ip route flush [dev IFACE] [via PREFIX]#查看路由过程ip route get IP 范例 1234ip route add 192.168.0.0/24 via 172.16.0.1ip route add 192.168.1.100 via 172.16.0.1ip route add default via 172.16.0.1ip route flush dev eth0 范例: 查看路由过程 123456[root@centos8 ~]#ip route get 10.0.0.710.0.0.7 dev eth0 src 10.0.0.8 uid 0 cache[root@centos8 ~]#ip route get 8.8.8.88.8.8.8 via 10.0.0.2 dev eth0 src 10.0.0.8 uid 0 cache 四、ss命令ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢 12345678910111213141516171819-t: tcp协议相关-u: udp协议相关-w: 裸套接字相关-x：unix sock相关-l: 只显示listen状态的连接-a: 所有-n: 数字格式-p: 相关的程序及进程-e: 扩展的信息-m：显示连接内存使用情况-o：计时器信息-4：仅显示IPV4连接数据-6：仅显示IPV6连接数据-0：仅显示PACKET数据-M：仅显示mptcp数据-S：仅显示sctp数据-d：仅显示dccp数据--tipc：仅显示tipc数据--vsock：仅显示vsock数据 格式说明 123456789101112131415FILTER : [ state TCP-STATE ] [ EXPRESSION ]TCP的常见状态： tcp finite state machine: LISTEN: 监听（实际上就是机器上开启哪些了服务，远程用户可以通过其端口连接） ESTABLISHED：已建立的连接 FIN_WAIT_1 FIN_WAIT_2 SYN_SENT SYN_RECV CLOSEDEXPRESSION: dport = sport = [::]：表示ipv6的回环地址 范例 123456789101112131415161718192021222324#监控主机所有状态ss -nta#显示本地打开的所有端口ss -l#显示每个进程具体打开的socketss -pl#显示所有tcp socketss -t -a#显示所有的UDP Socektss -u -a#显示所有已建立的ssh连接ss -o state established &#x27;( dport = :ssh or sport = :ssh )&#x27;#显示所有已建立的HTTP连接ss -o state established &#x27;( dport = :http or sport = :http )&#x27;[root@centos8 ~]#ss -no state established &#x27;( dport = :21 or sport = :21 )&#x27;#列出当前socket详细信息[root@centos8 ~]#ss -s 查询网络连接情况： 1netstat -n | awk &#x27;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#x27; 五、nmcli命令可以自动生成网卡的配置文件 命令中的配置项和配置文件中的配置项对应关系： nmcli con mod|add ifcfg-* 文件 ipv4.method manual BOOTPROTO&#x3D;none ipv4.method auto BOOTPROTO&#x3D;dhcp ipv4.addresses 192.168.2.1&#x2F;24 IPADDR&#x3D;192.168.2.1 PREFIX&#x3D;24 ipv4.gateway 172.16.0.200 GATEWAY&#x3D;192.0.2.254 ipv4.dns 8.8.8.8 DNS0&#x3D;8.8.8.8 ipv4.dns-search example.com DOMAIN&#x3D;example.com ipv4.ignore-auto-dns true PEERDNS&#x3D;no connection.autoconnect yes ONBOOT&#x3D;yes connection.id（con-name） eth0 NAME&#x3D;eth0 connection.interface-name（ifname）eth0 DEVICE&#x3D;eth0 type Ethernet TYPE&#x3D;Ethernet 范例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#查看你当前的连接情况[root@centos ~]#nmcli conNAME UUID TYPE DEVICE eth0 5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03 ethernet eth0 ens33 ceda805a-2188-45fc-8edc-ae3cdf6780e7 ethernet -- Wired connection 1 8d83ec65-dbef-36bb-94d2-5ee21f2f436a ethernet -- #系统自动生成的#修改名称nmcli con modify Wired\\ connection\\ 1 con-name eth0-lan1#修改网卡的ip地址和网关并生效nmcli con modify eth0-lan1 ipv4.addresses 192.168.1.100/24 ipv4.gateway 192.168.1.1 ipv4.method manual nmcli con reloadnmcli con up eth0-lan1#查看网络连接配置nmcli con show eth0-lan1#删除连接nmcli con del eth0#启用nmcli con up con-eth1#禁用nmcli con down con-eth1#显示所有活动连接nmcli con show --active#显示设备状态nmcli dev status#显示网络接口属性nmcli dev show eth0#修改配置文件执行生效nmcli con reload #刷新nmcli con up con-name#创建新连接default，IP自动通过dhcp获取nmcli con add con-name default type Ethernet ifname eth0#创建新连接static ，指定静态IP，不自动连接nmcli con add con-name static ifname eth0 autoconnect no type Ethernet ipv4.addresses 172.25.X.10/24 ipv4.gateway 172.25.X.254#新增网卡配置，自动生成配置文件nmcli con add con-name con-eth1 ipv4.addresses 10.0.0.110/24 ipv4.gateway 10.0.0.2 ipv4.dns 114.114.114.114 ipv4.method manual type ethernet ifname eth1#启用static连接配置nmcli con up static#启用default连接配置nmcli con up default#同一设备新增配置nmcli con mod con-eth1 +ipv4.addresses 10.0.0.119/24nmcli con mod con-eth1 +ipv4.dns 8.8.8.8#同一设备删除配置nmcli con mod con-eth1 -ipv4.addresses 10.0.0.119/24nmcli con mod con-eth1 -ipv4.dns 8.8.8.8#同一设备修改配置nmcli con mod con-eth1 connection.autoconnect nonmcli con mod con-eth1 ipv4.addresses 10.0.0.119/24nmcli con mod con-eth1 ipv4.dns 8.8.8.8#DNS设置存放在/etc/resolv.conf，PEERDNS=no 表示当IP通过dhcp自动获取时，dns仍是手动设置，不自动获取等价于下面命令nmcli con mod “system eth0” ipv4.ignore-auto-dns yes","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"}]},{"title":"网络配置","slug":"Linux/network-manage/configuration","date":"2025-08-21T03:00:25.000Z","updated":"2025-08-28T12:33:05.272Z","comments":true,"path":"Linux/network-manage/configuration/","permalink":"https://aquapluto.github.io/Linux/network-manage/configuration/","excerpt":"","text":"1 网络配置文件1.1 IP、MASK、GW、DNS相关的配置文件12345678910111213141516171819202122#rocky/etc/sysconfig/network-scripts/ifcfg-IFACE#Ubuntu/etc/netplan/*.yamlTYPE #接口类型；常见有的Ethernet, BridgeNAME #此配置文件应用到的设备DEVICE #设备名HWADDR #对应的设备的MAC地址UUID #设备的惟一标识BOOTPROTO #激活此设备时使用的地址配置协议，常用的dhcp, static, none, bootpIPADDR #指明IP地址NETMASK #子网掩码,如:255.255.255.0PREFIX #网络ID的位数, 如:24GATEWAY #默认网关DNS1 #第一个DNS服务器地址DNS2 #第二个DNS服务器地址DOMAIN #主机不完整时，自动搜索的域名后缀ONBOOT #在系统引导时是否激活此设备USERCTL #普通用户是否可控制此设备PEERDNS #如果BOOTPROTO的值为“dhcp”，YES将允许dhcp server分配的dns服务器信息直接覆盖至/etc/resolv.conf文件，NO不允许修改resolv.confNM_CONTROLLED #NM是NetworkManager的简写，此网卡是否接受NM控制 1.2 配置当前主机的主机名CentOS 6 之前版本 123/etc/sysconfig/networkHOSTNAME=在文件里修改完以后，还需要执行hostname xxxx才可以保存 CentOS 7 以后版配置文件: 123/etc/hostname默认没有此文件，通过DNS反向解析获取主机名，主机名默认为：localhost.localdomain删除文件/etc/hostname，恢复主机名localhost.localdomain Ubuntu 1/etc/hostname 1.3 DNS域名解析12345/etc/resolv.confnameserver DNS_SERVER_IP1nameserver DNS_SERVER_IP2nameserver DNS_SERVER_IP3search DOMAIN 常见公共DNS 123456789101112131415161718192021180.76.76.76 百度223.5.5.5 阿里223.6.6.6 阿里119.29.29.29 腾讯119.28.28.28 腾讯114.114.114.114 电信114.114.115.115 电信1.2.4.8 CNNIC210.2.4.8 CNNIC240c::6666 CNNIC240c::6644 CNNIC80.80.80.80 Freenom World80.80.81.81 Freenom World8.8.8.8 Google8.8.4.4 Google1.1.1.1 Cloudflare117.50.11.11 OneDNS117.50.22.22 OneDNS52.80.66.66 OneDNS117.50.10.10 OneDNS 52.80.52.52 OneDNS /etc/hosts 和 /etc/resolv.conf 的区别 /etc/hosts 主要用于本地主机名到 IP 地址的静态映射，而 /etc/resolv.conf 主要用于配置 DNS 解析器的设置，指定 DNS 服务器和其他相关选项。 /etc/hosts 的查询优先级高于 DNS，因为它是在本地执行的，而 /etc/resolv.conf 则是指示系统使用哪些 DNS 服务器进行域名解析。 1.4 修改 &#x2F;etc&#x2F;hosts和DNS的优先级123456789vim /etc/hosts10.0.0.8 www.baidu.comvim /etc/sysconfig/nerwork-scripts/ifcfg-eth0....DOMAIN=magedu.com....由于hosts比DNS优先级高，所以在/etc/hosts将www.baidu.com指向的IP地址为10.0.0.8后，去ping www.baidu.com得出的IP地址是10.0.0.8，就不是原先百度的地址 修改 12vim etc/nsswitch.confhosts: files dns 1.5 路由相关的配置文件12345678910/etc/sysconfig/network-scripts/route-IFACE两种风格：(1) TARGET via GW如：10.0.0.0/8 via 172.16.0.1(2) 每三行定义一条路由ADDRESS#=TARGETNETMASK#=maskGATEWAY#=GW 范例: CentOS7 创建&#x2F;etc&#x2F;sysconfig&#x2F;static-routes文件添加持久静态路由 1234567891011121314151617181920212223242526272829303132#查看network脚本调用路由文件[root@centos7 ~]#grep -A 3 &quot;/etc/sysconfig/static-routes&quot; /etc/init.d/network if [ -f /etc/sysconfig/static-routes ]; then if [ -x /sbin/route ]; then grep &quot;^any&quot; /etc/sysconfig/static-routes | while read ignore args ;do /sbin/route add -$args done else #查看当前路由[root@centos7 ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.2 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0#创建文件[root@centos7 ~]#vim /etc/sysconfig/static-routes[root@centos7 ~]#cat /etc/sysconfig/static-routesany net 192.168.1.0/24 gw 10.0.0.254any net 192.168.2.0/24 gw 10.0.0.254[root@centos7 ~]#systemctl restart network#确认路由生效[root@centos7 ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.2 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0192.168.1.0 10.0.0.254 255.255.255.0 UG 0 0 0 eth0192.168.2.0 10.0.0.254 255.255.255.0 UG 0 0 0 eth0 2 网卡配置注意：在虚拟机加网卡开着机加，不要关机加，不然会损坏虚拟机 2.1 网卡名称systemd对网络设备的命名方式 如果Firmware或BIOS为主板上集成的设备提供的索引信息可用，且可预测则根据此索引进行命名，如：eno1 如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名，如：ens1 如果硬件接口的物理位置信息可用，则根据此信息命名，如：enp2s0 如果用户显式启动，也可根据MAC地址进行命名，如：enx2387a1dc56 上述均不可用时，则使用传统命名机制 基于BIOS支持启用biosdevname软件 12内置网卡：em1,em2 pci卡：pYpX Y：slot ,X:port 网卡组成格式 1234567en: Ethernet 有线局域网wl: wlan 无线局域网ww: wwan无线广域网o&lt;index&gt;: 集成设备的设备索引号s&lt;slot&gt;: 扩展槽的索引号x&lt;MAC&gt;: 基于MAC地址的命名p&lt;bus&gt;s&lt;slot&gt;: enp2s1 使用传统命名方式 1234567891011121314151617181920212223242526Rocky8.61 编辑文件/etc/default/grubGRUB_CMDLINE_LINUX=&quot;*quiet net.ifnames=0 biosdevname=0&quot;2 为grub2生成其配置文件基于UEFI模式引导的系统# grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg基于BIOS模式引导的系统# grub2-mkconfig -o /boot/grub2/grub.cfg# grub2-mkconfig -o /etc/grub2.cfg3 重启rebootUbuntu22.041 编辑文件/etc/default/grubGRUB_CMDLINE_LINUX=&quot; net.ifnames=0&quot;2 重新读取配置文件grub-mkconfig -o /boot/grub/grub.cfg2 重启reboot 自定义网卡名 1GRUB_CMDLINE_LINUX=&quot;... net.ifnames.prefix=&lt;required prefix&gt;&quot; 范例：自定义网卡名 12345678910111213141516[root@centos8 ~]# vi /etc/default/grubGRUB_CMDLINE_LINUX=&quot;net.ifnames.prefix=wang&quot;[root@centos8 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg[root@centos8 ~]# reboot[root@centos8 ~]# ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULTgroup default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: wang0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UPmode DEFAULT group default qlen 1000 link/ether 00:0c:29:15:9b:83 brd ff:ff:ff:ff:ff:ff3: wang1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UPmode DEFAULT group default qlen 1000 link/ether 00:0c:29:15:9b:8d brd ff:ff:ff:ff:ff:ff 2.2 网卡地址配置配置选择 1234567891011121314151617181920212223#必须配置DEVICE=ens33 #指定网卡设备名称NAME=ens33 #命令行下显示的配置名称BOOTPROTO=static #IP地址类型，获取IP方式，dhcp 动态获取，none|static 静态地址IPADDR=10.193.12.23 #IPV4的IP地址，多个地址可以写成 IPADDR2，IPADDR3NETMASK=255.255.255.0 | PREFIX=24 #传统写法 NETMASK=255.255.255.0；新写法 PREFIX=24，多地址可以写成PREFIX2GATEWAY=10.193.12.254 #网关，提供跨网段通讯功能DNS1=10.1.26.188#以下可选DOMAIN=magedu.com #域后缀TYPE=EthernetUUID=ef482e1b-4f2f-4d23-ae65-784122f24201ONBOOT=yes #网卡设备是否开机启用，yes 启用，no 禁用BROWSER_ONLY=noPROXY_METHOD=noneDEFROUTE=yesIPV4_FAILUREFATAL=noIPV6INIT=yesIPV6AUTOCONF=yesIPV6_DEFROUTE=yesIPV6FAILURE_FATAL=noIPV6ADDR_GEN_MODE=stable-privacy 范例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556571 进入目录[root@centos ~]#cd /etc/sysconfig/network-scripts2 配置文件[root@centos network-scripts]#vim ifcfg-eth0 #必须ifcfg开头，后面跟网卡名#动态获取地址DEVICE=eth0 NAME=eth0BOOTPROTO=dhcp[root@centos network-scripts]#nmcli con reload #centos8执行这两条命令[root@centos network-scripts]#nmcli con up eth0[root@centos ~]#systemctl restart network #centos7执行这条命令#静态获取地址（手工配置）DEVICE=eth0 NAME=eth0BOOTPROTO=static | none #二选一IPADDR=10.0.0.183NETMASK=255.255.255.0 | PREFIX=24 #子网掩码，二选一GATEWAY=10.0.0.2 #网关，不能随便写，看网络规划DNS1=10.0.0.2 #DNS至少配两个，如果第一个服务器坏了，可以通过第二个DNS服务器来做解析DNS2=100.76.76.76 #百度的DNS地址[root@centos network-scripts]#nmcli con reload #centos8执行这两条命令[root@centos network-scripts]#nmcli con up eth0[root@centos ~]#systemctl restart network #centos7执行这条命令#查看[root@rocky86 network-scripts]# nmcli connection#查看网关[root@centos ~]#route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.2 0.0.0.0 UG 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0#查看DNS[root@centos ~]#cat /etc/resolv.conf # Generated by NetworkManagernameserver 10.0.0.2nameserver 100.76.76.76#一个网卡配置多个ip地址DEVICE=eth0 NAME=eth0BOOTPROTO=staticIPADDR=10.0.0.183PREFIX=24 IPADDR1=10.0.0.184PREFIX1=24 IPADDR2=10.0.0.185PREFIX2=24 GATEWAY=10.0.0.2 DNS1=10.0.0.2 DNS2=100.76.76.76 域后缀 12345678910111213141516171819202122[root@rocky86 network-scripts]# vim ifcfg-eth1DEVICE=eth1NAME=con-eth1IPADDR=10.0.0.88PREFIX=24GATEWAY=10.0.0.2DNS1=10.0.0.2DNS2=114.114.114.114DOMAIN=magedu.com#查看DNS和域后缀[root@rocky86 network-scripts]# cat /etc/resolv.conf# Generated by NetworkManagersearch localdomain magedu.comnameserver 10.0.0.2nameserver 114.114.114.114#默认补全[root@rocky86 network-scripts]# ping wwwPING www.magedu.com (160.121.140.246) 56(84) bytes of data.64 bytes from 160.121.140.246 (160.121.140.246): icmp_seq=1 ttl=128 time=54.3 ms...... 2.3 网卡别名将多个IP地址绑定到一个NIC上 每个IP绑定到独立逻辑网卡，即网络别名，命名格式： ethX:Y，如：eth0:1 、eth0:2、eth0:3 范例：ifconfig 命令 12ifconfig eth0:0 192.168.1.100/24 upifconfig eth0:0 down 范例：ip 命令 1234ip addr add 172.16.1.1/16 dev eth0ip addr add 172.16.1.2/16 dev eth0 label eth0:0ip addr del 172.16.1.2/16 dev eth0 label eth0:0ip addr flush dev eth0 label eth0:0 为每个设备别名生成独立的接口配置文件，格式为：ifcfg-ethX:xxx 范例： 给 lo 网卡加别名(此方式不适用于CentOS8) 123456789101112131415161718192021[root@centos7 network-scripts]#cat ifcfg-lo:1DEVICE=lo:1IPADDR=137.0.0.1NETMASK=255.0.0.0NETWORK=137.0.0.0# If you&#x27;re having problems with gated making 127.0.0.0/8 a martian,# you can change this to something else (255.255.255.255, for example)BROADCAST=137.255.255.255ONBOOT=yesNAME=loopback1[root@centos7 network-scripts]#ip addr show lo1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN groupdefault qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet 137.0.0.1/8 brd 137.255.255.255 scope global lo:1 valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 注意： 建议 CentOS 6 关闭 NetworkManager 服务 网卡别名必须使用静态地址 2.4 网卡模式繁杂模式：在默认情况下，网卡只会接收发给自己MAC地址的数据帧，其它的数据帧则会被过滤丢弃。但是当我们把网卡设置为繁杂模式时，网卡将接收通过该网卡的所有数据帧，无论这些数据帧的目标MAC地址是什么。这个特性在一些特定的情况下很有用，例如网络监听（sniffing）和网络调试。 多播模式：允许一个网络节点将数据发送到多个接收节点，但又不像广播那样向所有网络节点发送。多播通过使用特定的IP地址范围（224.0.0.0到239.255.255.255）和MAC地址范围，来标示一组特定的接收节点。当发送节点发送数据时，只有加入了相应多播组的节点会接收和处理这份数据，其它未加入的节点则会忽略这份数据。多播技术可有效减少网络流量，提升网络的利用效率，因此在一些需要数据共享的场景，例如视频直播和在线游戏，多播技术得到了广泛的应用。 12345ifconfig eth0 promisc # 开启繁杂模式ifconfig eth0 -promisc # 关闭繁杂模式ifconfig ens33 multicast # 开启多播ifconfig ens33 -multicast # 关闭多播 3 linux上的网络3.1 linux处理数据包的过程 当向外界主机发送数据时，在它从网卡流入后需要对它做路由决策，根据其目标决定是流入本机的用户空间还是在内核空间就直接转发给其他主机 123456789# 1、如果是流入本机用户空间的数据，则数据会从内核空间进入用户空间(被应用程序接收并处理)；此时如果本机用户空间的应用程序不需要产生新的数据包对外发送，那便不再涉及到从某个网卡流出数据；但是如果本机用户空间的应用程序需要产生新的数据包对外发送，那便需要从某个网卡流出数据，但在流出之前，也需要做路由决策：根据目标决定从哪个网卡流出。 # 2、如果不是流入本机用户空间的数据，仅仅只是要经由本机把数据包转发给其他主机则必然涉及到从某个网卡流出，此时数据包必须从流入网卡完整地转发给流出网卡，这要求Linux主机能够完成这样的转发。但Linux主机默认未开启ip_forward功能，这使得数据包无法转发而被丢弃。 ps：Linux主机和路由器不同，路由器本身就是为了转发数据包，所以路由器内部默认就能在不同网卡间转发数据包，而Linux主机默认则不能转发。若要开启linux主机的转发功能，有很多方式，如下所示 临时开启linux主机的路由转发功能，重启网络服务则失效 12345# 方式1：echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 方式2：sysctl -w net.ipv4.ip_forward=1 若要永久生效，则应该写入配置文件 1234567# 在CentOS 6中:将/etc/sysctl.conf文件中的&quot;net.ipv4.ip_forward&quot;值改为1即可 #在CentOS 7中:systemd管理了太多的功能，sysctl的配置文件也分化为多个，包括/etc/sysctl.conf、/etc/sysctl.d/*.conf和/usr/lib/sysctl.d/*.conf，并且这些文件中默认都没有net.ipv4.ip_forward项。当然，直接将此项写入到这些配置文件中也都是可以的，建议写在/etc/sysctl.d/*.conf中，这是systemd提供自定义内核修改项的目录。例如： echo &quot;net.ipv4.ip_forward=1&quot; &gt; /etc/sysctl.d/ip_forward.conf 注意了注意注意了：只有当本机被别人当成网关并且本机开启路由转发功能时，别人发来的请求包，本机才会帮忙转发，这一点很重要，请务必记住 3.2 网关Linux上分为3种路由： 主机路由：掩码位32位，Destination精确到某一台主机， 所以主机路由是直接指明到某台具体的主机怎么走，主机路由也就是所谓的静态路由 网络路由：掩码小于32位，Destination精确到某一个网段的主机 所以网络路由指明到某类网络怎么走 默认路由：掩码通常为0 不走主机路由的和网络路由的、全部都走默认路由。操作系统上设置的默认路由一般也称为网关。 路由是区分优先级的：若Linux上到某主机有多条路由可以选择，这时候会挑选优先级高的路由 12345678910大前提：主机范围越小、越精确、优先级越高，而缩小主机范围的恰恰就是子网掩码，掩码越长范围越小、越精确、优先级越高 优先级区分：# 1、在Linux中，路由条目的优先级确定方式是先匹配掩码位长度，掩码越长的优先级高也就是说，掩码位长的路由条目优先级一定比掩码位短的优先级高，所以主机路由的优先级最高，然后是直连网络(即同网段)的路由(也算是网络路由)次之，再是网络路由，最后才是默认路由即网关。 # 2、若路由条目的掩码长度相同，则比较节点之间的管理距离(比如metric)，管理距离短的生效。 例如1：在本机查看到路由表如下 12345678[root@egon ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.100.2 0.0.0.0 UG 100 0 0 eth0172.16.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eth1192.168.0.0 192.168.100.70 255.255.0.0 UG 0 0 0 eth0192.168.100.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0192.168.100.78 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 在本机ping 192.168.5.20 12345# 先检索掩码长的路由条件，即按照如下顺序255.255.255.255 &gt; 255.255.255.0 &gt; 255.255.0.0 &gt; 0.0.0.0 于是先对应192.168.100.78发现无法匹配，然后比对192.168.100.0，发现也无法匹配，接着再匹配192.168.0.0这条网络路由条目，发现能匹配，所以选择该路由条目，从eth0发出数据包 例2：如下路由表。由于两块网卡eth0和eth1都是192.168.100.0&#x2F;24网段地址，所以它们的路由条目在掩码长度的匹配上是相同的，但是和eth0直连的网段主机通信时，肯定会选择eth0这条路由条目（即第二条），因为eth1和该网段主机隔了一个eth0，距离增加了1。 123456[root@egon ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.100.2 0.0.0.0 UG 100 0 0 eth0192.168.100.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0192.168.100.0 0.0.0.0 255.255.255.0 U 101 0 0 eth1 3.3 ICMP范例：修改IP报文段的TTL值 1echo 100 &gt; /proc/sys/net/ipv4/ip_default_ttl 范例：发现IP冲突的主机 12345678[root@centos8 ~]#arping 10.0.0.6ARPING 10.0.0.6 from 10.0.0.8 eth0Unicast reply from 10.0.0.6 [00:0C:29:E0:2F:37] 0.779msUnicast reply from 10.0.0.6 [00:0C:29:32:80:38] 0.798msUnicast reply from 10.0.0.6 [00:0C:29:32:80:38] 0.926msUnicast reply from 10.0.0.6 [00:0C:29:32:80:38] 0.864ms^CSent 3 probes (1 broadcast(s))Received 4 response(s) 范例: 禁用IPv6 12345678910111213141516171819202122232425262728#默认启动IPv6#修改内核配置[root@centos8 ~]#vim /etc/sysctl.conf#加下面两行net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1[root@centos8 ~]#sysctl -p#注意:禁用IPv6可能会影响一些服务的启动,如:ssh,postfix,mysql等[root@centos8 ~]#vim /etc/ssh/sshd_config#AddressFamily any 此行修改为以下行AddressFamily inet[root@centos8 ~]#systemctl restart sshd[root@centos8 ~]#vim /etc/postfix/main.cf#inet_interfaces = localhost 此行修改为以下行inet_interfaces = 127.0.0.1 [root@centos8 ~]#systemctl restart postfix[root@centos8 ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 100 127.0.0.1:25 0.0.0.0:* 4 Ubuntu网络配置4.1 主机名12345678910111213#修改主机名root@ubuntu1804:~# hostnamectl set-hostname ubuntu1804.magedu.orgroot@ubuntu1804:~# cat /etc/hostnameubuntu1804.magedu.orgroot@ubuntu1804:~# hostnameubuntu1804.magedu.orgroot@ubuntu1804:~# echo $HOSTNAMEubuntu1804root@ubuntu1804:~# exitlogoutwang@ubuntu1804:~$ sudo -iroot@ubuntu1804:~# echo $HOSTNAMEubuntu1804.magedu.org 4.2 网卡名称12345678910111213141516#修改配置文件为下面形式root@ubuntu1804:~#vi /etc/default/grubGRUB_CMDLINE_LINUX=&quot;net.ifnames=0&quot;#或者sed修改root@ubuntu1804:~# sed -i.bak &#x27;/^GRUB_CMDLINE_LINUX=/s#&quot;$#net.ifnames=0&quot;#&#x27; /etc/default/grub#生效新的grub.cfg文件root@ubuntu1804:~# grub-mkconfig -o /boot/grub/grub.cfg#或者root@ubuntu1804:~# update-grubroot@ubuntu1804:~# grep net.ifnames /boot/grub/grub.cfg#重启生效root@ubuntu1804:~# reboot 4.3 网卡配置配置选项 123456dhcp4addressesgateway4 nameservers #DNSversion #版本，默认写2search #域后缀 范例 123456#两个写法等价addresses: [10.0.0.6/24,10.0.0.66/24]addresses: - 10.0.0.6/24 - 10.0.0.66/24 4.3.1 配置自动获取IP网卡配置文件采用YAML格式,必须以 &#x2F;etc&#x2F;netplan&#x2F;XXX.yaml 文件命名方式存放 可以每个网卡对应一个单独的配置文件,也可以将所有网卡都放在一个配置文件里 123456789101112root@ubuntu1804:~# cat /etc/netplan/01-netcfg.yaml# This file describes the network interfaces available on your system# For more information, see netplan(5).network: version: 2 renderer: networkd ethernets: #指定网卡类型：以太网 eth0: dhcp4: yes #通过ipv4自动获取 #修改网卡配置文件后需执行命令生效root@ubuntu1804:~#netplan apply 4.3.2 配置静态IP123456789101112131415161718192021222324252627282930313233343536#一个网卡network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.0.0.129/24 gateway4: 10.0.0.2 nameservers: #DNS search: [baidu.com, baidu.org] #实现域名访问的时候可以省略预后缀，比如正常来说是ping www.baidu.com，但是如果说写成ping www，那么就会自动添加baidu.com或者baidu.org来进行ping addresses: [10.0.0.2,180.76.76.76] #两个网卡network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.0.0.129/24 #gateway4: 10.0.0.2 #nameservers: #search: [baidu.com, baidu.org] #addresses: [10.0.0.2,180.76.76.76] eth1: addresses: [10.0.0.128/24， 1.1.1.1/24， 2.2.2.2/24] gateway4: 10.0.0.2 nameservers: search: [baidu.com] addresses: - 223.6.6.6 - 180.76.76.76 #一般来说，默认路由和DNS只需要其中一个网卡就行了，所以可以在eth0写，也可以在eth1写 查看ip和gateway 12root@ubuntu1804:~#ip addrroot@ubuntu1804:~#route -n 查看DNS 12root@ubuntu2004:~# resolvectl status #Ubuntu 20.04新命令root@ubuntu1804:~# systemd-resolve --status 5 Rocky9网络配置5.1 NetworkManager和network服务network服务和NetworkManager是两种不同的网络管理工具，每种工具都有自己的特点和适用场景。 1、network服务：它是基于传统的Linux网络管理方法，即手动配置网络接口和服务。在使用network服务时， 管理员需要编辑&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;目录下的ifcfg文件来配置网络接口。 network服务在系统启动时读取这些配置文件，并应用这些设置。network服务的优势在于其稳定性和可预测性，特别适合服务器环境。 2、NetworkManager：它是一个更现代的网络管理工具，可以自动管理其他网络接口和服务， 主要用于桌面环境。NetworkManager可以管理各种类型的网络连接，例如有线网络、无线网络和VPN等， 并在网络环境改变时动态更新网络配置。通常情况下，这两种服务不会同时运行，因为它们可能会产生冲突。 3、但是在CentOS 9中，NetworkManager已经成为默认的网络管理工具，而network服务已被移除。 也就是说，你需要使用NetworkManager来管理你的网络接口和连接。这相比早期的CentOS版本， 使得网络配置更加灵活和自动化，特别是对于经常需要切换网络环境的桌面用户来说。 但是，这也可能需要服务器管理员熟悉新的网络管理方法。 123cenetos7.9中我们直接关闭掉它，而使用network服务，而在centos9中则只能用NetworkManager[root@egon ~]# systemctl stop NetworkManager[root@egon ~]# systemctl disable NetworkManager 5.2 配置静态ipcentos9中修改的则是&#x2F;etc&#x2F;NetworkManager&#x2F;system-connections&#x2F;下的文件 详见：https://rockylinux.cn/notes/rocky-linux-9-network-configuration.html 用命令直接设置静态ip 1234567nmcli con mod ens33 ipv4.addresses &quot;192.168.1.100/24&quot;nmcli con mod ens33 ipv4.gateway &quot;192.168.1.1&quot;nmcli con mod ens33 ipv4.dns &quot;8.8.8.8,8.8.4.4&quot; # 多个dnsnmcli con mod ens33 ipv4.method manual # 默认获取ip信息的method为auto，即DHCP模式，此处需要改为手动模式，不然会出现网络连接一会正常，一会中断的情况。这一点非常重要 nmcli con down ens33nmcli con up ens33 修改配置文件 12345678910111213141516171819202122[connection]id=ens18uuid=7f49fd62-02d9-323e-8f35-0c8249647a74type=ethernetautoconnect-priority=-999interface-name=ens18timestamp=1669365850[ethernet][ipv4]address1=192.168.11.172/24,192.168.11.254 # 第一个ip地址：前一个地址是ip，后一个是网关# address2=192.168.11.145/24,192.168.11.254 # 第二个ip地址：同上dns=114.114.114.114;223.6.6.6;dns-search=rockylinux.cn;rockylinux.org;method=manual[ipv6]addr-gen-mode=eui64method=disabled[proxy]","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"}]},{"title":"逻辑卷管理器LVM","slug":"Linux/disk-manage/LVM","date":"2025-08-21T02:59:57.000Z","updated":"2025-08-28T12:33:05.185Z","comments":true,"path":"Linux/disk-manage/LVM/","permalink":"https://aquapluto.github.io/Linux/disk-manage/LVM/","excerpt":"","text":"1 概念传统磁盘管理的痛点 磁盘空间耗尽后，通常需要将系统脱机，然后通过一系列繁琐而复杂的操作，以增加磁盘分区的可用空间，不能直接扩容 如果分区设置的过大，就白白浪费了磁盘空间； 如果分区设置的过小，就会导致空间不够用的情况出现。 对于分区过小的问题，我们可以重新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样做虽然能够临时解决问题，但是给管理带来了麻烦。 LVM：可以允许对卷进行方便操作的抽象层，包括重新设定文件系统的大小，允许在多个物理设备间重新组织文件系统；LVM可以弹性的更改LVM的容量，通过交换PE来进行资料的转换，将原来LV内的PE转移到其他的设备中以降低LV的容量，或将其他设备中的PE加到LV中以加大容量 可以创建和管理“逻辑”卷，而不是直接使用物理硬盘。可以让管理员弹性的管理逻辑卷的扩大缩小，操作简单，而不损坏已存储的数据。可以随意将新的硬盘添加到LVM，以直接扩展已经存在的逻辑卷。LVM并不需要重启就可以让内核知道分区的存在。 物理卷(PV):（physical volume）,把常规的磁盘设备通过pvcreate命令对其进行初始化，形成了物理卷。其实就是硬盘或分区。（面粉） 卷组(VG):（volume group）,把多个物理卷组成一个逻辑的整体，这样卷组的大小就是多个硬盘之和。或者理解就是由一个或多个PV组成的整体。（面团） 逻辑卷(LV)：（logical volume），从卷组中划分需要的空间大小出来。用户仅需对其格式化然后即可挂载使用。从VG中切割出的空间用于创建文件系统。（切成馒头） 基本单元(PE)：(physical extend),分配的逻辑大小的最小单元，默认为4MB的基本块。（假设分配100MB逻辑空间，则需要创建25个PE） LVM的缺点 因为加入了额外的操作，存取性能受到影响。 当卷组中的一个磁盘损坏时，整个卷组都会受到影响。 解释：LVM如果有一个磁盘损坏,整个lvm都坏了，lvm只有动态扩展作用 方案：底层用RAID + 上层LVM &#x3D; 既有冗余又有动态扩展 LVM的动态扩容：逻辑卷要是想扩容，必须保证卷组有足够的空间，若是卷组没有空间了，就要新增一个磁盘，打造为物理卷，添加到卷组中才可以进行扩容 2 实现逻辑卷相关工具来自于 lvm2 包 硬盘变成逻辑卷步驟 把硬盘或者分区通过pvcreate变成物理卷，物理卷是用固定大小的物理区域（Physical Extent，PE）来定义的 把多个物理卷通过vgcreate变成卷组 把卷组通过lvcreate分出空间给逻辑卷 创建文件系统 挂载 12345678910111213141516#/dev/sdb 20G 假如不想20G全部都加逻辑卷，先分区#分区要改ID，改成8e（硬盘不用改）fdisk /dev/sdb#将硬盘和分区一起创建1 pvcreate /dev/sdc /dev/sdb1（pvcreate /dev/sd&#123;b1,c&#125;）#-s指定PE的大小为16M，默认为4M；testvg0随意起名字，PE是分配将来空间以及进行容量扩容的时候的最小单位，扩容一个P一个P的扩2 vgcreate -s 16 testvg0 /dev/sdc /dev/sdb1 #-L指定从testvg0卷组中分配空间大小，大小不能超过整个卷组的空间大小（假如现在卷组空间大小为15G）；-n起名字3 lvcreate -L 6G -n lv-mysql testvg0 4 mkfs.ext4 /dev/testvg0/lv-mysql5 mount /dev/testvg0/lv-mysql /data/mysql 第一个逻辑卷对应设备名：&#x2F;dev&#x2F;dm-# dm：device mapper，将一个或多个底层块设备组织成一个逻辑设备的模块 软链接： &#x2F;dev&#x2F;mapper&#x2F;VG_NAME-LV_NAME &#x2F;dev&#x2F;VG_NAME&#x2F;LV_NAME 范例 1234567[root@rocky86 ~]# ll /dev/mapper/rl*lrwxrwxrwx 1 root root 7 Aug 1 09:38 /dev/mapper/rl-home -&gt; ../dm-2lrwxrwxrwx 1 root root 7 Aug 1 09:38 /dev/mapper/rl-root -&gt; ../dm-0lrwxrwxrwx 1 root root 7 Aug 1 09:38 /dev/mapper/rl-swap -&gt; ../dm-1[root@ubuntu2204 ~]# ll /dev/mapper/*lvlrwxrwxrwx 1 root root 7 May 14 12:11 /dev/mapper/ubuntu--vg-ubuntu--lv -&gt;../dm-0 2.1 pv管理工具将块设备创建为物理卷，本质上就是给块设备打一个标签块设备数量和物理卷数量是对应的，有几个块设备，就可以创建几个物理卷块设备容量大小不限，可以跨分区 显示pv 12pvs #简要pv信息显示pvdisplay #详细 创建pv 1pvcreate /dev/DEVICE 删除pv 1pvremove /dev/DEVICE 2.2 vg管理工具显示卷组 12vgsvgdisplay 范例 12345678[root@ubuntu2204 ~]# vgdisplay testvg.....VG Size &lt;24.97 GiB #总大小PE Size 16.00 MiB #PE大小Total PE 1598 #总PE数量Alloc PE / Size 0 / 0 #己分配的PEFree PE / Size 1598 / &lt;24.97 GiB #可用PE..... 创建卷组 12345vgcreate [-s Size ] vgname pv1 [pv2...]-s 指定PE大小，默认4M，数字加单位，单位为 k|K|m|M|g|G|t|T|p|P|e|E#示例vgcreate -s 16M vg0 /dev/sdb /dev/sdc 管理卷组 12vgextend vgname pv1 [pv2...] #扩展卷组，将新的物理卷添加到已有的卷组vgreduce vgname pv1 [pv2...] #从卷组中移除物理卷 扩展卷组可以带来以下好处： 增加存储空间：通过添加新的物理卷（磁盘或分区）来扩展卷组，可以为卷组提供额外的存储空间。 提高灵活性：扩展卷组后，可以利用新的空间创建新的逻辑卷，或者将现有的逻辑卷扩展到更大的空间。 优化性能：如果原有的物理卷已经接近满载，扩展卷组并添加新的物理卷可以提高读写性能，因为数据可以在更多的物理设备上分布。 高可用性：扩展卷组后，可以将数据迁移到新的物理卷上，以提高数据的冗余度和可用性。 范例：扩展vg 123456789101112131415161718[root@ubuntu2204 ~]# pvsPV VG Fmt Attr PSize PFree/dev/sda3 ubuntu-vg lvm2 a-- &lt;198.00g 99.00g/dev/sdb1 testvg lvm2 a-- 4.98g 4.98g/dev/sdb2 lvm2 --- 5.00g 5.00g/dev/sdc testvg lvm2 a-- 19.98g 19.98g#往testvg中增加 pv[root@ubuntu2204 ~]# vgextend testvg /dev/sdb2Volume group &quot;testvg&quot; successfully extended#再次查看pv[root@ubuntu2204 ~]# pvsPV VG Fmt Attr PSize PFree/dev/sda3 ubuntu-vg lvm2 a-- &lt;198.00g 99.00g/dev/sdb1 testvg lvm2 a-- 4.98g 4.98g/dev/sdb2 testvg lvm2 a-- 4.98g 4.98g/dev/sdc testvg lvm2 a-- 19.98g 19.98g 删除卷组 删除vg之前，要先把对应的 pv 解除绑定 121 pvmove2 vgremove 2.3 lv管理工具显示逻辑卷 12lvsLvdisplay 创建逻辑卷 12345678lvcreate -L #[mMgGtT] -n NAME VolumeGroup-L #指定大小，创建一个特定大小的逻辑卷，允许你手动指定逻辑卷的大小-n #逻辑卷名称-l #指定PE个数,也可用百分比，通常跟一个加号（+）和设备名，用来指定新的逻辑卷应该使用该设备上的所有剩余空间，用于自动分配所有可用的空间#范例lvcreate -l +60%VG -n mylv testvglvcreate -l +100%FREE -n yourlv testvg 扩展逻辑卷 12345lvextend &#123;-L N[mMgGtT]|-l N&#125; LV_NAME-L[+]Size[mMgGtT] #N个单位大小，也可写成+10M-l[+]Number[PERCENT] #N个PE，也可以写成+10，表示在原基础上加10个PE大小，+100%free 表示把剩下空间都用完-r #自动重置文件系统大小 缩减逻辑卷 1234lvreduce &#123;-L N[mMgGtT]|-l N&#125; LV_NAME-L #指定逻辑卷的大小，N个单位大小，也可写成-10M-l #指定逻辑卷的大小，N个PE，也可以写成-10，表示在原基础上减10个PE大小 删除逻辑卷 1lvremove /dev/VG_NAME/LV_NAME 重设文件系统大小 修改了逻辑卷大小后，要同步文件系统 12345678fsadm [options] resize device [new_size[BKMGTEP]]xfs_growfs /mountpoint #只支持xfs系列文件系统resize2fs [-f] [-F] [-M] [-P] [-p] device [new_size] #只支持ext系列文件系统-f：强制执行调整操作，不需要检查文件系统的完整性。-F：显示当前文件系统的特性（例如，是否启用了日志功能）。-M：显示文件系统的超级块备份信息。-P：显示文件系统的备用超级块位置。-p：在调整文件系统大小之前，检查并修复文件系统的错误。 范例：创建lv 123456789101112131415#从 testvg 中创建lv1,大小为100个PE[root@ubuntu2204 ~]# lvcreate -l 100 -n lv1 testvgLogical volume &quot;lv1&quot; created.#创建lv2，大小为5G[root@ubuntu2204 ~]# lvcreate -L 5G -n lv2 testvgLogical volume &quot;lv2&quot; created.#创建lv3,大小为testvg卷组中所有物理卷剩下可用PE数量的20%[root@ubuntu2204 ~]# lvcreate -l 20%free -n lv3 testvgLogical volume &quot;lv3&quot; created.#创建lv4,大小为testvg卷组总大小的10%[root@ubuntu2204 ~]# lvcreate -l 10%VG -n lv4 testvgLogical volume &quot;lv4&quot; created. 逻辑卷的使用跟硬盘分区使用一样，要先创建文件系统，再进行挂载 2.4 扩展和缩减逻辑卷2.4.1 在线扩展逻辑卷扩展逻辑卷之前，要先保证卷组上还有空间 两步实现，先扩展逻辑卷，再扩容文件系统 12345678#第一步实现逻辑卷的空间扩展lvextend -L [+]#[mMgGtT] /dev/VG_NAME/LV_NAME#第二步实现文件系统的扩展#针对extresize2fs /dev/VG_NAME/LV_NAME#针对xfsxfs_growfs MOUNTPOINT 一步实现容量和文件系统的扩展 1234567lvresize [option] /dev/VG_NAME/LV_NAME#选项说明-L #指定逻辑卷的大小, 单位为“kKmMgGtT”字节 -l #指定逻辑卷的大小（LE数）-r #可以同时扩展卷和文件系统-A #自动调整逻辑卷的大小，如果扩展失败可以使用这个选项 范例 123456#扩容之前先vgs看看卷组还有多少空间#+100%free是把卷组所剩空间全部都扩容lvextend -L +100%free /dev/testvg0/lv-mysql #只会先扩逻辑卷空间resize2fs /dev/testvg0/lv-mysql #扩文件系统lvresize -r -l +100%FREE /dev/testvg0/lv-mysql #一步实现 学习问题1 问题：一开始创建逻辑卷，sdb1和sdb2都关联到了test-mysql逻辑卷，然后将sdb3扩展到test卷组，但是为什么扩展到了之后，sdb3没有关联到test-mysql卷组 解答：之所以test-mysql存在sdb1和sdb2上，是因为它需要6G的那个空间，而sdb1和sdb2都只有5G，加起来10G，所以它才会同时存在这两个地方，已经确保有6G足够可用的空间，test-mysql存在了sdb1和2上，已经存好了，3上不用存了，test-mysql需要的空间已经足够了，那么扩展卷组的用处就是比如原本test卷组10G容量，然后已经分完容量给一个逻辑卷，想扩展逻辑卷的话没有容量了，那么扩展卷组后多了容量，就可以扩展逻辑卷了，所以也就是说，当test-mysql扩容到10G，到达了test卷组的最大容量，sdb3有10G，扩展到test卷组，那么test卷组就有了20G的容量，那么test-mysql又可以继续扩容了，或者创建新的逻辑卷 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@rocky8 ~]#lvcreate -L 6G -n mysql testWARNING: xfs signature detected on /dev/test/mysql at offset 0. Wipe it? [y/n]: y Wiping xfs signature on /dev/test/mysql. Logical volume &quot;mysql&quot; created. [root@rocky8 ~]#lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root rl -wi-ao---- &lt;17.00g swap rl -wi-ao---- 2.00g mysql test -wi-a----- 6.00g [root@rocky8 ~]#lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─rl-root 253:0 0 17G 0 lvm / └─rl-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 5G 0 part │ └─test-mysql 253:2 0 6G 0 lvm ├─sdb2 8:18 0 5G 0 part │ └─test-mysql 253:2 0 6G 0 lvm └─sdb3 8:19 0 10G 0 part sr0 11:0 1 10.5G 0 rom [root@rocky8 ~]#vgs VG #PV #LV #SN Attr VSize VFree rl 1 2 0 wz--n- &lt;19.00g 0 test 2 1 0 wz--n- &lt;9.97g &lt;3.97g [root@rocky8 ~]#pvs PV VG Fmt Attr PSize PFree /dev/sda2 rl lvm2 a-- &lt;19.00g 0 /dev/sdb1 test lvm2 a-- 4.98g 0 /dev/sdb2 test lvm2 a-- 4.98g &lt;3.97g /dev/sdb3 lvm2 --- &lt;10.00g &lt;10.00g [root@rocky8 ~]#vgextend test /dev/sdb3 Volume group &quot;test&quot; successfully extended [root@rocky8 ~]#pvs PV VG Fmt Attr PSize PFree /dev/sda2 rl lvm2 a-- &lt;19.00g 0 /dev/sdb1 test lvm2 a-- 4.98g 0 /dev/sdb2 test lvm2 a-- 4.98g &lt;3.97g /dev/sdb3 test lvm2 a-- 9.98g 9.98g [root@rocky8 ~]#lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─rl-root 253:0 0 17G 0 lvm / └─rl-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 5G 0 part │ └─test-mysql 253:2 0 6G 0 lvm ├─sdb2 8:18 0 5G 0 part │ └─test-mysql 253:2 0 6G 0 lvm └─sdb3 8:19 0 10G 0 part sr0 11:0 1 10.5G 0 rom 学习问题2 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#根分区已满[root@ubuntu2004 ~]#df -hFilesystem Size Used Avail Use% Mounted onudev 1.9G 0 1.9G 0% /devtmpfs 389M 41M 349M 11% /run/dev/mapper/ubuntu--vg-ubuntu--lv 9.8G 9.8G 0 100% /tmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda2 1.5G 209M 1.2G 16% /boot/dev/loop1 68M 68M 0 100% /snap/lxd/21835/dev/loop2 92M 92M 0 100% /snap/lxd/24061/dev/loop3 41M 41M 0 100% /snap/snapd/20290/dev/loop4 64M 64M 0 100% /snap/core20/2015tmpfs 389M 0 389M 0% /run/user/0/dev/loop5 64M 64M 0 100% /snap/core20/2264#两种命令扩容报错[root@ubuntu2004 ~]#lvresize -r -L +8G /dev/mapper/ubuntu--vg-ubuntu--lv /etc/lvm/archive/.lvm_ubuntu2004_50678_558404538: write error failed: No space left on device[root@ubuntu2004 ~]#lvextend -L +8G /dev/mapper/ubuntu--vg-ubuntu--lv /etc/lvm/archive/.lvm_ubuntu2004_50678_558404538: write error failed: No space left on device #但是卷组还有空间[root@ubuntu2004 ~]#vgdisplay --- Volume group --- VG Name ubuntu-vg System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 2 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 1 Act PV 1 VG Size &lt;18.50 GiB PE Size 4.00 MiB Total PE 4735 Alloc PE / Size 2560 / 10.00 GiB Free PE / Size 2175 / &lt;8.50 GiB VG UUID d0xfxL-9ith-021w-xHBF-GALw-41Nk-TYZnQ1 #解决#该命令重新调整了 /dev/mapper/ubuntu 的 lv 大小，并刷新了文件系统[root@ubuntu2004 ~]#lvresize -A n -L +8G /dev/mapper/ubuntu--vg-ubuntu--lv Size of logical volume ubuntu-vg/ubuntu-lv changed from 10.00 GiB (2560 extents) to 18.00 GiB (4608 extents). WARNING: This metadata update is NOT backed up. Logical volume ubuntu-vg/ubuntu-lv successfully resized. [root@ubuntu2004 ~]#resize2fs -p /dev/mapper/ubuntu--vg-ubuntu--lvresize2fs 1.45.5 (07-Jan-2020)Filesystem at /dev/mapper/ubuntu--vg-ubuntu--lv is mounted on /; on-line resizing requiredold_desc_blocks = 2, new_desc_blocks = 3The filesystem on /dev/mapper/ubuntu--vg-ubuntu--lv is now 4718592 (4k) blocks long.[root@ubuntu2004 ~]#df -hFilesystem Size Used Avail Use% Mounted onudev 1.9G 0 1.9G 0% /devtmpfs 389M 1.6M 388M 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 18G 9.8G 7.0G 59% /tmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda2 1.5G 209M 1.2G 16% /boot/dev/loop1 68M 68M 0 100% /snap/lxd/21835/dev/loop2 92M 92M 0 100% /snap/lxd/24061/dev/loop3 41M 41M 0 100% /snap/snapd/20290/dev/loop4 64M 64M 0 100% /snap/core20/2015tmpfs 389M 0 389M 0% /run/user/0/dev/loop5 64M 64M 0 100% /snap/core20/2264 2.4.2 缩减逻辑卷注意：缩减有数据损坏的风险，建议先备份再缩减，不支持在线缩减，要先取消挂载，xfs文件系统不支持缩减 范例: 缩减ext4文件系统的逻辑卷 1234561 取消挂载umonut /data/mysql2 缩减逻辑卷和文件系统lvreduce -L 8G -r /dev/testvg0/lv-mysql #只支持ext4系统3 重新挂载mount /dev/testvg0/lv-mysql /data/mysql 范例: 缩减XFS文件系统的逻辑卷 123456789101112131415161718192021#先备份XFS文件系统数据[root@centos8 ~]#yum -y install xfsdump#备份/data挂载点对应的逻辑卷#注意挂载点后面不要加/,否则会出错:xfsdump: ERROR: /data/ does not identify a file system[root@centos8 ~]#xfsdump -f data.img /data#卸载文件系统[root@centos8 ~]#umount /data#缩减逻辑卷[root@centos8 ~]#lvreduce -L 10G /dev/vg0/lv0#重新创建文件系统[root@centos8 ~]#mkfs.xfs -f /dev/vg0/lv0#重新挂载[root@centos8 ~]#mount /dev/vg0/lv0 /data#还原数据[root@centos8 ~]#xfsrestore -f data.img /data 2.5 跨主机迁移卷组源计算机上 （1）在旧系统中，umount 所有卷组上的逻辑卷 （2）禁用卷组 12vgchange -a n vg0lvdisplay （3）导出卷组 123vgexport vg0pvscanvgdisplay （4）拆下旧硬盘在目标计算机上,并导入卷组 1vgimport vg0 （5）启用 1vgchange -ay vg0 （6）mount 所有卷组上的逻辑卷 2.6 拆除即将坏掉的硬盘拆除一个硬盘之前要先把它上面所存的数据挪到同一个卷组的其他成员，首先先查看这个硬盘存放数据的大小，再查看卷组的大小，若卷组的大小大于硬盘大小，则可以直接挪，反之要新增加一个硬盘，把它加入到卷组中，扩大卷组的大小，才可以挪，挪完就可以删了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[root@ubuntu2204 ~]# vgdisplay testvg --- Volume group ---VG Name testvgSystem ID Format lvm2Metadata Areas 3Metadata Sequence No 6VG Access read/writeVG Status resizableMAX LV 0Cur LV 4Open LV 0Max PV 0Cur PV 3Act PV 3VG Size 29.95 GiBPE Size 16.00 MiBTotal PE 1917Alloc PE / Size 910 / &lt;14.22 GiBFree PE / Size 1007 / 15.73 GiBVG UUID lm1nmp-0SS1-icze-jnWP-UHhb-VYma-AxOaJW[root@ubuntu2204 ~]# pvdisplay --- Physical volume ---PV Name /dev/sdb1VG Name testvgPV Size 5.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 319Free PE 28Allocated PE 291PV UUID rjdv3i-minb-ge0w-cL0Y-b6ye-2fxo-GHeCk7 --- Physical volume ---PV Name /dev/sdcVG Name testvgPV Size 20.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 1279Free PE 660Allocated PE 619PV UUID PC5EE2-1duK-dvF2-08GF-zzxI-qoNA-GVhrpD --- Physical volume ---PV Name /dev/sdb2VG Name testvgPV Size 5.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 319Free PE 319Allocated PE 0PV UUID rqn1EO-bmaI-ak0M-0bT3-rEp4-r3cf-2kDHQb............#把 testvg 上的某个 pv 拆除，前提是 testvg上还有足够多的空间，能容纳要拆除的 pv 上的数据#把 pv 上的数据先移走[root@ubuntu2204 ~]# pvmove /dev/sdb1/dev/sdb1: Moved: 8.59%/dev/sdb1: Moved: 34.36%/dev/sdb1: Moved: 100.00%#再次查看 /dev/sdb1 上己经没有数据了[root@ubuntu2204 ~]# pvdisplay --- Physical volume ---PV Name /dev/sdb1VG Name testvgPV Size 5.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 319Free PE 319Allocated PE 0PV UUID rjdv3i-minb-ge0w-cL0Y-b6ye-2fxo-GHeCk7 --- Physical volume ---PV Name /dev/sdcVG Name testvgPV Size 20.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 1279Free PE 369Allocated PE 910PV UUID PC5EE2-1duK-dvF2-08GF-zzxI-qoNA-GVhrpD --- Physical volume ---PV Name /dev/sdb2VG Name testvgPV Size 5.00 GiB / not usable 16.00 MiBAllocatable yesPE Size 16.00 MiBTotal PE 319Free PE 319Allocated PE 0PV UUID rqn1EO-bmaI-ak0M-0bT3-rEp4-r3cf-2kDHQb[root@ubuntu2204 ~]# pvsPV VG Fmt Attr PSize PFree/dev/sda3 ubuntu-vg lvm2 a-- &lt;198.00g 99.00g/dev/sdb1 testvg lvm2 a-- 4.98g 4.98g/dev/sdb2 testvg lvm2 a-- 4.98g 4.98g/dev/sdc testvg lvm2 a-- 19.98g &lt;5.77g#从 vg 中拆除[root@ubuntu2204 ~]# vgreduce testvg /dev/sdb1Removed &quot;/dev/sdb1&quot; from volume group &quot;testvg&quot;[root@ubuntu2204 ~]# pvsPV VG Fmt Attr PSize PFree/dev/sda3 ubuntu-vg lvm2 a-- &lt;198.00g 99.00g/dev/sdb1 lvm2 --- 5.00g 5.00g/dev/sdb2 testvg lvm2 a-- 4.98g 4.98g/dev/sdc testvg lvm2 a-- 19.98g &lt;5.77g#删除 pv[root@ubuntu2204 ~]# pvremove /dev/sdb1Labels on physical volume &quot;/dev/sdb1&quot; successfully wiped. 3 逻辑卷快照3.1 逻辑卷快照原理快照是特殊的逻辑卷，它是在生成快照时存在的逻辑卷的准确拷贝,对于需要备份或者复制的现有数据临时拷贝以及其它操作来说，快照是最合适的选择,快照只有在它们和原来的逻辑卷不同时才会消耗空间，建立快照的卷大小小于等于原始逻辑卷,也可以使用lvextend扩展快照 逻辑卷管理器快照就是将当时的系统信息记录下来，就好像照相一般，若将来有任何数据改动了，则原始数据会被移动到快照区，没有改动的区域则由快照区和文件系统共享 逻辑卷快照工作原理 在生成快照时会分配给它一定的空间，但只有在原来的逻辑卷或者快照有所改变才会使用这些空间 当原来的逻辑卷中有所改变时，会将旧的数据复制到快照中 快照中只含有原来的逻辑卷中更改的数据或者自生成快照后的快照中更改的数据 如果log_lv 中的文件不做任何修改，则快照空间为空 修改f1，第一次修改时，将修改前的f1推到快照，后面的修改不管 删除f2，将f2推送到快照 新建f3,不会被推送到快照 使用快照还原，则f1被还原，f2被还原，f3也没有了 由于快照区与原本的LV共用很多PE的区块，因此快照与被快照的LV必须在同一个VG中。系统恢复的时候的文件数量不能高于快照区的实际容量 快照特点 起到数据备份的效果 快照的大小和逻辑卷的大小可以不一样 应用场景是测试环境，不能完成代替备份 快照后，逻辑卷的修改速度会一定有影响 3.2 实现逻辑卷快照范例 123456789101112131415假设/data/mysql下有f&#123;1,2,3&#125;.txt文件1 创建快照lvcreate -n lv-mysql-snapshot -s -p r -L 1G /dev/testvg0/lv-mysql #-n起名字；-s快照；-p r实现只读，防止被误操作；-L指定大小；对/dev/testvg0/lv-mysql做快照2 挂载mount /dev/testvg0/lv-mysql-snapshot /mnt这个时候不管你f&#123;1,2,3&#125;.txt文件如何增删改，/mnt下都保留着f&#123;1,2,3&#125;.txt文件的原始数据利用快照还原数据3 取消所有挂载umount /data/mysql4 恢复lvconvert --merge /dev/testvg0/lv-mysql-snapshot5 重新挂载mount /dev/testvg0/lv-mysql /data/mysql 范例 123456789101112131415161718mkfs.xfs /dev/vg0/datamount /dev/vg0/data/ /mnt/data#为现有逻辑卷创建快照,注意ext4建议使用-p r 实现只读lvcreate -l 64 -s -n data-snapshot /dev/vg0/data#挂载快照,xfs注意要使用-o ro实现只读,防止快照被修改mkdir -p /mnt/snapmount -o ro,nouuid /dev/vg0/data-snapshot /mnt/snap#恢复快照umount /dev/vg0/data-snapshotumount /dev/vg0/datalvconvert --merge /dev/vg0/data-snapshot#删除快照umount /mnt/snaplvremove /dev/vg0/data-snapshot","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://aquapluto.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"磁盘管理命令","slug":"Linux/disk-manage/disk-command","date":"2025-08-21T02:59:52.000Z","updated":"2025-08-28T12:33:05.196Z","comments":true,"path":"Linux/disk-manage/disk-command/","permalink":"https://aquapluto.github.io/Linux/disk-manage/disk-command/","excerpt":"","text":"1 df查看磁盘分区使用情况：当你需要了解每个挂载点或磁盘分区的已用、可用以及总空间时，应该使用df命令。df可以快速给出整个文件系统的空间使用摘要，因为它直接从文件系统获取信息，而不是通过计算文件大小。 只能查看挂载下的文件系统 文件系统空间实际真正占用等信息的查看工具 格式 12345678910111213141516df [OPTION]... [device]...-a|--all #显示所有-B|--block-size=SIZE #显示时指定块大小--direct #将挂载点那一列标题显示为文件-h|--human-readable #以方便阅读的方式显示-H|--si #以1000为单位，而不是1024-i|--inodes #显示inode 信息而非块使用量-k #同 --block-size=1K-l|--local #只显示本机的文件系统--output[=FIELD_LIST] #只显示指定字段-P|--portability #以Posix兼容的格式输出--total #最后加一行汇总数据-t|--type=TYPE #根据文件系统类型过滤-T|--print-type #显示文件系统类型-x|--exclude-type=TYPE #根据文件系统类型反向过滤 范例 1234567891011121314#显示文件系统的inode使用情况，而不是磁盘空间使用情况df -i#显示文件系统类型df -T#显示总磁盘空间使用情况，包括所有文件系统df -h --total#以MB为单位显示磁盘空间使用情况df -m#显示指定文件系统类型之外的文件系统df -x tmpfs -x devtmpfs 2 du查看文件或目录占用空间：如果你想要知道某个目录或一组文件具体占用了多少磁盘空间，可以使用du命令。du会遍历指定目录中的所有文件和子目录，逐一报告它们的大小。这个命令尤其有用当你需要找出哪个文件或目录占用了最多空间时 查看某目录总体空间实际占用状态 显示指定目录下面各个子目录的大小,单位为KB 格式 1234567891011121314151617du [OPTION]... DIRdu [OPTION]... --files0-from=F-0 #输出时以NULL分割，而不是换行-a #显示所有文件和目录大小-B #指定块大小-b #同 --apparent-size --block-size=1-c #汇总-d #指定最大目录层级-h #以方便阅读的格式显示-k #同 --block-size=1K-m #同 --block-size=1M--si #友好显示，以1000为单位，而不是1024-s #只显示外层目录-X #根据文件名忽略--exclude=PATTERN #根据正则表达式忽略-x #忽略不在同一个文件系统的目录 范例 12345#查看目录占用多大空间[root@ubuntu2204 ~]# du -sh /etc/#查看目录下每个文件或子目录大小[root@ubuntu2204 ~]# du -sh /var/log/* | head -n 3 范例 1234567891011121314#显示目录下所有文件和子目录的磁盘使用情况du -a /path/to/directory#以人类可读的格式显示目录下一级子目录的磁盘使用情况du -h --max-depth=1 /path/to/directory#显示指定目录的磁盘使用情况，排除挂载的文件系统du -shx /path/to/directory#显示多个目录的总磁盘使用情况du -c /path/to/directory1 /path/to/directory2#跟踪符号链接指向的文件或目录的磁盘使用情况du -L /path/to/symlink 3 df和du的差别df命令关注的是文件系统的磁盘空间使用情况，它包括了被文件和程序占用的空间，甚至包括已经删除但尚未由操作系统释放的文件所占用的空间。这意味着df命令提供的是一个更为全面的磁盘使用概览，它可以帮助我们了解磁盘的空闲空间以及整体的使用状况。 du命令则专注于计算文件或目录占用的磁盘空间，它是一个面向文件的命令，只会统计当前存在的文件所占用的空间。du命令通过累加各个文件的大小来计算总占用空间，这使得它特别适合于查找特定目录下的磁盘使用详情。例如，当我们需要找出哪个文件或哪个目录占用了大量空间时，du命令就会非常有用。 特点 df du 功能 显示文件系统的磁盘空间使用情况 估算文件和目录的磁盘空间使用情况 范围 显示已挂载文件系统的磁盘空间使用情况 递归计算指定目录下所有文件和子目录的磁盘空间使用情况 输出信息 文件系统的磁盘空间使用情况，包括总容量、已使用、可用和挂载点等信息 文件和目录的磁盘空间使用量 查找大文件 否 是 用途 查看整个文件系统的使用情况和可用空间 定位存储占用问题，查找占用空间较大的文件或目录 4 dddd命令的全称是disk dump，意为磁盘转储。在Unix&#x2F;Linux中，用于复制和转换文件。可以读取&#x2F;或写入到硬件的设备驱动（如硬盘）和特殊设备文件（如&#x2F;dev&#x2F;zero和&#x2F;dev&#x2F;random），就像普通文件一样，即按照指定的规则复制文件、转换文件格式以及创建镜像文件 12345678910111213141516171819202122232425dd if=/PATH/FROM/SRC of=/PATH/TO/DEST bs=# count=#/PATH/FROM/SRC：要复制内容的源文件/PATH/TO/DEST：目标文件，将接收复制的内容if=file #从所命名文件读取而不是从标准输入，即输入文件（源文件）of=file #写到所命名的文件而不是到标准输出，即输出文件（目标文件）ibs=size #一次从源文件读size个byteobs=size #一次在目标文件写size个bytebs=size #block size, 块大小，用于指定每次读取和写入的数据块大小cbs=size #一次转化size个byteskip=blocks #从开头忽略blocks个ibs大小的块seek=blocks #从开头忽略blocks个obs大小的块count=n #复制n个bsconv=conversion[,conversion...] #用指定的参数转换文件#conversion 转换参数:ascii #转换 EBCDIC 为 ASCIIebcdic #转换 ASCII 为 EBCDIClcase #把大写字符转换为小写字符ucase #把小写字符转换为大写字符nocreat #不创建输出文件noerror #出错时不停止notrunc #不截短输出文件sync #把每个输入块填充到ibs个字节，不足部分用空(NUL)字符补齐fdatasync #写完成前，物理写入输出文件 范例：创建空白文件 123456789dd if=/dev/zero of=test bs=block_size count=number_of_blocks#这个代码是使用dd命令来创建一个文件，具体地说，它会生成一个填充了零（null bytes）的文件。下面是对这个命令的详细解释：1 dd: 这是命令本身，代表disk dump。2 if=/dev/zero: 这是输入文件（input file）的路径。这里指定的是/dev/zero，这是一个特殊的设备文件，它只产生零字节（null bytes）。3 of=test: 这是输出文件（output file）的路径。在这个例子中，输出的文件名为test。4 bs=block_size: 这是块大小（block size）。这意味着每次读取和写入的数据块的大小。例如，如果block_size是4K，那么每次读取和写入的数据块将是4KB。5 count=number_of_blocks: 这指定了要读取和写入的块数。因此，如果block_size是4K，并且number_of_blocks是100，那么将创建400KB的文件。#所以，这个命令的总体效果是从/dev/zero读取零字节，并将这些零字节写入到test中，总共写入number_of_blocks个块，每个块的大小为block_size,文件内容为0 范例 1234567dd if=/dev/zero of=test bs=1M count=1000在当前目录下会生成一个1000M的test文件，文件内容为全0（因从/dev/zero中读取，/dev/zero为0源），但是这样为实际写入硬盘，文件产生速度取决于硬盘读写速度，如果欲产生超大文件，速度很慢。在某种场景下，我们只想让文件系统认为存在一个超大文件在此，但是并不实际写入硬盘则可以dd if=/dev/zero of=test bs=1M count=0 seek=100000此时创建的文件在文件系统中的显示大小为100000MB，但是并不实际占用block，因为count=0，因此创建速度与内存速度相当，seek的作用是跳过输出文件中指定大小的部分，这就达到了创建大文件，但是并不实际写入的目的。当然，因为不实际写入硬盘，所以你在容量只有10G的硬盘上创建100G的此类文件都是可以的。 范例：随机生成1百万个1K的文件 1seq 1000000 | xargs -i dd if=/dev/zero of=&#123;&#125;.dat bs=1024 count=1 范例：创建随机数据文件 12#通过读取/dev/urandom设备生成的随机数据，你可以轻松创建一个用于测试或加密目的的文件dd if=/dev/urandom of=output_file bs=block_size count=number_of_blocks 范例：制作设备镜像 12#dd不仅可以操作文件，还可以处理设备。比如制作设备的镜像，特别是在备份或克隆存储设备时dd if=input_device of=output_file bs=4M 范例 1234567891011121314151617181920212223242526272829[root@centos8 ~]#cat f1.txt;abcdef[root@centos8 ~]#cat f2.txt123456789[root@centos8 ~]#dd if=f1.txt of=f2.txt bs=1 count=2 skip=3 seek=4 2+0 records in2+0 records out2 bytes copied, 6.6515e-05 s, 30.1 kB/s[root@centos8 ~]#cat f2.txt1234de[root@centos8 ~]#echo 123456789 &gt; f2.txt[root@centos8 ~]#cat f2.txt123456789[root@centos8 ~]#cat f1.txtabcdef[root@centos8 ~]#cat f1.txt; cat f2.txtabcdef123456789[root@centos8 ~]#dd if=f1.txt of=f2.txt bs=1 count=2 skip=3 seek=4 conv=notrunc2+0 records in2+0 records out2 bytes copied, 7.6153e-05 s, 26.3 kB/s[root@centos8 ~]#cat f2.txt1234de789 范例 12345678910111213141516171819202122232425262728293031323334353637383940414243#备份MBRdd if=/dev/sda of=/tmp/mbr.bak bs=512 count=1#破坏MBR中的bootloaderdd if=/dev/zero of=/dev/sda bs=64 count=1 seek=446#有一个大与2K的二进制文件fileA。现在想从第64个字节位置开始读取，需要读取的大小是128Byts。又有fileB, 想把上面读取到的128Bytes写到第32个字节开始的位置，替换128Bytes，实现如下dd if=fileA of=fileB bs=1 count=128 skip=63 seek=31 conv=notrunc#将本地的/dev/sdx整盘备份到/dev/sdydd if=/dev/sdx of=/dev/sdy#将/dev/sdx全盘数据备份到指定路径的image文件dd if=/dev/sdx of=/path/to/image#备份/dev/sdx全盘数据，并利用gzip压缩，保存到指定路径dd if=/dev/sdx | gzip &gt;/path/to/image.gz#将备份文件恢复到指定盘dd if=/path/to/image of=/dev/sdx#将压缩的备份文件恢复到指定盘gzip -dc /path/to/image.gz | dd of=/dev/sdx#将内存里的数据拷贝到root目录下的mem.bin文件dd if=/dev/mem of=/root/mem.bin bs=1024#拷贝光盘数据到root文件夹下，并保存为cdrom.iso文件dd if=/dev/cdrom of=/root/cdrom.iso#销毁磁盘数据dd if=/dev/urandom of=/dev/sda1#通过比较dd指令输出中命令的执行时间，即可确定系统最佳的block size大小dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000dd if=/dev/zero of=/root/1Gb.file bs=2048 count=500000 dd if=/dev/zero of=/root/1Gb.file bs=4096 count=250000#测试硬盘写速度dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000#测试硬盘读速度dd if=/root/1Gb.file bs=64k | dd of=/dev/null 注意：虽然dd命令强大，但使用时务必小心。一不小心，错误的命令参数就可能导致数据丢失，因此在执行任何操作之前，一定要仔细检查命令 高级应用：定制化dd命令 123456789101112#显示进度，在处理大文件或设备时，你可能想要知道操作的进度。通过使用status=progress参数，dd会在执行过程中显示进度信息，让你对操作的完成情况有更直观的了解，status=progress: 该参数显示复制进度信息，你可以在终端中看到复制的进度百分比和已经复制的数据量dd if=input_file of=output_file bs=4M status=progress#错误处理，dd可以通过conv=sync,noerror参数进行错误处理，即使在读取错误的情况下，它也会继续进行操作。这在处理损坏的设备或损坏的文件时可能很有用dd if=input_file of=output_file bs=4M conv=sync,noerror#跳过部分数据，有时候，你可能只对文件的一部分数据感兴趣。使用skip参数可以告诉dd跳过输入文件的前几个块dd if=input_file of=output_file bs=4M skip=10#合并多个文件，通过使用if参数指定多个输入文件，你可以使用dd将它们合并成一个输出文件，seek=1表示在输出文件中跳过一个块，以确保新的数据追加到正确的位置dd if=input_file1 of=output_file bs=4Mdd if=input_file2 of=output_file bs=4M seek=1","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://aquapluto.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"文件系统","slug":"Linux/disk-manage/file-system","date":"2025-08-21T02:59:47.000Z","updated":"2025-08-28T12:33:05.200Z","comments":true,"path":"Linux/disk-manage/file-system/","permalink":"https://aquapluto.github.io/Linux/disk-manage/file-system/","excerpt":"","text":"1 概念文件系统：操作系统内核中用来控制硬盘的一种程序 磁盘必须格式化制作文件系统，然后挂载才能使用 可以为整个磁盘格式化制作文件系统 也可以为某个MBR或者GPT分区格式化制作文件系统 每个硬盘分区都要有一个文件系统 硬盘分区—-》打隔断，分割出一个个小空间 硬盘的最小存取单位-》扇区（512字节，相当于0.5KB） 文件系统—-》对一个个小空间做装修，负责把空间的数据组织好 操作系统的最小存取单位-》block块（4KB，8个扇区） 操作系统读取硬盘的时候，不会一个扇区一个扇区地读取，这样效率太低，于是操作系统中的文件系统负责将磁盘的多扇区组织成一个个的block块，这样操作系统就可以一次性读取一个”块”（block），即一次性连续读取多个扇区，所以文件系统组织好了之后带来的方便之处 使用者—–》block块（文件系统）—–》n个扇区（硬盘的读写单位） 一个文件系统包含的三大类块 inode block块：存放文件的元数据 ls -l 的结果如权限、属主、数组 对一个文件来说，inode block就1个 data block块：存放文件的内容数据 cat看到的结果，真正的内容 对一个文件来说，如果过大，data block可能有多个 superblock超级块：记录此filesystem的整体信息，包括inode&#x2F;block的总量、使用量、剩余量，以及文件系统的格式与相关信息等； superblock一个文件系统整体就一个 查看当前内核支持的文件系统 1cat /lib/modules/`uname -r`/kernel/fs 查看当前系统可用的文件系统 1cat /proc/filesystems 当前系统支持的文件系统和当前系统可用的文件系统是两回事，modules 中的文件系统在编译时选择了才是可用的，而可用的文件系统包含了默认支持的文件系统，如果需要使用某个文件系统，而该文件系统又不在proc 中，则需要重新编译内 各种文件系统 固态硬盘（SSD）的分区格式实际是指文件系统。文件系统是操作系统用来控制如何在硬盘上存储和检索数据的一种方法。选择正确的文件系统对于最大化SSD 性能和兼容性至关重要 从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，安全控制，日志，压缩，加密等。 2 文件系统的组成文件系统的组成部分 内核中的模块：ext4, xfs, vfat Linux的虚拟文件系统：VFS 用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfat VFS（Virtual Filesystem Switch）称为虚拟文件系统或虚拟文件系统转换，是一个内核软件层，在具体的文件系统之上抽象的一层，用来处理与 Posix 文件系统相关的所有调用，表现为能够给各种文件系统提供一个通用的接口，使上层的应用程序能够使用通用的接口访问不同文件系统，同时也为不同文件系统的通信提供了媒介。VFS 并不是一种实际的文件系统，它只存在于内存中，不存在任何外存空间，VFS 在系统启动时建立，在系统关闭时消亡。VFS由 超级块、inode、dentry、vfsmount 等结构来组成。 超级块 一个超级块对应一个文件系统(已经安装的文件系统类型如ext2，此处是实际的文件系统，不是VFS)。超级块是反映了文件系统整体的控制信息。超级块能够以多种的方式存在，对于基于磁盘的文件系统，它以特定的格式存在于磁盘的固定区域（取决于文件系统类型）上。在挂载文件系统时，该超级块中的内容被读入磁盘中，从而构建出位于内存中的新的超级块。 块组描述符表(GDT) ext文件系统每一个块组信息使用32字节描述，这32个字节称为块组描述符，所有块组的块组描述符组成块组描述符表GDT(group descriptor table)。虽然每个块组都需要块组描述符来记录块组的信息和属性元数据，但是不是每个块组中都存放了块组描述符。将所有块组的块组信息组成一个GDT保存,并将该GDT存放于某些块组中，类似存放superblock和备份superblock的块 3 文件系统类型本地文件系统（Local File Systems）： 本地文件系统是直接挂载到计算机上的物理或虚拟存储设备上的文件系统。 用于存储本地数据，如硬盘驱动器、固态驱动器、USB 驱动器等。 常见的本地文件系统包括 EXT 家族（ext2、ext3、ext4）、Btrfs、XFS、F2FS 等。 Linux 常用文件系统 ext2：Extended file system 适用于那些分区容量不是太大，更新也不频繁的情况，例如 &#x2F;boot 分区 ext3：是 ext2 的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中恢复 ext4：是 ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使用巨型文件(16TB)、最大1EB的文件系统，以及速度的提升 EXT4是Linux系统下的日志文件系统，是EXT3文件系统的后继版本 Ext4的文件系统容量达到1EB，而支持单个文件则达到16TB 理论上支持无限数量的子目录 Ext4文件系统使用64位空间记录块数量和 inode数量 Ext4的多块分配器支持一次调用分配多个数据块 修复速度更快 xfs：SGI，支持最大8EB的文件系统 根据所记录的日志在很短的时间内迅速恢复磁盘文件内容 用优化算法，日志记录对整体文件操作影响非常小 是一个全64-bit的文件系统，最大可以支持8EB的文件系统，而支持单个文件则达到8EB 能以接近裸设备I&#x2F;O的性能存储数据 swap：交换分区专用的文件系统 iso9660：光盘文件系统 btrfs（Oracle） reiserfs Windows 常用文件系统 FAT32：最多只能支持16TB的文件系统和4GB的文件 与多种操作系统兼容性好，如 Windows、Mac OS 和 Linux，适用于移动存储设备，适用于需要在不同操作系统间移动数据的用户 NTFS：最多只能支持16EB的文件系统和16EB的文件 支持大文件和大容量硬盘，拥有数据恢复、文件加密、磁盘配额等高级功能 exFAT Unix： FFS（fast） UFS（unix）：UFS是UNIX文件系统的简称，几乎是大部分UNIX类操作系统默认的基于磁盘的文件系统 JFS2 网络文件系统： 网络文件系统允许远程计算机通过网络访问和共享文件。这些文件系统通过网络协议（如 NFS、SMB&#x2F;CIFS 等）提供文件共享数据。 NFS CIFS 集群文件系统： GFS2：基于X86_64，最大文件系统可到100TB OCFS2（oracle） 分布式文件系统： fastdfs ceph：不仅仅是一个文件系统，还是一个有企业级功能的对象存储生态环境 moosefs mogilefs glusterfs Lustre RAW： 裸文件系统,未经处理或者未经格式化产生的文件系统 虚拟文件系统（Virtual File Systems）： 虚拟文件系统是 Linux 内核中的一种抽象层，用于管理文件系统的抽象概念，而不是物理存储。 它允许操作系统访问不同类型的文件系统，如本地文件系统、网络文件系统和特殊文件系统，以统一的方式。 procfs 文件系统（&#x2F;proc，用于访问进程和系统信息） sysfs 文件系统（&#x2F;sys，用于管理设备和内核参数） tmpfs 文件系统（用于临时文件系统）等。 特殊文件系统（Special File Systems）： 特殊文件系统用于提供对系统和硬件资源的访问，通常不存储文件数据，而是提供对系统信息的访问。 这些文件系统通常位于&#x2F;proc和&#x2F;sys目录下。 &#x2F;proc文件系统提供了有关正在运行的进程、系统信息和内核参数的信息。有时候面试会问你，&#x2F;proc 目录占用磁盘空间吗？显然是不占用的。 虚拟化文件系统（Virtualization File Systems）： 这些文件系统用于虚拟化环境中，例如虚拟机管理器（如 KVM、VirtualBox）中，它们允许虚拟机访问主机系统上的文件和资源。 9pfs（用于QEMU虚拟机） 日志文件系统（Logging File Systems）： 这些文件系统使用日志记录（journaling）来跟踪文件系统的变化，以提高数据一致性和恢复性。 ext3和ext4是常见的日志文件系统。 闪存文件系统（Flash File Systems）： 闪存文件系统专门设计用于闪存存储设备 SSD、USB 闪存驱动器和 SD 卡 F2FS 文件系统。 4 创建文件系统mkfs命令 123456789101112131415161718191 mkfs.FS_TYPE /dev/DEVICEFS_TYPE：ext4xfsbtrfsvfat2 mkfs -t FS_TYPE /dev/DEVICE-b #指定块 block 大小 (1024|2048|4096)-L LABEL #设置卷标-V|--verbose #显示创建过程-j #同 -t ext3-i N #为数据空间中每多少个字节创建一个inode；不应该小于block大小-N N #指定分区中创建多少个inode-I N #一个inode记录占用的磁盘空间大小，128---4096-m N #默认5%,为管理人员预留空间占总空间的百分比-O FEATURE[,...] #启用指定特性-O ^FEATURE #关闭指定特性 范例 12345678#主流mkfs.ext4mkfs.xfs#创建ext4 文件系统[root@ubuntu2204 ~]# mkfs.ext4 /dev/sdc1#创建xfs文件系统[root@ubuntu2204 ~]# mkfs.xfs /dev/sdc2 mke2fs：ext系列文件系统专用管理工具 123456789101112mke2fs [OPTION]... DEVICE-t #&#123;ext2|ext3|ext4|xfs&#125; 指定文件系统类型-b #&#123;1024|2048|4096&#125; 指定块 block 大小-L #‘LABEL’ 设置卷标-j #相当于 -t ext3， mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3-i # 为数据空间中每多少个字节创建一个inode；不应该小于block大小-N # 指定分区中创建多少个inode-I #一个inode记录占用的磁盘空间大小，128---4096-m # 默认5%,为管理人员预留空间占总空间的百分比-O FEATURE[,...] #启用指定特性-O ^FEATURE #关闭指定特性 5 管理文件系统5.1 e2label管理ext系列文件系统的LABEL 1e2label DEVICE [LABEL] 5.2 tune2fs重新设定ext系列文件系统可调整参数的值 1234567-l #查看指定文件系统超级块信息；super block-L &#x27;LABEL’ #修改卷标-m N #修预留给管理员的空间百分比-j #将ext2升级为ext3-O #文件系统属性启用或禁用, -O ^has_journal-o #调整文件系统的默认挂载选项，-o ^acl-U UUID #修改UUID号 范例 1[root@ubuntu2204 ~]# tune2fs -l /dev/sdc1 5.3 dumpe2fs显示ext文件系统信息，将磁盘块分组管理 1-h #查看超级块信息，不显示分组信息 超级块存放整个文件系统的数据，都有备份，万一文件系统被破坏了，利用超级块的备份块可以修复 范例 1234[root@ubuntu2204 ~]# dumpe2fs /dev/sdc1#查看超级块信息[root@ubuntu2204 ~]# dumpe2fs -h /dev/sdc1 5.4 xfs_info显示示挂载或已挂载的 xfs 文件系统信息 1xfs_info mountpoint|devname 范例 1[root@centos8 ~]#xfs_info /dev/sda7 6 xfs文件系统备份与恢复xfsdump备份工具： 完全备份：每一次都是对所有数据的备份 增量备份：和第一次备份进行比较，仅备份有差异的数据 xfsdump使用限制 必须用root权限 只能备份已挂载的文件系统 只能备份XFS文件系统 只能用xfsrestore解释 透过文件系统的UUID来分辨备份档，因此不能备份相同UUID的文件系统 xfsdump选项 123456-l：注意不是大写字母L而是小写，就是指定level，有0~9共10个等级，默认为0，即完整备份。-L：xfsdump会记录每次备份的session Label，这里可以填写针对此文件系统的简易说明；-M：xfsdump可以记录存储Media Label，这里可以填写此媒体的简易说明。-f：后面接产生的文件和destination file 。例如/dev/st0设备文件名或其他一般文件文件名-I：大写的“i”，从/var/lib/xfsdump/inventory 列出目前备份的信息状态。 xfsdump备份和xfsrestore恢复 12345678910111213141516171819# 1、数据备份# 1.1 先做全量备份，切记“备份的源路径”末尾不要加左斜杠/注意：（1）-L与-M后的你起的名字保持一致就行，也方便你记忆（2）备份的源路径写/dev/sda1这种文件系统名字是通用写法，虽然在centos7.9中写挂载点路径虽然也可以，但是还是推荐用通用的靠谱一些xfsdump -l 0 -L sdb3_bak -M sdb3_bak -f 全量备份的成果路径1 备份的源路径 # 1.2 再做增量备份xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径2 备份的源路径 xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径3 备份的源路径 xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径4 备份的源路径 # 2、数据恢复# 2.1、先恢复全量备份xfsrestore -f 全量备份的成果路径1 数据恢复的路径# 2.2、再依次恢复增量xfsrestore -f 增量备份的成果路径2 数据恢复的路径xfsrestore -f 增量备份的成果路径2 数据恢复的路径xfsrestore -f 增量备份的成果路径2 数据恢复的路径 数据备份示例 12345678910111213141516171819202122232425262728293031323334353637383940# 1、准备一个分区并制作好xfs文件系统，挂载好后给它加一点初始数据[root@localhost ~]# df文件系统 1K-块 已用 可用 已用% 挂载点。。。。。。/dev/sdb3 1038336 76836 961500 8% /opt[root@localhost ~]# cp -r /etc/ /opt/[root@localhost ~]# echo 111 &gt; /opt/1.txt[root@localhost ~]# ls /opt/1.txt etc[root@localhost ~]# # 2、先做全量备份[root@localhost ~]# xfsdump -l 0 -L sdb3_bak -M sdb3_bak -f /all.bak /opt # 3、往/opt下新增文件2.txt，然后作增量备份[root@localhost ~]# echo 222 &gt; /opt/2.txt[root@localhost ~]# xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f /add.bak1 /opt # 4、往/opt下新增文件3.txt，然后作增量备份[root@localhost ~]# echo 333 &gt; /opt/3.txt[root@localhost ~]# xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f /add.bak2 /opt 注意上面你备份的都是挂载点/opt,对应文件系统/dev/sdb3，这个在centos7.9中还可用，但是到了rockylinux9.3中会报错：xfsdump: version 3.1.12 (dump format 3.0) - type ^C for status and controlxfsdump: ERROR: /mydata/ does not identify a file systemxfsdump: usage: xfsdump [ -a (dump DMF dualstate files as offline) ]解决办法就是把挂载点/opt换成/dev/sdb3如：xfsdump -l 0 -L sdb3_bak -M sdb3_bak -f /all.bak /dev/sdb3 # 5、查看一下备份文件大小[root@localhost ~]# du -sh /opt/41M /opt/ [root@localhost ~]# ll -h /all.bak # 全量备份大小-rw-r--r--. 1 root root 37M 11月 4 18:44 /all.bak[root@localhost ~]# ll -h /add.bak1 # 增量备份大小-rw-r--r--. 1 root root 22K 11月 4 18:45 /add.bak1[root@localhost ~]# ll -h /add.bak2 # 增量备份大小-rw-r--r--. 1 root root 23K 11月 4 18:46 /add.bak2 数据恢复示例 1234567891011[root@localhost ~]# rm -rf /opt/*[root@localhost ~]# xfsrestore -f /all.bak /opt/ # 先恢复全量......[root@localhost ~]# ls /opt/1.txt etc[root@localhost ~]# xfsrestore -f /add.bak1 /opt/ # 再恢复增量1[root@localhost ~]# ls /opt/1.txt 2.txt etc[root@localhost ~]# xfsrestore -f /add.bak2 /opt/ # 再恢复增量2[root@localhost ~]# ls /opt/1.txt 2.txt 3.txt etc 7 挂载Linux 系统中“一切皆文件”，所有文件都放置在以根目录为树根的树形目录结构中。在Linux 看来，任何硬件设备也都是文件，它们各有自己的一套文件系统 (文件目录结构)。 因此产生的问题是，当在 Linux 系统中使用这些硬件设备时，只有将Linux本身的文件目录与硬件设备的文件目录合二为一，硬件设备才能为我们所用。合二为一的过程称为“挂载”，如果不挂载，通过Linux系统中的图形界面系统可以查看找到硬件设备，但命令行方式无法找到。 挂载：将磁盘挂载到某一个目录下(最好是空目录)，这个目录下的文件就会存储在这个磁盘中，所挂载的目录称为挂载点 卸载：为解除此关联关系的过程 7.1 挂载文件系统格式 1mount [-fnrsvw] [-t vfstype] [-o options] device mountpoint device：指明要挂载的设备 设备文件：例如:&#x2F;dev&#x2F;sda5 卷标：-L ‘LABEL’, 例如 -L ‘MYDATA’ UUID： -U ‘UUID’：例如 -U ‘0c50523c-43f1-45e7-85c0-a126711d406e’ 伪文件系统名称：proc, sysfs, devtmpfs, configfs mountpoint：挂载点目录必须事先存在，建议使用空目录 mount 常用命令选项 123456789101112131415161718192021222324252627282930313233343536-t fstype #指定要挂载的设备上的文件系统类型,如:ext4,xfs-r #readonly，只读挂载-w #read and write, 读写挂载,此为默认设置,可省略-n #不更新/etc/mtab，mount不可见-a #自动挂载所有支持自动挂载的设备(定义在了/etc/fstab文件中，且挂载选项中有auto功能)-L &#x27;LABEL&#x27; #以卷标指定挂载设备-U &#x27;UUID&#x27; #以UUID指定要挂载的设备-B #绑定目录到另一个目录上--source device 指明源(路径、标签、uuid) -L #同 LABEL=label -U #同 UUID=uuid LABEL=label #用label值指定设备 UUID=uuid #用uuid值指定设备 PARTLABEL=label #按PARTLABEL值指定设备 PARTUUID=uuid #按PARTUUID值指定设备 device #按路径指定设备 directory #绑定式挂载的挂载点(参阅 --bind/rbind) file #用于设置回环设备的常规文件 -o options：(挂载文件系统的选项)，多个选项使用逗号分隔 async #异步模式,内存更改时,写入缓存区buffer,过一段时间再写到磁盘中，效率高，但不安全 sync #同步模式,内存更改时，同时写磁盘，安全，但效率低下 atime/noatime #包含目录和文件 diratime/nodiratime #目录的访问时间戳 auto/noauto #是否支持开机自动挂载，是否支持-a选项 exec/noexec #是否支持将文件系统上运行应用程序 dev/nodev #是否支持在此文件系统上使用设备文件 suid/nosuid #是否支持suid和sgid权限 remount #重新挂载 ro/rw #只读、读写 user/nouser #是否允许普通用户挂载此设备，/etc/fstab使用 acl/noacl #启用此文件系统上的acl功能 loop #使用loop设备 _netdev #当网络可用时才对网络资源进行挂载，如：NFS文件系统 defaults #相当于rw, suid, dev, exec, auto, nouser, async 挂载规则 一个挂载点同一时间只能挂载一个设备 一个挂载点同一时间挂载了多个设备，只能看到最后一个设备的数据，其它设备上的数据将被隐藏 一个设备可以同时挂载到多个挂载点 通常挂载点一般是已存在空的目录 范例 123#只读挂载[root@ubuntu2204 ~]# mount --source /dev/sdc2 -o ro /sdc2mount /dev/sdb1 /opt/ 往目录&#x2F;opt下新建的文件存到了哪里？ 存到了 /dev/sdb1磁盘分区下 卸载&#x2F;opt后，数据是否存在？ 存在，因为数据已经存到了磁盘，重新挂载还是可以看到数据 重新格式化&#x2F;dev&#x2F;sdb1后，数据是否依然存在？ 不存在了 同一个分区&#x2F;文件系统挂载到不同的文件夹下，数据的来源是否一致？ 一致，因为他们的数据都是会存在同一个磁盘中，可以共享里面的数据 sdb1挂载到 &#x2F;，sdb2挂载到 &#x2F;opt，那么sdb1可以存储 &#x2F;opt 下的数据吗？ 不可以，虽然opt是在 &#x2F; 下，但是 &#x2F;opt 已经挂载到sdb2上了，那么sdb2就是它存储数据的硬盘，如果说 &#x2F;opt 没有被挂载到哪个硬盘上，那么数据就会存储在sdb1上 7.2 卸载文件系统卸载时：可使用设备，也可以使用挂载点 1umount 设备名|挂载点 7.3 查看挂载情况查看挂载 123456#通过查看/etc/mtab文件显示当前已挂载的所有设备mount#查看内核追踪到的已挂载的所有设备cat /proc/mounts#通过查看/etc/mtab文件显示当前已挂载的所有设备cat /etc/mtab 查看挂载点情况 1findmnt MOUNT_POINT|device 范例 1234567#默认查看整个系统挂载树[root@ubuntu2204 ~]# findmnt......#查看指定设备或挂载点[root@ubuntu2204 ~]# findmnt /dev/sdc1TARGET SOURCE FSTYPE OPTIONS/sdc1 /dev/sdc1 ext4 rw,relatime 查看正在访问指定文件系统的进程 12lsof MOUNT_POINTfuser -v MOUNT_POINT 终止所有在正访问指定文件系统的进程 1fuser -km MOUNT_POINT 7.4 持久挂载开机自动挂载两种方式 将挂载命令写入/etc/rc.local中，注意这是个软链接，需要给源文件加x执行权限 在/etc/fstab按照格式写入信息，UUID可以通过blkid命令查看 当写入文件的内容不小心写错的时候，导致重启开机失败，我们先在VM里以故障状态登陆root，然后打开 &#x2F;etc&#x2F;fstab，将有错误的更改或者注释，就可以了 每行定义一个要挂载的文件系统,，其中包括共 6 项 1234567891011[root@rocky8 ~]#cat /etc/fstab /dev/mapper/rl-root / xfs defaults 0 0UUID=a1564c83-06da-4ee2-9442-409727529931 /boot xfs defaults 0 0/dev/mapper/rl-swap none swap defaults 0 0第一项： 设备的标识 (LABEL=label | UUID=uuid | /dev/sda1)第二项： mountpoint ，必须是事先存在的目录第三项： 文件系统 ext4 ,iso9660第四项: 挂载选项，defaults ，acl，bind，ro，rw 等第五项： 备份频率 0 不做备份; 1 每天转储; 2 每隔一天转储第六项; fsck检查的文件系统的顺序：0 不自检 ; 1 首先自检，一般只有rootfs才用；2 非rootfs使用 添加新的挂载项，需要执行下面命令生效，此命令只针对文件新增行或删除行有效，如果在中间修改了挂载选项，则此命令无效 1mount -a 范例：centos7, 8 &#x2F;etc&#x2F;fstab 的分区UUID错误，无法启动 1234不需要其他操作，自动进入emergency mode,系统提示输入root 密码#cat /proc/mounts 可以查看到/ 以rw方式挂载#vim /etc/fstab#reboot 范例：centos 6 &#x2F;etc&#x2F;fstab 的分区UUID错误，无法启动 123456如果/etc/fstab 的挂载设备出错，比如文件系统故障，并且文件系统检测项（即第6项为非0），将导致无法启动自动进入emergency mode,输入root 密码#cat /proc/mounts 可以查看到/ 以ro方式挂载，无法直接修改配置文件#mount -o remount,rw /#vim /etc/fstab将故障行的最后1项，即第6项修改为0，开机不检测此项挂载设备的健康性，从而忽略错误，能实现启动 7.5 重新挂载修改了&#x2F;etc&#x2F;fstab 文件中的挂载规则，无法通过 mount -a 生效，要执行执行挂载 1mount -o remount MOUNTPOINT","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://aquapluto.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"磁盘分区","slug":"Linux/disk-manage/disk-partition","date":"2025-08-21T02:59:41.000Z","updated":"2025-08-28T12:33:05.197Z","comments":true,"path":"Linux/disk-manage/disk-partition/","permalink":"https://aquapluto.github.io/Linux/disk-manage/disk-partition/","excerpt":"","text":"1 linux中的磁盘1.1 设备文件Linux 哲学思想：一切皆文件。对于硬件设备，在Linux系统中，也是以文件的形式呈现出来的 /sys 文件是系统是和 /proc 一样，是一个内存文件系统 ，在磁盘上并没有对应的内容。通常称其为sysfs，这是内核 “暴露” 给用户空间的一个 驱动模型层次结构的展现。因此，host0, host1 这些 “文件”是内核根据设备驱动程序 “发现” 的设备后在内存中创建的对应的 “文件” 和 “文件层次”。 设备文件：关联至一个设备驱动程序，进而能够跟与之对应硬件设备进行通信 1234567#设备文件[root@ubuntu2204 ~]# ll /dev/sdabrw-rw---- 1 root disk 8, 0 Jul 29 08:51 /dev/sda#设备文件[root@ubuntu2204 ~]# ll /dev/tty0crw--w---- 1 root tty 4, 0 Jul 29 08:51 /dev/tty0 设备号码： 主设备号：major number, 标识设备类型 次设备号：minor number, 标识同一类型下的不同设备 设备类型： 块设备：block，存取单位“块”，磁盘 字符设备：char，存取单位“字符”，键盘 磁盘设备的设备文件命名 设备类型 设备文件命名 SAS,SATA,SCSI,IDE,USB &#x2F;dev&#x2F;sda; &#x2F;dev&#x2F;sdb; &#x2F;dev&#x2F;sdc; …… nvme协议硬盘 &#x2F;dev&#x2F;nvme0n1; &#x2F;dev&#x2F;nvme0n2; &#x2F;dev&#x2F;nvme0n3; …… 虚拟磁盘 &#x2F;dev&#x2F;vda; &#x2F;dev&#x2F;vdb; &#x2F;dev&#x2F;xvda; &#x2F;dev&#x2F;xvdb; …… 逻辑卷，从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略 &#x2F;dev&#x2F;dm-0;&#x2F;dev&#x2F;dm-1;…… RAID设备 &#x2F;dev&#x2F;md0;&#x2F;dev&#x2F;md1;…… 块设备 &#x2F;dev&#x2F;loop1;&#x2F;dev&#x2F;loop2;…… 不同磁盘标识：a-z,aa,ab… 1/dev/sda，/dev/sdb, ... 同一设备上的不同分区：1,2, … 12/dev/sda1/dev/sda5 范例 12345[root@Rocky ~]#ll /dev/nvme0*crw------- 1 root root 243, 0 8月 20 11:50 /dev/nvme0brw-rw---- 1 root disk 259, 0 8月 20 11:50 /dev/nvme0n1brw-rw---- 1 root disk 259, 1 8月 20 11:50 /dev/nvme0n1p1brw-rw---- 1 root disk 259, 2 8月 20 11:50 /dev/nvme0n1p2 1.2 磁盘操作范例：查看CHS 1234567891011121314151617181920212223242526#rocky8.6默认只有扇区信息，ubuntu2204同样[root@rocky8 ~]#fdisk -l /dev/sdaDisk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x43a6eadaDevice Boot Start End Sectors Size Id Type/dev/sda1 * 2048 2099199 2097152 1G 83 Linux/dev/sda2 2099200 41943039 39843840 19G 8e Linux LVM#加参数后可显示更详细信息[root@rocky8 ~]#fdisk -u=cylinder -l /dev/sdaDisk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectorsGeometry: 255 heads, 2 sectors/track, 2610 cylindersUnits: cylinders of 510 * 512 = 261120 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x43a6eadaDevice Boot Start End Cylinders Size Id Type/dev/sda1 * 5 4117 4113 1G 83 Linux/dev/sda2 4117 82242 78126 19G 8e Linux LVM 范例：识别SSD和机械硬盘类型 123456789101112131415161718192021222324#1表示机械，0表示SSD[root@centos8 ~]#lsblk -d -o name,rotaNAME ROTAsda 1sr0 1nvme0n1 0nvme0n2 0[root@centos8 ~]#ls /sys/block/nvme0n1 nvme0n2 sda sr0[root@centos8 ~]#cat /sys/block/*/queue/rotational0011[root@centos8 ~]#cat /sys/block/sda/queue/rotational1[root@centos8 ~]#cat /sys/block/sr0/queue/rotational1[root@centos8 ~]#cat /sys/block/nvme0n1/queue/rotational0[root@centos8 ~]#cat /sys/block/nvme0n2/queue/rotational0 范例: 测速 123[root@ubuntu1804 ~]#dd | hdparm -t /dev/sda/dev/sda:Timing buffered disk reads: 1854 MB in 3.00 seconds = 617.80 MB/sec 自动检测新的硬盘 123echo &#x27;- - -&#x27; &gt; /sys/class/scsi_host/hostx/scanfor i in /sys/class/scsi_host/host*/scan;do echo &#x27;- - -&#x27; &gt; $i;done ubuntu 自动检测新的硬盘 12345678910#两种写法1 循环遍历[root@ubuntu2204 ~]# for i in `ls /sys/class/scsi_host/`;do echo &#x27;- - -&#x27; &gt;/sys/class/scsi_host/$i/scan;done2 找出SPI总线对应的 host，只扫描该 host[root@ubuntu2204 ~]# grep mptspi /sys/class/scsi_host/host*/proc_name/sys/class/scsi_host/host32/proc_name:mptspi[root@ubuntu2204 ~]# echo &#x27;- - -&#x27; &gt; /sys/class/scsi_host/host32/scan#此处是重新扫描 SCSI 总线来添加设备，之所以是 SCSI 总线，是因为我们添加的 SCSI 类型的硬盘 2 磁盘分区2.1 为什么分区 优化I&#x2F;O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不同文件系统 2.2 分区类型分区主要分为三类：主分区&lt;— 扩展分区&lt;— 逻辑分区 逻辑分区属于扩展分区，扩展分区属于主分区 主分区又叫做引导分区，是可以安装系统的分区 2.3 分区格式2.3.1 MBR分区MBR 分区，MBR 的意思是 “主引导记录”。MBR 最大支持 2TB 容量，在容量方面存在着极大的瓶颈。并且只支持创建最多4个主分区，也可以3主分区+1扩展(N个逻辑分区)。而GPT分区方式就没有这些限制 划分分区的单位： CentOS 5 之前按整柱面划分 CentOS 6 版本后可以按Sector划分 0磁道0扇区：512bytes 446字节存放计算机启动的程序 64字节存放划分分区的信息，每个分区占16字节 2字节 55AA 标识位 硬盘主引导记录MBR由4个部分组成 主引导程序（偏移地址0000H–0088H），它负责从活动分区中装载，并运行系统引导程序 出错信息数据区，偏移地址0089H–00E1H为出错信息，00E2H–01BDH全为0字节 分区表（DPT,Disk Partition Table）含4个分区项，偏移地址01BEH–01FDH,每个分区表项长16个字节，共64字节为分区项1、分区项2、分区项3、分区项4 结束标志字，偏移地址01FE–01FF的2个字节值为结束标志55AA 为什么不能超过4个主分区？ 因为在0磁道0扇区上只留了64bytes空间存储分区表信息，而一个分区的关键信息要占用16个字节来存放 为什么单分区不能超2T？ 一个分区信息占用16个字节，其中记录分区开始位置的空间为4个字节，记录分区结束位置的空间也是4个字节； 一个字节8位，4个字节是32位，则起始位最小值为32个0，结束位最大值为32个1， 所以一个分区，最大就是2的32次方个扇区，一个扇区512字节，则最大空间是 232*29 &#x3D; 241 字节； 240是T，那么241表示不超过2T 范例：二进制查看扇区情况 1hexdump -C -n 512 /dev/sda 范例：备份MBR的分区表,并破坏后恢复 123456789101112131415161718192021222324252627#备份MBR分区表[root@centos8 ~]#dd if=/dev/sda of=/data/dpt.img bs=1 count=64 skip=446bs=1：块大小1个字节 count=64：备份64字节 skip=446：不要前面446字节，取后面的64字节/dev/sda：使用lsblk查看当前虚拟机的硬盘名称/data/dpt.img：备份到的文件[root@centos8 ~]#hexdump -C /data/dpt.img[root@centos8 ~]#scp /data/dpt.img 10.0.0.102:#破坏MBR分区表[root@centos8 ~]#dd if=/dev/zero of=/dev/sda bs=1 count=64 seek=446#无法启动[root@centos8 ~]#reboot#进入虚拟机，手速要快按下ESC键进入一个选择界面，选择CD-ROM Drive,进入Linux安装光盘界面，选择Troubleshooting，选择第2项rescue，选第1项continue，回车继续，配置网络，将之前备份到远程主机的文件拷贝过来#配置网络ifconfig ens160 10.0.0.8/24ip a a 10.0.0.8/24 dev ens160#传送文件scp 10.0.0.102:/root/dpt.img .#恢复MBR分区表dd if=dpt.img of=/dev/sda bs=1 count=64 seek=446reboot 问题：如何利用分区策略相同的另一台主机的分区表来还原和恢复当前主机破环的分区表？ 123456789# 在正常主机上备份分区表，使用 sfdisk 导出分区表sudo sfdisk -d /dev/sdX &gt; partition_table.sfdisk# 将分区表传输到目标主机scp partition_table.sfdisk user@target_host:/path/to/destination/# 在目标主机上恢复分区表sudo sfdisk --verify /dev/sdX &lt; partition_table.sfdisksudo sfdisk /dev/sdX &lt; partition_table.sfdisk 2.3.2 GPT分区GPT 分区（ubuntu装系统默认就是GPT分区），GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。 GPT：GUID（Globals Unique Identifiers） partition table 支持128个分区，当数据较大时可以使用GPT分区，使用64位，支持8Z（ 512Byte&#x2F;block ）64Z （ 4096Byte&#x2F;block） 使用128位UUID(Universally Unique Identifier) 表示磁盘和分区，GPT分区表自动备份在头和尾两份， 并有CRC校验位，自动备份 UEFI (Unified Extensible Firmware Interface 统一可扩展固件接口)硬件支持GPT，使得操作系统可以启动 2.4 管理分区2.4.1 parted 命令高级分区操作，可以是交互或非交互方式 注意：parted的操作都是实时生效的，小心使用 格式 123456789101112131415161718192021222324parted [选项]... [设备 [命令 [参数]...]...]#常用选项-l|--list #显示所有硬盘分区信息 -s|--script #不输出提示信息 #常用子命令align-check TYPE N #检查分区是否满足对齐(最小|最佳)类型的对齐方式help [COMMAND] #显示命令帮助mklabel|mktable LABEL-TYPE #指定磁盘的分区类型 gpt|msdos(mbr)mkpart PART-TYPE [FS-TYPE] START END #新建分区,指定分区类型，文件系统，开始结束位置name NUMBER NAME #重命名指定分区print [devices|free|list,all|NUMBER] #显示quit #退出rescue START END #空间碎片整理resizepart NUMBER END #重置分区大小rm NUMBER #删除指定分区select DEVICE #选择设备disk_set FLAG STATE #为设备打标签disk_toggle [FLAG] #修改flagset NUMBER FLAG STATE #设置flagtoggle [NUMBER [FLAG]] #修改flagunit UNIT #设置默认单位, 默认为MB，B|KB|MB|GB|TBversion #显示版本 范例 12345parted /dev/sdb mklabel gpt|msdos #选择使用GPT还是MBR分区parted /dev/sdb print #打印分区表情况parted /dev/sdb mkpart primary 1 200（默认M） #指定从第一个分区到第200个分区进行创建主分区parted /dev/sdb rm 1 #删除分区（1是硬盘编号）parted -l #列出所有硬盘分区信息 范例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101[root@centos8 ~]#parted /dev/sdb printError: /dev/sdb: unrecognised disk labelModel: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: unknownDisk Flags:[root@centos8 ~]#parted /dev/sdb mklabel gptInformation: You may need to update /etc/fstab.[root@centos8 ~]#parted /dev/sdb printModel: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags[root@centos8 ~]#parted /dev/sdb mkpart primary 1 1001Information: You may need to update /etc/fstab.[root@centos8 ~]#parted /dev/sdb printModel: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags1 1049kB 1001MB 1000MB primary[root@centos8 ~]#parted /dev/sdb mkpart primary 1002 1102Information: You may need to update /etc/fstab.[root@centos8 ~]#parted /dev/sdb printModel: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags1 1049kB 1001MB 1000MB primary2 1002MB 1102MB 99.6MB primary[root@centos8 ~]#parted /dev/sdb rm 2Information: You may need to update /etc/fstab.[root@centos8 ~]#parted /dev/sdb print Model: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags1 1049kB 1001MB 1000MB primary[root@centos8 ~]#parted /dev/sdb mklabel msdosWarning: The existing disk label on /dev/sdb will be destroyed and all data onthis disk will be lost. Do you want to continue?Yes/No? YInformation: You may need to update /etc/fstab.[root@centos8 ~]#parted /dev/sdb print Model: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosDisk Flags:Number Start End Size Type File system Flags[root@centos8 ~]#parted /dev/sdb #交互式操作GNU Parted 3.2Using /dev/sdbWelcome to GNU Parted! Type &#x27;help&#x27; to view a list of commands.(parted) helpalign-check TYPE N check partition N for TYPE(min|opt)alignmenthelp [COMMAND] print general help, or help onCOMMANDmklabel,mktable LABEL-TYPE create a new disklabel (partitiontable)mkpart PART-TYPE [FS-TYPE] START END make a partitionname NUMBER NAME name partition NUMBER as NAMEprint [devices|free|list,all|NUMBER] display the partition table,available devices, free space, all found partitions, or a particular partitionquit exit programrescue START END rescue a lost partition near STARTand ENDresizepart NUMBER END resize partition NUMBER rm NUMBER delete partition NUMBERselect DEVICE choose the device to editdisk_set FLAG STATE change the FLAG on selected devicedisk_toggle [FLAG] toggle the state of FLAG on selecteddevice set NUMBER FLAG STATE change the FLAG on partition NUMBERtoggle [NUMBER [FLAG]] toggle the state of FLAG on partitionNUMBERunit UNIT set the default unit to UNITversion display the version number andcopyright information of GNU Parted(parted) 2.4.2 分区工具fdisk和gdisk格式 123fdisk -l [-u] [device...] #查看分区fdisk [device...] #管理MBR分区gdisk [device...] #类fdisk 的管理GPT分区工具 选项 1234567891011-b|--sector-size &lt;size&gt; #指定扇区大小，默认512字节-L|--color[=color] #显示时是否添加颜色(auto|always|never)默认启用颜色-l|--list #显示-o|--output &lt;list&gt; #只显示指定列-u|--units[=&lt;unit&gt;] #设置显示单位 cylinders|sectors，默认sectors-s|--getsz #显示设备有多少个扇区-b|--bytes N #以指定的字节大小来计算扇区数量-t|--type type #只显示指定类型的分区表-C|--cylinders N #指定柱面数-H|--heads N #指定磁头数-S|--sectors N #指定每条磁道的扇区数 子命令 123456789101112131415161718192021222324252627fdiskp #分区列表t #更改分区类型n #创建新分区d #删除分区v #校验分区u #转换单位w #保存并退出q #不保存并退出x #高级功能(专家模式)gdiskb #备份分区表到指定文件c #修改分区名d #删除分区i #显示分区详细信息l #列出所有分区类型n #新建分区o #创建新的分区表p #查看分区q #退出r #恢复和转换选项，非专业人士勿用s #排序t #修改分区类型，默认 8300,表示普通分区v #检测硬盘是否有问题w #保存退出x #额外功能，专家模式 CentOS 7,8 同步分区表 1partprobe CentOS6 通知内核重新读取硬盘分区表 12345678910111213#新增分区用partx -a /dev/DEVICEkpartx -a /dev/DEVICE -f: force#示例：[root@centos6 ~]#partx -a /dev/sda#删除分区用partx -d --nr M-N /dev/DEVICE #M，N表示分区数#示例：[root@centos6 ~]#partx -d --nr 6-8 /dev/sda#同步分区表[root@centos6 ~]#partx -a /dev/sda 范例:非交互式创建分区 1echo -e &#x27;n\\np\\n\\n\\n+2G\\nw\\n&#x27; | fdisk /dev/sdc 范例: 批量创建分区 1234567[root@centos8 ~]#echo -e &#x27;n\\np\\n\\n\\n+1G\\nw&#x27; | fdisk /dev/sdb[root@centos8 ~]#fdisk /dev/sdb &lt;&lt;EOFnp+1GwEOF 范例 12345#显示指定列fdisk -lo id,size,type /dev/sda#查看内核是否已经识别新的分区cat /proc/partitions 范例 123456789101112131415161718192021222324[root@centos7 ~]#fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0x057e0640.Command (m for help): n #输入子命令Partition type: p primary (0 primary, 0 extended, 4 free) #选择主分区 e extended #选择扩展分区Select (default p): Partition number (1-4, default 1): #选择分区编号First sector (2048-41943039, default 2048): #选择开始扇区位置，2048表示起始位置是2MLast sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): #选择大小Command (m for help): w #w保存The partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 范例：硬盘分区问题 123456789101112131415161718192021222324252627282930313233#看出磁盘的第二个分区的起始位置为1026048，计算：1026048*512=525M（因为512个字节一个扇区），结束位置为1599M，1599-525=1074，相当于分了1G空间[root@centos7 ~]#fdisk -l /dev/sdbDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x166a0e04 Device Boot Start End Blocks Id System/dev/sdb2 1026048 3123199 1048576 83 Linux#现在想要在第一个分区分5G的容量[root@centos7 ~]#fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): pPartition number (1,3,4, default 1): 1First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-1026047, default 1026047): +5GValue out of range. #失败了#失败的原因是在一个磁盘空间里，之间在525M到1599M的区间分了一个分区，在第一个分区分的起始位置只能是2048(2M)，而2M到525M的区间不足5G，因为分区必须是连续空间，不能是东凑一块西凑一块，要分5G空间就只能是在起始位置1599(3123199)开始分第三个分区 范例：修改分区类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869[root@centos7 ~]#fdisk -l /dev/sdbDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x166a0e04 Device Boot Start End Blocks Id System/dev/sdb1 2048 1026047 512000 83 Linux #现在是83/dev/sdb2 1026048 3123199 1048576 83 Linux [root@centos7 ~]#fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): t #更改分区类型Partition number (1,2, default 2): 1 #选择分区编号Hex code (type L to list all codes): L #列出所有分区类型 0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden C: c6 DRDOS/sec (FAT- 4 FAT16 &lt;32M 40 Venix 80286 85 Linux extended c7 Syrinx 5 Extended 41 PPC PReP Boot 86 NTFS volume set da Non-FS data 6 FAT16 42 SFS 87 NTFS volume set db CP/M / CTOS / . 7 HPFS/NTFS/exFAT 4d QNX4.x 88 Linux plaintext de Dell Utility 8 AIX 4e QNX4.x 2nd part 8e Linux LVM df BootIt 9 AIX bootable 4f QNX4.x 3rd part 93 Amoeba e1 DOS access a OS/2 Boot Manag 50 OnTrack DM 94 Amoeba BBT e3 DOS R/O b W95 FAT32 51 OnTrack DM6 Aux 9f BSD/OS e4 SpeedStor c W95 FAT32 (LBA) 52 CP/M a0 IBM Thinkpad hi eb BeOS fs e W95 FAT16 (LBA) 53 OnTrack DM6 Aux a5 FreeBSD ee GPT f W95 Ext&#x27;d (LBA) 54 OnTrackDM6 a6 OpenBSD ef EFI (FAT-12/16/10 OPUS 55 EZ-Drive a7 NeXTSTEP f0 Linux/PA-RISC b11 Hidden FAT12 56 Golden Bow a8 Darwin UFS f1 SpeedStor 12 Compaq diagnost 5c Priam Edisk a9 NetBSD f4 SpeedStor 14 Hidden FAT16 &lt;3 61 SpeedStor ab Darwin boot f2 DOS secondary 16 Hidden FAT16 63 GNU HURD or Sys af HFS / HFS+ fb VMware VMFS 17 Hidden HPFS/NTF 64 Novell Netware b7 BSDI fs fc VMware VMKCORE 18 AST SmartSleep 65 Novell Netware b8 BSDI swap fd Linux raid auto1b Hidden W95 FAT3 70 DiskSecure Mult bb Boot Wizard hid fe LANstep 1c Hidden W95 FAT3 75 PC/IX be Solaris boot ff BBT 1e Hidden W95 FAT1 80 Old Minix Hex code (type L to list all codes): 8e #选择分区类型编号Changed type of partition &#x27;Linux&#x27; to &#x27;Linux LVM&#x27;Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[root@centos7 ~]#fdisk -l /dev/sdbDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x166a0e04 Device Boot Start End Blocks Id System/dev/sdb1 2048 1026047 512000 8e Linux LVM #改成8e（逻辑卷）/dev/sdb2 1026048 3123199 1048576 83 Linux 学习问题：就是这个sda2挂载了&#x2F;boot，sda3那个lvm挂载了&#x2F;，疑问就是&#x2F;boot所占的空间，会影响到&#x2F;的空间吗，因为boot也是在&#x2F;下的 解答：&#x2F;boot是单独分出来的sda2，跟sda3没关系，不会互相影响。 12345678910[root@ubuntu2004 ~]#df -hFilesystem Size Used Avail Use% Mounted onudev 1.9G 0 1.9G 0% /devtmpfs 389M 1.6M 388M 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 18G 2.8G 15G 17% /tmpfs 1.9G 4.0K 1.9G 1% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda2 1.5G 209M 1.2G 16% /boottmpfs 389M 0 389M 0% /run/user/0 2.4.3 lsblk格式 123456789101112131415161718192021222324252627282930#常用选项-a|--all #输出所有设备信息-b|--bytes #以字节为单位显示设备大小-d|--nodeps #不显示分区信息-e|--exclude &lt;list&gt; #以主设备号排除设备-f|--fs #显示文件系统-i|--ascii #只使用 ascii 字符输出-I|--include &lt;list&gt; #仅显示指定的设备-J|--json #以json格式显示输出-l|--list #以列表显示-T|--tree #以树状结构显示，默认项-m|--perms #显示属主属组及权限-n|--noheadings #不显示表头-o|--output &lt;list&gt; #只显示指定列-O|--output-all #显示所有列-p|--paths #显示设备全路径-P|--pairs #以 k=&gt;v 的格式显示输出-r|--raw #原样输出-s|--inverse #反向显示关联信息-S|--scsi #显示scsi设备(small computer system interface device,小型计算机接口设备)-t|--topology #显示拓扑信息#-o常用字段NAME #设备名称MAJ:MIN #主设备号:次设备号RM #是否是可移动设备SIZE #设备容量大小RO #是否是只读设备TYPE #设备类型MOUNTPOINT #挂载点 范例 123456#查看指定设备[root@ubuntu2204 ~]# lsblk -f /dev/sdc#查看所有设备[root@rocky86 ~]# lsblk -f#查看指定列[root@ubuntu2004 ~]#lsblk -d -o NAME,SIZE 2.4.4 blkid可以查看块设备属性信息 格式 1234blkid [OPTION]... [DEVICE]-U UUID #根据指定的UUID来查找对应的设备-L LABEL #根据指定的LABEL来查找对应的设备 范例 1234567891011121314151617#显示所有[root@ubuntu2004 ~]#blkid/dev/sr0: UUID=&quot;2022-02-23-09-27-00-00&quot; LABEL=&quot;Ubuntu-Server 20.04.4 LTS amd64&quot; TYPE=&quot;iso9660&quot; PTUUID=&quot;492bdcc4&quot; PTTYPE=&quot;dos&quot;/dev/sda2: UUID=&quot;04c587f7-1f97-4632-970a-0dd3e08fb398&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;118bc546-3a2d-4411-9c74-25f5a37bdbf3&quot;/dev/sda3: UUID=&quot;8LrQLS-6cfS-HTCn-w7Vo-flx7-90dy-qDukq7&quot; TYPE=&quot;LVM2_member&quot; PARTUUID=&quot;b07f78ba-02aa-4575-ae26-7c97b4a43b73&quot;/dev/mapper/ubuntu--vg-ubuntu--lv: UUID=&quot;8ef803b3-d204-4c23-b2e7-1a5ba91ea557&quot; TYPE=&quot;ext4&quot;/dev/loop1: TYPE=&quot;squashfs&quot;/dev/loop2: TYPE=&quot;squashfs&quot;/dev/loop3: TYPE=&quot;squashfs&quot;/dev/loop4: TYPE=&quot;squashfs&quot;/dev/loop5: TYPE=&quot;squashfs&quot;/dev/loop6: TYPE=&quot;squashfs&quot;/dev/sda1: PARTUUID=&quot;b96ee049-d3f9-49d0-a7dd-10cdd163f152&quot;#查询[root@ubuntu2004 ~]#blkid -U &quot;04c587f7-1f97-4632-970a-0dd3e08fb398&quot;/dev/sda2 PARTUUID是分区的唯一标识符，而UUID是文件系统的唯一标识符。以下是它们的具体解释： PARTUUID（Partition UUID）：是针对GPT（GUID Partition Table）分区方案的分区表级别的唯一标识符。它是在创建分区时生成的，并且即使对分区进行重新格式化或更改文件系统类型，该标识符仍然保持不变。因为PARTUUID是从分区表中直接检索得到的，所以它可以访问分区而不依赖于分区内的文件系统内容。 UUID（Universally Unique Identifier）：通常是指文件系统级别的唯一标识符。它用于唯一识别一个特定的文件系统实例，比如一个ext4或NTFS分区。当文件系统被创建（例如，通过格式化操作）时，会生成一个UUID，并存储在文件系统的元数据中。如果文件系统被删除或重新格式化，UUID会改变。 简而言之，PARTUUID与分区结构相关联，而UUID与分区内的文件系统相关联。 2.4.5 findfs查找分区 12findfs [options] LABEL=&lt;label&gt;findfs [options] UUID=&lt;uuid&gt; 范例 123456[root@centos8 ~]#findfs UUID=f7f53add-b184-4ddc-8d2c-5263b84d1e15/dev/sda2[root@ubuntu2204 ~]# findfs LABEL=&#x27;Ubuntu-Server 22.04 LTS amd64&#x27;/dev/sr0[root@centos8 ~]#findfs `sed -En &#x27;/data/s#^([^ ]+).*#\\1#p&#x27; /etc/fstab`/dev/sda3 2.5 Swap分区2.5.1 配置swap分区注意：为优化性能，可以将swap 分布存放，或高性能磁盘存放 Redhat 官方推荐推荐系统 swap 空间 系统中的 RAM 量 推荐的 swap 空间 允许休眠的建议 swap 空间大小 低于 2 GB RAM 量的2倍数 RAM 容量的三倍 2 GB - 8 GB 等于 RAM 量 RAM 量的倍数 8 GB - 64 GB 4 GB 到 RAM 容量的 0.5 倍 RAM 容量的 1.5 倍 8 GB - 64 GB 独立负载（至少 4GB） 不建议使用休眠功能 范例 1234567891011121314[root@ubuntu2204 ~]# free -h total used free shared buff/cache availableMem: 1.9Gi 347Mi 896Mi 1.0Mi 697Mi 1.4GiSwap: 2.0Gi 0B 2.0Gi#Mem和Swap加起来都没有30G，所以失败了[root@ubuntu2204 ~]# dd if=/dev/zero of=/dev/null bs=30G count=1dd: memory exhausted by input buffer of size 32212254720 bytes (30 GiB)#这里文件大小虽然超过了，但有SWAP空间，所以可以执行成功[root@ubuntu2204 ~]# dd if=/dev/zero of=/dev/null bs=3G count=10+1 records in0+1 records out2147479552 bytes (2.1 GB, 2.0 GiB) copied, 7.40064 s, 290 MB/s 查询swap内存有哪些程序在使用： 12345678910111213141516171819for i in $(cd /proc;ls | grep &quot;^[0-9]&quot; | awk &#x27;$0&gt;100&#x27;); do awk &#x27;/Swap:/&#123;a=a+$2&#125;END&#123;print &quot;$i&quot;,a/1024&quot;M&quot;&#125;&#x27; /proc/$i/smaps;done| sort -k2nr#命令解析#遍历/proc目录下的所有进程目录，只考虑数字开头的目录（即进程ID）for i in $(cd /proc;ls | grep &quot;^[0-9]&quot; | awk &#x27;$0&gt;100&#x27;); do#对于每个进程，读取其smaps文件，统计Swap内存的使用量（单位为KB），并将其转换为MBawk &#x27;/Swap:/&#123;a=a+$2&#125;END&#123;print &quot;$i&quot;,a/1024&quot;M&quot;&#125;&#x27; /proc/$i/smaps#将结果按照第二列（即Swap内存使用量）从大到小排序sort -k2nr#查看swap分区的信息swapon -s#查看占用内存最多的前10个进程ps aux --sort=-%mem | head#筛选出使用了swap内存的进程ps aux --sort=-%mem | grep -E &#x27;S|Z&#x27; | head 2.5.2 交换分区实现过程 创建交换分区或者文件，然后使用mkswap写入特殊签名 可以使用整个磁盘，或者一个磁盘分区，使用 mkswap 命令制作swap分区 mkswap /dev/sdb1 通过文件制作，本质上还是磁盘 dd if=/dev/zero of=/swap_file bs=1M count=200 chmod 0600 /swap_file mkswap -f /swap_file 在&#x2F;etc&#x2F;fstab文件中添加适当的条目 激活swap分区：swapon 磁盘路径 关闭swap分区：swapoff 磁盘路径 启用swap分区 12345678910111213141516171819202122232425262728293031323334swapon [OPTION]... [DEVICE]#选项-a|--all #激活 /etc/fstab 中的所有交换区-d|--discard[=policy] #根据条件禁用(once|pages)-e|--ifexists #自动跳过不存在的设备而不提示-f|--fixpgsz #必要时重新初始化交换区-o|--options list #指定选项，swapon -o pri=1,discard=pages,nofail /dev/sda2-p|--priority N #指定交换设备的优先级(-1到32767)，值越大优先级越高,也可在/etc/fstab第4列指定pri=value-s|--summary #显示已使用交换设备的摘要--show[=columns] #以可自定义的表格形式打印摘要 swapon --show|swapon--show=NAME,TYPE--noheadings #不打印表头，配合 --show 选项--raw #使用原生输出格式，配合 --show 选项--bytes #在 --show 输出中以字节数显示交换区大小-v|--verbose #显示详细信息#&lt;spec&gt; 参数：-L label #同 LABEL=label-U uuid #同 UUID=uuidLABEL=label #按交换区标签指定设备UUID=uuid #按交换区 UUID 指定设备PARTLABEL=label #按分区标签指定设备PARTUUID=uuid #按分区 UUID 指定设备device #要使用设备的名称filename #要使用文件的名称#可显示列NAME #设备文件或分区路径TYPE #设备的类型SIZE #交换区大小USED #已使用字节数PRIO #交换优先级UUID #uuidLABEL #label 创建swap分区 123456789101112#第一种（以硬盘方式）1 给硬盘设备修改分区类型为Linux swap2 mkswap [device] #创建3 写入/etc/fstab文件中4 swapon -a #使其生效#第二种（以文件方式）1 dd if=/dev/zero of=/swapfile bs=1M count=10242 mkswap /swapfile3 chmod 600 /swapfile 4 写入/etc/fstab文件中5 swapon -a #使其生效 禁用swap分区 12345678910111213141516171819#第一种方法（立即生效）swapon -s 查看设备名称swapoff [OPTION]... [DEVICE]#第二种方法（下一次重启才会生效）1 在/etc/fstab中注释或删除swap那一行2 sed -i &#x27;/swap/s/^/#/&#x27; /etc/fstab#常用选项-a|--all #禁用 /proc/swaps 中的所有交换区-v|--verbose #显示过程#spec 参数-L label #要使用设备的标签-U uuid #要使用设备的 UUIDLABEL=label #要使用设备的标签UUID=uuid #要使用设备的 UUIDdevice #要使用设备的名称filename #要使用文件的名称 查看swap分区 Priority越大，优先级越高，会被优先使用 123456[root@ubuntu2204 ~]# swapon -sFilename Type Size Used Priority/swap.img file 2097148 0 -2/dev/sdc3 partition 2097148 0 -3[root@ubuntu2204 ~]# cat /proc/swaps SWAP的优先级 可以指定swap分区0到32767的优先级，值越大优先级越高 如果用户没有指定，那么核心会自动给swap指定一个优先级，这个优先级从-1开始，每加入一个新的没有用户指定优先级的swap，会给这个优先级减一 先添加的swap的缺省优先级比较高，除非用户自己指定一个优先级，而用户指定的优先级(是正数)永远高于核心缺省指定的优先级(是负数) 范例: 以文件实现swap功能 123456789101112[root@centos8 ~]#dd if=/dev/zero of=/swapfile bs=1M count=1024[root@centos8 ~]#mkswap /swapfile[root@centos8 ~]#blkid /swapfile &gt;&gt; /etc/fstab[root@centos8 ~]#vim /etc/fstab/swapfile swap swap defaults 0 0 #不要用UUID,使用文件的路径[root@centos8 ~]#chmod 600 /swapfile[root@centos8 ~]#swapon -a[root@centos8 ~]#swapon -sFilename Type Size Used Priority/dev/sda5 partition 2097148 0 -2/swapfile file 1048572 0 -3 永久禁用swap 1234567891011#删除swap行[root@ubuntu2204 ~]#sed -i.bak &#x27;/swap/d&#x27; /etc/fstab#或注释swap行[root@ubuntu2204 ~]#sed -i.bak &#x27;/swap/s@^@#@&#x27; /etc/fstab#禁用swap，由于修改了配置文件，所以重启也不会有SWAP[root@ubuntu2204 ~]#swapoff -a#需要重启生效[root@ubuntu2204 ~]#systemctl mask swap.target 关闭Swap交换分区的优点 提高性能：Swap交换分区通常会在物理内存不足时被使用，这会导致额外的I&#x2F;O操作和延迟。当系统使用物理内存满足所有应用程序的需求时，关闭Swap交换分区可以避免这种情况的发生，从而提高服务器的性能。 减少磁盘使用：Swap交换分区通常占用一部分硬盘空间，关闭Swap交换分区可以减少磁盘使用，从而为其他用途释放空间。 减少系统管理复杂性：当系统有Swap交换分区时，需要定期检查Swap交换分区的使用情况，并可能需要调整Swap交换分区的大小。关闭Swap交换分区可以避免这些问题，从而简化系统管理。 关闭Swap交换分区也存在一些缺点： 内存压力增大：如果系统物理内存不足，关闭Swap交换分区会导致系统无法使用硬盘空间作为额外的内存，这可能导致应用程序崩溃或性能下降。 系统不稳定：在极端情况下，如果系统物理内存不足并且没有Swap交换分区可用，可能会导致系统不稳定或无法正常运行。 2.5.3 swap的使用策略什么样的数据才能往swap里面放？ 1234567# cat /proc/meminfo | grep -i active Active: 233836 kB Inactive: 1280348 kB Active(anon): 138780 kB Inactive(anon): 26740 kB Active(file): 95056 kB Inactive(file): 1253608 kB active活跃数据，inactive非活跃数据，又分为匿名数据和文件数据 匿名数据不能往swap里面放 文件形式的active不能往swap里放，只有文件的inactive才能往swap放 所以并不是有了swap，内存就解决了 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness 的值（默认30）决定了当内存占用达到一定的百分比时，会启用swap分区的空间 使用规则 当内存使用率达到100-swappiness时,会启用交换分区 简单地说这个参数定义了系统对swap的使用倾向，此值越大表示越倾向于使用swap 可以设为0，这样做并不会禁止对swap的使用，只是最大限度地降低了使用swap的可能性，Linux内核3.5-rcl版本，包括RedHat企业版内核2.6.32-303，0意味着“在任何情况下都不要发生交换”。所以现在建议把这个值设置为1 当 /proc/sys/vm/swappiness 的值为 0 时，表示系统完全避免使用交换空间，只使用物理内存。这意味着系统将尽可能多地使用物理内存，即使物理内存不足，也不会使用交换空间。这可能会导致性能下降，因为频繁地访问物理内存比访问交换空间要慢得多。 当 /proc/sys/vm/swappiness 的值为 1 时，表示系统更倾向于使用交换空间而不是物理内存。这意味着系统在物理内存不足时会使用交换空间，但仍然优先考虑使用物理内存。这种设置可能会提高性能，因为交换空间通常比物理内存更快。然而，如果系统经常需要使用交换空间，那么性能可能会受到影响。 1echo 1 &gt; /proc/sys/vm/swappiness 范例 123456789101112131415161718#说明：CentOS7和8默认值为30，内存在使用到100-30=70%的时候，就开始出现有交换分区的使用[root@centos8 ~]# cat /proc/sys/vm/swappiness30[root@centos7 ~]# cat /proc/sys/vm/swappiness30[root@centos6 ~]# cat /proc/sys/vm/swappiness60#修改[root@rocky86 ~]# vim /etc/sysctl.confvm.swappiness=0#生效[root@rocky86 ~]# sysctl -pvm.swappiness = 0[root@ubuntu2204 ~]# cat /proc/sys/vm/swappiness0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://aquapluto.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"作业管理与并行运行","slug":"Linux/process-manage/job-parallel","date":"2025-08-21T02:59:12.000Z","updated":"2025-08-28T12:33:05.289Z","comments":true,"path":"Linux/process-manage/job-parallel/","permalink":"https://aquapluto.github.io/Linux/process-manage/job-parallel/","excerpt":"","text":"一、作业管理 Linux的作业控制 前台作业：通过终端启动，且启动后一直占据终端 后台作业：可通过终端启动，但启动后即转入后台运行（释放终端） 让作业运行于后台 运行中的作业： Ctrl+z（变成stop态） 尚未启动的作业： COMMAND &amp; 后台作业虽然被送往后台运行，但其依然与终端相关；退出终端，将关闭后台作业。如果希望送往后台后，剥离与终端的关系 nohup COMMAND &amp;&gt;&#x2F;dev&#x2F;null &amp; screen；COMMAND tmux；COMMAND 后台运行的进程和终端关系 进程虽然放到了后台执行，但还是终端下的子进程 查看当前终端所有作业编号 1234567[root@ubuntu ~]# jobs[1] Stopped ping www.baidu.com[2]- Stopped ./a.sh 123[3]+ Stopped ./a.sh 456-：倒数第二个后台进程+：最后一个后台进程 作业控制 1234fg [[%]JOB_NUM] 把指定的后台作业调回前台bg [[%]JOB_NUM] 让送往后台的作业在后台继续运行kill [%JOB_NUM] 终止指定的作业cmd &amp; 直接是后台运行 范例：作业控制，让后台stop进程继续运行 123456789101112131415[root@ubuntu ~]# jobs[1] Stopped ./a.sh 123[2]- Stopped ./a.sh 456[3]+ Stopped ./a.sh 789#让后台stop 进程继续running[root@ubuntu ~]# bg[3]+ ./a.sh 789 &amp;[root@ubuntu ~]# bg 1[1]- ./a.sh 123 &amp;[root@ubuntu ~]# jobs[1] Running ./a.sh 123 &amp;[2]+ Stopped ./a.sh 456[3]- Running ./a.sh 789 &amp; 范例: 后台运行的进程和终端关系 123456789101112#终端1运行后台进程[root@centos8 ~]#ping 127.0.0.1 &amp;[1] 30545#终端2 可以查看到进程[root@centos8 ~]#ps aux|grep pingroot 30545 0.0 0.2 32408 2416 pts/0 S 12:25 0:00 ping 127.0.0.1root 30547 0.0 0.1 12108 988 pts/2 S+ 12:25 0:00 grep --color=auto ping#关闭终端1后,在终端2查看不到进程[root@centos8 ~]#ps aux|grep pingroot 30552 0.0 0.1 12108 1084 pts/2 S+ 12:25 0:00 grep --color=auto ping 范例：将进程从前台运行（占用终端窗口，不会输出其他命令结果）变成后台运行（仍处于运行状态，但可以输出其他命令） 123456789101112131415161718192021222324252627282930313233[root@centos ~]#ping 10.0.0.183PING 10.0.0.183 (10.0.0.183) 56(84) bytes of data.64 bytes from 10.0.0.183: icmp_seq=1 ttl=64 time=0.100 ms64 bytes from 10.0.0.183: icmp_seq=2 ttl=64 time=0.051 ms64 bytes from 10.0.0.183: icmp_seq=3 ttl=64 time=0.052 ms64 bytes from 10.0.0.183: icmp_seq=4 ttl=64 time=0.135 ms64 bytes from 10.0.0.183: icmp_seq=5 ttl=64 time=0.057 ms64 bytes from 10.0.0.183: icmp_seq=6 ttl=64 time=0.153 ms64 bytes from 10.0.0.183: icmp_seq=7 ttl=64 time=0.056 ms^Z #Ctrl+z停止运行[1]+ Stopped ping 10.0.0.183#通过jobs查看作业编号1[root@centos ~]#jobs [1]+ Stopped ping 10.0.0.183#实现后台执行（或者kill -18 11596）[root@centos ~]#bg 1 [1]+ ping 10.0.0.183 &amp;[root@centos ~]#64 bytes from 10.0.0.183: icmp_seq=8 ttl=64 time=0.032 ms64 bytes from 10.0.0.183: icmp_seq=9 ttl=64 time=0.059 ms64 bytes from 10.0.0.183: icmp_seq=10 ttl=64 time=0.046 msls #不占用终端资源，可以输出命令结果anaconda-ks.cfg apps data dir motd_peiqi passwd pwd[root@centos ~]#64 bytes from 10.0.0.183: icmp_seq=11 ttl=64 time=0.037 ms64 bytes from 10.0.0.183: icmp_seq=12 ttl=64 time=0.156 ms64 bytes from 10.0.0.183: icmp_seq=13 ttl=64 time=0.045 ms[root@centos ~]#pidof ping11596[root@centos ~]#kill -19 11596 #停止运行[root@centos ~]#fg 1 #恢复前台 范例: nohup（在后台运行，不会随着窗口的关闭而停止运行，而是将内容重定向到一个文件） 1234567891011[root@centos8 ~]#nohup ping 127.0.0.1nohup: ignoring input and appending output to &#x27;nohup.out&#x27;[root@centos8 ~]#cat nohup.out64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.037 ms64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.040 ms64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.042 ms64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.047 ms#如果不想它重定向到一个文件，放进垃圾箱并后台执行[root@centos8 ~]#nohup ping 127.0.0.1 &amp;&gt; /dev/null &amp; 二、并行运行利用后台执行，实现并行功能，即同时运行多个进程，提高效率 方法1：写脚本 12345cat all.shf1.sh&amp;f2.sh&amp;f3.sh&amp;#在脚本里最后要加上wait才能退出 方法2 1(f1.sh&amp;);(f2.sh&amp;);(f3.sh&amp;) 方法3 1f1.sh&amp;f2.sh&amp;f3.sh&amp; 停止运行 1killall cmd 多组命令实现并行并停止 12[root@centos8 ~]#&#123; ping -c3 127.1; ping 127.2; &#125;&amp; &#123; ping -c3 127.3 ;ping 127.4;&#125;&amp;[root@centos8 ~]#killall ping 范例：网段检测 12345678910111213141516[root@centos8 ~]#cat scanhost.sh#!/bin/bash#顺序执行net=10.0.0for i in &#123;1..254&#125;;do ping -c1 -W1 $net.$i &amp;&gt; /dev/null &amp;&amp; echo $net.$i is up || echo $net.$i is downdone#并发执行NET=10.0.0for i in &#123;1..254&#125;;do &#123; ping -c1 -W1 $&#123;NET&#125;.$&#123;i&#125; &amp;&gt; /dev/null &amp;&amp; echo $&#123;NET&#125;.$&#123;i&#125; is up || echo $&#123;NET&#125;.$&#123;i&#125; is down &#125;&amp;donewait","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://aquapluto.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"信号发送","slug":"Linux/process-manage/signal","date":"2025-08-21T02:58:59.000Z","updated":"2025-08-28T12:33:05.296Z","comments":true,"path":"Linux/process-manage/signal/","permalink":"https://aquapluto.github.io/Linux/process-manage/signal/","excerpt":"","text":"一、HUP信号HUP信号，主要涉及两种应用场景 终端关闭时，系统会向与该终端相连的所有进程发送SIGHUP信号，这会导致这些进程被关闭(所有才有了脱离终端运行的需求) 用kill命令给进程发送SIGHUP信号实现该进程的平滑重启 需要注意的是，并非所有的进程或应用都能处理SIGHUP信号，只有程序内写过专门的捕获并处理该信号的代码才行，nginx的源代码里就写了，并且会响应该信号来实现平滑重启 当我们的进程在前台或者后台运行的时候，会因为用户退出、网络断开、终端关闭导致一起关闭，要想解决有两种的方法 让进程忽略HUP信号 让进程运行在新会话中，从而成为不属于此终端的子进程，就不会在当前终端挂掉的情况下一起挂掉 nohup命令：忽略HUP信号，和&amp;一起使用，输出信息(1,2)会缺省重定向到 nohup.out 文件。当当前终端关掉后，该终端的进程的父id会变成1 setsid命令：直接将进程的父id变成1 二、kill命令kill：内部命令，可用来向进程发送控制信号，以实现对进程管理,每个信号对应一个数字，信号名称以SIG开头（可省略），不区分大小写 执行流程kill命令的执行流程：用户空间的kill命令—–》内核空间（sys_kill()—&gt;_send_signal()—&gt;sig_task_ignored()）——》用户空间的另外一个进程 没有被sig_task_ignored()忽略掉的信号才会发送给用户态的的另外一个进程，sig_task_ignored()就相当于一层关卡，被它放行的信号才会通知给用户态的指定进程（如下图所示pid为1的进程） sig_task_ignored()代码如下，主要有三个判断条件，任意一个条件成立，都会返回true，代表应该忽略（Ignore）当前信号，我们主要看一下第二个if判断 1t-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE 进程必须是SIGNAL_UNKILLABLE该条件才成立， 在每个Namespace中1号进程创建时，都会被打上SIGNAL_UNKILLABLE的标签 也就是说只要是容器内的1号进程，该条件一定成立 1handler == SIG_DFL 如果用户进程没有针对本信号注册自己的handler处理函数，那么会有一个默认的handler程序 这个默认的handler就叫SIG_DFL 所以，总结一句话就是如果你进程没有针对本信号注册handler，那该条件就程序 ps：如果进程使用的是默认&#x2F;缺省行为那该条件就成立 如果目标进程对-15信号注册了handler处理函数，那么该条件就为false 如果没有注册该条件就为true 1!(force &amp;&amp; sig_kernel_only(sig) force结果的真假取决于发送信号的进程与接收信号的进程是否在同一个namespace里， 如果是那结果就为0，否则结果就为1 1sig_kernel_only(sig) 只有信号为-9信号或者-19结果才true 使用方式格式 12345678910kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]-SIGNAL：信号名称-s：指定信号-u uid: 生效者-U uid: 真正发起运行命令者-t terminal: 与指定终端相关的进程-l: 显示进程名（pgrep可用）-a: 显示完整格式的进程名（pgrep可用）-P pid: 显示指定进程的子进程 显示当前系统可用信号 12345678910111213kill -l trap -l#常用信号0) 检测进程是否正常，此方式有局限性，即使进程处于停止或僵尸状态，此方式仍然认为是进程是健康的1) SIGHUP 无须关闭进程而让其重读配置文件2) SIGINT 中止正在运行的进程；相当于Ctrl+c3) SIGQUIT 相当于ctrl+\\9) SIGKILL 强制杀死正在运行的进程,可能会导致数据丢失,慎用!10) SIGUSR1 用来触发一些特定的动作或者事件，比如重新加载配置文件、启动某些特定的操作等，不需要重启15) SIGTERM 终止正在运行的进程，默认信号18) SIGCONT 继续运行19) SIGSTOP 后台休眠 指定信号的方法 : 信号的数字标识：1, 2, 9 信号完整名称：SIGHUP，sighup 信号的简写名称：HUP，hup 向进程发送信号： 按PID： 123456kill -1 pid …kill -n 9 pidkill -s SIGINT pid[root@centos8 ~]#kill -int `pidof ping`[root@centos8 ~]#kill -sigint `pidof ping` 按名称：killall 来自于psmisc包 1234killall [-SIGNAL] comm…#范例killall nginx 范例：查看HUP信号 123#许多服务的支持的reload操作，实际就是发送了HUP信号#service httpd reload 即相当于 killall -1 httpd[root@centos6 ~]#grep -A 10 -w reload -m 1 /etc/init.d/httpd 范例：利用 0 信号实现进程的健康性检查 123456789[root@centos8 ~]#killall -0 ping[root@centos8 ~]#echo $?0[root@centos8 ~]#killall -0 pingping: no process found[root@centos8 ~]#echo $?1#此方式有局限性，即使进程处于停止或僵尸状态，此方式仍然认为是进程是健康的 按模式 1pkill [options] pattern 范例：踢出指定终端，高版本内核无效 1[root@rocky ~]# pkill -t pts/1 范例: pkill和pgrep支持正则表达式 123456[root@centos8 ~]#pkill &#x27;^p&#x27;[root@centos8 ~]#pgrep -a &#x27;^p&#x27;9278 pickup -l -t unix -u9281 ping 1.1.1.19311 ping 2.2.2.2 范例: nginx服务的信号 1234567891011121314151617181920[root@centos8 ~]#man nginx SIGUSR1 Reopen log files. SIGUSR2 Upgrade the nginx executable on the fly. SIGWINCH Shut down worker processes gracefully. [root@wang-liyun-pc ~]# cat /etc/logrotate.d/nginx/apps/nginx/logs/*.log &#123; daily rotate 100 missingok notifempty nocompress delaycompress create 644 nginx nginx postrotate if [ -f /apps/nginx/logs/nginx.pid ]; then kill -USR1 `cat /apps/nginx/logs/nginx.pid` #发送USR1信号,重新打开日志文件 fi endscript&#125; 范例：关掉指定端口的进程 1234567891011[root@ubuntu ~]# lsof -i:80COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEapache2 1220 root 4u IPv6 38019 0t0 TCP *:http (LISTEN)apache2 1225 www-data 4u IPv6 38019 0t0 TCP *:http (LISTEN)apache2 1226 www-data 4u IPv6 38019 0t0 TCP *:http (LISTEN)#强制关闭使用 TCP 端口 80 的所有进程[root@ubuntu ~]# fuser -k -9 80/tcp80/tcp: 1220 1225 1226[root@ubuntu ~]# lsof -i:80 三、-9和-15信号当我们使用kill pid时，实际相当于kill -15 pid。也就是说默认信号为15。使用kill -15时，系统会发送一个SIGTERM的信号给对应的程序。当程序接收到该信号后，具体要如何处理自己可以决定。这时候，应用程序可以选择： 立即停止程序 释放响应资源后停止程序 忽略该信号，继续执行程序 因为kill -15信号只是通知对应的进程要进行”安全、干净的退出”，程序接到信号之后，退出前一般会进行一些”准备工作”，如资源释放、临时文件清理等等，如果准备工作做完了，再进行程序的终止。 但是，如果在”准备工作”进行过程中，遇到阻塞或者其他问题导致无法成功，那么应用程序可以选择忽略该终止信号。 这也就是为什么我们有的时候使用kill命令是没办法”杀死”应用的原因，因为默认的kill信号是SIGTERM（15），而SIGTERM（15）的信号是可以被阻塞和忽略的。 和kill -15相比，kill -9就相对强硬得多，系统会发出SIGKILL信号，他要求接收到该信号的程序应该立即结束运行，不能被阻塞或者忽略。 所以，kill -9在执行时，应用程序是没有时间进行”准备工作”的，所以这通常会带来一些副作用，数据丢失或者终端无法恢复到正常状态等。 四、特权信号进程收到信号后的三种反应 忽略（Ignore）: 就是对该信号不做任何处理， 捕获（Catch）：就是让用户进程可以注册自己针对这个信号的handler，一旦进程收到该信号后，就会触发handler的功能运行 默认&#x2F;缺省行为（Default）：linux系统为每个信号都定义了默认要做的事情，我们可以通过man 7 signal来查看，对于大多数信号来说，我们都不需要捕获并注册自己的handler，使用默认的就好 两个特权信号 SIGKILL（-9）：强制杀死 SIGSTOP（-19）：暂停进程的运行，恢复运行需要发送-18信号 这两个特权信号特权就特权在： 无法被忽略 无法被捕获 因为这两信号是linux系统为内核和超级用户准备的特权，可以删除任意的进程，任何进程只要收到了这俩信号，只能执行缺省行为，任何进程收到了这俩信号都只能乖乖听话。至于SIGTERM（-15）信号，代表的是平滑关闭，该信号是可以被忽略或者说捕获的","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://aquapluto.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"进程管理命令","slug":"Linux/process-manage/command","date":"2025-08-21T02:58:53.000Z","updated":"2025-08-28T12:33:05.276Z","comments":true,"path":"Linux/process-manage/command/","permalink":"https://aquapluto.github.io/Linux/process-manage/command/","excerpt":"","text":"一、查看进程相关信息linux启动的第一个进程是0号进程，是静态创建的 在0号进程启动后会接连创建两个进程，分别是1号进程和2和进程。 1号进程最终会去调用可init可执行文件，init进程最终会去创建所有的应用进程。 2号进程会在内核中负责创建所有的内核线程 所以说0号进程是1号和2号进程的父进程；1号进程是所有用户态进程的父进程；2号进程是所有内核线程的父进程。 进程树pstreepstree 可以用来显示进程的父子关系，以树形结构显示 123456pstree [OPTION] [ PID | USER ]-p 显示PID-T 不显示线程thread,默认显示线程-u 显示用户切换-H pid 高亮显示指定进程及其前辈进程 范例 1234567891011#高亮显示前辈进程[root@centos8 ~]#pstree -pH 1780#显示进程切换[root@ubuntu ~]# pstree -u | grep jose#显示指定用户的进程 [root@ubuntu ~]# pstree jose#不显示线程[root@ubuntu ~]# pstree -pT | grep httpd 进程信息 ps可以进程当前状态的快照，默认显示当前终端中的进程，Linux系统各进程的相关信息均保存在&#x2F;proc&#x2F;PID目录下的各文件中 12345678910111213141516171819202122232425ps [OPTION]...a #查看所有终端的进程u #选项显示进程所有者的信息x #选项包括不链接终端的进程，即后台运行的进程（守护进程）f #选项显示进程树o #属性… 选项显示定制的信息，pid、cmd、%cpu、%mem、nik #对属性排序，属性前加 - 表示倒序L #显示支持的属性列表-ef #显示列 C 表示cpu利用率-L #显示线程-e #显示所有进程，相当于-A-f #显示完整格式程序信息-F #显示更完整格式的进程信息-H #以进程层级格式显示进程相关信息-u #userlist 指定有效的用户ID或名称-U #userlist 指定真正的用户ID或名称-g #gid或groupname 指定有效的gid或组名称-G #gid或groupname 指定真正的gid或组名称-p #pid 显示指pid的进程-M #显示SELinux信息，相当于Z--ppid pid #显示属于pid的子进程--sort #对属性排序，属性前加 - 表示倒序-t ttylist #指定tty,相当于 t-C cmdlist #指定命令，多个命令用，分隔 ps 输出属性 1234567891011121314151617181920212223242526272829303132333435363738USER(UID)：进程属主PID：进程IDPPID：父进程ID%CPU(C)：CPU占用率%MEM：内存占用率VSZ: 虚拟内存集，线性内存，虚似内存 指该进程已分配的线性空间大小，即在程序代码中申请的内存大小 这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多 比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小RSS: 常驻内存集，实际占用物理内存TTY：终端STAT：进程状态 R：running S: interruptable sleeping D: uninterruptable sleeping T: stopped Z: zombie +: 前台进程 |：表示多进程（管道） l: 当前进程是多线程模式 L：内存分页并带锁 N：低优先级进程 &lt;: 高优先级进程 s: 表示该进程是会话(session)的领导/领导进程，用来接收用户请求，然后自己不干给儿子进程去干(nginx) I：空闲内核线程，CentOS 8 新特性，不是用户模式下的空闲进程。这个状态通常只应用于内核线程，用户进程通常不会有这个状态START(STIME)：进程开始时间TIME：累计分配给进程的cpu时长COMMAND(CMD)：对应的程序及参数 带[]号的代表内核态进程 不带[]号的代表用户态进程UID：进程属主C：cpu利用率，取整ni: nice值pri: 进程的实际优先级，通常与 ni 字段相关联rtprio: 进程的实时优先级psr: processor CPU编号，即进程运行在哪个处理器上euser：有效用户，通常指的是进程的真正拥有者ruser：真实用户，即启动进程的用户 常用组合 12345aux-ef-eFH-eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,commaxo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm 范例 12345678910111213141516171819202122232425262728#查看进程详细信息[root@centos8 ~]#ps -ef[root@centos8 ~]#ps aux #可以更精确看到CPU使用情况和内存使用情况#查看进程的父子关系[root@centos8 ~]#ps auxf#查看进程的特定属性[root@centos8 ~]#ps axo pid,cmd,%mem,%cpu#按CPU利用率倒序排序[root@centos8 ~]#ps aux k -%cpu[root@centos8 ~]#ps axo pid,cmd,%cpu,%mem k -%cpu#按内存倒序排序[root@centos8 ~]#ps axo pid,cmd,%cpu,%mem --sort %mem#linux下获取占用内存资源最多的10个进程ps aux|head -1;ps aux|grep -v PID|sort -rn -k +4|head#内存消耗最大进程ps aux --sort -rss | head#输出中仅展示有关内存消耗过程的特定信息ps -eo pid,ppid,%mem,%cpu,cmd --sort=-%mem | head#只想查看命令名称而不是命令的绝对路径ps -eo pid,ppid,%mem,%cpu,comm --sort=-%mem | head 范例：有效用户和实际用户 1234567[wang@centos8 ~]$passwdChanging password for user wang.Current password:[root@centos8 ~]#ps axo pid,cmd,%cpu,%mem,user,euser,ruser | grep passwd 1965 passwd 0.0 1.0 root root wang 1970 grep --color=auto passwd 0.0 0.1 root root root 范例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#查询你拥有的所有进程ps -x#显示指定实际用户名(RUID)或用户ID的进程ps -fU apacheps -fU 48#显示指定有效用户名(EUID)或用户ID的进程ps -fu wangps -fu 1000#查看以root用户权限（实际和有效ID）运行的每个进程ps -U root -u root#列出某个组拥有的所有进程（实际组ID：RGID或名称）ps -fG nginx#列出有效组名称（或会话）所拥有的所有进程ps -fg mysqlps -fg 27#显示指定的进程ID对应的进程ps -fp 1234#以父进程ID来显示其下所有的进程，如显示父进程为1234的所有进程ps -f --ppid 1234#显示指定PID的多个进程ps -fp 1204,1239,1263#要按tty显示所属进程ps -ft pts/0#以进程树显示系统中的进程如何相互链接ps -e --forest#以进程树显示指定的进程ps -f --forest -C sshdps -ef --forest | grep -v grep | grep sshd#要显示一个进程的所有线程,将显示LWP（轻量级进程）以及NLWP（轻量级进程数）列ps -fL -C nginx#要列出所有格式说明符ps L#查看进程的PID，PPID，用户名和命令ps -eo pid,ppid,user,cmd#自定义格式显示文件系统组,ni值开始时间和进程的时间ps -p 1234 -o pid,ppid,fgroup,ni,lstart,etime#使用其PID查找进程名称：ps -p 1244 -o comm=#要以其名称选择特定进程，显示其所有子进程ps -C sshd,bash#查找指定进程名所有的所属PID，在编写需要从std输出或文件读取PID的脚本时这个参数很有用ps -C httpd,sshd -o pid=#检查一个进程的执行时间ps -eo comm,etime,user | grep nginx#排序，查找占用最多内存和CPU的进程ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | headps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head#显示安全信息ps -eMps --context#使用以下命令以用户定义的格式显示安全信息ps -eo euser,ruser,suser,fuser,f,comm,label#使用watch实用程序执行重复的输出以实现对就程进行实时的监视，如下面的命令显示每秒钟的监视watch -n 1 &#x27;ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head&#x27; 范例：查看优先级和CPU绑定关系 12345678910[root@centos8 ~]#ps axo pid,cmd,ni,pri,psr,rtprio |grep migration 11 [migration/0] - 139 0 99 16 [migration/1] - 139 1 99 2246 grep --color=auto migration 0 19 0 -[root@centos8 ~]#ps axo pid,cmd,ni,pri,psr |grep dd 2 [kthreadd] 0 19 1 138 [ipv6_addrconf] -20 39 0 2153 dd if=/dev/zero of=/dev/nul 19 0 0 2228 grep --color=auto dd 0 19 1 查看进程信息 prtstat可以显示进程信息,来自于psmisc包 12345prtstat [options] PID ...-r raw格式显示[root@centos8 ~]#prtstat 18395[root@centos8 ~]#prtstat -r 18395 搜索进程按条件搜索进程 ps 选项 | grep ‘pattern’ 灵活 pgrep 按预定义的模式 &#x2F;sbin&#x2F;pidof 按确切的程序名称查看pid pgrep12345678910111213pgrep [options] pattern-u uid #生效者-U uid #真正发起运行命令者-t terminal #与指定终端相关的进程-l #显示进程名-a #显示完整格式的进程名-x #根据指定的命令匹配-w #显示线程ID-c #统计匹配到的进程数量-P pid #显示指定进程的子进程-s &lt;SID,...&gt; #根据会话ID显示-F &lt;file&gt; #从文件中读取PID作为条件 范例 123456789101112131415161718192021222324[root@centos8 ~]#pgrep -u wang23032330[root@centos8 ~]#pgrep -lu wang2303 bash2330 dd#错误写法[root@centos8 ~]#pgrep -ul wangpgrep: invalid user name: l[root@centos8 ~]#pgrep -au wang2303 -bash2330 dd if=/dev/zero of=/dev/null[root@centos8 ~]#pgrep -aP 23032330 dd if=/dev/zero of=/dev/null#查找指定终端的进程[root@centos8 ~]#pgrep -at pts/21482 -bash2302 su - wang2303 -bash2330 dd if=/dev/zero of=/dev/null 范例：发起用户和生效用户 12345678910111213141516#普通用户发起passwd 进程[jose@ubuntu ~]$ passwdChanging password for user jose.Current password:#实际进程属主是root[root@ubuntu ~]# ps aux | grep passwdroot 15440 0.0 0.4 331172 8564 pts/1 S+ 22:24 0:00 passwd#查看user 和 ruser[root@ubuntu ~]# ps axo pid,cmd,user,ruser#根据 real user查找[root@ubuntu ~]# pgrep -aU jose2843 -bash15440 passwd pidof查看相关命令的进程编号 123456789101112131415161718192021pidof [options] [program [...]]-x 按脚本名称查找pid-s 多个结果时只显示一条[root@centos8 ~]#pidof bash19035 18813 18789 1251#只显示一个进程号[root@ubuntu ~]# pidof -s bash8274[root@centos7 ~]#cat ping.sh#!/bin/bashping 127.0.0.1#centos8 执行命令可以查看到pid[root@centos7 ~]#pidof ping.sh#ping.sh必须有shebang机制,否则pidof -x 也无法查找到[root@centos7 ~]#pidof -x ping.sh19035 查看进程实时状态toptop 命令是一个用于实时监视 Linux 系统中进程的命令行工具，它提供了有关系统性能和进程活动的实时信息。它没有参数，直接运行它将显示实时的系统性能信息和进程列表。默认情况下，top会按CPU利用率降序排列进程。 top命令统计的cpu状态信息就是从&#x2F;proc&#x2F;stat中取的，系统所有进程的运行状态都在&#x2F;proc下 cpu：&#x2F;proc&#x2F;cpuinfo 内存：&#x2F;proc&#x2F;meminfo 内核启动参数：&#x2F;proc&#x2F;cmdline 1234567891011121314151617181920212223242526272829303132333435363738394041内核空间进程占用的CPU；[root@centos ~]#toptop - 17:19:29 up 1 day, 9:55, 2 users, load average: 0.00, 0.01, 0.05Tasks: 109 total, 1 running, 108 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 stKiB Mem : 1863028 total, 1305272 free, 187488 used, 370268 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 1508764 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND #第一行：uptime格式17:19:29：系统当前时间up 1 day, 9:55：系统己开机运行时长2 users：当前有两个用户登录load average: 0.00, 0.01, 0.05：系统的平均负载，1分钟，5分钟，15分钟#第二行：一共109个进程，其中1个在运行，108个在睡觉，0个停止态。0个僵尸态#第三行：us：高优先级进程的用户态进程占用cpu时间的百分比sy：内核态进程占用cpu时间的百分比ni：nice值为1-19的进程，即低优先级进程的用户态占cpu时间的百分比id：CPU空闲时间的百分比wa：CPU等待I/O完成的时间的百分比，该时间不计入进程的CPU时间hi：处理硬件中断的时间的百分比，该时间不计入进程的CPU时间si：处理软件中断的时间的百分比，该时间不计入进程的CPU时间st：被嵌套虚拟机跑进程所使用的时间，即同一宿主机上的其他虚拟机抢走的CPU时间#第四行：Mem：物理总内存大小，未使用内存大小，已使用物理内存大小，内核缓存占用内存大小#第五行：swap：交换区大小，未使用交换区大小，已使用交换区大小#第六行PID：进程号USER：用户PR：优先级VIRT：虚拟物理内存，包括所有代码、数据和共享库，以及已交换的页面和已映射但未使用的内存RES：实际物理内存，共享的内存比如动态库也会计算在内SHR：共享物理内存，并非所有共享的内存都是常驻的S：进程状态%CPU：CPU占用率%MEM：内存占用率TIME+：时间片累加值 为了便于理解，假设只有一个cpu，按照从上到下从左到右的顺序以此解析每个框的含义 第一个框us：一个用户程序开始运行，那么就对应于着第一个“us”框，代表linux用户态的Cpu Usage。普通的用户程序代码中，只要不是调用系统调用（System Call），这些代码的指令消耗的CPU就都属于“us”。 第二个框sys：当这个用户程序代码调用了系统调用，比如read()去读取一个文件，这时候这个用户的进程就会从用户态切换到内核态。内核态read()系统调用在读到真正disk上的文件前，就会进行一些文件系统层的操作，那么这些代码指令的消耗就属于“sys”，代表内核cpu使用 第三个框wa：接下来，这个read()系统调用会向linux的Block Layer发出一个I&#x2F;O Request,触发一个真正的磁盘读取操作，此时，这个进程一般会被置为不可中断睡眠状态TASK_UNINTERUPTIBLE。而linux会把这段时间标识成“wa”， 第四个框sys：紧接着，当磁盘返回数据时，进程在内核态拿到数据，这里仍旧是内核态CPU使用中的“sy” 第五个框us：然后进程再从内核态切回用户态，在用户态得到文件数据，这里进程又回到用户态CPU使用，即“us” 第六个框id：好，在这里我们假设一下，这个用户进程在读取数据之后，没事可做就休眠了，并且假设此时在这个CPU上也没有其他需要运行的进程了，那么系统就会进入“id”这个步骤，代表系统处于空闲状态 第七个框hi：如果此时这台机器收到一个网络包，网卡就会发出一个中断（interrupt），该中断为硬中断，cpu必须响应，cpu响应后进入中断服务程序，此时cpu就会进入“hi”，代表cpu处理硬中断的开销。 第八个框si：由于我们的中断服务需要关闭中断，所以这个硬中断的时间不能太长。但发生中断之后的工作是必须要完成的，如果这些工作比较耗时怎么办？linux中有一个软中断的概念（softirq），它可以完成这些耗时比较长的工作。从网卡收到的数据包的大部分工作，都是通过软中断来最终处理的。 强调：无论是hi还是si，占用的cpu时间，都不会计入进程的cpu时间，因为本来中断程序就是单独的程序，它们在处理时本就不属于任何一个进程。 此外还有两个类型的cpu：一个是“ni”，另外一个是“st” “ni”是nice的缩写，这里表示如果进程的nice值是正值（1-19），代表优先级比较低的进程运行时所占用的cpu “st”是steal的缩写，是虚拟机里用的cpu使用类型，表示有多少时间是被同一个宿主机上的其他虚拟机抢走的 强调：无论是hi还是si，占用的cpu时间，都不会计入进程的cpu时间，因为本来中断程序就是单独的程序，它们在处理时本就不属于任何一个进程，即不属于用户态也不属于内核态，因此cgroup不会限制它们 交互环境下子命令 1234567891011121314151617帮助：h 或 ？ ，按 q 或esc 退出帮助排序：P：以占据的CPU百分比,%CPUM：占据内存百分比,%MEMT：累积占据CPU时长,TIME+首部信息显示：uptime信息：l命令tasks及cpu信息：t命令cpu分别显示：1 (数字)memory信息：m命令退出命令：q修改刷新时间间隔：s终止指定进程：k保存文件：W 快捷键 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#h：获取帮助按下h键，top命令将为您展示所有可用的快捷键和功能说明。这是您使用top命令时的得力助手，随时提供帮助和指导。#k：结束进程选中要结束的进程，按下k键，然后输入要结束的进程的PID（进程ID），即可终止选定的进程。这是一个强大而危险的功能，可用于关闭不响应或占用过多资源的进程。#r：修改进程优先级按下r键，可以修改选定进程的优先级。通过输入要修改的进程的PID和新的优先级值，您可以更好地管理系统资源分配，提高系统性能。#f：选择显示字段按下f键，进入字段选择界面，允许您自定义top命令中显示的字段。您可以根据需求选择要显示的字段，如CPU使用率、内存占用等，以便更全面地了解系统性能。#o：按指定字段排序按下o键，可以按指定字段对进程列表进行排序。输入要排序的字段名称，top命令将根据该字段的值对进程进行排序，如按CPU使用率排序、按内存占用排序等。#s：更改刷新间隔按下s键，可以修改top命令的刷新间隔。输入新的刷新间隔值（以秒为单位），默认为3秒。通过调整刷新频率，您可以更准确地监控系统的实时性能。#q：退出top命令按下q键，可以退出top命令，返回到命令行界面。#1：切换到单核模式按下数字键1，可以切换到单核模式，只显示一个CPU核心的性能数据。这对于单核处理器的系统非常有用，可以更清晰地查看单个核心的性能情况。#i：隐藏空闲和僵尸进程按下i键，可以切换是否显示空闲和僵尸进程。当显示大量进程信息时，隐藏空闲和僵尸进程可以使界面更清晰，专注于关注的活动进程。#m：切换单位显示按下m键，可以切换单位显示方式。您可以在字节、千字节、兆字节和吉字节之间进行切换，以适应不同的内存规模。#t：显示进程和CPU信息摘要按下t键，可以在顶部显示进程和CPU信息的摘要。这个摘要可以帮助您更快速地了解系统的整体性能情况。#W：保存当前设置为配置文件按下大写字母W键，可以将当前top命令的设置保存为配置文件。下次启动top命令时，将使用保存的配置，节省您的时间和努力。#L：切换显示平均负载和启动时间按下大写字母L键，可以切换top命令的显示模式，显示平均负载和系统的启动时间。这对于监控系统负载和了解系统运行时间非常有用。#F：跟踪选定进程按下F键，可以跟踪选定的进程。在进程列表中选中要跟踪的进程，然后按下F键，top命令将仅显示该进程的信息，以便更详细地监控其性能和资源消耗。#e：切换显示所有进程按下e键，可以切换显示所有进程。默认情况下，top命令仅显示活动进程，按下e键后，将显示所有进程，包括空闲和僵尸进程。#n：设置显示进程数量按下n键，可以设置top命令显示的进程数量。通过输入新的进程数量值，您可以控制显示的进程数量，以适应您的需求。##：切换显示进程编号按下#键，可以切换是否显示进程编号。当处理大量进程时，隐藏进程编号可以使界面更清晰，减少混乱。#&amp;：设置进程筛选条件按下&amp;键，可以设置进程筛选条件。您可以输入一个或多个条件，如进程ID、进程名称等，以便于快速筛选和定位特定的进程。#u：仅显示指定用户的进程按下u键，可以仅显示指定用户的进程。输入用户名后，top命令将仅显示该用户的进程信息，有助于对特定用户的进程进行监控和管理。#z：切换颜色/显示模式按下z键，可以切换top命令的颜色和显示模式。您可以选择不同的配色方案或切换到单色模式，以适应您的偏好和环境。 选项 123456-d #指定刷新时间间隔，默认为3秒-b #全部显示所有进程-n #刷新多少次后退出-H #线程模式-p #指定进程号^%Cpu #过滤以 %CPU 开头的行 示例 1top -H -p `pidof mysqld` 范例 1234567891011121314151617181920212223#10s刷新一次[root@ubuntu ~]# top -d 10#显示指定用户的进程统计[root@ubuntu ~]# top -u jose#显示指定进程的线程[root@ubuntu ~]# top -Hp 1444#显示进程的具体命令[root@ubuntu ~]# top -p 1331 -c#输出展示多个 CPU 的情况top -b -n1 | grep ^%Cpu#获取包含百分比符号及保留两位小数的 CPU 占用率top -b -n1 | grep ^%Cpu | awk &#x27;&#123;printf(&quot;Current CPU Utilization is : %.2f%&quot;), 100-$8&#125;&#x27;#在 Linux 中查找内存消耗最大的进程top -c -b -o +%MEM | head -n 20 | tail -15#只想查看命令名称而不是命令的绝对路径top -b -o +%MEM | head -n 20 | tail -15 htopcentos来自EPEL源，比top功能更强，ubuntu 中可以直接安装 选项 123-d #: 指定延迟时间；-u UserName: 仅显示指定用户的进程-s COLUME: 以指定字段进行排序 子命令 1234s：跟踪选定进程的系统调用l：显示选定进程打开的文件列表a：将选定的进程绑定至某指定CPU核心t：显示进程树 语法 123htop#想要查看那个区的具体指标，鼠标点点点即可 如何自定义显示字段？ 设置（F2） 选择 Columns 字段，并按照下图添加即可，最右边的列为可选列 此时你会发现已经添加完成了 上图可分为 5 大区： CPU 状态区 展示每个每个 CPU 逻辑核的使用百分比，并通过不同颜色条进行区分，蓝色表示 low-prority 使用，绿色表示 normal 使用情况，红色表示 Kernel 使用情况，青色表示 vistualiz 使用情况，上图案例中共有 2 个逻辑核。 内存状态区 展示物理内存和 Swap Space 的状态，同样也使用不同的颜色条来区分，其中绿色表示已使用内存情况，蓝色表示用于缓冲的内存情况，黄色表示用于缓存的内存情况。 整体状态区 Task 表示当前系统进程总数和当前正在运行的进程数； Load average 表示过去 1、5、15 分钟的系统平均负载； Uptime 表示系统运行时长。 进程状态区 PID：进程 ID（Process ID），表示每个正在运行的进程的唯一标识符。 USER：进程的所有者（用户），显示启动进程的用户帐户。 PRI：进程的优先级（Priority），通常是一个负整数。较低的数值表示更高的优先级。 NI：进程的 Nice 值（Nice Value），用于调整进程的优先级。负值表示较高的优先级，正值表示较低的优先级。 VIRT：虚拟内存大小（Virtual Memory），表示进程已分配但未必使用的虚拟内存大小，以千字节（KB）为单位。 RES：常驻内存大小（Resident Set Size），表示进程实际占用的物理内存大小，以千字节（KB）为单位。 SHR：共享内存大小（Shared Memory），表示多个进程之间共享的内存大小，以千字节（KB）为单位。 S：进程的状态，可以是以下之一： R：运行中（Running） S：睡眠中（Sleeping） D：不可中断的休眠状态（Uninterruptible Sleep） Z：僵尸进程（Zombie） T：已停止（Stopped） t：跟踪&#x2F;停止（Tracing&#x2F;Stopped） W：等待内存交换（Paging） X：死掉（Dead） K：内核线程（Kernel Thread） %CPU：进程的 CPU 利用率，表示进程使用 CPU 的百分比。 %MEM：进程的内存使用率，表示进程使用系统内存的百分比。 TIME+：进程已运行的累计 CPU 时间，以小时:分钟:秒的格式表示。 COMMAND：进程的命令名称，显示启动进程的完整命令。 查看进程打开文件 lsof查看当前系统文件的工具。在linux环境下，一切皆文件，用户通过文件不仅可以访问常规数据，还可以访问网络连接和硬件如传输控制协议 (TCP) 和用户数据报协议 (UDP)套接字等，系统在后台都为该应用程序分配了一个文件描述符 lsof使用注意事项 需要root权限才能使用lsof命令。 lsof命令需要一定时间才能完成扫描，因此不应在生产环境下滥用。 使用lsof命令时应确保使用的是最新版本，以防止出现已知的bug。 使用时应仔细查看命令输出，尤其是对于打开套接字的程序及其连接，以避免意外暴露敏感信息。 lsof命令的扫描范围包括所有已打开的文件和网络套接字，因此执行时可能会对系统性能产生一定的影响，如果对性能敏感，应考虑使用其他更轻量级的工具。 在使用lsof命令时，应确保已经对电脑进行了必要的安全保护，以避免受到黑客攻击或数据泄露。 命令选项 12345678910111213-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程(4、6、协议、:端口、 @ip )-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息。-n: 不反向解析网络名字 字段说明 COMMAND列：打开文件的进程的名称 PID列：打开文件的进程的标识符 USER列：打开文件的进程的所有者 FD列：打开文件的进程的文件描述符 TYPE列：打开文件的类型，如REG（常规文件）、DIR（目录）、CHR（字符设备）、FIFO（管道）、SOCK（套接字）等 DEVICE列：打开文件所在的设备的编号 SIZE&#x2F;OFF列：文件的大小或偏移量 NODE列：打开文件的节点号码 NAME列：打开文件的路径和文件名。 范例：查看某个进程打开的所有文件 12345678910111213#例如查询sshd服务进程的PID号[root@jeven ~]# ps aux |grep ssh root 9347 0.0 0.0 112756 4312 ? Ss 06:22 0:00 /usr/sbin/sshd -D root 30102 0.0 0.0 161316 6052 ? Ss 17:14 0:00 sshd: root@pts/1 root 30109 0.0 0.0 161312 6040 ? Ss 17:14 0:00 sshd: root@notty root 30154 0.0 0.0 74176 2940 ? Ss 17:14 0:00 /usr/libexec/openssh/sftp-server root 31429 0.0 0.0 112712 968 pts/1 S+ 18:57 0:00 grep --color=auto ssh#使用lsof查询该进程打开的所有文件[root@jeven ~]#lsof -p 9347 #或者这种方法[root@centos8 ~]#lsof -p `pidof ssh` 范例：查看某个用户打开的所有文件 1[root@jeven ~]# lsof -u apache |head 范例：查看某个文件被哪些进程打开 1[root@centos8 ~]#lsof /var/log/messages 范例：查看某个端口被哪些进程占用 12345#查看所有网络连接[root@jeven ~]#lsof -i #查看某个端口被哪些进程占用[root@jeven ~]# lsof -i :22 范例 123456789101112131415161718192021222324252627282930#lsof 列出当前所有打开的文件[root@centos8 ~]#lsof | head#查看由登陆用户启动而非系统启动的进程[root@centos8 ~]#lsof /dev/pts/1[root@centos8 ~]#lsof `tty`#查看指定程序打开的文件[root@centos8 ~]#lsof -c httpd[root@centos8 ~]#lsof -c bc#查看指定目录下被打开的文件，参数+D为递归列出目录下被打开的文件，参数+d为列出目录下被打开的文件[root@centos8 ~]#lsof +D /var/log/[root@centos8 ~]#lsof +d /var/log/ #查看打开某个类型文件的进程列表[root@jeven ~]# lsof -t /usr/sbin/httpd #查看所有网络连接，通过参数-i查看网络连接的情况，包括连接的ip、端口等以及一些服务的连接情况，例如：sshd等。也可以通过指定ip查看该ip的网络连接情况[root@centos8 ~]#lsof -i –n [root@centos8 ~]#lsof -i@127.0.0.1#查看端口连接情况，通过参数-i:端口可以查看端口的占用情况，-i参数还有查看协议，ip的连接情况等[root@centos8 ~]#lsof -i :80 -n#查看指定进程打开的网络连接，参数-i、-a、-p等，-i查看网络连接情况，-a查看存在的进程，-p指定进程[root@centos8 ~]#lsof -i –n -a -p 9527#查看指定状态的网络连接，-n:no host names, -P:no port names,-i TCP指定协议，-s指定协议状态通过多个参数可以清晰的查看网络连接情况、协议连接情况等[root@centos8 ~]#lsof -n -P -i TCP -s TCP:ESTABLISHED 范例：利用 lsof 恢复正在使用中的误删除的文件 12345678910111213141516171819202122232425262728#打开文件[root@ubuntu ~]# tail -f /var/log/syslog#删除文件[root@ubuntu ~]# rm -rf /var/log/syslog[root@ubuntu ~]# ls /var/log/syslogls: cannot access &#x27;/var/log/syslog&#x27;: No such file or directory#找出进程[root@ubuntu ~]# ps aux | grep tailroot 6037 0.0 0.1 217128 976 pts/4 S+ 02:29 0:00 tail -f /var/log/syslog#查看内存映射[root@ubuntu ~]# ll /proc/6037/fd/total 0lrwx------ 1 root root 64 May 29 02:32 0 -&gt; /dev/pts/4lrwx------ 1 root root 64 May 29 02:32 1 -&gt; /dev/pts/4lrwx------ 1 root root 64 May 29 02:32 2 -&gt; /dev/pts/4lr-x------ 1 root root 64 May 29 02:32 3 -&gt; &#x27;/var/log/syslog (deleted)&#x27;lr-x------ 1 root root 64 May 29 02:32 4 -&gt; anon_inode:inotify#打开，文件内容还在[root@ubuntu ~]# cat /proc/6037/fd/3#恢复[root@ubuntu ~]# cat /proc/6037/fd/3 &gt; /var/log/syslog[root@ubuntu ~]# ll /var/log/syslog-rw-r--r-- 1 root root 1885719 May 29 02:38 /var/log/syslog 二、设置和调整进程优先级一个进程在运行的时候会涉及到内核态与用户态的转换，关于进程的优先级，top命令查看到两个相关的值PR与NI PR-》内核态使用的值 NI-》用户态使用的值 系统调度器最终是根据PR的值来决定进程的运行顺序 PR值越小优先级越高 PR值&#x3D;20+NICE值 # NICE值的范围为-20到+19 用户无法修改内核态的PR值，但是我们可用nice命令修改用户态得NI值，来影响内核态的PR值 123系统优先级：0-139, 数字越小，优先级越高,各有140个运行队列和过期队列实时优先级: 99-0 值最大优先级最高nice值：-20到19，对应系统优先级100-139 进程优先级调整 123静态优先级：100-139进程默认启动时的nice值为0，优先级为120只有根用户才能降低nice值（提高优先性） nice命令： 以指定的优先级来启动进程 12nice [OPTION] [COMMAND [ARG]...]-n, --adjustment=N add integer N to the niceness (default 10) 范例 123[root@ubuntu ~]# nice -n 11 ping www.baidu.com[root@ubuntu ~]# ps axo pid,cmd,nice | grep ping 3887 ping www.baidu.com 11 renice命令： 可以调整正在执行中的进程的优先级 1renice -n 优先级号 pid 范例 123456789[root@centos8 ~]#renice -n -20 21182106 (process ID) old priority -10, new priority -20[root@centos8 ~]#ps axo pid,cmd,nice |grep ping 2118 ping 127.0.0.1 -20 2200 grep --color=auto ping 0#越界不会报错[root@ubuntu ~]# renice -n -30 21183734 (process ID) old priority 0, new priority -20 三、进程对应的内存映射进程和内存之间的使用情况，查看进程占了哪部分内存 12345pmap [options] pid [...]-x: 显示详细格式的信息-X：显示更详细信息、-d：显示设备 另外一种实现 1cat /proc/PID/maps 范例 1234567[root@centos8 ~]#pmap 3347733477: ping 127.0.0.1000055f708aa7000 56K r-x-- ping000055f708cb5000 4K r---- ping000055f708cb6000 4K rw--- ping000055f708cb7000 140K rw--- [ anon ]000055f70a7cc000 132K rw--- [ anon ] 四、查看系统&#x2F;库调用查看系统调用 strace 12345678910[root@centos7 ~]#dnf -y install strace[root@centos7 ~]#strace lsexecve(&quot;/usr/bin/ls&quot;, [&quot;ls&quot;], 0x7ffd4b9dad50 /* 25 vars */) = 0brk(NULL) = 0x55ed4c7d7000arch_prctl(0x3001 /* ARCH_??? */, 0x7ffd500ae390) = -1 EINVAL (Invalid argument)access(&quot;/etc/ld.so.preload&quot;, R_OK) = -1 ENOENT (No such file or directory)openat(AT_FDCWD, &quot;/etc/ld.so.cache&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=73944, ...&#125;) = 0mmap(NULL, 73944, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fce5dfa7000close(3) 查看库调用 ltrace 1234567891011#查看库调用[root@centos7 ~]#yum -y install ltrace[root@centos7 ~]# ltrace ls__libc_start_main(0x402910, 1, 0x7ffcca28b1b8, 0x4129a0 &lt;unfinished ...&gt;strrchr(&quot;ls&quot;, &#x27;/&#x27;) = nilsetlocale(LC_ALL, &quot;&quot;) = &quot;en_US.utf8&quot;bindtextdomain(&quot;coreutils&quot;, &quot;/usr/share/locale&quot;) = &quot;/usr/share/locale&quot;textdomain(&quot;coreutils&quot;) 五、系统资源统计dstat 由 pcp-system-tools 包提供，但安装 dstat 包即可，可用于代替 vmstat，iostat功能 12345678910111213141516171819202122232425dstat [-afv] [options..] [delay [count]]-c #显示cpu相关信息-C 0,3,...,total #指定显示项，cpu0,cpu3和总计-d #显示disk相关信息-D total,sda,sdb,... #指定显示项，sda，sdb和总计-g #显示page相关统计数据-m #显示memory相关统计数据-n #显示network相关统计数据-p #显示process相关统计数据-r #显示io请求相关的统计数据-s #显示swapped相关的统计数据-S swap1,total #指定swap--tcp #显示所有tcp信息--udp #显示所有udp信息--unix --raw--socket #显示所有socket信息--ipc--top-cpu #显示最占用CPU的进程--top-io #显示最占用io的进程--top-mem #显示最占用内存的进程--top-latency #显示延迟最大的进程--vm #显示vm统计信息--vm-adv #显示高级vm统计信息 范例 12[root@centos8 ~]#yum -y install dstat[root@centos8 ~]#dstat 1 6","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://aquapluto.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"性能分析命令","slug":"Linux/process-manage/performance-analysis","date":"2025-08-21T02:58:45.000Z","updated":"2025-08-28T12:33:05.291Z","comments":true,"path":"Linux/process-manage/performance-analysis/","permalink":"https://aquapluto.github.io/Linux/process-manage/performance-analysis/","excerpt":"","text":"一、内存性能分析freefree 命令用于显示Linux系统上的内存使用情况。它提供了有关物理内存（RAM）和交换空间（swap）的信息，包括已使用、空闲、缓冲区和缓存内存等 12345678-b 以字节为单位-m 以MB为单位-g 以GB为单位-h 易读格式-o 不显示-/+buffers/cache行-t 显示RAM + swap的总和-s n 刷新间隔为n秒-c n 刷新n次后即退出 缓冲区（buffers）是操作系统用来临时存储I&#x2F;O数据的内存区域。例如，当读写文件时，内核会将磁盘上的数据暂时存放在缓冲区内，然后再批量写，以减少磁盘碎片和硬盘反复寻道，快速处理后续的I&#x2F;O请求。这样可以提高系统性能，减少对磁盘的直接访问，主要用于硬盘与内存之间的数据交互，缓存(cached) 是指文件的内容要被多个进程使用的时候，则可以将内容放入缓存区，则后续就可以直接从内存中读，而不用再消耗IO 缓存（cache）主要指的是页面缓存或文件缓存。这部分内存用来存储最近访问过的文件内容，使得再次访问同一文件时能更快地从内存而不是硬盘中读取数据。还包括inode缓存等内核用于加速文件系统操作的数据结构，主要作用于CPU和内存之间的数据交互（本来要用IO读硬盘文件，现在变成了读内存） 向&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches中写入相应的修改值，会清理缓存。建议先执行sync（sync 命令将所有未写的系统缓冲区写到磁盘中，包含已修改的 i-node、已延迟的块 I&#x2F;O 和读写映射文件）。执行echo1、2、3 至 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches, 达到不同的清理目的 如果因为是应用会存在像内存泄露、溢出的问题时，从swap的使用情况是可以比较快速可以判断的，但通过执行free 反而比较难查看。但核心并不会因为内存泄露等问题并没有快速清空buffer或cache（默认值是0），生产也不应该随便去改变此值。 一般情况下，应用在系统上稳定运行了，free值也会保持在一个稳定值的。当发生内存不足、应用获取不到可用内存、出现OOM错误等问题时，还是更应该去分析应用方面的原因，否则，清空buffer，强制腾出free的大小，可能只是把问题给暂时屏蔽了。 排除内存不足的情况外，除非是在软件开发阶段，需要临时清掉buffer，以判断应用的内存使用情况；或应用已经不再提供支持，即使应用对内存的时候确实有问题，而且无法避免的情况下，才考虑定时清空buffer。 1234[root@ubuntu2004 ~]#free -h total used free shared buff/cache availableMem: 3.8Gi 352Mi 425Mi 1.0Mi 3.0Gi 3.2GiSwap: 0B 0B 0B 字段说明 total：物理内存的总量，包括实际可用内存和内核保留的内存 used：已使用的物理内存量，包括用于进程和系统的内存 free：空闲的物理内存量，尚未分配给任何进程 当前完全没有被程序使用的内存 shared：被共享的内存量，通常用于共享内存段的进程（如进程间通信机制），即多个进程共享的内存 buff&#x2F;cache：用于缓冲区和缓存的内存量。这包括Linux内核用于缓存文件系统数据的内存，以及用于文件I&#x2F;O的内存缓冲区 cache在有需要时，是可以被释放出来以供其它进程使用的（当然，并不是所有cache都可以释放，比如当前被用作ramfs的内存） available：可用内存量，表示系统当前可供新进程使用的内存，包括缓冲区和缓存，buffer、cache可以释放大部分，所以这里近似等于 free+buffer&#x2F;cache的大小 真正表明系统目前可以提供给新启动的应用程序使用的内存 Mem：物理内存的相关信息，包括总内存空间、使用、剩余等相关信息。 Swap：交换空间的信息，包括总交换空间、已使用的交换空间和空闲交换空间。 公式 123used = total - free - buffers - cache buff/cache = buffers +cache程序可用的 &lt;= free + buffers + cache buffers/cached不是100%都能释放出来使用的，“可用内存”其实就是个近似值。新版本系统的输出中有一个available项目表示可用内存，值小于 free + buff/cache，内核 3.14 之后支持该特性（虽然也不是绝对意义上的精确的可用内存大小，囧）。 Linux 2.4.10 内核之前，磁盘的缓存有两种，即 Buffer Cache和 Page Cache。前者缓存管理磁盘文件系统时读取的块，后者存放访问具体文件内容时生成的页。在 2.4.10 之后，Buffer Cache这个概念就不存在了，这些数据被放在Page Cache中（这种 Page 被称为 Buffer Pages）。 简而言之，现在磁盘的 cache 只有 Page Cache 一种，在Page Cache 中，有一种Page叫Buffer Page ，这种Page都与一个叫buffer_head的数据结构关联，这些页也就在内存统计中用buffers这个指标来单独统计了。 范例: 清理缓存 12345678910111213[root@centos8 ~]#cat /proc/sys/vm/drop_caches0[root@centos8 ~]#dd if=/dev/zero of=/f1.img bs=1M count=1024[root@centos8 ~]#free -h total used free shared buff/cache availableMem: 1.8Gi 355Mi 724Mi 9.0Mi 726Mi 1.2GiSwap: 2.0Gi 0B 2.0Gi[root@centos8 ~]#echo 3 &gt; /proc/sys/vm/drop_caches[root@centos8 ~]#free -h total used free shared buff/cache availableMem: 1.8Gi 320Mi 1.3Gi 9.0Mi 152Mi 1.3GiSwap: 2.0Gi 0B 2.0Gi smemsmem 是一个用于查看 Linux 系统中进程内存使用情况的工具。它提供了详细的内存统计信息，包括物理内存、虚拟内存、共享内存、缓冲区和缓存等各种内存指标。smem 命令的功能比标准的 ps 或 top 命令更加详细，可以帮助我们更好地了解各个进程占用内存的情况。 该命令需要额外安装，具体安装方式如下： 12yum install -y epel* # 需安装扩展源（因为本地软件仓库中没有找到smem软件包）或下载源码进行编译安装yum install -y smem 语法 123456789101112smem [选项]-r：按照内存使用量的逆序（从高到低）排序显示进程列表。-u：以用户模式显示内存使用情况，按照用户分类显示内存使用情况。-U：显示虚拟内存（VIRT）的信息。-P：显示共享内存（SHR）的信息。-c：显示缓冲区的信息。-C：显示缓存的信息。-k：指定按KB显示。-p：指定按百分比显示。-P：指定具体的进程。-s：指定排序规则（如 -s uss，表示对 USS 列进行排序 - 默认为升序） 字段输出解释： PID：进程ID。 User：进程所属用户。 Command：进程的命令行。 Swap：进程占用的交换空间。 USS：唯一内存使用（Unique Set Size），表示进程独占的内存。只计算进程独自占用的内存大小,不包含任何共享的部分 PSS：共享内存使用（Proportional Set Size），表示进程独占内存加上共享内存的平均值。 RSS：物理内存使用（Resident Set Size），表示进程当前实际占用的物理内存。 默认情况下，smem 命令以物理内存（RES）的信息排序，并显示前10个进程。 不添加任何选项 smem 显示内存单位并指定字段进行排序 123smem -k -s uss# 显示每个进程占用的系统内存大小 以百分比显示并指定字段进行排序 123smem -p -s uss# 显示每个进程占用系统内存的百分比 查看每个用户使用内存的情况 smem -u 查看指定进程使用系统内存的情况 123smem -k -P dockerd# 查看dockerd进程使用系统内存的情况 虚拟内存信息 vmstat用于监控系统性能和虚拟内存统计的命令。它提供了关于CPU、内存、磁盘I&#x2F;O和系统上下文切换等方面的信息。 虚拟内存 虚拟内存是操作系统提供的一种内存管理技术，操作系统会为每个进程分配一套独立的，连续的，私有的内存空间，让每个程序都以为自己独享所有主存的错觉，这样做的目的是方便内存管理。 程序所使用的内存是虚拟内存 CPU使用的内存是物理内存 MMU LTB 虚拟内存地址和物理内存地址之间的映射和转换由CPU中的内存管理单元(MMU)进行管理 1234[root@centos ~]#vmstatprocs -----------memory------------- ---swap-- -----io--- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 1305664 2108 368540 0 0 1 1 20 36 0 0 100 0 0 字段说明 procs：显示队列和等待状态 r 列：表示运行队列中的进程数，即当前正在运行的进程数。如果这个值长期大于系统 CPU 个数，说明 CPU 紧张，需进行 CPU 升级（即增加系统 CPU）。 b 列：表示在等待资源的进程数，即处于不可中断（blocked）状态的进程数，通常是等待 I&#x2F;O、内存交换完成的进程数。由于硬盘速度特别慢而导致内存同步的时候没成功，那么现在告诉程序，说你先不要产生数据，这就是阻塞 b越大证明硬盘压力很大 memory：显示物理内存状态 swpd 列：表示交换（swap）的虚拟内存使用量，表示从实际物理内存已经交换到交换空间的数据量，我这里的值为 0，因为我压根就没有启用 Swap Space。如果你启用了交换空间，发现swpd 列下的值很大，只要 swap 字段下的 si、so 列的值长期为 0，这也不会影响系统性能。 free 列：表示当前可用的空闲物理内存。 buff 列：Buffers Cache，表示内存缓冲区缓存的数据量，一般对块设备的读写才需要缓冲（即通常用于文件I&#x2F;O缓存）。 cache 列：Page Cache，表示内存的页高速缓存的数据量，一般作为文件系统的缓存（即通常用于文件系统缓存），频繁访问的文件都会被缓存，如果 cache 列的值比较大，说明页缓存的文件数较多，如果此时 io 字段中的 bi 列的值较小，说明文件系统效率较好。 swap：显示交换分区读写情况 si 列：表示每秒从磁盘（即交换空间）交换到内存的数据量（swap in)（单位KB&#x2F;s），内存进，从swap出。 so 列：表示每秒从内存交换到磁盘（即交换空间）的数据量（swap out）（单位KB&#x2F;s），内存出，进到swap里面，腾出内存空间运行应用程序。 说明：如果 si、so 长期不为 0，那我们的 Linux 系统的物理内存资源肯定不足了。为什么呢？你想一想，根据内存的相关机制，我们知道长期不为 0，说明数据频繁地在物理内存和交换空间中交换数据，如：需要使用内存的进程会在内存中运行，然后内存会将不常用的文件数据交换到 Swap Space，这样的话 si、so 值势必是不会为 0 的，而且会存在频繁波动。如果发现si、so里面有数据，说明内存可能不够用了 io：显示磁盘读写情况 bi 列：表示每秒从块设备（磁盘）读取的块数量（blocks in）（单位KB&#x2F;s），从块设备读入数据到系统的速率(kb&#x2F;s)，进内存。 bo 列：表示每秒写入块设备（磁盘）的块数量（blocks out）（单位KB&#x2F;s），保存数据至块设备的速率，出内存 说明：如果 bi + bo 的值大于 1000KB&#x2F;s，且 wa 值较大，则表示系统磁盘 I&#x2F;O 有瓶颈，应该提高磁盘的读写性能。 system：显示采集间隔内发生的中断数 in 列：每秒中断的数量，包括时钟中断、网络中断等。 cs 列：每秒上下文切换的数量，包括进程切换和内核线程切换。 说明：如果这两个值越大，说明内核消耗的 CPU 时间会越多。 cpu：显示 CPU 的使用状态 us 列：用户空间占用CPU时间的百分比。如果长期大于 50%，就需要考虑优化程序或算法。 sy 列：内核空间占用CPU时间的百分比。如果 us + sy 长期大于 80%，说明 CPU 资源不足。 id 列：CPU空闲时间的百分比。 wa 列：等待 I&#x2F;O 完成的CPU时间的百分比。wa 越高说明 IO 等待越严重，一般如果 wa 超过 20%，说明 IO 等待严重（可能是因为磁盘大量的随机读写造成）。 st 列：用于虚拟机监控程序（hypervisor）的CPU时间的百分比（仅在虚拟化环境中可见） 选项 12345678-a #分开显示活动和非活动内存-s #显示事件统计-d #统计磁盘设备相关信息-D #综合统计磁盘-p &lt;dev&gt; #统计指定分区-S &lt;char&gt; #指定显示单位 k|K|m|M-w #以宽格式显示-t #显示时间 范例 12345678#每秒显示一次[root@ubuntu ~]# vmstat 1#使用vmstat检测，每隔1秒刷新一次，共刷新3次[root@localhost proc]# vmstat 1 3#显示统计数据[root@ubuntu ~]# vmstat -s 范例 123456# vmstat -1 # dd if=/dev/zero of=/aa bs=1G count=1 //这条命令之后查看bo的数值，发现bo产生数据 记录了1+0 的读入 记录了1+0 的写出 1073741824字节(1.1 GB)已复制，4.90872 秒，219 MB/秒#find / //这条命令之后查看bi，发现bi产生数据 如果 一直开着vmstat发现bo 5秒钟一个数，这就是因为脏数据5秒钟一次 如果要拿这个数据做图，bo的第一个数据一定要剔除到，这个数字是上一次重启到敲vmstat这条命令之间的平均值，所以这个数字没用 二、CPU性能分析负载查询 uptime&#x2F;proc&#x2F;uptime 包括两个值，单位 s 系统启动时长 空闲进程的总时长（按总的CPU核数计算）uptime 和 w 显示以下内容 当前时间 系统已启动的时间 当前上线人数 系统平均负载（1、5、15分钟的平均负载，一般不会超过1，超过5时建议警报，15分钟的平均CPU负载，数字越小越好） 系统平均负载: 指在特定时间间隔内运行队列中的平均进程数,通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。如果每个CPU内核的任务数大于5，那么此主机的性能有严重问题 负载是指等待CPU资源的进程数量，所以这三个负载值一般不要长期超过系统的 CPU 核数，否则负载较高，影响系统性能（但不是绝对的，偶尔大于系统 CPU 核数也是每问题的）。 如：linux主机是1个双核CPU，当Load Average 为6的时候说明机器已经被充分使用 12345678910111213[root@centos8 ~]#uptime09:38:34 up 1 day, 1:04, 2 users, load average: 0.00, 0.00, 0.0009:38:34 #系统当前时间up 1 day, 1:04 #系统己开机运行时长2 users #当前登录到系统的用户数量load average: 0.00, 0.00, 0.00 #系统的平均负载，1分钟，5分钟，15分钟[root@centos8 ~]#w09:38:29 up 1 day, 1:04, 2 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.0.0.1 Wed08 0.00s 0.32s 0.00s wroot pts/1 10.0.0.1 09:10 5:25 0.06s 0.00s /bin/bash./ping.sh 显示CPU相关统计 mpstatmpstat 是 Multiprocessor Statistics（即多处理器统计），它用于显示多核CPU系统中每个CPU核心的性能统计信息。这个命令可以帮助系统管理员监控和分析系统的CPU使用情况，尤其是在多核 CPU 的环境中。一般地，有些 Linux 发行版默认没有安装次工具，需我们手动安装。来自于sysstat包 该命令与 vmstat 命令类似，mpstat 是通过 &#x2F;proc&#x2F;stat 里面的状态信息进行统计的，mpstat 的好处在于，它可以查看多核 CPU 中每个 CPU 计算核的统计数据的情况，而 vmstat 只能查看系统整体 CPU 的情况。 1234567891011121314[root@centos ~]#mpstatLinux 3.10.0-1160.el7.x86_64 (centos) 09/16/2023 _x86_64_ (2 CPU)04:49:20 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle04:49:20 PM all 0.03 0.00 0.05 0.00 0.00 0.00 0.00 0.00 0.00 99.92#每一秒查看CPU利用情况[root@centos ~]#mpstat 1 #查看第一颗cpu运行情况[root@ubuntu ~]# mpstat -P 0#查看所有[root@ubuntu ~]# mpstat -P ALL 字段输出解释： Linux 3.10.0-1160.el7.x86_64 (centos)：显示操作系统版本和主机名。 09&#x2F;16&#x2F;2023：显示当前日期。 x86_64：显示系统架构（在此示例中为x86_64，表示64位系统）。 (2 CPU)：显示 CPU 核心数量，本例中有 2 个CPU核心。 04:49:20 PM：显示统计信息的时间戳。 CPU：处理器的 ID 号，采集时不指定则默认为系统整体 CPU 情况（all 表示系统整体 CPU 情况，其他如 CPU 0、CPU 1 等）。 %usr：用户空间占用 CPU 时间的百分比。 %nice：优先级较高的用户空间占用 CPU 时间的百分比。 %sys：内核空间占用 CPU 时间的百分比。 %iowait：CPU 等待 I&#x2F;O 操作完成的百分比。涉及到磁盘的IO或者网络的IO，值过大说明磁盘和网络的性能较差 %irq：CPU 处理硬件中断的百分比。 %soft：CPU 处理软件中断的百分比。 %steal：CPU 被虚拟机监控程序（hypervisor）”偷取”的百分比，即被嵌套虚拟机跑进程所使用的时间 %guest：运行虚拟机中的操作系统时，CPU花费在虚拟机中的百分比，即运行虚拟化主机cpu自身时间的占比 %gnice：虚拟机中运行的优先级较高的用户空间占用CPU时间的百分比，即运行虚拟cpu上的nice 进程的占比 %idle：CPU空闲时间的百分比，值越高，CPU利用率越低 Average：平均值，如果指定了采集次数，系统为自动为我们计算出相关字段的平均值。 三、磁盘IO性能分析统计CPU和设备IO信息 iostatiostat 命令是用于监视 Linux 系统中磁盘和 CPU 使用情况的命令行工具。它可以提供有关系统的磁盘 I&#x2F;O 和 CPU 使用的详细统计信息 此工具由sysstat包提供 123456常用选项:-c 只显示CPU行-d 显示设备（磁盘）使用状态-k 以KB(千字节)为单位显示输出-t 在输出中包括时间戳-x 在输出中包括扩展的磁盘指标 范例 12345678910111213141516[root@centos8 ~]#iostatLinux 4.18.0-80.el8.x86_64 (centos8.localdomain) 01/09/2020 _x86_64_ (4CPU)avg-cpu: %user %nice %system %iowait %steal %idle 0.01 0.00 0.06 0.00 0.00 99.93Device tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 0.31 2.57 3.52 238227 326708scd0 0.01 0.14 0.00 13140 0#每秒刷新一次数据[root@ubuntu ~]# iostat 1#每隔1秒刷新一次，共刷新3次[root@centos8 ~]#iostat 1 3#指定设备（sda）的磁盘 I/O 统计信息，包括磁盘的读写速度、I/O 请求的响应时间等[root@centos8 ~]#iostat -d sda -t -k 1 3 字段说明 %usr：用户空间进程占用的CPU %nice：调整优先级占用的CPU %system：内核空间进程占用的CPU %iowait：等待IO，涉及到磁盘的IO或者网络的IO，值过大说明磁盘和网络的性能较差 %steal：被嵌套虚拟机跑进程所使用的时间 %idle：空闲值，值越高，CPU利用率越低 Device：磁盘设备的名称，表示正在监视的磁盘或分区。 tps：每秒传输的 I&#x2F;O 操作次数。这个值表示每秒完成的读取和写入磁盘的总操作数，即该设备每秒的传输次数，”一次传输”意思是”一次I&#x2F;O请求”。多个逻辑请求可能会被合并为”一次I&#x2F;O请求”。”一次传输”请求的大小是未知的 kB_read&#x2F;s：每秒从磁盘读取的数据量。这个值表示每秒从磁盘读取的数据量，以千字节（KB）为单位。 kB_wrtn&#x2F;s：每秒写入磁盘的数据量。这个值表示每秒写入磁盘的数据量，以千字节（KB）为单位。 kB_read：自系统启动以来从磁盘读取的总数据量。这个值表示自系统启动以来累积的总读取数据量，以千字节（KB）为单位。 kB_wrtn：自系统启动以来写入磁盘的总数据量。这个值表示自系统启动以来累积的总写入数据量，以千字节（KB）为单位。 范例 1234[root@centos8 ~]#iostat -d sda 1 3 -xLinux 4.18.0-193.el8.x86_64 (centos8.wangxiaochun.com) 11/24/2020 _x86_64_(2 CPU)Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %utilsda 12.70 2.93 523.99 183.34 0.05 0.78 0.41 20.93 0.37 0.75 0.00 41.26 62.53 0.50 0.78 字段说明 r&#x2F;s: 每秒合并后读的请求数 w&#x2F;s: 每秒合并后写的请求数 rsec&#x2F;s：每秒读取的扇区数 wsec&#x2F;：每秒写入的扇区数 rKB&#x2F;s：每秒向设备发出的读取请求数 wKB&#x2F;s：每秒向设备发出的写入请求数 rrqm&#x2F;s：每秒这个设备相关的读取请求有多少被合并了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同块的数据，FS会将这个请求合并） wrqm&#x2F;s：每秒这个设备相关的写入请求有多少被合并了 %rrqm: 读取请求在发送到设备之前合并在一起的百分比 %wrqm: 写入请求在发送到设备之前合并在一起的百分比 avgrq-sz：平均请求扇区的大小 avgqu-sz：是平均请求队列的长度。毫无疑问，队列长度越短越好 await：每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。 svctm：表示平均每次设备I&#x2F;O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I&#x2F;O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I&#x2F;O队列等待太长，系统上运行的应用程序将变慢。 %util：在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util &#x3D; 0.8&#x2F;1 &#x3D; 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。 监视磁盘I&#x2F;O iotop来自于iotop包 iotop命令是一个用来监视磁盘I&#x2F;O使用状况的top类工具，iotop具有与top相似的UI，其中包括PID、用户、I&#x2F;O、进程等相关信息，可查看查看哪些进程正在读取或写入磁盘，可定位哪个进程消耗IO的时间最长 123456789[root@centos8 ~]#iotopTotal DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/sActual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/sTID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND#第一行：Read和Write速率总计#第二行：实际的Read和Write速率 字段输出解释： TID：线程或进程的唯一标识符（Thread&#x2F;Task ID），表示正在进行磁盘 I&#x2F;O 操作的进程或线程的ID。 PRIO：进程的优先级（Priority），通常用于指示进程的执行优先级。 USER：执行磁盘 I&#x2F;O 操作的用户的用户名。 DISK READ：磁盘读取速率，表示进程正在从磁盘读取数据的速度。以字节&#x2F;秒（Bytes per Second）为单位显示。 DISK WRITE：磁盘写入速率，表示进程正在向磁盘写入数据的速度。以字节&#x2F;秒为单位显示。 SWAPIN：表示进程从交换空间中读取数据的速率，通常用于虚拟内存操作。以字节&#x2F;秒为单位显示。 IO&gt;：磁盘 I&#x2F;O 操作的总和，包括读取和写入。以百分比形式表示，表示磁盘 I&#x2F;O 占用的总带宽。 COMMAND：正在进行磁盘 I&#x2F;O 操作的进程或线程的命令名称。 iotop常用参数 1234567891011121314-o #只显示正在产生I/O的进程或线程，除了传参，可以在运行过程中按o生效-b #非交互模式，一般用来记录日志-n NUM|--iter=NUM #设置监测的次数，默认无限。在非交互模式下很有用-d SEC|--delay=SEC #设置每次监测的间隔，默认1秒，接受非整形数据例如1.1-p PID|--pid=PID #指定监测的进程/线程-u USER|--user=USER #指定监测某个用户产生的I/O-P #仅显示进程，默认iotop显示所有线程-a #显示累积的I/O，而不是带宽-k #使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用-t #加上时间戳，非交互非模式-q #禁止头几行，非交互模式，有三种指定方式-q #只在第一次监测时显示列名-qq #永远不显示列名-qqq #永远不显示I/O汇总 交互按键 1234567left和right方向键：改变排序r：反向排序o：切换至选项--onlyp：切换至--processes选项a：切换至--accumulated选项q：退出i：改变线程的优先级 四、网络性能分析显示网络带宽使用情况 iftop和ethtool通过EPEL源的 iftop 包 可以看到机器和哪个远程主机的网络带宽占用比较高 选项 123456789101112-h #显示帮助-n #以IP的形式显示主机-N #直接显示端口号，而不是服务名-p #显示同一网段其它主机的流量-b #不显示图形化的进度条-B #以 bytes 为单位显示网络带宽-a #以数据包为单位显示带宽-i #指定监听的网卡-F #只显示ipv4流量-G #只显示ipv6流量-l #显示本地ipv6流量，默认关闭-P #显示流量端口号 范例 1234567891011[root@centos8 ~]#iftop -ni eth0TX：总的发送数据包速度RX：总的接收数据包速度peak：峰值#只监听ens160上 ipv4的流量[root@ubuntu ~]# iftop -nF ens160#显示进出流量的端口号[root@ubuntu ~]# iftop -nPF ens160 ethtool可以看到总带宽 1[root@rocky8 ~]#ethtool eth0 查看网络实时吞吐量 nloadnload 是一个实时监控网络流量和带宽使用情况，以数值和动态图展示进出的流量情况,通过EPEL源安装 选项 12345-m #显示所有设备-t N #数据刷新频率，单位毫秒，默认500-u h|b|k|m|g|H|B|K|M|G #显示单位(h: auto b: Bit/s k: kBit/s m: MBit/s H:auto B: Byte/s K: kByte/s M: MByte/s)-U h|b|k|m|g|H|B|K|M|G #总流量显示单位devices #指定设备 字段说明 12345Curr #当前流量Avg #平均流量Min #最小流量Max #最大流量Ttl #总流量 界面操作 123上下方向键、左右方向键、enter键或者tab键都就可以切换查看多个网卡的流量情况按 F2 显示选项窗口按 q 或者 Ctrl+C 退出 nload 范例 1234567891011121314#查看所有网络设备进出流量，第一页显于一个设备[root@ubuntu ~]# nload#一屏显示所有设备流量[root@ubuntu ~]# nload -m#在nload后面指定网卡，可以指定多个,按左右键分别显示网卡状态[root@ubuntu ~]#nload eth0 eth1#1000 毫秒刷新一次数据[root@ubuntu ~]# nload -t 1000 ens160#设置单位：显示两种单位一种是显示Bit/s、一种是显示Byte/s，默认是以Bit/s，也可不显示/s[root@ubuntu ~]#nload -u M eth0 查看进程网络带宽的使用情况 nethogsNetHogs是一个开源的命令行工具（类似于Linux的top命令），用来按进程或程序实时统计网络带宽使用率 红帽系统的nethogs包来自于EPEL源 选项 123456-d #数据刷新时间间隔，默认1秒-v #显示单位(0：KB/s，1：total KB，2：total B，3：total MB)-t #跟踪显示-s #按发送数据量排序-a #显示所有设备数据，包含回环设备device #指定设备 交互式命令 1234q #退出s #根据发送数据量排序r #根据接收数据量排序m #切换显示单位 范例 12345#默认[root@ubuntu ~]# nethogs#显示指定设备数据[root@ubuntu ~]# nethogs ens160 网络监视工具iptraf-ng来自于iptraf-ng包,可以进网络进行监控,对终端窗口大小有要求 选项 12345678-i &lt;iface&gt; #指定网络设备，默认所有-d &lt;iface&gt; #指定网络设备，显示详细信息-s &lt;iface&gt; #指定网络设备，统计tcp和udp信息-z &lt;iface&gt; #指定网络设备，统计数据包-B #在后台执行-f #清除所有锁和计数器-t N #仅统计指定的时长，单位分钏-L &lt;logfile&gt;#指定日志文件 范例 12#对终端窗口大小有要求,如果太小否则无法显示[root@centos8 ~]#iptraf-ng","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://aquapluto.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"源码编译安装","slug":"Linux/software-manage/source-code-compilation","date":"2025-08-21T02:46:28.000Z","updated":"2025-08-28T12:33:05.363Z","comments":true,"path":"Linux/software-manage/source-code-compilation/","permalink":"https://aquapluto.github.io/Linux/software-manage/source-code-compilation/","excerpt":"","text":"1 编译安装过程利用编译工具，通常只需要三个大的步骤 ./configure (1) 通过选项传递参数，指定安装路径、启用特性等；执行时会参考用户的指定以及Makefile.in文件生成Makefile (2) 检查依赖到的外部环境，如依赖的软件包 make 根据Makefile文件，会检测依赖的环境，进行构建应用程序 make install 复制文件到相应路径 注意：安装前可以通过查看README，INSTALL获取帮助 1.1 编译安装准备准备：安装相关的依赖包 开发工具：make, gcc (c&#x2F;c++编译器GNU C Complier) 开发环境：开发库（glibc：标准库），头文件，可安装开发包组 Development Tools 软件相关依赖包 生产实践：基于最小化安装的系统建议安装下面相关包 1yum install gcc make autoconf gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel vim lrzsz tree tmux lsof tcpdump wget net-tools iotop bc bzip2 zip unzip nfs-utils man-pages 1.2 编译安装第一步：运行 configure 脚本，生成 Makefile 文件 其选项主要功能： 可以指定安装位置 指定启用的特性 安装路径设定 123--prefix=/PATH：指定默认安装位置,默认为/usr/local/--sysconfdir=/PATH：配置文件安装位置System types：支持交叉编译 软件特性和相关指定： 1234567Optional Features: 可选特性--disable-FEATURE--enable-FEATURE[=ARG]Optional Packages: 可选包--with-PACKAGE[=ARG] 依赖包--without-PACKAGE 禁用依赖关系 注意：通常被编译操作依赖的程序包，需要安装此程序包的”开发”组件，其包名一般类似于name-devel-VERSION 第二步：make 1make -j x #加多x个进程，提高速度（x的个数取决于内核的数量） 第三步：make install 注意：make和make install执行失败的原因 121 有一些依懒性的包没安装，看报错提示安装 xxx-devel2 可能因为一些杂糅，可以删除解压后的包，重新解压，再重复之前的操作 1.3 安装后配置 二进制程序目录导入至PATH环境变量中，编辑文件/etc/profile.d/NAME.sh 1export PATH=/PATH/TO/BIN:$PATH 相关用户及文件 有些开源软件编译完成后，还需要创建相关的用户及文件 导入帮助手册 编辑&#x2F;etc&#x2F;man.config|man_db.conf文件，添加一个MANPATH 2 编译安装实战2.1 编译安装新版 tree源码建议放在&#x2F;usr&#x2F;local&#x2F;src 1.进入官方网站查询最新版本，然后复制下载链接（FTP或者HTTP的都行） 12345678910111213141516171819202122[root@centos ~]#rpm -qi treeName : treeVersion : 1.6.0 #版本Release : 10.el7Architecture: x86_64Install Date: Wed 16 Aug 2023 03:33:17 PM CSTGroup : Applications/FileSize : 89505License : GPLv2+Signature : RSA/SHA256, Fri 04 Jul 2014 01:36:46 PM CST, Key ID 24c6a8a7f4a80eb5Source RPM : tree-1.6.0-10.el7.src.rpmBuild Date : Tue 10 Jun 2014 03:28:53 AM CSTBuild Host : worker1.bsys.centos.orgRelocations : (not relocatable)Packager : CentOS BuildSystem &lt;http://bugs.centos.org&gt;Vendor : CentOSURL : http://mama.indstate.edu/users/ice/tree/ #官方网站Summary : File system tree viewerDescription :The tree utility recursively displays the contents of directories in atree-like format. Tree is basically a UNIX port of the DOS treeutility. 2.下载 1234[root@centos ~]#wget http://mama.indstate.edu/users/ice/tree/src/tree-2.1.1.tgz[root@centos src]#lstree-2.1.1.tgz 3.解压 123456789[root@centos src]#tar xf tree-2.1.1.tgz[root@centos src]#lstree-2.1.1 tree-2.1.1.tgz[root@centos src]#cd tree-2.1.1[root@centos tree-2.1.1]#lsCHANGES doc filter.c html.c INSTALL LICENSE Makefile strverscmp.c tree.c unix.ccolor.c file.c hash.c info.c json.c list.c README TODO tree.h xml.c#因为该文件太简单了，所以官方没给configure脚本，直接给了Makefile文件 4.查看说明书 12[root@centos tree-2.1.1]#less README[root@centos tree-2.1.1]#less INSTALL 5.根据需要修改Makefile文件（安装路径设定，软件特性和相关指定） 12[root@centos tree-2.1.1]#vim Makefile PREFIX=/apps/tree 6.改版本号（选做） 12345678910111213[root@centos tree-2.1.1]#grep 2.1.1 *CHANGES:Version 2.1.1 (05/31/2023)grep: doc: Is a directoryMakefile:VERSION=2.1.1tree.c:char *version = &quot;$Version: $ tree v2.1.1 %s 1996 - 2023 by Steve Baker, Thomas Moore, Francesc Rocher, Florian Sesser, Kyosuke Tokoro $&quot;;tree.c:char *hversion= &quot;\\t\\t tree v2.1.1 %s 1996 - 2023 by Steve Baker and Thomas Moore &lt;br&gt;\\n&quot;[root@centos tree-2.1.1]#sed -i &#x27;s/v2.1.1/v6.6.6/&#x27; tree.c[root@centos tree-2.1.1]#grep 6.6.6 *grep: doc: Is a directorytree.c:char *version = &quot;$Version: $ tree v6.6.6 %s 1996 - 2023 by Steve Baker, Thomas Moore, Francesc Rocher, Florian Sesser, Kyosuke Tokoro $&quot;;tree.c:char *hversion= &quot;\\t\\t tree v6.6.6 %s 1996 - 2023 by Steve Baker and Thomas Moore &lt;br&gt;\\n&quot; 7.make 1234567891011121314[root@centos tree-2.1.1]#makegcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o tree.o tree.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o list.o list.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o hash.o hash.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o color.o color.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o file.o file.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o filter.o filter.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o info.o info.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o unix.o unix.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o xml.o xml.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o json.o json.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o html.o html.cgcc -ggdb -std=c11 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o strverscmp.o strverscmp.cgcc -o tree tree.o list.o hash.o color.o file.o filter.o info.o unix.o xml.o json.o html.o strverscmp.o 8.make install 123456789101112131415161718[root@centos tree-2.1.1]#make installinstall -d /apps/tree/bininstall -d /apps/tree/man/man1install tree /apps/tree/bin/tree; \\install -m 644 doc/tree.1 /apps/tree/man/man1/tree.1[root@centos tree-2.1.1]#cd[root@centos ~]#ls /apps/tree/bin man[root@centos ~]#/apps/tree/bin/tree --versiontree v6.6.6 © 1996 - 2023 by Steve Baker, Thomas Moore, Francesc Rocher, Florian Sesser, Kyosuke Tokoro[root@centos ~]#tree /apps/tree/apps/tree├── bin│ └── tree└── man └── man1 └── tree.1 9.将旧的tree改为新的tree 123456789101112131415161718192021222324252627282930#用的还是旧的[root@centos ~]#which tree/usr/bin/tree#旧的路径是/usr/bin/[root@centos ~]#echo $PATH /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/wu/.local/bin:/home/wu/bin#第一种方法将/apps/tree/bin/tree创建软链接在/usr/bin/之前，优先匹配它就行了在/usr/bin/前面的只有/usr/local/bin[root@centos ~]#ln -s /apps/tree/bin/tree /usr/local/bin[root@centos ~]#tree --version #因为原来的路径有缓存，所以还是旧版本tree v1.6.0 (c) 1996 - 2011 by Steve Baker, Thomas Moore, Francesc Rocher, Kyosuke Tokoro [root@centos ~]#hash -r #清除缓存[root@centos ~]#which tree/usr/local/bin/tree[root@centos ~]#tree --versiontree v6.6.6 © 1996 - 2023 by Steve Baker, Thomas Moore, Francesc Rocher, Florian Sesser, Kyosuke Tokoro#第二种方法修改PATH变量，将/apps/tree/bin/tree放在/usr/bin/之前[root@centos ~]#vim /etc/profile.d/tree.shPATH=/apps/tree/bin:$PATH[root@centos ~]#. /etc/profile.d/tree.sh #生效[root@centos ~]#echo $PATH /apps/tree/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/wu/.local/bin:/home/wu/bin[root@centos ~]#which tree/apps/tree/bin/tree[root@centos ~]#tree --versiontree v6.6.6 © 1996 - 2023 by Steve Baker, Thomas Moore, Francesc Rocher, Florian Sesser, Kyosuke Tokoro 2.2 编译安装nginx12345678910111213yum install gcc gcc-c++ autoconf automake make -yyum -y install zlib zlib-devel openssl openssl-devel pcre pcre-devel wget https://nginx.org/download/nginx-1.24.0.tar.gztar xf nginx-1.24.0.tar.gzcd nginx-1.24.0# 1、定制安装信息./configure --prefix=/usr/local/nginx_1.24.0 --with-http_stub_status_module --with-http_ssl_module --with-stream --with-http_gzip_static_module --with-http_sub_module# 2、编译，并发4个任务去编译make -j 4# 3、安装make install# 使用ln -s /usr/local/nginx_1.24.0 /usr/local/nginx 3 源码编译安装和二进制安装的区别源码包 概述：源代码包里面包括了程序原始的程序代码，需要在你的计算机上进行编译成二进制程序后才可以产生可以运行程序 优点： 开源，可修改源代码 可自由选择所需要的功能 编译安装，更加适合自己的系统，更加稳定效率更高 卸载方便也更加干净 缺点： 安装步骤过多，容易出现错误 编译过程较长，安装比二进制包安装时间长 二进制包 概述：二进制包里面包括了已经经过编译，可以马上运行的程序。你只需要下载和解包（安装）它们以后，就马上可以使用 优点： 包管理系统简单，只需要几个命令即可实现安装，卸载等等 安装速度比源码包安装快很多 缺点： 不是开源的，看不到源代码 功能选择不如源代码灵活 安装软件包需要依赖于其他的软件包","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"软件包管理","slug":"软件包管理","permalink":"https://aquapluto.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"}]},{"title":"Ubuntu软件管理","slug":"Linux/software-manage/Ubuntu","date":"2025-08-21T02:46:22.000Z","updated":"2025-08-28T12:33:05.362Z","comments":true,"path":"Linux/software-manage/Ubuntu/","permalink":"https://aquapluto.github.io/Linux/software-manage/Ubuntu/","excerpt":"","text":"1 dpkg包管理器dpkg是一个底层的包管理工具，主要用于安装、卸载和管理.deb格式的软件包。它不会自动解决软件包之间的依赖关系，也就是说，如果一个软件包依赖于其他软件包，用户需要手动安装这些依赖包。此外，dpkg不会从远程仓库获取软件包，只能安装本地已经下载的.deb文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#安装包，不支持包的依赖dpkg -i package.deb#删除包，不建议，不自动卸载依赖于它的包dpkg -r package#删除包（包括配置文件）dpkg -P package#列出当前已安装的包，类似rpm -qadpkg -l#显示该包的简要说明dpkg -l package#列出该包的状态，包括详细信息，类似rpm –qidpkg -s package#列出该包中所包含的文件，类似rpm –qldpkg -L package#搜索包含pattern的包，类似rpm –qfdpkg -S &lt;pattern&gt;#配置包，-a 使用，配置所有没有配置的软件包dpkg --configure package#列出 deb 包的内容，类似rpm –qpldpkg -c package.deb#解开 deb 包的内容dpkg --unpack package.deb#列出系统上安装的所有软件包dpkg -l#列出软件包安装的文件dpkg -L bash#查看/bin/bash来自于哪个软件包dpkg -S /bin/bash#安装本地的 .deb 文件dpkg -i /mnt/cdrom/pool/main/z/zip/zip_3.0-11build1_amd64.deb#卸载软件包dpkg -r zip 注意：一般建议不要使用dpkg卸载软件包。因为删除包时，其它依赖它的包不会卸载，并且可能无法再正常运行 2 apt1234567891011121314151617apt install #安装软件包apt remove #移除软件包（删不干净）apt purge #移除软件包及配置文件（删的干净）apt update #刷新存储库索引（安装软件之前先执行这个命令更新一下）apt upgrade #升级所有可升级的软件包（谨慎使用）apt autoremove #自动删除不需要的包apt full-upgrade #升级整个系统，必要时可以移除旧软件包apt search #搜索应用程序apt show #显示安装细节apt list #列出包含条件的包（已安装，可升级等）apt edit-sources #编辑源列表apt-cache madison #查看仓库中软件包有哪些版本可以安装#查看文件来自于哪个包,类似redhat中的yum provides &lt;filename&gt;，需要安装apt-file search &#x27;string&#x27; #默认是包含此字符串的文件apt-file search -x &#x27;正则表达式&#x27;apt-file search -F /path/file APT包索引配置文件（相当于yum的仓库配置文件） 123/etc/apt/sources.list/etc/apt/sources.list.d#可以修改上面文件为国内的安装源，提高速度 apt命令操作（如安装和删除软件包）日志文件 1/var/log/dpkg.log 2.1 查看文件来自于哪个包范例: 查找存在的文件来自于哪个包 123#dpkg -S filename ：在当前安装的包里查找文件[root@ubuntu1804 ~]#dpkg -S /bin/lscoreutils: /bin/ls 范例: 查找不存在的文件存在于哪个包 1234567891011121314[root@ubuntu1804 ~]#apt -y install apt-file[root@ubuntu1804 ~]#apt update[root@ubuntu1804 ~]#apt-file search -x &#x27;/sl$&#x27;espeak-data: /usr/lib/x86_64-linux-gnu/espeak-data/voices/test/slespeak-ng-data: /usr/lib/x86_64-linux-gnu/espeak-ng-data/lang/zls/sllanguage-pack-sl-base: /var/lib/locales/supported.d/slpython-langdetect: /usr/lib/python2.7/dist-packages/langdetect/profiles/slpython3-langdetect: /usr/lib/python3/dist-packages/langdetect/profiles/slqemu-system-common: /usr/share/qemu/keymaps/slrdesktop: /usr/share/rdesktop/keymaps/slsl: /usr/games/slvirtualbox: /usr/share/virtualbox/rdesktop-vrdp-keymaps/sl[root@ubuntu1804 ~]#apt-file search -F /usr/games/slsl: /usr/games/sl 2.2 查看包相关信息12345678910#显示系统安装包的统计信息,可以统计已经安装包的数量，大小，占用空间等[root@ubuntu1804 ~]#apt-cache stats#显示xxx包的信息,可以看到某个包的源、版本等信息#apt-cache show xxx #更详细#apt show xxx[root@ubuntu1804 ~]#apt show keepalived[root@ubuntu1804 ~]#apt-cache show keepalived 2.3 查看仓库中的指定软件的所有版本123456789101112[root@ubuntu1804 ~]#apt-cache madison docker-cedocker-ce | 5:19.03.13~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packagesdocker-ce | 5:19.03.12~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packagesdocker-ce | 5:19.03.11~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packagesdocker-ce | 5:19.03.10~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages#安装指定版本[root@ubuntu1804 ~]#apt -y install docker-ce=5:19.03.13~3-0~ubuntu-bionic 2.4 查看文件的依赖1234567891011#查询软件xxx依赖哪些包#apt depends xxx#apt-cache depends xxx[root@ubuntu1804 ~]#apt depends keepalived#查询软件xxx被哪些包依赖#apt rdepends xxx#apt-cache rdepends xxx[root@ubuntu1804 ~]#apt rdepends bash","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"软件包管理","slug":"软件包管理","permalink":"https://aquapluto.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"}]},{"title":"Centos软件管理","slug":"Linux/software-manage/Centos","date":"2025-08-21T02:46:13.000Z","updated":"2025-08-28T12:33:05.362Z","comments":true,"path":"Linux/software-manage/Centos/","permalink":"https://aquapluto.github.io/Linux/software-manage/Centos/","excerpt":"","text":"1 rpm包管理器1.1 安装12345rpm &#123;-i|--install&#125; [install-options] PACKAGE_FILE…-v: verbose-vv:-h: 以#显示程序包管理执行进度 常用组合 1rpm -ivh PACKAGE_FILE ... 选项 12345678910--test: 测试安装，但不真正执行安装，即dry run模式--nodeps：忽略依赖关系--replacepkgs | replacefiles--nosignature: 不检查来源合法性--nodigest：不检查包完整性--noscripts：不执行程序包脚本 %pre: 安装前脚本 --nopre %post: 安装后脚本 --nopost %preun: 卸载前脚本 --nopreun %postun: 卸载后脚本 --nopostun 1.2 升级和降级rpm包升级 12rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE...rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE... 对应选项 12345upgrade：安装有旧版程序包，则&quot;升级&quot;，如果不存在旧版程序包，则&quot;安装&quot;freshen：安装有旧版程序包，则&quot;升级&quot;， 如果不存在旧版程序包，则不执行升级操作--oldpackage：降级--force: 强制安装 常用组合 12rpm -Uvh PACKAGE_FILE ...rpm -Fvh PACKAGE_FILE ... 升级注意项： 不要对内核做升级操作；Linux支持多内核版本并存，因此直接安装新版本内核 如果原程序包的配置文件安装后曾被修改，升级时，新版本提供的同一个配置文件不会直接覆盖老版本的配置文件，而把新版本文件重命名(FILENAME.rpmnew)后保留 1.3 包查询123456789-p rpmfile #针对尚未安装的程序包文件做查询操作-q PACKAGE #查询有没有安装到该包-qi PACKAGE #了解包的信息-ql PACKAGE #列出这个包的所有文件列表-q --scripts PACKAGE #查看该包的脚本-qf file #查询磁盘上的文件或命令来自于哪个包，自己建的文件查不到-qc PACKAGE #只列出这个包里面包含的配置文件-qd PACKAGE #只列出这个包里面包含的文档-qa --last #查看最近安装的包 范例: 查看最近安装的包 1[root@centos8 ~]# rpm -qa --last|head 范例：查询包详细信息 123456#没有安装，可以指定程序包[root@rocky86 h]# rpm -qi httpdpackage httpd is not installed#-p指定rpm 包文件，新版可以省略此选项[root@rocky86 h]# rpm -qip httpd-2.4.37-47.module+el8.6.0+823+f143cee1.1.x86_64.rpm 范例：根据文件查询包信息 12345678910111213[root@rocky86 h]# rpm -qf /usr/sbin/nginxnginx-1.14.1-9.module+el8.4.0+542+81547229.x86_64[root@centos ~]#rpm -qf `which ifconfig`net-tools-2.0-0.25.20131004git.el7.x86_64#还没安装的包，此处不能省略-p参数[root@rocky86 h]# rpm -qpf httpd-2.4.37-47.module+el8.6.0+823+f143cee1.1.x86_64.rpmhttpd-2.4.37-47.module+el8.6.0+823+f143cee1.1.x86_64#自己编译的，不属于任何包[root@rocky86 0727]# rpm -qf testfile /root/0727/test is not owned by any package 1.4 包卸载1rpm &#123;-e|--erase&#125; [--allmatches] [--nodeps] [--noscripts] [--notriggers] [--test] PACKAGE_NAME ... 注意：当包卸载时，对应的配置文件不会删除， 以FILENAME.rpmsave形式保留 范例：强行删除rpm包，并恢复 123456789[root@centos7 ~]#rpm -e rpm --nodeps#重启进入rescue模式#mkdir /mnt/cdrom#mount /dev/sr0 /mnt/cdrom如果已经有挂载直接df查看挂载点#rpm -ivh /mnt/cdrom/Packages/rpm-4.11.3-40.el7.x86_64.rpm --root=/mnt/sysimagerpm -ivh /run/install/repo/BaseOS/Packages/r/rpm-4.xxx.rpm --root=/mnt/sysroot --force#reboot 注意：当包卸载时，对应的配置文件不会删除(前提是该文件被改动过)， 以FILENAME.rpmsave形式保留 1.5 包校验在安装包时，系统也会检查包的来源是否是合法的 检查包的完整性和签名 1rpm -K 【PATH】rpmfile 范例 1234567[root@centos Packages]#rpm -K zip-3.0-11.el7.x86_64.rpm zip-3.0-11.el7.x86_64.rpm: rsa sha1 (md5) pgp md5 OK[root@centos ~]#rpm -K zip-3.0-11.el7.x86_64.rpm error: zip-3.0-11.el7.x86_64.rpm: open failed: No such file or directory[root@centos ~]#rpm -K /misc/cd/Packages/zip-3.0-11.el7.x86_64.rpm /misc/cd/Packages/zip-3.0-11.el7.x86_64.rpm: rsa sha1 (md5) pgp md5 OK 在检查包的来源和完整性前，必须导入所需要公钥 1234567891011#导入公钥[root@rocky86 v]# rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficialrpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#查看己导入的公钥[root@rocky86 v]# rpm -qa &quot;gpg-pubkey&quot;gpg-pubkey-2f86d6a1-5cf7cefbgpg-pubkey-6d745a60-60287f36#查看[root@rocky86 v]# rpm -qi gpg-pubkey-6d745a60-60287f36 软件在安装时，会将包里的每个文件的元数据，如：大小，权限，所有者，时间等记录至rpm相关的数据库中，可以用来检查包中的文件是否和当初安装时有所变化 123456789101112131415rpm -V PACKAGErpm -Va 检测所有安装好的包里面的所有文件的属性，看看自从这些包安装好后，哪些文件的信息发生了变化#字段说明S #文件大小不一样M #文件权限不一样或文件类型不一样5 #md5 校验值不一样D #版本号值不一样L #链接路径不一样U #属主发生了改变G #属组发生了改变T #修改时间发生了改变P #功能发生了改变c|d|g|l|r #文件类型 c配置文件, d数据文件，g该文件不属于此处，l许可文件(licens file)，r自述文件(READ ME)#如果占位符是 . 则表示该处与安装时没有任何改变 1.6 数据库维护rpm包安装时生成的信息，都放在rpm数据库中 &#x2F;var&#x2F;lib&#x2F;rpm 可以重建数据库 123rpm &#123;--initdb|--rebuilddb&#125;initdb: 初始化，如果事先不存在数据库，则新建之，否则，不执行任何操作rebuilddb：重建已安装的包头的数据库索引目录 1.7 包更新日志1rpm -q --changelog packageName 2 yum和dnfCentOS 使用 yum, dnf 解决rpm的包依赖关系 yum&#x2F;dnf 工作原理 yum&#x2F;dnf 是基于C&#x2F;S 模式 yum 服务器存放rpm包和相关包的元数据库 yum 客户端访问yum服务器进行安装或查询等 yum 实现过程 先在yum服务器上创建 yum repository（仓库），在仓库中事先存储了众多rpm包，以及包的相关的元数据文件（放置于特定目录repodata下） 当yum客户端利用yum&#x2F;dnf工具进行安装时包时，会自动下载repodata中的元数据，查询远数据是否存在相关的包及依赖关系，自动从仓库中找到相关包下载并安装。 2.1 yum客户端配置yum客户端配置文件 12/etc/yum.conf #为所有仓库提供公共配置/etc/yum.repos.d/*.repo： #为每个仓库的提供配置文件，配置文件必须以repo为后缀 repo仓库配置文件指向的定义 123456789101112[repositoryID] #仓库的标识，如果有多个仓库，内容必须唯一，不能带有空格name=Some name for this repository #描述这个仓库是干什么的baseurl=url://path/to/repository/ #仓库的路径，可添加多个路径，防止网站没了enabled=&#123;1|0&#125; #可以不加，要想禁用仓库的话就要加并且等于0gpgcheck=&#123;1|0&#125; #校验包是否合法，默认为1，禁用就是0gpgkey=URL#以下可以不写mirrorlist=http://list/ #仓库地址列表，在这里写了多个 baseurl指向的地址enablegroups=&#123;1|0&#125; #是否启用yum group,默认值为 1failovermethod=&#123;roundrobin|priority&#125; #有多个baseurl，此项决定访问规则，roundrobin 随机，priority:按顺序访问roundrobin：意为随机挑选，默认值，priority:按顺序访问cost=1000 #开销，或者是成本，YUM程序会根据此值来决定优先访问哪个源,默认为1000 yum服务器的baseurl形式 1234baseurl=file:///cdrom/AppStream/baseurl=https://mirrors.aliyun.com/rockylinux/8.6/AppStream/x86_64/os/baseurl=http://mirrors.aliyun.com/rockylinux/8.6/AppStream/x86_64/os/baseurl=ftp://10.0.0.159/ 注意：yum仓库指向的路径一定必须是repodata目录所在目录 相关变量 123456yum的repo配置文件中可用的变量：$releasever: 当前OS的发行版的主版本号，如：8，7，6$arch: CPU架构，如：aarch64, i586, i686，x86_64等$basearch：系统基础平台；i386, x86_64$contentdir：表示目录，比如：centos-8，centos-7$YUM0-$YUM9:自定义变量 范例 123http://server/centos/$releasever/$basearch/http://server/centos/7/x86_64http://server/centos/6/i386 范例：CentOS 8 配置文件 12345678910[root@centos8 ~]# ll /etc/yum.conflrwxrwxrwx. 1 root root 12 May 14 2019 /etc/yum.conf -&gt; dnf/dnf.conf[root@centos8 ~]#cat /etc/yum.conf[main]gpgcheck=1 #安装包前要做包的合法和完整性校验installonly_limit=3 #同时可以安装3个包，最小值为2，如设为0或1，为不限制clean_requirements_on_remove=True #删除包时，是否将不再使用的包删除best=True #升级时，自动选择安装最新版，即使缺少包的依赖skip_if_unavailable=False #跳过不可用的 范例：CentOS 7 的配置文件 1234567891011121314151617[root@centos7 ~]# ll /etc/yum.conf-rw-r--r--. 1 root root 970 Aug 8 19:57 /etc/yum.conf[root@centos7 ~]# cat /etc/yum.conf[main]cachedir=/var/cache/yum/$basearch/$releasever #缓存路径keepcache=0 #如果为1,则下载rpm并缓存下来,不删除,默认安装rpm后会删除rpm包debuglevel=2logfile=/var/log/yum.logexactarch=1obsoletes=1gpgcheck=1plugins=1installonly_limit=5bugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release baseurl 指向的路径 阿里云提供了写好的CentOS,Rocky和ubuntu的仓库文件下载链接 1http://mirrors.aliyun.com/repo/ Rocky 系统的yum源 12345678#南京大学https://mirror.nju.edu.cn/rocky/$releasever/#上海交大https://mirrors.sjtug.sjtu.edu.cn/rocky/$releasever/#山东大学https://mirrors.sdu.edu.cn/rocky/$releasever/ CentOS系统的yum源 1234567891011#阿里云https://mirrors.aliyun.com/centos/$releasever/#腾讯云https://mirrors.cloud.tencent.com/centos/$releasever/#华为云https://repo.huaweicloud.com/centos/$releasever/#清华大学https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/ EPEL的yum源 1234567891011#阿里云https://mirrors.aliyun.com/epel/$releasever/x86_64#腾讯云https://mirrors.cloud.tencent.com/epel/$releasever/x86_64#华为云https://mirrors.huaweicloud.com/epel/$releasever/x86_64#清华大学https://mirrors.tuna.tsinghua.edu.cn/epel/$releasever/x86_64 查看本地磁盘密钥路径 12[root@centos ~]#ls /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 RPM-GPG-KEY-CentOS-Debug-7 RPM-GPG-KEY-CentOS-Testing-7 范例：为CentOS7用系统安装光盘作的本地yum仓库 12345678910#挂载光盘至某目录,如/mnt/cdrommount /dev/cdrom /mnt/cdrom#创建配置文件[root@centos7 ~]#vim /etc/yum.repos.d/centos7.repo[CentOS7]name=CentOS 7baseurl=file:///mnt/cdromgpgcheck=0enabled=1 范例：为CentOS 8 配置 yum 的系统和EPEL源仓库 12345678910111213141516171819202122[root@centos8 ~]#cat /etc/yum.repos.d/base.repo[BaseOS]name=BaseOSbaseurl=file:///misc/cd/BaseOSgpgcheck=1gpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial [AppStream]name=AppStreambaseurl=file:///misc/cd/AppStreamgpgcheck=0[epel]name=EPELbaseurl=http://mirrors.aliyun.com/epel/$releasever/Everything/$basearchgpgcheck=0enabled=1[extras]name=extrasbaseurl=https://mirrors.aliyun.com/centos/$releasever/extras/$basearch/osgpgcheck=0 范例：安装epel仓库包 12345678910111213141516[root@centos ~]#cd /etc/yum.repos.d/[root@centos yum.repos.d]#lsCentOS-Base.repo CentOS-Debuginfo.repo CentOS-Media.repo CentOS-Vault.repoCentOS-CR.repo CentOS-fasttrack.repo CentOS-Sources.repo CentOS-x86_64-kernel.repo[root@centos yum.repos.d]#vim test.repo[root@centos yum.repos.d]#cat test.repo [epel]name=epel repobaseurl=https://mirrors.aliyun.com/epel/$releasever/$basearch https://mirrors.tuna.tsinghua.edu.cn/epel/$releasever/$basearchgpgcheck=1gpgkey=https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-7 https://mirrors.tuna.tsinghua.edu.cn/epel/RPM-GPG-KEY-EPEL-7 [root@centos ~]#yum -y install sl epel属于额外的包，安装需要操作系统自身的包，操作系统的包在光盘里(&#x2F;misc&#x2F;cd)，所以光盘这个包是要加上去的 centos7中所有软件包都在一个仓库里，所以repodata文件是单独的，不需要另外建仓库，而centos8中把所有软件包分成两个仓库，所 以repodata的文件是有两个的，一个在AppStream里，一个在BaseOS里，需要另外建两个仓库 1234567891011121314151617181920#centos8[BaseOS]name=BaseOSbaseurl=file:///misc/cd/BaseOSgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7[AppStream]name=AppStreambaseurl=file:///misc/cd/AppStreamgpgcheck=0[epel]name=epel repobaseurl=https://mirrors.aliyun.com/epel/$releasever/$basearch https://mirrors.tuna.tsinghua.edu.cn/epel/$releasever/$basearchgpgcheck=1gpgkey=https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-7 https://mirrors.tuna.tsinghua.edu.cn/epel/RPM-GPG-KEY-EPEL-7 范例2：升级内核（慎重） 1234567891011121314151617yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm #centos7或者红帽7yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm #centos8或者红帽8[root@centos ~]#yum list kernel*发现都是已经安装好的了，没有最新版的文件，原因是脚本里设置禁用[root@centos ~]#cd /etc/yum.repos.d/[root@centos yum.repos.d]#lsCentOS-Base.repo CentOS-Debuginfo.repo CentOS-Media.repo CentOS-Vault.repo elrepo.repoCentOS-CR.repo CentOS-fasttrack.repo CentOS-Sources.repo CentOS-x86_64-kernel.repo test.repo[root@centos yum.repos.d]#vim elrepo.repo 找到[elrepo-kernel]，将enabled=0改成1[root@centos ~]#yum list kernel*就可以发现有最新的了，安装推荐lt版[root@centos yum.repos.d]#yum -y install kernel-lt 2.2 yum-config-manager命令可以生成yum仓库的配置文件及启用或禁用仓库，来自于yum-utils包 格式 123456#增加仓库yum-config-manager --add-repo URL或file#禁用仓库yum-config-manager --disable &quot;仓库名&quot;#启用仓库yum-config-manager --enable &quot;仓库名&quot; 范例：创建仓库配置 1234567[root@centos8 ~]#rpm -qf `which yum-config-manager `dnf-utils-4.0.2.2-3.el8.noarch[root@centos8 ~]#yum-config-manager --add-repohttps://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoAdding repo from: https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@centos8 ~]#ls /etc/yum.repos.d/backup base.repo docker-ce.repo 范例：创建仓库配置 123456789#生成172.16.0.1_cobbler_ks_mirror_8_.repo[root@centos8 ~]#yum-config-manager --add-repo=http://172.16.0.1/cobbler/ks_mirror/8/Adding repo from: http://172.16.0.1/cobbler/ks_mirror/8/[root@centos8 ~]#cat /etc/yum.repos.d/172.16.0.1_cobbler_ks_mirror_8_.repo[172.16.0.1_cobbler_ks_mirror_8_]name=created by dnf config-manager from http://172.16.0.1/cobbler/ks_mirror/8/baseurl=http://172.16.0.1/cobbler/ks_mirror/8/enabled=1 范例：创建仓库配置 123456[root@centos8 ~]#ls /etc/yum.repos.d/backup base.repo[root@centos8 ~]#yum-config-manager --add-repo /data/docker-ce.repoAdding repo from: file:///data/docker-ce.repo[root@centos8 ~]#ls /etc/yum.repos.d/backup base.repo docker-ce.repo 范例：启用和禁用仓库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@centos8 ~]#yum repolist[root@centos8 ~]#yum-config-manager --disable epel[root@centos8 ~]#cat /etc/yum.repos.d/base.repo[BaseOS]name=BaseOSbaseurl=file:///misc/cd/BaseOSgpgcheck=0[AppStream]name=AppStreambaseurl=file:///misc/cd/AppStreamgpgcheck=0[epel]name=EPELbaseurl=http://mirrors.aliyun.com/epel/$releasever/Everything/$basearch http://mirrors.huaweicloud.com/epel/$releasever/Everything/$basearchgpgcheck=0enabled=0[extras]name=extrasbaseurl=https://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os http://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch/osgpgcheck=0enabled=1[root@centos8 ~]#yum repolistBaseOS 3.8 MB/s | 3.9 kB 00:00 AppStream 4.2 MB/s | 4.3 kB 00:00 extras 10 kB/s | 1.5 kB 00:00 repo id repo name statusAppStream AppStream 4,755BaseOS BaseOS 1,659extras extras 12[root@centos8 ~]#yum-config-manager --disable extras[root@centos8 ~]#yum repolistBaseOS 3.8 MB/s | 3.9 kB 00:00 AppStream 4.2 MB/s | 4.3 kB 00:00 repo id repo name statusAppStream AppStream 4,755BaseOS BaseOS 1,659[root@centos8 ~]#yum-config-manager --enable extras[root@centos8 ~]#yum repolistBaseOS 3.8 MB/s | 3.9 kB 00:00 AppStream 4.2 MB/s | 4.3 kB 00:00 extras 12 kB/s | 1.5 kB 00:00 repo id repo name statusAppStream AppStream 4,755BaseOS BaseOS 1,659extras extras 12 2.3 yum命令1234567yum [options] [command] [package ...]-y #自动回答为&quot;yes&quot;-q #静默模式--nogpgcheck #禁止进行gpg check--enablerepo=repoidglob #临时启用此处指定的repo，支持通配符，如：&quot;*&quot;--disablerepo=repoidglob #临时禁用此处指定的repo,和上面语句同时使用，放在后面的生效 2.3.1 列出所有仓库12[root@centos yum.repos.d]#yum repolist[root@centos yum.repos.d]#yum repolist -v 可以看到仓库有多少个包 2.3.2 显示程序包查看包来自哪个仓库 1[root@centos ~]#yum list sl 只查看已经安装的包 1[root@centos8 ~]#yum list installed|head 查看可安装的包 1[root@centos8 ~]#yum list available |head 查看可以升级的包 1[root@centos8 ~]#yum list updates 范例: 查看指定的包 123[root@centos8 ~]#yum list exim#支持通配符[root@centos8 ~]#yum list exim* 2.3.3 安装程序包12345yum install package1 [package2] [...]yum reinstall package1 [package2] [...] #重新安装--downloadonly #只下载相关包默认至/var/cache/yum/x86_64/7/目录下,而不执行install/upgrade/erase--downloaddir=&lt;path&gt;, --destdir=&lt;path&gt; #--downloaddir选项来指定下载的目录,如果不存在自动创建 范例：只下载相关的依赖包,而不安装 123456789101112#/data/目录如果不存在,会自动创建[root@centos8 ~]#yum -y install --downloadonly --downloaddir=/data/httpd httpd[root@centos8 ~]#ls /data/httpd/apr-1.6.3-9.el8.x86_64.rpm httpd-2.4.37-16.module_el8.1.0+256+ae790463.x86_64.rpmapr-util-1.6.1-6.el8.x86_64.rpm httpd-filesystem-2.4.37-16.module_el8.1.0+256+ae790463.noarch.rpmapr-util-bdb-1.6.1-6.el8.x86_64.rpm httpd-tools-2.4.37-16.module_el8.1.0+256+ae790463.x86_64.rpmapr-util-openssl-1.6.1-6.el8.x86_64.rpm mailcap-2.1.48-3.el8.noarch.rpmcentos-logos-httpd-80.5-2.el8.noarch.rpm mod_http2-1.11.3-3.module_el8.1.0+213+acce2796.x86_64.rpm 注意: 下载包也可以通过启用配置文件实现 1234[root@centos7 ~]# cat /etc/yum.conf[main]cachedir=/var/cache/yum/$basearch/$releasever #缓存路径keepcache=1 #如果为1,则下载rpm并缓存下来,不删除,默认安装rpm后会删除rpm包 2.3.4 卸载包1[root@centos ~]#yum remove httpd 2.3.5 升级和降级检查可用升级 1yum check-update 升级和降级 123yum upgrade|update [package1] [package2] [...]yum upgrade-minimal #最小化升级yum downgrade package1 [package2] [...] (降级) 2.3.6 查询查看包的信息 1[root@centos ~]#yum info sl 查看没有安装的文件（命令）来自于哪个包 12345678910111213141516171819yum provides file#注意：文件要写全路径，而不只是文件名，否则可能无法查询到#注意要写文件全路径才能查询到（文件路径可以用which查）[root@centos8 ~]#yum provides vsftpd.confLast metadata expiration check: 0:56:45 ago on Fri 10 Apr 2020 11:24:00 AM CST.Error: No Matches found[root@centos8 ~]#yum provides `which ifconfig`[root@centos8 ~]# yum provides /etc/vsftpd/vsftpd.confLast metadata expiration check: 0:33:13 ago on Fri 27 Dec 2019 03:47:34 PM CST.vsftpd-3.0.3-28.el8.x86_64 : Very Secure Ftp DaemonRepo : AppStreamMatched from:Filename : /etc/vsftpd/vsftpd.conf#使用通配符[root@centos8 ~]#yum provides */vsftpd.conf[root@centos8 ~]#yum provides */updatedb* 查看yum安装卸载历史 12yum history ...info 编号 #查看该编号的包的信息 以指定的关键字搜索程序包名 12yum search string1 [string2] [...]yum search mysql #查看关于MySQL的包 查看指定包所依赖的capabilities 1yum deplist package1 [package2] [...] 2.3.7 仓库缓存清除目录&#x2F;var&#x2F;cache&#x2F;yum&#x2F;缓存 1yum clean all 构建缓存 1yum makecache 2.3.8 查看yum事务历史yum 执行安装卸载命令会记录到相关日志中 日志文件： 123456#CentOS 7以前版本日志/var/log/yum.log#CentOS 8 版本日志/var/log/dnf.rpm.log/var/log/dnf.log 查看yum安装卸载历史 1234yum history [info|list|packages-list|packages-info|summary|addon-info|redo|undo|rollback|new|sync|stats]info N #查看该编号的包的信息undo N #回滚第N条记录redo N #重新执行第N条记录 2.3.9 安装及升级本地程序包12yum localinstall|install rpmfile1 [rpmfile2] [...]yum localupdate|update rpmfile1 [rpmfile2] [...] 2.3.10 查看包的安全警报1yum updateinfo --summary|--list|--info 2.3.11 包组管理的相关命令包组管理（不建议安装包组） 12345yum grouplist [hidden] [groupwildcard] [...]yum groupinstall group1 [group2] [...]yum groupupdate group1 [group2] [...]yum groupremove group1 [group2] [...]yum groupinfo group1 [...] 范例：最小化安装的系统安装图形环境 123[root@centos8 ~]#yum grouplist[root@centos8 ~]#yum groupinstall &quot;Server with GUI&quot;[root@centos8 ~]#init 5 2.3.12 yum安装失败原因12345678yum的配置文件格式或路径错误解决方法：检查/etc/yum.repos.d/*.repo文件格式yum cache解决方法：yum clean all网络不通：解决方法：网卡配置 2.4 dnf命令配置文件：&#x2F;etc&#x2F;dnf&#x2F;dnf.conf 仓库文件：&#x2F;etc&#x2F;yum.repos.d&#x2F; *.repo 日志：&#x2F;var&#x2F;log&#x2F;dnf.rpm.log、&#x2F;var&#x2F;log&#x2F;dnf.log dnf 用法与yum一致 123456789101112dnf [options] &lt;command&gt; [&lt;arguments&gt;...]dnf --versiondnf repolistdnf reposyncdnf install httpddnf remove httpddnf clean alldnf makecachednf list installeddnf list availablednf search nanodnf history undo 1 范例: CentOS 8 查看未安装包的文件列表 1234567[root@centos8 ~]#rpm -q memcachedpackage memcached is not installed[root@centos8 ~]#dnf repoquery -l memcachedLast metadata expiration check: 2:35:45 ago on Tue 14 Jul 2020 08:56:26 AM CST./etc/sysconfig/memcached/usr/bin/memcached...... 范例: CentOS 7 查看未安装包的文件列表 1234567[root@centos7 ~]#rpm -q memcachedpackage memcached is not installed[root@centos7 ~]#yum -y install yum-utils[root@centos7 ~]#repoquery -ql memcached/etc/sysconfig/memcached/usr/bin/memcached...... 用yum安装软件时是先把元数据下载到缓存中，缓存存在&#x2F;var&#x2F;cache&#x2F;dnf，在有些情况下会影响软件的安装，比如仓库的信息发生变化，缓存不会及时更新，还是旧的缓存信息，这样会影响安装新软件，为了避免缓存影响我们安装软件，可以清理缓存 1dnf clean all 3 制作本地yum源 先准备rpm包，扔到一个文件夹中&#x2F;my_rpms 123456rpm包的来源：1、镜像2、网上的yum源3、使用yum命令把某个仓库里的包下载到本地（只下载不安装）$ yum install --downloadonly --downloaddir=/my_rpms httpd -y4、开启keepcache=1 在上述文件夹&#x2F;my_rpms下生成repodata目录（存放依赖性关系） 12yum install createrepo -y createrepo /my_rpms 安装软件，通过该软件把你的文件&#x2F;my_rpms共享出去 12345678910客户端与服务都关闭selinux与防火墙systemctl stop firewalldsetenforce 0 服务端安装yum install vsftpd -y 把服务机器的yum仓库放到/var/ftp目录下ln -s /my_rpms /var/ftp/my_rpms或者用cp、mv都可以 使用者：配置一个repo文件，baseurl指向上面的yum源地址 123456789101112131415cat &gt; my.repo &lt;&lt; EOF[local]name=localbaseurl=file:///my_rpmsenabled=1gpgcheck=0EOF cat &gt; ftp.repo &lt;&lt; EOF[local]name=localbaseurl=ftp://服务都ip地址/my_rpmsenabled=1gpgcheck=0EOF 4 实现yum私有仓库原理：例如epel源，它是在互联网上的，互联网上的包要在公司内部搭，要先从互联网上下载到本机，然后把本机下载到的所有数据利用http协议发布出去，共享出来，那么公司内部的机器就可以利用http协议从创建好的http的共享服务器上获取仓库信息 利用http协议要先下载软件httpd，下载后可以搭建公司内部的http服务器，它的共享数据目录是在&#x2F;var&#x2F;www&#x2F;html 启动http服务：systemctl enable --now httpd 启动之后就相当于外部网站了，可以在微软等软件上输入机器的ip地址就可以访问了 从互联网上下载epel源 123456789#默认只下载rpm包，不下载 meta数据，需要指定--download-metadata 才能下载 metadnf reposync --repoid=REPOID --download-metadata -p /path--repoid=REPOID：你要下载哪个仓库--download-metadata -p /path：下载元数据，下载到哪个地方（/path），这个地方要用http协议共享出来[root@repo-server ~]#dnf reposync --repoid=epel --download-metadata -p /var/www/html然后就可以在网站输入10.0.0.8/epel/访问了 在新机器上下载epel 12345678修改yum仓库配置[epel]name=epel repobaseurl=https://10.0.0.8/epel/gpgcheck=0enabled=1然后就可以正常下载了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"软件包管理","slug":"软件包管理","permalink":"https://aquapluto.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"}]},{"title":"软件包介绍","slug":"Linux/software-manage/introduce","date":"2025-08-21T02:46:07.000Z","updated":"2025-08-28T12:33:05.363Z","comments":true,"path":"Linux/software-manage/introduce/","permalink":"https://aquapluto.github.io/Linux/software-manage/introduce/","excerpt":"","text":"1 软件运行与编译1.1 C语言程序实现过程gcc编译过程 12345678#分步骤编译运行gcc -E hello.c -o hello.i 对hello.c文件进行预处理，生成了hello.i 文件gcc -S hello.i -o hello.s 对预处理文件进行编译，生成了汇编文件gcc -c hello.s -o hello.o 对汇编文件进行编译，生成了目标文件gcc hello.o -o hello 对目标文件进行链接，生成可执行文件#一步实现编译过程gcc hello.c -o hello 直接编译链接成可执行目标文件 1.2 模块（库）文件查看二进制程序所依赖的库文件 123ldd /PATH/TO/BINARY_FILE[root@rocky8 ~]# ldd /usr/bin/ls 管理及查看本机装载的库文件 12345#加载配置文件中指定的库文件ldconfig#显示本机已经缓存的所有可用库文件名及文件路径映射关系/sbin/ldconfig –p 配置文件 12/etc/ld.so.conf/etc/ld.so.conf.d/*.conf 缓存文件：/etc/ld.so.cache 范例：库文件破坏后，将导致依赖的程序无法正常运行，需要通过救援模式恢复 123456789101112131415161718192021222324[root@centos8 ~]#ldd /bin/lslinux-vdso.so.1 (0x00007ffc509fd000)libselinux.so.1 =&gt; /lib64/libselinux.so.1 (0x00007fc6ef24a000)libcap.so.2 =&gt; /lib64/libcap.so.2 (0x00007fc6ef044000)libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fc6eec81000)libpcre2-8.so.0 =&gt; /lib64/libpcre2-8.so.0 (0x00007fc6ee9fd000)libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fc6ee7f9000)/lib64/ld-linux-x86-64.so.2 (0x00007fc6ef698000)libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fc6ee5d9000)[root@centos8 ~]#ldd /bin/catlinux-vdso.so.1 (0x00007ffe335dd000)libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fa34749e000)/lib64/ld-linux-x86-64.so.2 (0x00007fa347a6b000)[root@centos8 ~]#mv /lib64/libc.so.6 /tmp[root@centos8 ~]#lsls: error while loading shared libraries: libc.so.6: cannot open shared objectfile: No such file or directory[root@centos8 ~]#catcat: error while loading shared libraries: libc.so.6: cannot open shared objectfile: No such file or directory 2 软件包和包管理器2.1 使用光盘NFS服务时，会将挂载信息写入”&#x2F;etc&#x2F;fstab”，系统每次开机都会自动将其挂载，但是这样会消耗很多的本地资源，给网络带宽和服务器的硬件资源带来很大的负载。autofs服务程序则是在用户需要使用该文件系统时才动态的去挂载，从而节约了网络资源和服务器的硬件资源。 123456789101112131415161718#神奇的光盘挂载目录#CentOS[root@centos8 ~]#rpm -q autofs || yum -y install autofs[root@centos8 ~]#systemctl enable --now autofs[root@centos ~]#cd /misc/cd[root@centos cd]#lsCentOS_BuildTag EULA images LiveOS repodata RPM-GPG-KEY-CentOS-Testing-7EFI GPL isolinux Packages RPM-GPG-KEY-CentOS-7 TRANS.TBL[root@centos cd]#cd Packages/ #存放红帽编译打包的各种rpm包[root@centos Packages]#ls[root@centos ~]#ls /var/lib/rpm #不能破坏#Ubunturoot@ubuntu2004:~# apt install autofs -yroot@ubuntu2004:~# vim /etc/auto.master/misc /etc/auto.miscroot@ubuntu2004:~# systemctl restart autofs 2.2 软件包种类rpm包：预先编译打包，安装简单，但缺乏可定制的灵活性 源码包：手动编译打包，安装繁琐，但可定制性强 二进制包：解压即可使用, 安装简单，但缺乏可定制的灵活性，与rpm包相比它可以改变安装目录 2.3 软件包中的文件分类 二进制文件 库文件 配置文件 帮助文件 范例：利用 cpio工具查看包文件列表 12rpm2cpio 包文件|cpio –itv 预览包内文件rpm2cpio 包文件|cpio –id &quot;*.conf&quot; 释放包内文件 2.4 系统发版的光盘或官方网站CentOS 镜像 123456https://www.centos.org/download/http://mirrors.aliyun.comhttps://mirrors.huaweicloud.com/https://mirror.tuna.tsinghua.edu.cn/http://mirrors.sohu.comhttp://mirrors.163.com Ubuntu 镜像 12http://cdimage.ubuntu.com/releases/http://releases.ubuntu.com","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"软件包管理","slug":"软件包管理","permalink":"https://aquapluto.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"}]},{"title":"文本管理工具","slug":"Linux/linux-basics/text-command","date":"2025-08-21T02:44:27.000Z","updated":"2025-08-28T12:33:05.260Z","comments":true,"path":"Linux/linux-basics/text-command/","permalink":"https://aquapluto.github.io/Linux/linux-basics/text-command/","excerpt":"","text":"1 文本编译工具vim常用选项 1234567+N #打开文件后让光标处于第N行的行首，+默认行尾+/PATTERN #让光标处于第一个被PATTERN匹配到的行行首-b file #二进制方式打开文件-d file1 file2… #比较多个文件，相当于 vimdiff-m file #只读打开文件-e file #直接进入ex模式，相当于执行ex file-y file #Easy mode (like &quot;evim&quot;, modeless)，直接可以操作文件，ctrl+o:wq|q! 保存和不保存退出 范例 1234[root@ubuntu2204 ~]# vim +3 f1.txt #光标在第3行[root@ubuntu2204 ~]# vim + f1.txt #光标在最后一行[root@ubuntu2204 ~]# vim +/^abc f2.txt #模式匹配定位[root@ubuntu2204 ~]# vim +/^bc* f2.txt #模式匹配定位 1.1 三种模式和切换三种模式 命令模式：实现移动光标，剪切或粘贴文本 插入模式：修改文本 扩展命令模式：保存，退出等 切换模式 命令模式–&gt;插入模式 123456i insert，在光标所在处输入I 在当前光标所在行的行首输入a 在光标所在处后面输入A 在当前光标所在行的行尾输入o 在当前光标所在行的下方打开一个新行O 在当前光标所在行的上方打开一个新行 插入模式 — ESC—–&gt; 命令模式 命令模式 —- : —-&gt; 扩展命令模式 扩展命令模式 —-ESC,enter—-&gt; 命令模式 范例: 插入颜色字符 123456789101112131 切换至插入模式2 按ctrl+v+[ 三个键,显示^[3 后续输入颜色信息,如:^[[32mhello^[[0m4 切换至扩展命令模式,保存退出5 cat 文件可以看到下面显示[root@centos7 ~]#vim color.txt^[[1;31mHello,vim^[[0m^[[1;32mGreen^[[0m[root@centos7 ~]#cat color.txt Hello,vimGreen 1.2 扩展命令模式1.2.1 基本命令12345678910w #写（存）磁盘文件wq #写入并退出x #写入并退出X #加密q #退出q！ #不存盘退出，即使更改都将丢失r #filename 读文件内容到当前文件中w #filename 将当前文件内容写入另一个文件!command #执行命令r!command #读入命令的输出 1.2.2 地址定界格式：:start_pos,end_pos CMD 地址定界格式 123456789101112# #具体第#行，例如2表示第2行#,# #从左侧#表示起始行，到右侧#表示结尾行#,+# #从左侧#表示的起始行，加上右侧#表示的行数，范例：2,+3 表示2到5行. #当前行$ #最后一行.,$-1 #当前行到倒数第二行% #全文, 相当于1,$/pattern/ #从当前行向下查找，直到匹配pattern的第一行,即:正则表达式/pat1/,/pat2/ #从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束#,/pat/ #从指定行开始，一直找到第一个匹配pattern的行结束/pat/,$ #向下找到第一个匹配patttern的行到整个文件的结尾的所有行 编辑命令 123456d #删除，3,6d：删掉第三行到第六行的内容；%d：全文删除y #复制，.,$y：复制当前行到最后一行的内容，p按键粘贴w file #将范围内的行另存至指定文件中r file #在指定位置插入指定文件中的所有内容t #行号，将前面指定的行复制到#行后m #行号，将前面指定的行移动到#行后 范例 123456789:2d #删除第2行:2,4d #删除第2到第4行:2;+3y #复制第2到第5行，总共4行:3;+4w test #将第2到第5行，总共4行内容写入新文件:5r /etc/issue #将/etc/issue 文件读取到第5行:t2 #将光标所在行复制到第2行:2;+3t10 #将第2到第5行，总共4行内容复制到第10行之后:.d #删除光标所在行:$y #复制最后一行 1.2.3 查找并替换格式 12:s/要查找的内容/替换为的内容/修饰符:%s 表示全文查找替换 说明 12要查找的内容：可使用基本正则表达式模式替换为的内容：不能使用模式，但可以使用\\1, \\2, ...等后向引用符号；还可以使用“&amp;”引用前面查找时查找到的整个内容 修饰符 1234不添加 #如果一行中有多个相同的字符串，只会替换第一个i #忽略大小写g #全局替换，默认情况下，每一行只替换第一次出现gc #全局替换，每次替换前询问 范例 12%s/root/ROOT #在全文查找root并替换为ROOT，但只会替换第一个（懒惰模式）%s/root/ROOT/g #在全文查找root并替换为ROOT，全部root都替换（贪婪模式） 查找替换中的分隔符&#x2F;可替换为其它字符，如：#,@ 12s@/etc@/var@gs#/boot#/#i 1.3 定制vim的工作特性扩展命令模式的配置只是对当前vim进程有效，可将配置存放在文件中持久保存 配置文件 12/etc/vimrc #全局~/.vimrc #个人 1.3.1 行号12显示：set number，简写 set nu取消显示：set nonumber, 简写 set nonu 1.3.2 忽略字符大小写12启用：set ignorecase，简写 set ic不忽略：set noic 1.3.3 自动缩进12启用：set autoindent，简写 set ai禁用：set noai 1.3.4 复制保留格式12启用：set paste禁用：set nopaste 1.3.5 显示Tab ^I和换行符 和$显示有些文件是不支持tab键 12启用：set list禁用：set nolist 1.3.6 高亮搜索12启用：set hlsearch禁用：set nohlsearch 简写：nohl 1.3.7 语法高亮12启用：syntax on禁用：syntax off 1.3.8 文件格式123启用windows格式：set fileformat=dos启用unix格式：set fileformat=unix简写 set ff=dos|unix 1.3.9 Tab 用空格代替123启用：set expandtab 默认为8个空格代替Tab禁用：set noexpandtab简写：set et 1.3.10 Tab用指定空格的个数代替12启用：set tabstop=# 指定#个空格代替Tab简写：set ts=4 1.3.11 设置缩进宽度1234#向右缩进 命令模式&gt;&gt;#向左缩进 命令模式&lt;&lt;#设置缩进为4个字符set shiftwidth=4 1.3.12 设置文本宽度12set textwidth=65 (vim only) #从左向右计数set wrapmargin=15 #从右到左计数 1.3.13 设置光标所在行的标识线12启用：set cursorline，简写 set cul禁用：set nocursorline 1.3.14 加密12启用： set key=password禁用： set key= 1.4 命令模式1.4.1 退出VIM12ZZ 保存退出ZQ 不保存退出 1.4.2 光标跳转字符间跳转 12345h: 左L: 右j: 下k: 上#COMMAND：跳转由#指定的个数的字符 单词间跳转 1234w：下一个单词的词首e：当前或下一单词的词尾b：当前或前一个单词的词首#COMMAND：由#指定一次跳转的单词数 当前页跳转 123456H：页首 M：页中间行 L：页底zt：将光标所在当前行移到屏幕顶端zz：将光标所在当前行移到屏幕中间zb：将光标所在当前行移到屏幕底端 行首行尾跳转 123^ 跳转至行首的第一个非空白字符0 跳转至行首$ 跳转至行尾 行间移动 1234#G 或者扩展命令模式下:# 跳转至由第#行G 最后一行1G, gg 第一行 句间移动 12) 下一句( 上一句 段落间移动 12&#125; 下一段&#123; 上一段 命令模式翻屏操作 1234Ctrl+f 向文件尾部翻一屏,相当于PagedownCtrl+b 向文件首部翻一屏,相当于PageupCtrl+d 向文件尾部翻半屏Ctrl+u 向文件首部翻半屏 1.4.3 字符编辑12345x 剪切光标处的字符#x 剪切光标处起始的#个字符xp 交换光标所在处的字符及其后面字符的位置~ 转换大小写J 删除当前行后的换行符 1.4.4 替换命令12r 只替换光标所在处的一个字符R 切换成REPLACE模式（在末行出现-- REPLACE -- 提示）,按ESC回到命令模式 1.4.5 删除命令1234567891011d 删除命令，可结合光标跳转字符，实现范围删除d$ 删除到行尾d^ 删除到非空行首d0 删除到行首dwdedb#COMMANDdd： 剪切光标所在的行#dd 多行删除D：从当前光标位置一直删除到行尾，等同于d$ 1.4.6 复制命令1234567891011y 复制，行为相似于d命令y$y0y^yeywyb#COMMANDyy：复制行#yy 复制多行Y：复制整行 1.4.7 粘贴命令12p 缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在处的后面P 缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在处的前面 1.4.8 改变命令命令 c 删除后切换成插入模式 12345678910c$c^c0cbcecw#COMMANDcc #删除当前行并输入新内容，相当于S#cc C #删除当前光标到行尾，并切换成插入模式,相当于c$ 1.4.9 查找1234/PATTERN：从当前光标所在处向文件尾部查找?PATTERN：从当前光标所在处向文件首部查找n：与命令同方向N：与命令反方向 1.4.10 撤消更改123456u 撤销最近的更改，相当于windows中ctrl+z#u 撤销之前多次更改U 撤消光标落在这行后所有此行的更改Ctrl-r 重做最后的“撤消”更改，相当于windows中crtl+y. 重复前一个操作#. 重复前一个操作#次 1.4.11 高级用法格式 12345678910111213&lt;start position&gt;&lt;command&gt;&lt;end positi#常见Commandy 复制、d 删除、gU 变大写、gu 变小写0y$ 命令0 → 先到行头y → 从这里开始拷贝$ → 拷贝到本行最后一个字符di&quot; 光标在” “之间，则删除” “之间的内容yi( 光标在()之间，则复制()之间的内容vi[ 光标在[]之间，则选中[]之间的内容dtx 删除字符直到遇见光标之后的第一个 x 字符ytx 复制字符直到遇见光标之后的第一个 x 字符 范例：粘贴“wang”100次 1100iwang [ESC] 1.5 可视化模式在末行有”– VISUAL – “指示，表示在可视化模式 允许选择的文本块 v 面向字符，– VISUAL – V 面向整行，– VISUAL LINE – ctrl-v 面向块，– VISUAL BLOCK – 可视化键可用于与移动键结合使用 w ) } 箭头等突出显示的文字可被删除，复制，变更，过滤，搜索，替换等 范例：在文件指定行的行首插入# 1234561、先将光标移动到指定的第一行的行首2、输入ctrl+v 进入可视化模式3、向下移动光标，选中希望操作的每一行的第一个字符4、输入大写字母 I 切换至插入模式5、输入 #6、按 ESC 键 范例：在指定的块位置插入相同的内容 123451、光标定位到要操作的地方2、CTRL+v 进入“可视块”模式，选取这一列操作多少行3、SHIFT+i(I)4、输入要插入的内容5、按 ESC 键 1.6 多文件模式12345678vim FILE1 FILE2 FILE3 ...:next 下一个:prev 前一个:first 第一个:last 最后一个:wall 保存所有:qall 不保存退出所有:wqall保存退出所有 1.7 多窗口模式1.7.1 多文件分割12345vim -o|-O FILE1 FILE2 ...-o: 水平或上下分割-O: 垂直或左右分割（vim only）在窗口间切换：Ctrl+w, Arrow：wqall：退出 1.7.2 单文件窗口分割12345Ctrl+w,s：split, 水平分割，上下分屏Ctrl+w,v：vertical, 垂直分割，左右分屏ctrl+w,q：取消相邻窗口ctrl+w,o：取消全部窗口:wqall 退出 1.8 文件恢复当我们正在编辑vim文件时，操作被中断，如死机、断电等等，我们编辑的文件就会丢失，可以看到目录中的文件，多出了一个swp文件，这个文件就保存了我们没有保存的信息，还有另一种情况也可能出现这种情况：其他用户正在编辑这个文件，可以通知其他用户，停止编辑，swp文件就会消失。 12345O #只读方式打开E #直接编辑，不会载入暂存文件，这样做可能会导致多个用户操作冲突R #恢复文件，即使使用R选项恢复了文件，swp文件也不会自动删除，需要我们手动进行删除，否则下次编辑还会出现Q #离开Vim不做任何操作A #忽略这个编辑行为，回到命令行，几乎和Q的作用相同 2 文本内容处理命令2.1 内容直接查看2.1.1 cat格式 1234567cat [option] file-A 显示所有控制符-E：显示行结束符$-n 加行号-b 非空行加行号-s 压缩连续的空行为一行 范例 123456789101112cat /proc/cpuinfo #显示CPU info的信息cat /proc/interrupts #显示中断cat /proc/meminfo #校验内存使用cat /proc/swaps #显示哪些swap被使用cat /proc/version #显示内核的版本cat /proc/net/dev #显示网络适配器及统计cat /proc/mounts #显示已加载的文件系统cat /proc/cpuinfo |grep &quot;cpu cores&quot; |uniq #查看核数cat /proc/cpuinfo |grep &quot;processor&quot; |wc -l #查看逻辑cpu个数cat /proc/cpuinfo |grep &quot;physical id&quot; |sort |uniq |wc -l #查看物理CPU个数cat /sys/class/fc_host/host1/supported_speeds #查看HBA卡cat /proc/cpuinfo |grep MHz|uniq #查看CPU的主频 2.1.2 nl显示行号，相当于cat -b 123456789[root@centos8 ~]#nl /data/f1.txt 1 a 2 b 3 c 4 d 5 e 6 f 7 g 8 h 2.1.3 tac逆向显示文本内容 123456789101112[root@centos8 ~]#cat /data/fa.txt12345[root@centos8 ~]#tac /data/fa.txt54321 2.1.4 rev将同一行的内容逆向显示 123456789101112[root@centos8 ~]#cat /data/fa.txt1 2 3 4 5a b c[root@centos8 ~]#tac /data/fa.txta b c1 2 3 4 5[root@centos8 ~]#rev /data/fa.txt5 4 3 2 1c b a[root@centos8 ~]#echo &#123;1..10&#125; |rev01 9 8 7 6 5 4 3 2 1 2.1.5 hexdump查看非文本文件内容 123-C 每个字节显示为16进制和相应的ASCII字符-n 只显示前n个长度的字符-s 从偏移量开始输出 范例 12hexdump -C -n 512 /dev/sda00000000 eb 63 90 10 8e d0 bc 00 b0 b8 00 00 8e d8 8e c0 |.c..............| 范例：跳过前735个字节,观察后面30个字节 1234[root@centos8 ~]#hexdump -s 735 -Cn 30 /bin/ls000002df 00 05 6d da 3f 1b 77 91 91 63 a7 de 55 63 a2 b9 |..m.?.w..c..Uc..|000002ef d9 d2 45 55 4c 00 00 00 00 03 00 00 00 7d |..EUL........&#125;|000002fd 2.2 内容分页查看2.2.1 more可以实现分页查看文件，可以配合管道实现输出信息的分页 123456more [OPTIONS...] FILE...-d: 显示翻页及退出提示空格键 一页一页往下翻q 退出（或者翻到底自动退出）Ctrl b 往回翻页 2.2.2 less可配合管道实现输出信息的分页 翻到底不会自动退出 12/文本 #搜索文本n/N #跳到下一个 或 上一个匹配 2.3 内容分行查看2.3.1 head可配合管道，可以显示文件或标准输入的前面行（默认前十行） 12345head [OPTION]... [FILE]...-c # 指定获取前#字节-n # 指定获取前#行,#如果为负数,表示不要倒数#行，即文件头取到倒数第#-1行-# 同上 2.3.2 tail可配合管道，可以显示文件或标准输入的倒数行 1234567tail [OPTION]... [FILE]...-c # 指定获取后#字节-n # 指定获取后#行,如果#为正数，显示不要前#-1行，即第#行取到文件尾-# 同上-f 跟踪显示文件fd新追加的内容,常用日志监控(/var/log/messages)，当文件删除再新建同名文件,将无法继续跟踪文件-F 跟踪文件名，当文件删除再新建同名文件,将可以继续跟踪文件 范例：查看最新发生的日志 12[root@centos8 ~]#tail -fn0 /var/log/messages[root@centos8 ~]#tail -0f /var/log/messages 2.4 合并多个文件内容2.4.1 cat123456789101112131415161718192021222324252627282930cat file1 file2（竖着合并）[root@centos8 ~]#cat alpha.logabcdefgh[root@centos8 ~]#cat seq.log12345[root@centos8 ~]#cat alpha.log seq.logabcdefgh12345 2.4.2 pastepaste 合并多个文件同行号的列到一行 1234paste [OPTION]... [FILE]...-d #分隔符：指定分隔符，默认用TAB-s #所有行合成一行显示 范例 123456789101112131415161718192021222324252627282930[root@centos8 ~]#paste alpha.log seq.loga 1b 2c 3d 4e 5fgh[root@centos8 ~]#paste -d&quot;:&quot; alpha.log seq.loga:1b:2c:3d:4e:5f:g:h:[root@centos8 ~]#paste -s seq.log1 2 3 4 5[root@centos8 ~]#paste -s alpha.loga b c d e f g h[root@centos8 ~]#paste -s alpha.log seq.loga b c d e f g h1 2 3 4 5[root@centos8 ~]#paste -s -d: f1.log f2.log1:2:3:4:5:6:7:8:9:10a:b:c:d:e:f:g:h:i:j 范例: 批量修改密码 12345678910[root@centos8 ~]#cat user.txtwangmage[root@centos8 ~]#cat pass.txt123456magedu[root@centos8 ~]#paste -d: user.txt pass.txtwang:123456mage:magedu[root@centos8 ~]#paste -d: user.txt pass.txt|chpasswd 2.5 分析文本2.5.1 收集文本统计数据 wc统计文件的行总数，单词总数，字节总数和字符总数 1234-l #只计行数-w #只计单词数-c #只计字节数-m #只计字符数 2.5.2 文本排序 sort文本排序，不改变原始文件 1234567sort [options] file(s)-r 反方向排序-n 按数字大小排序-t c 使用c作为分隔符-k # 按照使用c作为分隔符分隔的#列排序 -u 合并重复项，去重 范例：统计日志访问量 12[root@centos8 data]#cut -d&quot; &quot; -f1 /var/log/nginx/access_log |sort -u|wc -l201 范例：统计分区利用率 1[root@centos8 ~]#df | tr -s &quot; &quot; %|cut -d% -f5|tr -d &#x27;[:alpha:]&#x27; | sort -n 2.5.3 uniq 去重123-c 显示每行重复的次数-d 显示重复过的行-u 显示不曾重复过的行 范例：统计日志访问量最多的请求 12345678[root@centos8 data]#cut -d&quot; &quot; -f1 access_log |sort |uniq -c|sort -nr |head -3 4870 172.20.116.228 3429 172.20.116.208 2834 172.20.0.222[root@centos8 data]#lastb -f btmp-34 | tr -s &#x27; &#x27; |cut -d &#x27; &#x27; -f3|sort |uniq -c |sort -nr | head -3 86294 58.218.92.37 43148 58.218.92.26 18036 112.85.42.201 范例：并发连接最多的远程主机IP 123[root@centos8 ~]#ss -nt|tail -n+2 |tr -s &#x27; &#x27; : |cut -d: -f6|sort|uniq -c|sort -nr |head -n2 7 10.0.0.1 2 10.0.0.7 范例：取两个文件的相同和不同的行 1234567891011121314151617181920212223[root@centos8 data]#cat test1.txtab1c[root@centos8 data]#cat test2.txtbefc12#取文件的共同行[root@centos8 data]#cat test1.txt test2.txt | sort |uniq -d1bc#取文件的不同行[root@centos8 data]#cat test1.txt test2.txt | sort |uniq -u2aef 2.6 比较不同文件内容2.6.1 diff比较两个文件的区别 范例：知道一个文件怎么操作可以和另一个文件相同（-u） 123456789101112131415161718192021222324252627282930313233343536373839404142[20:01:23 root@10 data[]#cat a.txtabcd[20:02:03 root@10 data[]#cat b.txtaefdgh[20:02:08 root@10 data[]#diff a.txt b.txt2,3c2,3&lt; b&lt; c---&gt; e&gt; f4a5,6&gt; g&gt; h#&lt;代表a.txt ；&gt;代表b.txt ；2,3;5,6表示第二行到第三行，第五行到第六行不一样[20:02:18 root@10 data[]#diff -u a.txt b.txt--- a.txt 2023-08-10 20:01:15.394938187 +0800+++ b.txt 2023-08-10 20:02:03.802934670 +0800@@ -1,4 +1,6 @@ a-b-c+e+f d+g+h#-1,4表示a.txt的第一行到第四行；+1,6表示b.txt的第一行到第六行#a；d：表示两文件都有a，d#-b，-c，+e，+f，+g，+h：表示a.txt减b和c，加efgh后可以和b.txt一样 2.6.2 patch复制在其它文件中进行的改变（要谨慎使用） 1-b 选项来自动备份改变了的文件 范例：找回文件 前提 和diff相结合，可以将两个不同的文件直接用来生成一个新的被误删除的文件（ab.log），如果不小心把b.txt删了，可以结合a.txt和ab.txt把b.txt找回来 找回来后b.txt的内容会覆盖到a.txt上，加一个-b，可以给a.txt做备份，所以最后a.txt是原来b.txt的内容，a.txt.orig是原来a.txt的内容 123456789101112131415161718[20:06:59 root@10 data[]#diff -u a.txt b.txt &gt; ab.log[20:18:57 root@10 data[]#rm -f b.txt[20:21:25 root@10 data[]#patch -b a.txt ab.logpatching file a.txt[20:21:30 root@10 data[]#cat a.txtaefdgh[20:21:37 root@10 data[]#lsab.log a.txt a.txt.orig[20:21:40 root@10 data[]#cat a.txt.orig abcd 2.6.3 vimdiff相当于 vim -d 更加直观看到两个文件的区别，也可以去改 1vimdiff file1 file2 2.6.4 cmp范例：查看二进制文件的不同 12[root@centos8 ~]#cmp /bin/dir /bin/ls/bin/dir /bin/ls differ: byte 737, line 2 2.7 按列抽取文本cut12345678910cut [OPTION]... [FILE]...-d DELIMITER: 指明分隔符，默认tab-f FILEDS: #: 第#个字段,例如:3 #,#[,#]：离散的多个字段，例如:1,3,6 #-#：连续的多个字段, 例如:1-6 混合使用：1-3,7-c 按字符切割--output-delimiter=STRING指定输出分隔符 范例：以 : 为分隔符，取第1和第3列 1[root@centos8 ~]#cut -d: -f1,3 /etc/passwd 范例: 取分区利用率 123[root@centos8 ~]#df | cut -c 44-46|tail -n +2[root@centos8 ~]#df | tail -n +2|tr -s &#x27; &#x27; % |cut -d% -f5[root@centos8 ~]#df | tail -n +2|tr -s &#x27; &#x27; |cut -d&#x27; &#x27; -f5 |tr -d % 2.8 转换或删除字符tr它支持标准输入，它默认读取键盘输入的内容，做一些相关处理的转换，它可以读取标准输入，做转换，压缩，删除等等（一一对应），处理完还会在屏幕上继续把结果输出出来 12345678910111213141516171819202122232425262728293031tr [OPTION]... SET1 [SET2]#常用选项-d #删除-s #压缩-c #用SET2替换SET1中没有包含的字符-t #将SET1用SET2替换，SET2中不够的，就不处理#常用通配符[:alnum:] #字母和数字[:alpha:] #字母[:digit:] #数字[:lower:] #小写字母[:upper:] #大写字母[:space:] #空白字符[:print:] #可打印字符[:punct:] #标点符号[:graph:] #图形字符[:cntrl:] #控制（非打印）字符[:xdigit:] #十六进制字符#常用符号\\NNN #具有八进制值 NNN 的字符（1 到 3 个八进制数字）\\\\ #反斜杠\\a #发出警告声\\b #退格键\\f #form feed\\n #换行\\r #回车，即光标移至行首，但不换行\\t #插入tab\\v #垂直tab 范例 1234#把/etc/issue中的小写字符都转换成大写字符tr ‘a-z’ ‘A-Z’&lt; /etc/issue#删除fstab文件中的所有abc中任意字符tr –d abc &lt; /etc/fstab 范例 12345678910tr &#x27;a-z&#x27; &#x27;A-Z&#x27;（把a-z小写转换为A-Z大写）tr &#x27;abc&#x27; &#x27;xyz&#x27;（a转x，b转y，c转z）tr -d &#x27;\\n&#x27; &#x27; &#x27;（将换行转换为一个空格）tr -d &#x27;abc&#x27;（把abc删除）tr -d &#x27;\\n&#x27;（把换行删除）tr -s &#x27;abc&#x27;（把abc压缩，压缩只压相邻的）tr -s &#x27; &#x27;（压缩成为只有一个空格）tr -s &#x27; &#x27; +（压缩成为只有一个空格后，将空格转换为+） 范例 123456789#非123就替换成x[root@ubuntu2204 ~]# tr -c 123 x1357913xxxx#非2-5的内容替换成 x[root@ubuntu2204 ~]# tr -c &#x27;2-5&#x27; x123456789x2345xxxxx 范例：与管道符相应用 1234echo hallboc | tr &#x27;abc&#x27; &#x27;xyz&#x27;（输出结果为hxllyoz)echo hallboc | tr -d &#x27;abc&#x27;（输出结果为hllo)echo aaabbbccccc | tr -s &#x27;abc&#x27;（输出结果为abc)tr &#x27;\\n&#x27; &#x27; &#x27; | tr &#x27; &#x27; &#x27;\\n&#x27;（开始是换行转空格，接着空格转换行） 范例 1234567891011121314151617181920212223242526[lsc@localhost ~]$ cat test.shI love cats.I love rabbits.I love camels.#SET1多出来的字符映射为SET2最后一个字符[lsc@localhost ~]$ tr cat do &lt; test.shI love doos.I love robbios.I love domels.#SET1中有重复字符 —— 以SET2最后一次映射的为准[lsc@localhost ~]$ tr caa dog &lt; test.shI love dgts.I love rgbbits.I love dgmels.#-c选项的SET2只有最后一个字符是有效的，会将文本中除了SET1的所有字符替换为SET2的最后一个字符，这里包括文本最后的一个换行符，所以会发现Linux控制台前缀会出现在输出结果的后面，而不是另起一行[lsc@localhost ~]$ tr -c cat dog &lt; test.shgggggggcatgggggggggggagggtggggggggggcagggggg[lsc@localhost ~]$#[:alnum:]是SET1，即需要包含的内容，因为没有SET2，有个-d，所以就把不包含在SER1中的内容删掉[root@ubuntu2004 ~]#tr -dc dog &lt; test.txtooo[root@ubuntu2004 ~]#[root@ubuntu2004 ~]#tr -dc &#x27;[:alnum:]&#x27; &lt; test.txtIlovecatsIloverabbitsIlovecamels 2.9 双向输出tee利用 tee 命令可以重定向到多个目标，经常配合管道符一起使用 12命令1 | tee [-a ] 文件名 | 命令2 #把命令1的STDOUT保存在文件中，做为命令2的输入-a 追加，不会覆盖原来的内容 功能： 保存不同阶段的输出 复杂管道的故障排除 同时查看和记录输出 范例 123456789[root@centos7 ~]#tee c.logaabb^C[root@centos7 ~]#cat c.log ab 范例 123456789101112131415[root@centos7 ~]#echo -e &#x27;line1\\nline2\\nline3&#x27; | tee d.logline1line2line3[root@centos7 ~]#cat d.logline1line2line3[root@centos8 ~]#cat &lt;&lt;EOF | tee /etc/motd&gt; welcome to magedu&gt; happy new year&gt; EOFwelcome to mageduhappy new year","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"文件管理工具","slug":"Linux/linux-basics/file-command","date":"2025-08-21T02:44:22.000Z","updated":"2025-08-28T12:33:05.244Z","comments":true,"path":"Linux/linux-basics/file-command/","permalink":"https://aquapluto.github.io/Linux/linux-basics/file-command/","excerpt":"","text":"1 文件通配符匹配文件名的字符串 用来匹配符合条件的多个文件，方便批量管理文件 通配符采用特定的符号，表示特定的含义，此特定符号称为元 meta 字符 常见通配符 12345* #匹配零个或多个字符，不匹配 “.” 开头的文件，即隐藏文件？ #匹配任何单个字符，一个汉字也算一个字符~ #当前用户家目录** #匹配后代所有子目录[] #只会匹配[]中的一个字符，不可以为空 范例 12ls *.conf #把所有以.conf结尾的文件都输出ls * con* #把中间包含con的文件都输出 范例 123ls ??? #显示三个字符的文件，但是会显示文件夹）ls ??? -d #显示三个字符的文件，不会显示文件夹）ls ???.conf #显示三个字符，以.conf结尾的文件） 范例 12ls ~ #显示家目录ls ~wu #显示wu家（别人家）目录，如果都是隐藏文件，后面加个-a，即ls ~wu -a 范例 123456#这样子写会认为是c.*，g.*，f.*[root@centos7 etc]#ls [cfg].*ls: cannot access [cfg].*: No such file or directory[root@centos7 etc]#ls [cgf]*.*chrony.conf chrony.keys cron.deny csh.cshrc csh.login favicon.png fstab.log fuse.conf grub2.cfg 范例：匹配etc目录及其所有子目录下的所有以c开头的文件 1234567[root@centos7 ~]#ls /etc/**/c*/etc/libnl/classid /etc/pam.d/crond /etc/profile.d/csh.local /etc/sysconfig/chronyd/etc/logrotate.d/chrony /etc/postfix/canonical /etc/python/cert-verification.cfg /etc/sysconfig/cpupower/etc/my.cnf.d/client.cnf /etc/profile.d/colorgrep.csh /etc/security/chroot.conf /etc/sysconfig/crond/etc/pam.d/chfn /etc/profile.d/colorgrep.sh /etc/security/console.handlers /etc/systemd/coredump.conf/etc/pam.d/chsh /etc/profile.d/colorls.csh /etc/security/console.perms/etc/pam.d/config-util /etc/profile.d/colorls.sh /etc/selinux/config [] 匹配字符 123456789101112131415161718[0-9] #匹配数字范围[a-z] #一个小写字母[A-Z] #一个大写字母[wang] #匹配列表中的任何的一个字符[^wang] #匹配列表中的所有字符以外的字符[^a-z] #匹配列表中的所有字符以外的字符[:digit:] #任意数字，相当于0-9[:lower:] #任意小写字母,表示 a-z[:upper:] #任意大写字母,表示 A-Z[:alpha:] #任意大小写字母[:alnum:] #任意数字或字母[:blank:] #水平空白字符[:space:] #水平或垂直空白字符[:punct:] #标点符号[:print:] #可打印字符[:cntrl:] #控制（非打印）字符[:graph:] #图形字符[:xdigit:] #十六进制字符 特殊字符之 “-” 1234567#减号用在字符集“[…]”里表示一组字符“[1-3]” —— 表示1到5中的任意一个字符，所以“&lt;H[1-3]&gt;”表示“&lt;H1&gt;”、“&lt;H2&gt;”或者“&lt;H3&gt;”“[d-g]” —— 表示“d”、“e”、“f”或者“g”#如果不是用在字符集“[…]”里，就是普通的字符，即减号“1-[1-3]” —— 表示“1-1”、“1-2”或者“1-3”#但是，即使在字符集“[…]”里，却非连续字符之间，也失去了特殊含义“1[-1]” —— 表示“1-”或者“11” 范例： 1234567891011121314#先创建一个文件 touch /data/&#123;a..z&#125;.txt ls /data/[wang].txt #输出w,a,n,g字符开头的文件ls /data/[c-h].txt #输出c,d,e,f,g,h字符开头的文件ls /data/[ ^wang].txt #输出除了w,a,n,g字符开头的所有文件#然后接着创建touch /data/&#123;0..9&#125;.txtls /data/[wang1-3].txt #输出1,2,3,w,a,n,g字符开头的文件#最后创建touch /data/&#123;A..Z&#125;.txtls /data/[a-d].txt #输出a,A,b,B,c,C,d字符开头的文件ls /data/[[:lower:]].txt #输出所有小写字母开头的文件ls /data/[[:upper:]].txt #输出所有大写字母开头的文件ls /data/[[:alpha:]].txt #输出所有大小写字母开头的文件ls /data/[[:alnum:]].txt #输出所有字母和数字开头的文件 范例：比较有无*的功能区别 12345ls * #等同于 ls 列出当前目录内容，不包括 . 和 ..ls -a * #等同于 ls 列出当前目录内容，不包括 . 和 ..ls -a #列出当前目录所有内容，包括 . 和 ..ls .* #列出当前目录和上级目录的内容， .* 包括 .. 也就是上级目录 ls -d .* #只显示当前目录的内容，有预定的别名 l. 范例 123456789101112[root@centos7 data]#ls -a . .. a2.txt ab.log a.txt.orig backup2023-08-16 scripts[root@centos7 data]#ls -a *a2.txt ab.log a.txt.origbackup2023-08-16:. .. etcscripts:. chess.sh date.sh hello.sh ip.sh nginx.sh num_sort.sh sum.sh text3.sh t.sh user.sh.. color.sh first.sh hosts.txt nginx_install.sh num_add.sh ping.sh text2.sh text.sh useradd.sh var.sh 范例 123456[root@centos8 data]#touch file*.log[root@centos8 data]#touch file1.log[root@centos8 data]#ls file*.logfile1.log &#x27;file*.log&#x27;[root@centos8 data]#ls &#x27;file*.log&#x27;&#x27;file*.log&#x27; 2 CRUD文件和目录2.1 目录操作2.1.1 显示当前工作目录每个shell和系统进程都有一个当前的工作目录 CWD：current work directory 显示当前shell CWD的绝对路径 pwd命令: printing working directory -P 显示真实物理路径 -L 显示链接路径（默认） 12345#当前目录pwd#上一次目录oldpwd 2.1.2 绝对和相对路径（1）绝对路径 以&#x2F;即根目录开始，打出完整的文件位置路径 完整的文件的位置路径 可用于任何想指定一个文件名的时候 12[root@centos7 ~]#ls /etc/sysconfig/network-scripts/ifcfg-eth0/etc/sysconfig/network-scripts/ifcfg-eth0 （2）相对路径 不以&#x2F;开头，先以cd切换到了一个目录，再想访问其目录下的子目录的话，可以直接打出文件名，相对于当前目录的路径 123[root@centos7 ~]#cd /etc/sysconfig/[root@centos7 sysconfig]#ls network-scripts/ifcfg-eth0network-scripts/ifcfg-eth0 （3）basename 只取文件名不要路径 12[root@centos7 sysconfig]#basename /etc/sysconfig/network-scripts/ifcfg-eth0ifcfg-eth0 （4）dirname 只取路径不要文件名 12[root@centos7 sysconfig]#dirname /etc/sysconfig/network-scripts/ifcfg-eth0/etc/sysconfig/network-scripts 2.1.3 更改目录12345678910cd [-L|[-P [-e]] [-@]] [dir]#常用选项-L #切换至链接目录，默认选项-P #切换至真实目录，而非链接目录cd .. #切换至根目录cd - #切换到上一个目录cd | cd ~ #切换至当前用户家目录cd ~username #切换至指定用户家目录cd path #切换到指定目录 2.1.4 列出目录内容1234567891011121314151617181920ls （简略列出）-l #显示除文件名外的大小属性权限等，相当于ll-a #显示隐藏文件 -d #查看目录属性-S #按从大到小排序-R #目录递归-t #按mtime排序，时间新的靠前-u #配合-t选项，显示并按atime从新到旧排序-U #按目录存放顺序显示-X #按文件后缀排序-F #对不同类型文件显示时附加不同的符号：*/=&gt;@|-C #文件多时，以多列的方式显示文件，默认是一列（标准输出）-l --time=atime #atime是指access(使用) time，读取文件内容就会更新这个时间-l --time=ctime #ctime是指change(改变) time，元数据发生改变就会更改这个时间-l --time=mtime #mtime是指modify(修改) time，改变文件内容或者数据就会更改这个时间ll （详细列出）-a #显示隐藏文件 -d #查看目录属性!* #快速打上一条命令的后面部分 说明： ls 查看不同后缀文件时的颜色由 &#x2F;etc&#x2F;DIR_COLORS 和@LS_COLORS变量定义 ls -l 看到文件的大小，不一定是实际文件真正占用空间的大小 ll 是 ls命令的一个别名，在centos 和 ubuntu 系统中，该别名的参数不一样 12345[root@rocky86 ~]# alias llalias ll=&#x27;ls -l --color=auto&#x27;root@ubuntu20:~# alias llalias ll=&#x27;ls -alF&#x27; 范例 12345678910111213141516[root@centos8 ~]#vim /etc/DIR_COLORS.jpg 01;31 #修改此行[root@centos8 ~]#exit[root@centos8 ~]#echo $LS_COLORS....#ubuntu 中无此文件[root@ubuntu2204 ~]# ls /etc/DIR_COLORSls: cannot access &#x27;/etc/DIR_COLORS&#x27;: No such file or directory#ubuntu 中的颜色是在 dircolors 命令中定义的[root@ubuntu2204 ~]# dircolors -p...#在ubuntu 中定义颜色，类似于别名定义，加在 .bashrc 中即可 2.1.5 查看目录结构12345678910111213141516171819tree [-acdfghilnpqrstuvxACDFJQNSUX] [-H baseHREF] [-T title ]-a #显示所有，包括隐藏目录和文件-d #只显示目录-f #显示所有内容的完整路径-F #在执行文件，目录，Socket，符号链接，管道文件，各自加上&quot;*&quot;,&quot;/&quot;,&quot;=&quot;,&quot;@&quot;,&quot;|&quot;号-g #显示文件属组，没找到组名，以gid代替-u #显示文件属主，没找到用户名，以uid代替-p #显示内容权限-s #显示内容大小-i #不以层级结构显示-n #不显示颜色-t #显示时用修改时间排序-r #以默认显示顺序的反向规则显示，默认以数字，首字母的顺序规则来显示-D #显示内容修改时间-C #显示色彩-L n #只显示n层目录-P pattern #只显示由指定wild-card pattern匹配到的路径-o filename #将显示的内容输出到指定文件中 范例 1234567#显示当前目录的树[root@ubuntu2204 ~]# tree[root@ubuntu2204 ~]# tree dir1/#仅显示两层目录[root@ubuntu2204 ~]# tree -d -L 2 / 2.1.6 创建目录123456mkdir [OPTION]... DIRECTORY...#常用选项-m|--mode #目录权限属性-p|--parents #如果要创建的目录父级目录不存在，则一起创建，是递归的意思-v|--verbose #显示创建过程 范例 12345678#创建data下的文件夹dir1[root@ubuntu2204 ~]#mkdir /data/dir1 #这样子创建会失败，因为dir2还没有，dir3是不可能创建的，要想一键创建，需要-p[root@ubuntu2204 ~]#mkdir /data/dir1/dir2/dir3/dir4 #指定权限[root@ubuntu2204 ~]# mkdir -m=777 dirb 2.1.7 删除空目录rmdir只能删除空目录，如果想删除非空目录，可以使用rm -r 命令，递归删除目录树 123456rmdir [OPTION]... DIRECTORY...#常用选项--ignore-fail-on-non-empty #忽略非空错误提示-p|--parents #连着父目录一起删除-v|--verbose #显示删除过程 范例：从外层开始创建，从里层开始删除 1234567891011[root@ubuntu2204 ~]# mkdir -pv a/b/c/dmkdir: created directory &#x27;a&#x27;mkdir: created directory &#x27;a/b&#x27;mkdir: created directory &#x27;a/b/c&#x27;mkdir: created directory &#x27;a/b/c/d&#x27;[root@ubuntu2204 ~]# rmdir -pv a/b/c/drmdir: removing directory, &#x27;a/b/c/d&#x27;rmdir: removing directory, &#x27;a/b/c&#x27;rmdir: removing directory, &#x27;a/b&#x27;rmdir: removing directory, &#x27;a&#x27; 范例 12#rmdir具有局限性，只能删空目录，所以此命令只能删掉dir4，因为只有dir4是空的[root@ubuntu2204 ~]#rmdir /data/dir1/dir2/dir3/dir4 2.2 文件操作2.2.1 查看文件状态一个文件有两部份信息：元数据和具体内容 查看文件元数据 1234567stat [OPTION]... FILE...可以一键全部显示atime ctime mtime#常用选项-t|--terse #使用简洁格式显示-f|--file-system #显示相关的文件系统信息，所谓文件系统，对应的就是windows下面的硬盘分区-c|--format #使用特定格式输出 范例 1234567891011#查看文件所在分区的信息[root@ubuntu2204 ~]# stat -f /etc/fstabFile: &quot;/etc/fstab&quot;ID: 55a3efb585efc96c Namelen: 255 Type: ext2/ext3Block size: 4096 Fundamental block size: 4096Blocks: Total: 25397502 Free: 23933766 Available: 22632109Inodes: Total: 6488064 Free: 6395997#权限-inode-文件名[root@ubuntu2204 ~]# stat -c &quot;%a-%i-%n&quot; /etc/fstab644-3277488-/etc/fstab 2.2.2 判断文件是什么类型文件可以包含多种类型的数据，使用file命令检查文件的类型，然后确定适当的打开命令或应用程序使用 1234567file [options] &lt;filename&gt;...#常用选项-b|--brief #只显示结果，不显示文件名-f|--files-from FILE #从指定文件中获取要处理的文件名-F|--separator STRING #指定分割符-L|--dereference #跟随软链接 范例：windows的文本格式和Linux的文本格式的区别 1234567891011121314151617181920212223242526272829[root@ubuntu2204 ~]# cat linux.txtabc[root@ubuntu2204 ~]# cat win.txtabc[root@ubuntu2204 ~]# file linux.txt win.txtlinux.txt: ASCII textwin.txt: ASCII text, with CRLF line terminators#安装转换工具 [root@ubuntu2204 ~]# apt install dos2unix#将Windows的文本格式转换成的Linux文本格式[root@ubuntu2204 ~]# dos2unix win.txtdos2unix: converting file win.txt to Unix format...[root@ubuntu2204 ~]# file win.txtwin.txt: ASCII text#将Linux的文本格式转换成Windows的文本格式[root@ubuntu2204 ~]# unix2dos win.txtunix2dos: converting file win.txt to DOS format...[root@ubuntu2204 ~]# file win.txtwin.txt: ASCII text, with CRLF line terminators 范例：转换文件字符集编码 12345678910111213141516171819202122232425262728#显示支持字符集编码列表[root@centos8 ~]#iconv -l#windows7上文本默认的编码ANSI（GB2312）[root@centos8 data]#file windows.txtwindows.txt: ISO-8859 text, with no line terminators[root@centos8 data]#echo $LANGen_US.UTF-8#默认在linux无法正常显示文本内容[root@centos8 data]#cat windows.txt#将windows7上文本默认的编码ANSI（GB2312）转换成UTF-8[root@centos8 data]#iconv -f gb2312 windows.txt -o windows1.txt[root@centos8 data]#cat windows1.txt[root@centos8 data]#ll windows1.txt-rw-r--r-- 1 root root 12 Mar 23 10:13 windows1.txt[root@centos8 data]#file windows1.txtwindows1.txt: UTF-8 Unicode text, with no line terminators#将UTF-8转换成windows10上文本默认的编码ANSI（GB2312）[root@centos8 data]#iconv -f utf8 -t gb2312 windows1.txt -o windows2.txt[root@centos8 data]#file windows2.txtwindows2.txt: ISO-8859 text, with no line terminators 2.2.3 创建空文件和刷新时间touch命令可以用来创建空文件或刷新文件的时间，如果创建的文件已经存在，那么将会刷新三个时间戳 123456touch [OPTION]... FILE...-a #仅改变 atime和ctime-m #仅改变 mtime和ctime-t [[CC]YY]MMDDhhmm[.ss] #指定atime和mtime的时间戳-c #如果文件不存在，则不予创建 范例 1234567[root@centos8 data]#touch `date -d &quot;-1 day&quot; +%F_%T`.log[root@centos8 data]#ls2019-12-12_16:11:48.log[root@centos8 data]#touch $(date -d &quot;1 year&quot; +%F_%T).log[root@centos8 data]#ls2019-12-12_16:11:48.log 2020-12-13_16:13:11.log 2.2.4 复制文件和目录12345678910111213141516171819202122cp [OPTION]... source... directorycp [OPTION]... -t DIRECTORY SOURCE...-i #如果目标已存在，覆盖前提示是否覆盖-n #不覆盖，注意两者顺序-a #保留文件所有属性，递归复制目录及内部的所有内容-b #目标存在，覆盖前先备份，默认形式为 filename~ ,只保留最近的一个备份-r #递归复制目录及内部的所有内容-v #显示拷贝后的路径描述-d #不复制原文件，只复制链接名-f #强行复制文件或目录，不论是否存在-u #只复制源比目标更新文件或目标不存在的文件，即当源文件比目标文件新时，才执行复制操作--backup=numbered #目标存在，覆盖前先备份加数字后缀，形式为 filename.~#~ ，可以保留多个版本--preserve[=ATTR_LIST] #选择属性，默认为 mode,ownership,timestamps-p #等同--preserve=mode,ownership,timestampmode #权限ownership #属主属组timestamp #时间戳links #保留链接xattr #保留自定义属性context #保留selinux属性all #所有属性 源目标 不存在 存在且为文件 存在且为目录 一个文件 新建DEST，并将SRC中内容填充至DEST中 将SRC中的内容覆盖至DEST中，注意数据丢失风险！ 建议用 –i 选项 在DEST下新建与原文件同名的文件，并将SRC中内容填充至新文件中 多个文件 提示错误 提示错误 在DEST下新建与原文件同名的文件，并将原文件内容复制进新文件中 目录须使用-r选项 创建指定DEST同名目录，复制SRC目录中所有文件至DEST下 提示错误 在DEST下新建与原目录同名的目录，并将SRC中内容复制至新目录中 范例 12345678910111213141516171819202122232425262728#保留属主属组，时间戳[root@ubuntu2204 ~]# cp -p ~wang/issue /data/issue_wang2.bak#cp 整个目录[root@ubuntu2204 ~]# cp /etc/sysconfig/ /data/cp: -r not specified; omitting directory &#x27;/etc/sysconfig/&#x27;[root@ubuntu2204 ~]# cp -r /etc/sysconfig/ /data/#特殊文件复制，不能直接cp ,要加 a 选项[root@ubuntu2204 ~]# cp /dev/zero&#123;,.bak&#125;#保留多版本备份[root@ubuntu2204 0508]# cp --backup=numbered x.log y.log[root@ubuntu2204 0508]# lsx.log y.log y.log.~1~[root@ubuntu2204 0508]# cp --backup=numbered x.log y.log[root@ubuntu2204 0508]# lsx.log y.log y.log.~1~ y.log.~2~#如果复制目录的目录名已存在，将已复制目录的命令命名并成为该目录的子目录[root@ubuntu2004 ~]#cp -r /etc/ /opt/bak[root@ubuntu2004 ~]#ls /opt/bak[root@ubuntu2004 ~]#cp -r /etc/ /opt/bak[root@ubuntu2004 ~]#ls /opt/bak/ | grep etcetc[root@ubuntu2004 ~]#ls /opt/bak/etc...... 2.2.5 移动文件和重命名文件mv 命令可以实现文件或目录的移动和改名 同一分区移动数据，速度很快，数据位置没有变化 不同分区移动数据，速度相对慢，数据位置发生了变化 123456789101112mv [OPTION]... [-T] SOURCE DESTmv [OPTION]... SOURCE... DIRECTORYmv [OPTION]... -t DIRECTORY SOURCE...#常用选项-b #如果目标存在，则先备份-n #如果目标文件己存在，则跳过此文件移动-i #如果目标文件己存在，则提示是否覆盖-u #当源文件比目标文件新时，才执行移动操作-v #显示移动过程-f #强制-t distory #取反。当不知道要把什么文件移动时，可以加-t，就可以保证不知名文件移动到distory下 范例 1234567891011121314151617#将0.txt移动到opt下mv 0.txt /opt/ #将1.txt改名为11.txtmv 1.txt 11.txt #修改了ls的后缀（Linux对后缀不敏感）mv ls ls.mp3#将 abc目录放入 abcd 目录中，如果 abcd 目录不存在，则将 abc 目录改名为 abcd 目录[root@rocky86 ~]# mv abc/ abcd#将 abc 目录下所有内容移动到当前目录[root@rocky86 ~]# mv abc/* .#移动多个文件到目录[root@rocky86 ~]# mv a b c d abcd/ 利用 rename 可以批量修改文件名 1234567rename [options] &lt;expression&gt; &lt;replacement&gt; &lt;file&gt;...#常用选项-v|--verbose #显示过程-s|--symlink #如果目标是链接文件，则是重命名其指向-n|--no-act #不做任何改变-o|--no-overwrite #不覆盖己存在文件 范例 1234567891011121314#将所有txt后缀的文件改为txt.orig后缀 （*.txt表示在txt文件下修改）[root@rocky86 ~]#rename txt txt.orig *.txt#为所有的f开头包含conf的文件加上.bak后缀：[root@rocky86 ~]#rename &#x27;conf&#x27; &#x27;conf.bak&#x27; f*#去掉所有的bak后缀：[root@rocky86 ~]#rename &#x27;.bak&#x27; &#x27;&#x27; *.bak#将当前目录下 以.txt结尾的文件，批量改名成 .log结尾[root@rocky86 ~]# rename -v txt log *.txt#将 abc.link 指向的文件由 abc 改成 xyz[root@rocky86 ~]# rename -s abc xyz abc.link 2.2.6 删除文件使用 rm 命令可以删除文件和目录 注意：此命令非常危险，慎重使用，建议使用 mv 代替 rm 12345678rm [OPTION]... [FILE]...#常用选项-i #删除前确认-f #不确认直接删除-r|-R #递归删除-d #删除空目录--no-preserve-root #强删根目录 由于rm命令比较危险，可以设置别名，将删除的东西放进垃圾箱 1alias rm=&#x27;DIR=/data/backup`date +%F%T`;mkdir $DIR;mv -t $DIR&#x27; 或者用trash-put命令执行删除，删除的文件可以恢复，删除的文件默认在 ~&#x2F;.local&#x2F;share&#x2F;Trash&#x2F;files 范例：删除特殊文件 1234567891011121314151617181920212223242526272829303132333435[root@ubuntu2204 0508]# ls-f#删不掉[root@ubuntu2204 0508]# rm -f[root@ubuntu2204 0508]# ls-f#删不掉[root@ubuntu2204 0508]# rm -rf -f[root@ubuntu2204 0508]# ls-f#删不掉[root@ubuntu2204 0508]# rm -rf *[root@ubuntu2204 0508]# ls-f[root@ubuntu2204 0508]#rm -rf ./-f[root@ubuntu2204 0508]# ls[root@ubuntu2204 0508]# rm -- -f[root@ubuntu2204 0508]# ls[root@ubuntu2204 0508]# touch &#x27;~&#x27;[root@ubuntu2204 0508]# ls&#x27;~&#x27;[root@ubuntu2204 0508]# rm -f ~rm: cannot remove &#x27;/root&#x27;: Is a directory[root@ubuntu2204 0508]# rm -- ~rm: cannot remove &#x27;/root&#x27;: Is a directory[root@ubuntu2204 0508]# rm -f ./~ 范例：删除大文件 1cat /dev/null &gt; /var/log/huge.log 2.2.7 读取文件12345tail [OPTION]... [FILE]...-f 循环读取-q 不显示处理信息-v 显示详细的处理信息 2.2.8 快速删除一个大文件在大多数文件系统中，当你使用 rm 命令删除一个文件时，实际上被删除的是文件的目录项和对文件数据块的引用计数。也就是说，文件系统会移除指向该文件的数据块的指针，并将这些数据块标记为可用空间。然而，实际的数据块内容并没有立刻从磁盘上物理地擦除。 由于数据块只是被标记为“可重用”，而没有真正清零或覆盖，因此如果新的数据尚未写入这些块，那么原先的数据仍然存在于磁盘上。这意味着，在一定条件下（例如通过专门的数据恢复工具），这些数据是可以被恢复的。 有时，文件特别特别的大，或者磁盘IO繁忙，你直接用 rm -rf 删除的话会非常慢，进而影响其他进程的正常运行。如何处理呢？思路就在于inode块上，inode中存着文件的元数据（例如，文件大小、所有者ID、组ID、文件权限、时间戳等） 1truncate -s 0 /path/to/your/large/file truncate命令工作时，会直接修改inode中记录的文件大小，将其设置为0，而并不会去触及到文件内容所在的数据块。所以磁盘IO消耗极小，速度极快。设为0之后，你再用rm命令把这这个空文件删掉就可以了 3 文件查找和压缩3.1 文件查找工具3.1.1 locate locate 查询系统上预建的文件索引数据库 &#x2F;var&#x2F;lib&#x2F;mlocate&#x2F;mlocate.db 索引的构建是在系统较为空闲时自动进行(周期性任务)，执行updatedb可以更新数据库 索引构建过程需要遍历整个根文件系统，很消耗资源 locate和updatedb命令来自于mlocate包 搜索之前先用updatedb更新一下数据库 工作特点: 查找速度快 模糊查找 非实时查找，适合查找静止的文件 搜索的是文件的全路径，不仅仅是文件名 可能只搜索用户具备读取和执行权限的目录 12345678910locate [OPTION]... [PATTERN]...-i #不区分大小写的搜索-n N #只列举前N个匹配项目-r #使用基本正则表达式--regex #使用扩展正则表达式-A #输出所有能匹配到的文件名，不管文件是否存在-b #仅匹配文件名部份，而不匹配路径中的内容-c #只输出找到的数量-d #指定数据库 范例 12345678#搜索名称或路径中包含“conf&quot;的文件locate conf#使用Regex来搜索以“.conf&quot;结尾的文件locate -r &#x27;\\.conf$&#x27;#搜索ect目录中以a开头的文件或目录locate /etc/a#指定数据库locate -d /tmp/nofile conf 3.1.2 findfind 是实时查找工具，通过遍历指定路径完成文件查找 工作特点： 查找速度略慢 精确查找 实时查找 查找条件丰富 可能只搜索用户具备读取和执行权限的目录 1find [OPTION]... [查找路径] [查找条件] [处理动作] 查找路径：指定具体目标路径；默认为当前目录 查找条件：指定的查找标准，可以文件名、大小、类型、权限等标准进行；默认为找出指定路径下的所有文件 处理动作：对符合条件的文件做操作，默认输出至屏幕 3.1.2.1 指定搜索目录层级12-maxdepth level 最大搜索目录深度,指定目录下的文件为第1级-mindepth level 最小搜索目录深度 范例 123456#最大搜索深度[root@ubuntu2204 ~]# find /etc/ -maxdepth 2#最小搜索深度[root@ubuntu2204 ~]# find /etc/ -mindepth 2#仅搜索第二层目录[root@ubuntu2204 ~]# find /etc/ -maxdepth 2 -mindepth 2 3.1.2.2 对每个目录先处理目录内的文件，再处理目录本身1-depth 范例 12345678910111213141516[root@centos8 data]#find /data/test/data/test/data/test/f1.txt/data/test/f2.txt/data/test/test2/data/test/test2/test3/data/test/test2/test3/f3.txt/data/test/test2/test3/f4.txt[root@centos8 data]#find /data/test -depth/data/test/f1.txt/data/test/f2.txt/data/test/test2/test3/f3.txt/data/test/test2/test3/f4.txt/data/test/test2/test3/data/test/test2/data/test 3.1.2.3 根据文件名和inode查找123456-name &quot;文件名称&quot; #支持使用glob，如：*, ?, [], [^],通配符要加双引号引起来-iname &quot;文件名称&quot; #不区分字母大小写-inum n #按inode号查找-samefile name #相同inode号的文件-links n #链接数为n的文件-regex “PATTERN&quot; #以PATTERN匹配整个文件路径，而非文件名称 范例 12345678910111213141516171819find -name snow.pngfind -iname snow.pngfind / -name &quot;.txt&quot;find /var –name &quot;log*&quot;[root@centos8 data]#find -regex &quot;.*\\.txt$&quot;./scripts/b.txt./f1.txt[root@ubuntu2204 ~]# find -regex &quot;.*test-[a-z].*&quot;./test-a.log./test-a.txt./test-b.log./test-b.txt[root@ubuntu2204 ~]# find -regex &quot;.*dir3.*&quot;./dir1/dir2/dir3./dir1/dir2/dir3/fx./dir1/dir2/dir3/fy[root@ubuntu2204 ~]# find -regex &quot;.*dir3$&quot;./dir1/dir2/dir3 范例 1234find / -name file1 #从 &#x27;/&#x27; 开始进入根文件系统搜索文件和目录find /home/user1 -name \\*.bin #在目录 &#x27;/ home/user1&#x27; 中搜索带有&#x27;.bin&#x27; 结尾的文件find / -name \\*.rpm -exec chmod 755 &#x27;&#123;&#125;&#x27; \\; #搜索以 &#x27;.rpm&#x27; 结尾的文件并定义其权限find / -xdev -name \\*.rpm #搜索以 &#x27;.rpm&#x27; 结尾的文件，忽略光驱、捷盘等可移动设备 3.1.2.4 根据属主、属组查找123456-user USERNAME #查找属主为指定用户(UID)的文件-group GRPNAME #查找属组为指定组(GID)的文件-uid UserID #查找属主为指定的UID号的文件-gid GroupID #查找属组为指定的GID号的文件-nouser #查找没有属主的文件-nogroup #查找没有属组的文件 3.1.2.5 根据文件类型查找123456789-type TYPETYPE可以是以下形式：f: 普通文件d: 目录文件l: 符号链接文件s：套接字文件b: 块设备文件c: 字符设备文件p: 管道文件 范例 12#查看/home的目录find /home –type d -ls 3.1.2.6 空文件或目录1-empty 范例 1[root@centos8 ~]#find /app -type d -empty 3.1.2.7 组合条件123与：-a ，默认多个条件是与关系，所以可以省略-a或：-o非：-not ! 范例 12345678[root@centos8 ~]#find /etc/ -type d -o -type l |wc -l307#此处 ls 只列出了后一个条件的匹配[root@centos8 ~]#find /etc/ -type d -o -type l -ls |wc -l101#把条件括起来才表示全部[root@centos8 ~]#find /etc/ \\( -type d -o -type l \\) -ls |wc -l307 德·摩根定律 (非 A) 且 (非 B) &#x3D; 非(A 或 B) (非 A) 或 (非 B) &#x3D; 非(A 且 B) 示例 12!A -a !B = !(A -o B)!A -o !B = !(A -a B) 范例 123456789[root@centos8 data]#find ! \\( -type d -a -empty \\)| wc -l56[root@centos8 data]#find ! -type d -o ! -empty |wc -l56[mage@centos8 data]$find ! -user wang ! -user mage#找出/tmp目录下，属主不是root，且文件名不以f开头的文件find /tmp \\( -not -user root -a -not -name &#x27;f*&#x27; \\) -lsfind /tmp -not \\( -user root -o -name &#x27;f*&#x27; \\) –ls 3.1.2.8 排除目录1-prune #跳过，排除指定目录,必须配合 -path使用 范例 12345678#查找/etc/下，除/etc/security目录的其它所有.conf后缀的文件find /etc -path &#x27;/etc/security&#x27; -a -prune -o -name &quot;*.conf&quot;#查找/etc/下，除/etc/security和/etc/systemd,/etc/dbus-1三个目录的所有.conf后缀的文件find /etc \\( -path &quot;/etc/security&quot; -o -path &quot;/etc/systemd&quot; -o -path &quot;/etc/dbus-1&quot; \\) -a -prune -o -name &quot;*.conf&quot;#排除/proc和/sys目录find / \\( -path &quot;/sys&quot; -o -path &quot;/proc&quot; \\) -a -prune -o -type f -a -mmin -1 3.1.2.9 根据文件大小来查找1234-size [+|-]#UNIT #UNIT常用单位：k, M, G，c（byte）,注意大小写敏感#UNIT: #表示(#-1, #],如：6k 表示(5k,6k]-#UNIT #表示[0,#-1],如：-6k 表示[0,5k]+#UNIT #表示(#,∞),如：+6k 表示(6k,∞) 范例 1234567891011#大于2K，小于或等于3K的文件[root@ubuntu2204 ~]# find /var/log/ -size 3k -ls#小于或等于2k[root@ubuntu2204 ~]# find /var/log/ -size -3k -name &quot;*log&quot; -ls#大于2k[root@ubuntu2204 ~]# find /var/log/ -size +2k -name &quot;*log&quot; -ls#大于2k,小于或等于9k[root@ubuntu2204 ~]# find /var/log/ -size +2k -size -10k -name &quot;*log&quot; -ls 3.1.2.10 根据时间戳1234567891011121314#以“天&quot;为单位-atime [+|-]## #表示[#,#+1)+# #表示[#+1,∞]-# #表示[0,#)-mtime-ctime#以“分钟&quot;为单位-amin-mmin-cmin 范例 12find /usr/bin -type f -atime -100 #搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 #搜索在10天内被创建或者修改过的文件 3.1.2.11 根据权限查找123456-perm [/|-]MODEMODE #精确权限匹配/MODE #任何一类(u,g,o)对象的权限中只要有一位匹配即可，或关系，+ 从CentOS 7开始淘汰-MODE #每一类对象都必须同时拥有指定权限，与关系0 表示不关注 说明： find -perm 755 会匹配权限模式恰好是755的文件 只要当任意人有写权限时，find -perm &#x2F;222就会匹配 只有当每个人都有写权限时，find -perm -222才会匹配 只有当其它人（other）有写权限时，find -perm -002才会匹配 3.1.2.12 正则表达式12-regextype type #正则表达式类型，emacs|posix-awk|posix-basic|posix-egrep|posix-extended-regex pattern #正则表达式 范例 1find /you/find/dir -regextype posix-extended -regex &quot;regex&quot; 3.1.2.13 处理动作1234567-print：默认的处理动作，显示至屏幕-ls：类似于对查找到的文件执行&quot;ls -dils&quot;命令格式输出-fls file：查找到的所有文件的长格式信息保存至指定文件中，相当于 -ls &gt; file-delete：删除查找到的文件，慎用！-ok COMMAND &#123;&#125; \\; 对查找到的每个文件执行由COMMAND指定的命令，对于每个文件执行命令之前，都会交互式要求用户确认-exec COMMAND &#123;&#125; \\; 对查找到的每个文件执行由COMMAND指定的命令&#123;&#125;: 用于引用查找到的文件名称自身 关于 &#123;&#125; \\; 1https://askubuntu.com/questions/339015/what-does-mean-in-the-find-command 范例 1234567891011#备份配置文件，添加.orig这个扩展名find -name &quot;.conf&quot; -exec cp &#123;&#125; &#123;&#125;.orig \\;#提示删除存在时间超过３天以上的joe的临时文件find /tmp -ctime +3 -user joe -ok rm &#123;&#125; \\;#在主目录中寻找可被其它用户写入的文件find ~ -perm -002 -exec chmod o-w &#123;&#125; \\;#查找/data下的权限为644，后缀为sh的普通文件，增加执行权限find /data –type f -perm 644 -name &quot;*.sh&quot; –exec chmod 755 &#123;&#125; \\; 3.1.2.14 参数替换xargs由于很多命令不支持标准输入，xargs就可以用于产生某个命令的参数，读取标准输入的数据，把这个数据以空格或换行符将数据分割成参数，然后传递给某个命令，作为这个命令的参数 另外，许多命令不能接受过多参数，命令执行可能会失败，xargs 可以解决 注意：文件名或者是其他意义的名词内含有空格符的情况 12345xargs cmdxargs 默认所有元素都在一行xargs -n1 一行一个元素xargs -n2 一行两个元素 find 经常和 xargs 命令进行组合，形式如下： 1find | xargs COMMAND 范例 12345678910111213141516171819[root@centos8 ~]#seq 10 | xargs1 2 3 4 5 6 7 8 9 10[root@centos8 data]#echo &#123;1..10&#125; |xargs -n112345678910[root@centos8 data]#echo &#123;1..10&#125; |xargs -n21 23 45 67 89 10 范例 1234567891011121314151617181920212223#删除当前目录下的大量文件ls | xargs rm#批量创建和删除用户echo user&#123;1..10&#125; |xargs -n1 useraddecho user&#123;1..100&#125; | xargs -n1 userdel -r#批量创建文件echo f-&#123;1..130752&#125;.txt | xargs -n 10000 touch#查找有特殊权限的文件，并排序find /bin/ -perm /7000 | xargs ls -Sl #此命令和上面有何区别？find /bin/ -perm -7000 | xargs ls -Sl #以字符nul分隔find -type f -name &quot;*.txt&quot; -print0 | xargs -0 rm#并发执行多个进程seq 100 |xargs -i -P10 wget -P /data http://10.0.0.8/&#123;&#125;.html#并行下载bilibili视频yum install python3-pip -ypip3 install you-get seq 60 | xargs -i -P3 you-get https://www.bilibili.com/video/BV14K411W7UF?p=&#123;&#125; 范例：有一种文件名为&#39;c d.log&#39;，这种文件名系统会认为 c 和 d.log 都是文件，不会认为 c d.log 是完整的文件，一文件变成两文件，是空格导致的，利用xargs移动或删除这个文件名的时候会失败，这个时候就要用字符nul分隔，nul不会成为文件名，因为在Linux文件命令规范中nul和斜线是不能成为文件名的，也就是 -print0 1234567891011121314151617[14:09:46 root@10 ~[]#touch a.log[14:10:07 root@10 ~[]#touch &#x27;a b&#x27;[14:10:40 root@10 ~[]#touch a.conf[14:10:47 root@10 ~[]#touch &#x27;c d.log&#x27;[14:12:01 root@10 ~[]#ls&#x27;a b&#x27; a.conf a.log anaconda-ks.cfg &#x27;c d.log&#x27; c.txt data initial-setup-ks.cfg[14:12:34 root@10 ~[]#find -name &#x27;*.log&#x27; | xargs mv -t datamv: 无法获取&#x27;./c&#x27; 的文件状态(stat): 没有那个文件或目录mv: 无法获取&#x27;d.log&#x27; 的文件状态(stat): 没有那个文件或目录[14:12:43 root@10 ~[]#ls&#x27;a b&#x27; a.conf anaconda-ks.cfg &#x27;c d.log&#x27; c.txt data initial-setup-ks.cfg[14:13:32 root@10 ~[]#find -name &#x27;*.log&#x27; -print0 | xargs -0 rm[14:13:40 root@10 ~[]#ls&#x27;a b&#x27; a.conf anaconda-ks.cfg c.txt data initial-setup-ks.cfg 3.2 文件压缩和解压缩（主要针对某个文件压缩，非目录）3.2.1 compress和uncompress此工具来自于ncompress包,此工具目前已经很少使用 对应的文件是 .Z 后缀 123456compress Options [file ...]uncompress file.Z #解压缩-d 解压缩，相当于uncompress-c 结果输出至标准输出,不删除原文件-v 显示详情 3.2.2 gzip和gunzip来自于 gzip 包 对应的文件是 .gz 后缀 123456gzip [OPTION]... FILE ...-k keep, 保留原文件,CentOS 8 新特性-d 解压缩，相当于gunzip-c 结果输出至标准输出，保留原文件不改变-# 指定压缩比，#取值为1-9，值越大压缩比越大 范例 12345#解压缩gunzip file.gz #不显式解压缩的前提下查看文本文件内容zcat file.gz 范例 1234gzip -c messages &gt;messages.gzgzip -c -d messages.gz &gt; messageszcat messages.gz &gt; messagescat messages | gzip &gt; m.gz 3.2.3 bzip2和bunzip2来自于 bzip2 包 对应的文件是 .bz2 后缀 123456bzip2 [OPTION]... FILE ...-k keep, 保留原文件-d 解压缩-c 结果输出至标准输出，保留原文件不改变-# 1-9，压缩比，默认为9 范例 12bunzip2 file.bz2 #解压缩bzcat file.bz2 #不显式解压缩的前提下查看文本文件内容 3.2.4 xz和unxz来自于 xz 包 对应的文件是 .xz 后缀 123456xz [OPTION]... FILE ...-k keep, 保留原文件-d 解压缩-c 结果输出至标准输出，保留原文件不改变-# 压缩比，取值1-9，默认为6 范例 12unxz file.xz #解压缩xzcat file.xz #不显式解压缩的前提下查看文本文件内容 3.2.5 zip和unzipzip 可以实现打包目录和多个文件成一个文件并压缩，但可能会丢失文件属性信息，如：所有者和组信息，一般建议使用 tar 代替 分别来自于 zip 和 unzip 包 对应的文件是 .zip 后缀 范例 123456789101112131415#打包并压缩zip -r /backup/sysconfig.zip /etc/sysconfig/#不包括目录本身，只打包目录内的文件和子目录cd /etc/sysconfig; zip -r /root/sysconfig.zip *#默认解压缩至当前目录unzip /backup/sysconfig.zip #解压缩至指定目录,如果指定目录不存在，会在其父目录（必须事先存在）下自动生成unzip /backup/sysconfig.zip -d /tmp/config cat /var/log/messages | zip messages -#-p 表示管道unzip -p message.zip &gt; message 加密 12-e file.zip #压缩后的文件交互式加密-P passed file.zip #非交互式加密 范例 1zip -r -P 123456 etc.zip /etc/ 3.3 文件打包和解包3.3.1 tar可以实现打包目录和多个文件成一个文件并压缩，生成一个归档文件，保留文件属性不变，用于备份功能 对应的文件是.tar 后缀 1234567891011121314-t #列出归档内容-c #创建一个新归档-x #从归档中解出文件-v #详细地列出处理的文件-f #指定 (将要创建或已存在的) 归档文件名-r #追加文件至归档结尾-p #保留原文件的访问权限-z #gzip压缩-j #bzip2压缩-J #xz压缩--exclude #排除文件-T #选项指定输入文件-X #选项指定包含要排除的文件列表-C #指定目录 范例 12345678910111213141516171819202122232425262728#打包文件和目录，将文件file1、file2和目录dir1打包成一个名为archive.tar的归档文件，并在终端输出打包过程的详细信息tar cvf archive.tar file1 file2 dir1#解压归档文件，将解压归档文件archive.tar，并将其中的文件和目录恢复到当前目录。tar xvf archive.tar#将文件file1、file2和目录dir1打包成一个名为archive.tar.gz的归档文件，并使用gzip进行压缩tar czvf archive.tar.gz file1 file2 dir1#将解压归档文件archive.tar，并将其中的文件和目录恢复到当前目录，并保留它们的权限信息tar xvpf archive.tar#将文件newfile添加到归档文件archive.tar中，保持归档文件的完整性tar rvf archive.tar newfile#将显示归档文件archive.tar中的文件和目录列表，并输出它们的详细信息，而不解压缩归档文件tar tvf archive.tar#创建归档，保留权限 tar -cpvf /path/file.tar file#追加文件至归档，不支持对压缩文件追加tar -rf /path/file.tar file#解开归档#不加-C默认解开到当前目录，加-C解开到指定目录tar xf /path/file.tartar xf /path/file.tar -C /path/ 范例 1234567[root@centos8 ~]#tar zcvf etc.tar.gz /etc/[root@centos8 ~]#tar jcvf etc.tar.bz2 /etc/[root@centos8 ~]#tar Jcvf etc.tar.xz /etc/[root@centos8 ~]#ll etc.tar.*-rw-r--r-- 1 root root 3645926 Dec 20 22:00 etc.tar.bz2-rw-r--r-- 1 root root 5105347 Dec 20 21:59 etc.tar.gz-rw-r--r-- 1 root root 3101616 Dec 20 22:00 etc.tar.xz 范例: 只打包目录内的文件，不所括目录本身 123456#方法1[root@centos8 ~]#cd /etc[root@centos8 etc]#tar zcvf /root/etc.tar.gz ./#方法2[root@centos8 ~]#tar -C /etc -zcf etc.tar.gz ./ 范例 12tar zcvf /root/a.tgz --exclude=/app/host1 --exclude=/app/host2 /apptar zcvf mybackup.tgz -T /root/includefilelist -X /root/excludefilelist 3.3.2 split可以分割一个文件为多个文件 1split -b size 原文件 保存的文件 范例 12345678#分割大的 tar 文件为多份小文件split -b Size –d tar-file-name prefix-name示例:split -b 1M mybackup.tgz mybackup-parts#切换成的多个小分文件使用数字后缀split -b 1M –d mybackup.tgz mybackup-parts 切割后的多个文件合并成一个文件 1cat 保存的文件* &gt; 原文件 范例 1cat etc-split* &gt; etc.tar（*代表所有的文件）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"物理网络架构全链路","slug":"computer-basics/network/network-architecture","date":"2025-08-21T02:43:39.000Z","updated":"2025-08-28T12:33:05.388Z","comments":true,"path":"computer-basics/network/network-architecture/","permalink":"https://aquapluto.github.io/computer-basics/network/network-architecture/","excerpt":"","text":"流量类型 南北流量：内网机器与外网通信 东西流量：内网机器在局域网内彼此之间进行通信 跨数据中心的流量：跨数据中心之间的通信 家庭组网流程 购买路由器 向运营商付费开通宽带服务，并将运营商提供的网线一端连接其设备，另一端接入路由器，路由器会有两个IP地址：一个是内部私网IP，一个是与运营商设备连接的外网IP 通过网线将电脑等设备直连路由器 路由器提供无线功能，手机也能连接路由器 所有设备都在一个局域网内，要访问外网，都要经过路由转发，出去的时候，数据包的源地址都换成了路由器对外的IP地址 在家庭网络中，路由器的作用是什么？ 将多个设备连接到一起，并共享一个外网IP地址。它可以兼具交换机和路由器功能，帮助家庭内多台设备通过一个公共的外网IP地址访问互联网。此外，路由器还提供无线功能，允许手机等设备连接到网络 如何构建上万台服务器的集群？ 单个交换机的接口数有限，不能满足上万台服务器的连接需求，且广播包的大小受限，通过分层组织解决痛点： 接入层: 负责连接服务器，形成一个个局域网 汇聚层: 将接入层的交换机汇聚在一起，形成一个二层网络。 核心层: 汇聚多个汇聚层，形成统一的网络结构 网络出口用防火墙还是路由器？ 中小型网络使用防火墙出口较多 特定行业&#x2F;网络出口必须使用路由器 大型网络路由器与防火墙并存 网络通信的应用程序主要有两种架构： CS架构（Client-Server 架构）：客户端与服务器之间直接进行通信。 BS架构（Browser-Server 架构）：使用浏览器和前端代码（如HTML、CSS、JS）与服务器进行通信 集群能够把多个设备连在一起提供服务，有效避免单点故障，即一个设备坏了导致整个系统都挂了，南北流量和东西流量是把使用地理方向作比喻，大型集群通过分层架构解决交换机性能瓶颈，集群需关注时间同步与网络性能以此保证稳定性","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"应用层","slug":"computer-basics/network/application-layer","date":"2025-08-21T02:43:32.000Z","updated":"2025-08-28T12:33:05.381Z","comments":true,"path":"computer-basics/network/application-layer/","permalink":"https://aquapluto.github.io/computer-basics/network/application-layer/","excerpt":"","text":"一、DNS域名解析1.1 DNS介绍当前TCP&#x2F;IP网络中的设备之间进行通信，是利用和依赖于IP地址实现的。但数字形式的IP地址是很难记忆的。当网络设备众多，想要记住每个设备的IP地址，可以说是”不可能完成的任务”。那么如何解决这一难题呢？我们可以给每个网络设备起一个友好的名称，如： www.baidu.com，这种由文字组成的名称，显而易见要更容易记忆。但是计算机不会理解这种名称的，我们可以利用一种名字解析服务将名称转化成（解析）成IP地址。从而我们就可以利用名称来直接访问网络中设备了。除此之外还有一个重要功能，利用名称解析服务可以实现主机和IP的解耦，即：业务不需要固定依赖具体的IP，当主机IP变化时，只需要修改名称服务即可，用户仍可以通过原有的名称进行访问而不受影响。 DNS：应用层协议， 是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网，基于C&#x2F;S架构，服务器端：53&#x2F;udp, 53&#x2F;tcp，TCP 的53端口主要用于主从DNS之间的数据同步 域名的组成： 根域: 全球根服务器节点只有13个,10个在美国，1个荷兰，1个瑞典，1个日本，“.” 表示 一级域名：Top Level Domain: tld三类：组织域、国家域(.cn, .ca, .hk, .tw)、反向域com, edu, mil, gov, net, org, int,arpa 二级域名：baidu.com 三级域名：study.baidu.com 最多可达到127级域名 域名，又称网域，顾名思义，是一个域的名称。 是一串用点号分隔的字符，可以用来标识网络中某台主机或某个节点，由DNS服务维护域名和主机IP地址之间的映射关系，当我们在网络中访问某个域名时，实际上访问的是该域名对应的IP地址所标识的主机。 FQDN：全称域名 域名是一个域的名称，一个网域或一个节点，可以有多台主机，所以为了精确表示域里面的某台主机，我们在使用域名时，还需要加上主机名，FQDN指的就是同时带有主机名和域名的名称。 1234567891011全称域名=域名www.baidu.org.blog.baidu.org.study.baidu.org.www.sina.com.cn.主机名（www）+域名（baidu.org.） 实际上有三种域名baidu #二级域名org #一级域名， #根域 1.2 DNS服务工作原理 当客户端主机决定访问 https://www.baidu.com 这个域名时，首先会查询本机缓存； 如果本机缓存没有解析记录，则会向其配置的DNS服务器发起解析请求； DNS代理解析服务器会先查询其缓存是否有这条解析记录，如果有，则直接返回，如果没有，则继续向上解析； DNS代理解析服务器会向根域名服务器发起解析请求，根域名服务器返回 com 域名的DNS地址； DNS代理解析服务器继续向 com 域名服务器发起解析请求，com 域名服务器返回 baidu.com域名服务器DNS地址； DNS代理解析服务器继续向 baidu.com 域名服务器发起解析请求，baidu.com 域名服务器返回 www.baidu.com 主机的IP； DNS代理解析服务器将 www.baidu.com 的IP地址存入本机缓存，再读取缓存，将 IP地址发送给客户端主机； 客户端主机通过IP地址顺利访问 https://www.baidu.com； DNS服务只负责域名解析，也就是说DNS服务只负责返回与域名对应的IP地址，但该IP地址在网络上是否是可达的，并不由DNS决定。每个域名都有专门的服务器负责 1.3 DNS查询类型递归查询 是指DNS服务器在收到用户发起的请求时，必须向用户返回一个准确的查询结果。如果DNS服务器本地没有存储与之对应的信息，则该服务器需要询问其他服务器，并将返回的查询结构提交给用户。形象来讲你向一个人借钱，那个人即使没钱，都直接答应你了，自己去借高利贷等途径给你钱。 一般客户机和本地DNS服务器之间属于递归查询，即当客户机向DNS服务器发出请求后,若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到最终的肯定或否定的结果后转交给客户机。此查询的源和目标保持不变,为了查询结果只需要发起一次查询 递归算法：客户端向LocalDNS发起域名查询 –&gt; localDNS不知道域名对应的IP –&gt; 但它知道谁知道 –&gt; 他代为帮客户端去查找 –&gt; 最后再返回最终结果 迭代查询 是指DNS服务器在收到用户发起的请求时，并不直接回复查询结果，而是告诉另一台DNS服务器的地址，用户再向这台DNS服务器提交请求，这样依次反复，直到返回查询结果。形象来讲你向一个人借钱，那个人没钱，但是他认识有钱人，让你去找那个有钱人借钱。 一般情况下(有例外)本地的DNS服务器向其它DNS服务器的查询属于迭代查询,如：若对方不能返回权威的结果，则它会向下一个DNS服务器(参考前一个DNS服务器返回的结果)再次发起进行查询，直到返回查询的结果为止。此查询的源不变,但查询的目标不断变化,为查询结果一般需要发起多次查询。 迭代算法：客户端向LocalDNS发起域名查询 –&gt; localDNS不知道域名对应的IP –&gt; 但它知道谁知道并推荐客户端应该找谁 –&gt; 客户端自己去找它。 DNS缓存 DNS缓存是将解析数据存储在靠近发起请求的客户端的位置，也可以说DNS数据是可以缓存在任意位置，最终目的是以此减少递归查询过程，可以更快的让用户获得请求结果。 Windows系统 12345#显示DNS缓存C:\\Users\\44301&gt;ipconfig/displaydns#清除DNS缓存C:\\Users\\44301&gt;ipconfig/flushdns CentOS系统 12345#查看DNS缓存[root@rocky86 ~]# nscd -g#清除DNS缓存[root@rocky86 ~]# nscd -i hosts Ubuntu系统 12345#查看DNS缓存[root@ubuntu ~]# resolvectl statistics#清除DNS缓存[root@ubuntu ~]# resolvectl reset-statistics 二、HTTP详解2.1 什么是http协议1、全称Hyper Text Transfer Protocol（超文本传输协议） 普通文本：文件内存放的是一些人类认识的文字符号(汉字、英语、阿拉伯数字) 超级文本：除了普通文本内容之外，还有视频、图片、语音、超链接 http协议都能传输上述内容，所以说http协议是专用于传输超文本的协议 2、http主要用于B&#x2F;S架构 3、http是基于tcp协议的 强调：基于http协议发包之前，必须先建立tcp协议的双向通路 2.2 http协议的发展史2.2.1 http0.9请求方法：只支持GET方法 请求头：不支持 响应信息：只支持纯文本，不支持图片 无连接&#x2F;短连接&#x2F;非持久连接：利用完 tcp 连接之后会立即回收，所以无连接指的不是说没有连接，而是说没有持久连接&#x2F;长连接的http协议通信，先建立tcp连接，然后客户端发请求包，服务端收到后发送响应包，服务端一旦发送完响应包之后，服务端会立即主动断开tcp连接，下次http通信还需要重新建立tcp连接。 同一个用户在短期内访问多次服务端，那大量的时候都会消耗在重复创建tcp连接上，在高并发场景下，对服务端是非常大的消耗，客户端的访问速度也会非常的慢 无状态（一个http协议的请求无法标识自己的身份）：http无法保存状态，比如登录状态，那意味着每次请求都需要重新输出一次账号密码来认证 2.2.2 http1.0请求方法：支持PUT(增)、DELETE(删)、POST(改)、GET(查) 请求头：支持 响应信息：支持超文本 支持缓存 同一个用户在短期内访问多次服务端，不要重复建立tcp连接，而是能够共用一个tcp连接解决方案：支持持久连接&#x2F;长连接 keep-alive 前提：发送完http响应包之后，服务端立即断tcp连接，这是服务端的默认行为，要改变这种默认行为，要客户端通知服务端才行 实现： 客户端在发送http的请求时，需要再请求头里带上connection: keep-alive这个参数 服务端的keepalive timeout设置要大于0 服务端收到后读取该参数，服务端会保持与这一个客户端tcp连接一段时间，响应时也会在响应头里放connection:keep-alive这个参数 该tcp会保持一段时间直到达到服务端设置的keepalive_timeout时间 补充: 在http1.0协议还需要你发请求时你自己加上connection: keep-alive这个参数 在http1.1协议里所有的请求都会自动加上connection: keep-alive，也就是说在htp1.1客户端默认就开启了长连接支持，配套的服务端也要开启(服务端的keepalive_timeout设置要大于0) 服务端要客户端有状态(让客户端每次发请求的时候都能标识自身的唯一性)：解决方案是cookie、session、jwt 2.2.3 http1.1默认所有请求都启用长连接，请求与响应头里都带着connection:keep-alive，对应服务端需要设置keepalive timeout大于0 Pipelining(请求流水线化&#x2F;管道化) 分块传输编码chunked 2.2.4 http2.0引入头信息压缩机制：头信息使用gzip或compress压缩后再发送 允许服务器有新数据时未经请求，主动向客户端发送资源，而无需客户端拉取，即服务器推送（server push） 2.3 http协议的格式2.3.1 URI和URLURI：统一资源标识符 URL：统一资源定位服务，是URI的一种具体实现http://192.168.71.10:8080/a/b/1.txt?x=1&amp;y=2&amp;page=10#_label5 http:&#x2F;&#x2F; —&gt; 协议部分。不写协议，默认http协议 192.168.71.10:8080 —&gt; ip+port部分，不写端口默认服务端的端口是80 &#x2F;a&#x2F;b&#x2F;1.txt —&gt; 路径部分，不写路径，默认加一个&#x2F;结尾 ?x&#x3D;1&amp;y&#x3D;2&amp;page&#x3D;10 —&gt; 请求参数部分 #_label5 —&gt; 锚 URN：也是URI的一种具体实现，例如：mailto:java-net@java.sun.com. 2.3.2 请求request包含四部分： 请求首行：请求方法 请求的路径部分及后续部分 http协议版本 GET &#x2F;a.txt HTTP&#x2F;1.1 请求头：都是 key:value 格式，用来定制一些参数 空行 请求体数据 请求方法: GET(查) —-&gt; 请求的数据可以放在URL地址的?号后 POST(改) —-&gt; 携带请求体数据 DELETE(删) PUT(增) HEAD：类似GET请求，不一样的是不会获取响应的数据，但是会获取响应头，而响应头包含着状态码，状态码代表着本次访问是否成功，所以HEAD主要用来检测某个资源是否可以正常访问 OPTIONS：一般用作预检请求，在发真正请求之前先发个options请求预检一下服务端支持哪些http方法、跨域检测等 GET和POST的区别: 携带数据的方式不同 携带数据的话post更安全 传输数据大小 GET与POST这两个方法本身没有限制 但因为GET方法的数据都放在URL地址中，而URL地址的长度在一些浏览器中是有限制 所以如果要传一些比较大的数据，不能用GET方法，应该使用POST方法把数据放入请求里传输 2.3.3 响应response也是包含四部分： 响应首行：协议 状态码 HTTP&#x2F;1.1 200 OK 响应头 set-cookie：要求浏览器把cookie信息存入本地 cache-control：要求浏览器把一些文件缓存到本地 connection:keep-alive：要求浏览器保持长连接 Content-Type:text&#x2F;html：告诉浏览器本次返回内容的格式 text&#x2F;plain 告诉浏览器本次返回的内容格式是普通文本 空行 响应体 状态码 2xx：代表访问成功 3xx：本次请求被重定向 4xx：客户端错误 404：客户端访问的资源不存在 403：客户端没有对目标资源的访问权限 5xx：服务端错误 503：服务端故障 2.4 http协议完整的请求与响应流程浏览器访问一个URL地址：http://baidu.com:80/a/b/1.html 浏览器会先问本地DNS把域名baidu.com解析为ip地址 浏览器作为客户端会与目 ip:port 建立TCP三次握手 浏览器会基于HTTP协议封装请求包(OSI七层的封包流程) 服务端收到包(OSI七层的解包流程)，拿到一个HTTP协议的请求包，按照HTTP协议来解析请求会拿到请求路径部分 &#x2F;a&#x2F;b&#x2F;1.html，服务端会打开该文件(对一个文件描述符)把文件内容从硬盘读入内存，然后服务端程序会基于HTTP协议封装读入内存的数据，形成一个响应包，发给客户端浏览器 浏览器收到HTTP协议的响应包之后，先解析响应头，看到响应的状态码，知道本次是否成功，在解析响应头时，可以拿到Content-Type就知道该用什么数据格式来解析内容，如果值为 text&#x2F;html 就会按照html代码的方式来解析返回的内容，再读取内容部分，当成html代码来解析 在解析html代码的过程中，有可能遇到css、jss、图片、视频等资源，会发起二次、三次….请求，直到把整个页面都渲染完毕 三、HTTPS详解3.1 为什么使用HTTPShttp协议：明文传输，可能会遭到窃听、改、冒充&#x2F;挟持，因此使用HTTP协议传输隐私信息非常不安全。https：http协议 + ssl协议，密文传输，可以防止窃听、算改，并且有ca权威机构认证服务端身份，可以防冒充&#x2F;劫持 3.2 SSL协议SSL是一种加密协议，对http协议通信的加强，可以防窃听、改、伪装&#x2F;冒充 数字签名：防止篡改&#x2F;丢失 把包的内容做hash校验得到的hash值称之为摘要 —&gt; digest 服务端用自己的私钥对digest进行加密 —&gt; 得到东西叫数字签名signature 客户端收到包之后先用公钥解开得到digest —&gt; 重新hash，验证是否被篡改 数字证书：防止伪装&#x2F;冒充 CA中心：公认的权威认证中心，找一个证书中心为自己的公钥做认证。 CA中心用自己的私钥，对服务端的公钥和其他相关信息一起加密，生成“数字证书”。 数字证书就是加了密的服务端公钥。 非对称加密 两个密码(公钥、私钥)：公钥加密用私钥解密，私钥加密用公钥解密 优点： 公私分明，公钥任何人都可以获取，而私钥只有服务端自己手里有 安全性更高一些，只要私钥不泄露，就没法解开包 缺点：非对称加密的速度慢，不适合大规模数据加解密 对称加密 只有一个私钥，加解密用的都是同一套私钥 优点：加解密效率高 缺点：私钥的泄露几率高，一旦某一方泄露私钥，则加密信息就无法得到安全保障问题 SSL协议通信过程中即用了非对称加密，又用了对称加密 客户端先通过ssl通信的第二次握手获得服务端数字证书（内含公钥） 然后使用非对称加密传输对称加密的密钥（更安全），后面的数据传输就使用对称性加密（更高效）。 3.3 TLS协议SSL是一种技术，您的应用程序或浏览器可能使用该技术在任何网络上创建安全的加密通信通道。但是SSL是一种较老的技术，包含一些安全漏洞。传输层安全性协议(TLS)是SSL 的升级版本，用于修复现有 SSL 漏洞。TLS 可以更高效地进行身份验证，并继续支持加密的通信通道。 TLS协议就是一个升级版的SSL，由于SSL这一术语更为常用，所以我们通常仍将我们的安全证书称作SSL 3.4 HTTPS通信过程 客户端发起HTTPS请求 用户在浏览器里输入一个https网址，然后连接到服务器的443端口 服务端的配置 采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。这套证书其实就是一对公钥和私钥 传送服务器的证书给客户端 证书里其实就是公钥，并且还包含了很多信息，如证书的颁发机构，过期时间等等 客户端解析验证服务器证书 这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如：颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值。然后用证书中的公钥对该随机值进行非对称加密 客户端将加密信息传送服务器 这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了 服务端解密信息 服务端将客户端发送过来的加密后的随机值用服务器私钥解密后，得到了客户端传过来的随机值 服务器加密信息并发送信息 服务器将数据利用随机值进行对称加密,再发送给客户端 客户端接收并解密信息 客户端用之前生成的随机值解密服务段传过来的数据，于是获取了解密后的内容 四、跨域和Cookiecookie机制： 访问一个站点，服务端返回的响应头会设置set-cookie: k1&#x3D;v1;k2&#x3D;v2 浏览器收到后，会根据set-cookie来设置存入本地的cookie值 下次请求该网站，浏览器会从本地cookie里取出cookie值，放到http请求的cookie字段里，发往服务端 特点: cookie是浏览器的功能，是放在客户端的 cookie内存放的内容是可以被客户端篡改的 cookie机制+session机制： 访问一个站点，输入自己的账号密码进程认证，服务端收到请求之后认证通过，会产生一些标识用身份的数据 这些数据 —&gt; value 把这些数据关联一个 —&gt; key key:value key给客户端，存入cookie value放在服务端，称之为session 服务端会把key放入cookie放入set-cookie里，返回给客户端 客户端收到响应后，会把key存入本地的cookie 下次请求该网站，会带着该key去到目标站点，目标站点收到后，会根据key取出value，value里放着本次请求的身份 特点：把保密数据放在服务端，称之为session数据，然后针对session数据生成一个key值存入客户端的cookie中 可以防止篡改 在集群的场景下，需要做会话共享(session存入共享的地方) 通过会将session数据存入redis redis作为一个大家依赖的共享点，会影响集群的扩展性 总结cookie和session： 单用cookie来存放状态信息 优点:服务端不需要做会话共享 缺点:客户端可以算改状态信息，不安全 cookie+session 优点:状态信息即session数据是存放在服务端的，状态不会被改 缺点:服务端需要做会话共享，增加了集群的耦合性 JWT(json web token)： 服务端会将状态信息进行加密，然后把加密数据放入客户的cookie中，这个加密的数据称之为token —&gt; 篡改的问题解决了 下次请求会从cookie中取出token带上一起发送给服务端，服务端收到后用加密算法解密 —&gt; 不需要再做会话共享&#x2F;保持 追求：服务端不保存状态 优点：不需要做会话共享、又能很安全 缺点：最大的缺点就是无法做到主动废弃掉某个token，一个token一旦下发之后，就只能等着该token，服务端无法做到主动废弃该token —&gt; 想要做到随时都能主动废弃掉某个token，就需要开发额外的代码来支持","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"传输层","slug":"computer-basics/network/transport-layer","date":"2025-08-21T02:43:27.000Z","updated":"2025-08-28T12:33:05.402Z","comments":true,"path":"computer-basics/network/transport-layer/","permalink":"https://aquapluto.github.io/computer-basics/network/transport-layer/","excerpt":"","text":"一、TCP和UDP协议tcp协议：可靠传输，TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 之所以可靠，不是因为有双向通路，而是因为有确认机制 udp协议：不可靠传输，报头部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。 没有确定机制，所以不可靠 相对tcp协议来说数据传输效率高 二、TCP三次握手和四次挥手SYN：在建立连接时使用，用来同步序号。当SYN&#x3D;1，ACK&#x3D;0时，表示这是一个请求建立连接的报文段；当SYN&#x3D;1，ACK&#x3D;1时，表示对方同意建立连接 ACK：表示是否前面确认序列号字段是否有效。只有当ACK&#x3D;1时，前面的确认序列号字段才有效 seq：序列号 保证接收端数据有序接收； 可以根据序号判断是否以前接收过该数据，用于去除重复； 判断数据的合法性； 序号机制结合 ACK 可以完成数据重传 ack：确认号（由对方序列号+1组成），表示希望对方发送什么样的东西给它 TIME_WAIT状态说明 主动关闭方，等待足够的时间确保最后一个ACK到达对端，也确保所有仍在网络中的旧报文都有足够的时间被丢弃或到达目的地，防止旧报文干扰新连接 一般来说，服务器是主动挥手的一方，因为服务器发完数据后，为了不占用自身的资源，就会断开连接，不过频繁的建立和关闭连接也会增加负担。在web服务中，HTTP&#x2F;1.1默认使用了长连接，服务器通常是被动关闭的一方。 服务器是否主动关闭连接，取决于是否启用 keep-alive 和负载策略，在高并发环境下，保持连接复用比频繁建立、关闭连接更高效 如果服务器中TIME_WAIT状态比较多，可能说明在高并发中短连接请求数量多，或者被攻击，如syn洪水攻击 CLOSE_WAIT状态说明 被动关闭方，表示对方已经关闭连接，本端需要关闭，等待本地应用调用 close() 关闭连接 如果服务器中CLOSE_WAIT状态比较多，说明应用层没有正确关闭 socket，或者是客户端频繁断开，而服务端未及时释放资源 总结：长连接中主动挥手通常是客户端。短连接中主动挥手通常是服务端。但实际谁主动关闭取决于应用层协议、业务逻辑和配置。例如长连接中，服务端也可以检测客户端断开失败而主动关闭；短连接中，客户端也可能因为异常中断被动断开。 为什么要三次握手？ 确认双方的发送和接收能力：通过3次握手，客户端和服务器可以确认彼此都具备发送和接收数据的能力。这是建立可靠连接的基础 同步初始序列号：TCP协议通过序列号来标识发送的数据包，确保数据的顺序性和完整性。在3次握手过程中，双方会交换初始序列号，以便后续的数据传输能够正确地进行 避免已失效的连接请求报文段突然又传送到了服务端：这种情况可能发生在网络拥堵或者延迟较大的情况下。通过3次握手，服务端可以确认客户端的请求是有效的，而不是一个过时的请求 为什么不是四次握手？ 三次握手已满足可靠性要求，额外步骤会增加延迟且无必要。例如：若第三次握手后服务器再发送ACK，客户端需第四次确认，形成冗余循环 为什么要四次挥手？ 在关闭连接时，需要确保双方都完成了数据的传输和接收，以防止数据丢失或错误。如果只有三次挥手，可能会导致一些问题。 假设只有三次挥手，当客户端发送结束请求后，服务器收到后会发送确认，表示已收到客户端的结束请求。但是在此过程中，服务器可能还有未发送完的数据，如果直接关闭连接，那么这些数据就会丢失。因此，引入第三次挥手，服务器在发送结束请求前，先发送所有未发送完的数据，并等待客户端的确认。客户端接收到服务器的结束请求后，会确认并处理完未接收的数据，然后发送确认，表示自己已准备好关闭连接。 通过四次挥手，可以确保双方都能正确地结束连接，并处理未发送和未接收的数据，保证数据的完整性和可靠性。因此，关闭连接需要四次挥手。 为什么 TIME_WAIT 等待的时间是 2MSL？ 网络中可能存在来自发送方的数据包。当这些数据包被接收方处理后，它会向对方发送响应，因此往返需要等待2倍的时间。就是确保最后一个ACK被服务端接收到了，如果没有接收到也要给足时间让服务器端的第三次挥手的FIN重新传过来。例如被动关闭方没有收到断开连接的最后一个ACK报文，就会触发超时重发FIN报文。另一方收到FIN报文后，会重发ACK给被动关闭方，这样来回就需要2个MSL的时间 三、半连接池和syn洪水攻击半连接池：操作系统维护的一个队列，做完第一次握手后，客户端的tcp连接是进入到半连接池，随后操作系统从半连接池取出连接进行第二次握手，接着第三次握手，连接建立后从半连接池中移除。 SYN洪水攻击 建立大量的连接，将半连接池占满，即客户端变为ESTABLISHED状态，但不回复ack，服务端无法从SYN_RECD变为ESTABLISHED 一般来说，在服务器很少会看见SYN_RECD状态，如果看到很多，说明有可能遭受了攻击 其他攻击 DDOS：分布拒绝服务攻击 DOS：拒绝服务攻击 查看半连接池的数量：/proc/sys/net/ipv4/tcp_max_syn_backlog 可以提高半连接池的数量，可以适当防止SYN洪水攻击或高并发情况，但仅仅只是辅助手段，如果有大量的连接，不仅服务器自身资源消耗殆尽，也会导致网卡（过载，带宽限制），交换机（转发能力不足，MAC地址表溢出），路由器（路由表溢出）等硬件设备的性能瓶颈","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"网络层","slug":"computer-basics/network/network-layer","date":"2025-08-21T02:43:22.000Z","updated":"2025-08-28T12:33:05.389Z","comments":true,"path":"computer-basics/network/network-layer/","permalink":"https://aquapluto.github.io/computer-basics/network/network-layer/","excerpt":"","text":"一、网络基础OSI 七层&#x3D;&#x3D;第7层 应用层&#x3D;&#x3D; 应用层（Application Layer）提供为应用软件而设的接口，以设置与另一应用软件之间的通信。例如:HTTP、HTTPS、FTP、TELNET、SSH、SMTP、POP3、MySQL等 &#x3D;&#x3D;第6层 表示层&#x3D;&#x3D; 主条目：表示层（Presentation Layer）把数据转换为能与接收者的系统格式兼容并适合传输的格式 &#x3D;&#x3D;第5层 会话层&#x3D;&#x3D; 会话层（Session Layer）负责在数据传输中设置和维护电脑网络中两台电脑之间的通信连接。 &#x3D;&#x3D;第4层 传输层&#x3D;&#x3D; 传输层（Transport Layer）把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。例如:传输控制协议（TCP）等。 &#x3D;&#x3D;第3层 网络层&#x3D;&#x3D; 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成报文。网络表头包含了网络数据。例如:互联网协议（IP）等。 &#x3D;&#x3D;第2层 数据链接层&#x3D;&#x3D; 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。当表头和表尾被加至数据包时，会形成信息框（Data Frame）。数据链表头（DLH）是包含了物理地址和错误侦测及改错的方法。数据链表尾（DLT）是一串指示数据包末端的字符串。例如以太网、无线局域网（Wi-Fi）和通用分组无线服务（GPRS）等。分为两个子层：逻辑链路控制（logical link control，LLC）子层和介质访问控制（Mediaaccess control，MAC）子层 &#x3D;&#x3D;第1层 物理层&#x3D;&#x3D; 物理层（Physical Layer）在局部局域网上传送数据帧（Data Frame），它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、主机接口卡等 TCP&#x2F;IP五层协议&#x3D;&#x3D;第一层：物理层&#x3D;&#x3D; 数据称为bit，负责传输电信号，对其进行分组 高电压对应数字1，低电压对应数字0 &#x3D;&#x3D;第二层：数据链路层&#x3D;&#x3D; 使用的是以太网协议传输，即MAC地址 MAC地址是网卡上的地址，唯一的，在局域网内部用的地址，出不了局域网 在局域网中是基于以太网协议的广播方式，使用MAC地址去找到目标机器 一组电信号成为数据帧，每一个数据帧由两部分构成 head头部：长度固定18字节。源地址，目标地址和数据描述信息各占6字节（地址里用的是MAC地址） data：数据，默认最长的是1500字节 &#x3D;&#x3D;第三层：网络层&#x3D;&#x3D; 网络层由来：世界范围的互联网是由一个个彼此隔离的小的局域网组成的，如果所有的通信都采用以太网的广播方式，那么一台机器发送的包全世界都会收到，不仅效率低，也是安全问题 使用的是ipv4协议，用于跨网段通信，数据被称为数据包，由两部分构成 head：源ip地址和目标ip地址 data：数据，最长65515个字节 MAC地址标识局域网内唯一的服务器，ip地址标识唯一的局域网，ip+mac标识全世界唯一的服务器 ip地址要是既可以标识唯一的局域网，又可以标识该局域网内的某台机器的mac地址，就要用到了子网掩码 ip地址&#x3D;网络地址+主机地址 ip地址与子网掩码做与运算，得到网络地址 ARP协议：负责将ip地址解析成mac地址 一台主机通过arp协议获取另外一台主机的mac地址 所以网络通信用的是mac地址，注意不是ip地址 ip相关地址计算工具：https://ipjisuanqi.com/ &#x3D;&#x3D;第四层：传输层&#x3D;&#x3D; 传输层的由来：我们通过ip和mac找到了一台特定的主机，如何标识这台主机上的应用程序？端口，即应用程序与网卡关联的编号。 TCP&#x2F;UDP协议，基于端口工作，数据称之为数据段，负责建立端口到端口的通信 基于tcp协议或者udp协议工作的应用程序，都会拥有一个唯一的端口号（在一个操作系统里端口的范围0-65535，0-1023为系统占用端口） ip+port: 全世界范围内唯一的基于网络通信应用程序 &#x3D;&#x3D;第五层：应用层&#x3D;&#x3D; 应用程序是自己开发，所以应用层用用什么协议应用程序自己定义就好，负责规定好数据的组织形式 http协议、ssl协议 &#x3D;&#x3D;补充：socket抽象层&#x3D;&#x3D; 位于传输层与应用层之间 socket层是对传输层及其以下的封装，封装完之后提供了一系列简单的功能给上次应用程序去调用 基于网络通信的应用程序基本上都是基于socket开发的，所以又称之为套接字程序 网络通信流程网络通信必备的四个地址 不跨网段：ip地址+mac地址 跨网段：网关的ip地址+mac地址+子网掩码 如果有域名：还需要再加一个DNS服务器的地址 网络流量流向 东西流量：服务器集群机器之间进行通信 南北流量：与外网进行通信 网络通信流程 打开浏览器输入一个url地址：http:&#x2F;&#x2F; egonlin.com:80 计算机会请求本地dns把域名egonlin.com解析为ip地址：http:&#x2F;&#x2F; 1.1.1.1:80 应用层封包：用http协议把数据封装一下，假设为4960字节 传输层：用tcp协议封装一下，打上tcp的头（源端口，目标端口），tcp数据包为20字节，嵌入HTTP数据包，总长度为4980字节（TCP三次握手） 网络层：用ip协议封装一下，打上ip头（源ip，目标ip），ip数据包也为20字节，嵌入TCP数据包，总长度为5000字节 数据链路层：用以太网协议封装一下，打上ethernet协议的头（源mac、目标mac） 注意：以太网协议的数据部分默认最大传输单元是1500字节 —-》MTU 数据包需要分片发送，以1500个字节为单位，5000/1500=3.3，所以IP数据包必须分割成四个包 服务器端响应：服务器收到四个以太网数据包，拼起来取出完整的TCP数据包，读出里面的HTTP请求，做出HTTP响应，再用TCP协议发回来 同局域网通信前提条件： 发送端 IP：192.168.71.7/24 发送端 MAC：FFFFFFFFFFFF 接收端 IP：192.168.71.8/24 通信之前，ARP协议开始工作 判断是否在同一局域网 在一个局域网，ARP协议获取目标MAC地址（mac+广播） 发送端广播一个ARP请求帧，里面包含了发送端IP，MAC和接收端IP，局域网内的所有主机都会收到这个广播请求 192.168.71.8的接收端返回自己的mac给发送端 发送端将目标MAC地址缓存到本地ARP缓存表中 真正通信开始，封装数据帧进行传输，包含发送端的mac，接收端的mac，192.168.71.7/24，192.168.71.8/24和数据部分 跨局域网通信前提条件： 发送端 IP：192.168.71.7/24 发送端 MAC：FFFFFFFFFFFF 接收端 IP：172.16.202.8/24 通信之前，ARP协议开始工作 判断是否在同一局域网 不在一个局域网，跨网段通信靠路由器，接下来ARP协议获取路由器（默认网关）的MAC地址（mac+广播） FFFFFFFFFFFF 192.168.71.7 192.168.71.1 192.168.71.1网关返回自己的mac给发送端，发送端手里有网关mac，就可以把信息送给网关 真正通信开始，封装数据帧进行传输，包含发送端自己的mac地址网关的mac地址，192.168.71.7/24，172.16.202.8/24和数据部分 数据封装和数据解封数据封装：数据包在网络中传输时，为了更高效、准确的到达目的地，需要对其进行拆分和打包，比如在所发数据包上附加本地以及目标地址、加纠错字节、以及加密处理等。这些操作就是数据封装。 数据解封：是数据封装的逆过程，就是将发送方发过来的信息经过拆解协议包进而获得业务数据的过程。 网络通讯三种通讯模式unicast: 单播,目标设备是一个 broadcast: 广播,目标设备是所有 multicast: 多播,组播,目标设备是多个 冲突域和广播域冲突域：两个网络设备同时发送数据,如果发生了冲突,则两个设备处于同一个冲突域,反之,则各自处于不同的冲突域 广播域：一个网络设备发送广播，另一个设备收到了,则两个设备处于同一个广播域,反之,则各自处于不同的广播域 三种通讯机制 单工通信：只有一个方向的通信,比如: 收音机 半双工通信：通信双方都可以发送和接收信息，但不能同时发送，也不能同时接收,比如:对讲机 全双工通信：通信双方可以同时发送和同时接收,比如: 手机 范例：查看双工和速度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#如果mii-tool不支持，则可以使用 ethtool 命令#FD全双工，100千兆，base基带传输，T双绞线，link ok表示网络状态正常[root@localhost ~]# mii-tool eth0eth0: negotiated 100baseTx-FD, link ok[root@localhost ~]# mii-tool -v eth0eth0: negotiated 100baseTx-FD, link ok product info: vendor 00:07:32, model 17 rev 5 basic mode: autonegotiation enabled basic status: autonegotiation complete, link ok capabilities: 100baseTx-FD 100baseTx-HD 10baseT-FD 10baseT-HD advertising: 100baseTx-FD 100baseTx-HD 10baseT-FD 10baseT-HD flow-control link partner: 100baseTx-FD 100baseTx-HD 10baseT-FD 10baseT-HD[root@ubuntu2004 ~]#ethtool eth0Settings for eth0: Supported ports: [ TP ] #网卡接口支持的类型 TP 表示双绞线 Supported link modes: 10baseT/Half 10baseT/Full #支持的工作模式 100baseT/Half 100baseT/Full 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes #是否支持自动协商 Supported FEC modes: Not reported Advertised link modes: 10baseT/Half 10baseT/Full #通告模式 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: No Advertised auto-negotiation: Yes#通告是否使用自动协商 Advertised FEC modes: Not reported Speed: 1000Mb/s #当前速度 Duplex: Full #工作模式，全双工 Port: Twisted Pair #接口类型,Twisted Pair是双绞线,FIBRE是光纤 PHYAD: 0 Transceiver: internal Auto-negotiation: on #自动协商是否打开 MDI-X: off (auto) Supports Wake-on: d #是否支持Wake On LAN,d不支持，g支持 Wake-on: d #Wake On LAN是否启用 d禁用, g启用 Current message level: 0x00000007 (7) drv probe link Link detected: yes #是否连接到网络,可以判断网线有无断开 [root@ubuntu2004 ~]#ethtool -i eth0driver: e1000version: 7.3.21-k8-NAPI #网卡驱动firmware-version: expansion-rom-version: bus-info: 0000:02:01.0supports-statistics: yessupports-test: yessupports-eeprom-access: yessupports-register-dump: yessupports-priv-flags: no#网络断开的状态[root@centos8 ~]#mii-tool -v eth1eth1: no link product info: Yukon 88E1011 rev 3 basic mode: autonegotiation enabled basic status: no link capabilities: 1000baseT-FD 100baseTx-FD 100baseTx-HD 10baseT-FD 10baseT-HD advertising: 1000baseT-FD 100baseTx-FD 100baseTx-HD 10baseT-FD 10baseT-HD 二、局域网 Local Area Network网络为一个单位所拥有，地理范围和站点数目均有限，用于资源共享和数据通信，能方便地共享昂贵的外部设备、主机以及软件、数据。从一个站点可以访问全网，便于系统的扩展和逐渐演变，各设备的位置可灵活的调整和改变，提高系统的可靠性、可用性和易用性 交换机和网桥网桥和交换机都工作在数据链路层，根据 MAC 地址 转发数据帧， 传统网桥通常只有2个端口，用于连接两个网段 交换机本质上是一个具有多个端口的高速网桥，每个端口可以连接一台设备或一个网段，形成“端口到端口”的独立冲突域 交换机工作流程 从源 MAC 学习设备位置 查表转发目标帧 若目标未知 → 泛洪（广播到所有端口） 交换机会造成广播风暴：交换机会将广播帧（如ARP请求、DHCP请求）转发到所有端口，当网络中存在大量广播流量或存在环路时，可能引发广播风暴，占用大量带宽，导致网络拥塞甚至瘫痪 使用 VLAN 划分广播域，缩小广播范围 启用生成树协议（STP） 防止环路 路由器路由器：跨网络通信 工作层次：OSI 模型 网络层（第3层） 核心功能：将数据包从一个网络转发到另一个网络，实现跨网通信 关键机制：依靠路由表（基于IP地址）决定到达目标网络的最佳路径 功能：每个接口属于不同广播域，有效抑制广播风暴，分隔广播域和冲突域 路由器工作流程 接收数据包 → 查看目标 IP 地址 查询路由表：匹配目的网络 选择最佳路径 → 转发到下一跳（Next Hop） 若无匹配项 → 丢弃或转发至默认路由 虚拟局域网 VLAN因为交换机上各主机都属于同一网段，每个接口组合成了一个广播域，当有一个接口发起通讯时，在同一网段的其他接口都可以接收到，所以这样并不安全，所以利用了VLAN技术可以用交换机来进行网络隔离，要求交换机具有网络管理功能。有了VLAN划分局域网，交换机收到广播帧后，只转发到属于同一VLAN的其他端口 可以不用通过路由器来隔离不同广播域 可以突破地理位置的限制，在逻辑上划分出不同的广播域 基于端口的 VLAN这种模式中，在交换机上创建若干个VLAN，在将若干端口放在每个VLAN 中。每个端口在某一时刻只能属于一个VLAN。一个 VLAN 可以包含所有端口，或者部分端口。每个端口有个PVID （port VLAN identifier)。这种模式下，一个端口上收到的 frame 是 untagged frame，因此它不包含任何有关 VLAN 的信息。VLAN 的关系只能从端口的 PVID 上看出来。交换机在转发 frame 时，只将它转发到相同 PVID 的端口。 如上图所示，连接两个交换机的同一个 VLAN 中的两个计算机需要通信的话，需要在两个交换机之间连两根线： 一根从 Switch A 端口4 到 Switch B 端口 4 （VLAN 1） 一根从 Switch A 端口8 到 Switch B 端口 8 （VLAN 2） 带 VLAN 的交换机的端口分为两类： Access port 这些端口被打上了 VLAN Tag。离开交换机的 Access port 进入计算机的以太帧中没有 VLAN Tag，这意味着连接到 access ports 的机器不会觉察到 VLAN 的存在。离开计算机进入这些端口的数据帧被打上了 VLAN Tag。 Trunk port 有多个交换机时，组A中的部分机器连接到 switch 1，另一部分机器连接到 switch 2。要使得这些机器能够相互访问，你需要连接两台交换机。 要避免使用一根电缆连接每个 VLAN 的两个端口，我们可以在每个交换机上配置一个 VLAN trunk port。Trunk port 发出和收到的数据包都带有 VLAN header，该 header 表明了该数据包属于那个 VLAN。因此，只需要分别连接两个交换机的一个 trunk port 就可以转发所有的数据包了。通常来讲，只使用 trunk port 连接两个交换机，而不是用来连接机器和交换机，因为机器不想看到它们收到的数据包带有 VLAN Header。 Tagged VLANs （数据帧中带有 VLAN tag）这种模式下，frame 的VLAN 关系是它自己携带的信息中保存的，这种信息叫 a tag or tagged header。当交换机收到一个带 VLAN tag 的帧，它只将它转发给具有同样 VID 的端口。一个能够接收或者转发 tagged frame 的端口被称为 a tagged port。所有连接到这种端口的网络设备必须是 802.1Q 协议兼容的。这种设备必须能处理 tagged frame，以及添加 tag 到其转发的 frame。 上图中，两个交换机上的端口8 支持 VLAN 1 和 2， 因此一根线就可以了实现跨交换机的同VLAN 内的计算机互相通信了。 VLAN的不足VLAN 使用 12-bit 的 VLAN ID，所以 VLAN 的第一个不足之处就是它最多只支持 4096 个 VLAN 网络（当然这还要除去几个预留的），对于大型数据中心的来说，这个数量是远远不够的。 VLAN 操作需手工介入较多，这对于管理成千上万台机器的管理员来说是难以接受的。 三、Internet层地址解析协议ARP作用：将IP地址解析成MAC地址 主机发送信息时将包含目标IP地址的ARP请求广播到局域网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。地址解析协议是建立在网络中各个主机互相信任的基础上的，局域网络上的主机可以自主发送ARP应答消息，其他主机收到应答报文时不会检测该报文的真实性就会将其记入本机ARP缓存 同网段的ARP 跨网段的ARP 范例：ARP 表 12345678910111213141516171819202122232425262728293031[root@baidu ~]#ip neigh192.168.1.110 dev eth0 lladdr 60:02:b4:e3:8a:c0 STALE192.168.1.156 dev eth0 lladdr 50:01:d9:8a:1d:3f STALE192.168.1.114 dev eth0 lladdr 40:8d:5c:e1:97:34 STALE192.168.1.118 dev eth0 lladdr 94:65:2d:38:44:82 STALE#查看ARP缓存[root@baidu ~]#arp -nAddress HWtype HWaddress Flags Mask Iface192.168.1.110 ether 60:02:b4:e3:8a:c0 C eth0192.168.1.156 ether 50:01:d9:8a:1d:3f C eth0192.168.1.114 ether 40:8d:5c:e1:97:34 C eth0192.168.1.118 ether 94:65:2d:38:44:82 C eth0#ARP只对局域网有效，要是跨网段就实现不了[root@centos7 ~]#arp -nAddress HWtype HWaddress Flags Mask Iface10.0.0.1 ether 00:50:56:c0:00:08 C eth010.0.0.2 ether 00:50:56:ea:d3:07 C eth0[root@centos7 ~]#ping www.baidu.comPING www.a.shifen.com (183.2.172.185) 56(84) bytes of data.64 bytes from 183.2.172.185 (183.2.172.185): icmp_seq=1 ttl=128 time=19.7 ms[root@centos7 ~]#arp -nAddress HWtype HWaddress Flags Mask Iface10.0.0.1 ether 00:50:56:c0:00:08 C eth010.0.0.2 ether 00:50:56:ea:d3:07 C eth0#删除记录[root@centos7 ~]#arp -d [ipaddr] 范例：ARP静态绑定可以防止ARP欺骗 123456[root@centos8 ~]#arp -s 10.0.0.6 00:0c:29:32:80:38[root@centos8 ~]#arp -nAddress HWtype HWaddress Flags Mask Iface10.0.0.6 ether 00:0c:29:32:80:38 CM eth010.0.0.7 ether 00:0c:29:32:80:38 C eth010.0.0.1 ether 00:50:56:c0:00:08 C eth0 Gratuitous ARPGratuitous ARP也称为免费ARP，无故ARP。Gratuitous ARP 不同于一般的ARP请求，它并非期待得到ip对应的mac地址，而是当主机启动的时候，将发送一个Gratuitous arp请求，即请求自己的ip地址的mac地址 免费ARP可以有两个方面的作用： 验证IP是否冲突：一个主机可以通过它来确定另一个主机是否设置了相同的 IP地址 更换物理网卡：如果发送ARP的主机正好改变了物理地址（如更换物理网卡），可以使用此方法通知网络中其它主机及时更新ARP缓存 判断IP地址有没有地址冲突 1234567arping ipaddr如果同一IP地址出现两个MAC地址，说明地址冲突[root@LVS ~]#arping 10.0.0.100ARPING 10.0.0.10060 bytes from 00:0c:29:28:40:00 (10.0.0.100): index=0 time=219.480 usec60 bytes from 00:0c:29:fe:8e:b4 (10.0.0.100): index=1 time=297.546 usec 反向地址解析协议RARP作用：将MAC转换成IP IP地址IP地址组成它们可唯一标识 IP 网络中的每台设备 ，每台主机（计算机、网络设备、外围设备）必须具有唯一的地址 MAC 属于物理地址，mac 地址不可变，一出厂就写死，标识惟一设备 IP 属于逻辑地址，逻辑地址可修改，人为赋予，可以修改，使用灵活，便于管理 IP地址由两部分组成 网络 ID：标识网络，每个网段分配一个网络ID，处于高位（表示处于哪个网段） 主机 ID：标识单个主机，由组织分配给各设备，处于低位 IPv4地址格式：点分十进制记法 范例：IP地址转十进制INT 12345678#二进制转十进制[root@ubuntu2204 ~]# echo &quot;ibase=2;00001010000000000000000010011110&quot;|bc167772318[root@ubuntu2204 ~]# ping 167772318PING 167772318 (10.0.0.158) 56(84) bytes of data.64 bytes from 10.0.0.158: icmp_seq=1 ttl=64 time=0.973 ms64 bytes from 10.0.0.158: icmp_seq=2 ttl=64 time=0.823 ms 范例：遍历检测当前网段内的主机 12345678910111210.0.0.1 = 00001010 00000000 00000000 0000000110.0.0.254 = 00001010 00000000 00000000 11111110 254 = 128+64+32+16+8+4+2[root@ubuntu2204 ~]# echo &quot;ibase=2;00001010000000000000000000000001&quot;|bc167772161[root@ubuntu2204 ~]# echo &quot;ibase=2;00001010000000000000000011111110&quot;|bc167772414[root@ubuntu2204 ~]# for i in &#123;167772161..167772414&#125;;do ping -c1 -W1 $i &amp;&amp; echo the $i is up || echo the $i is down;done;[root@ubuntu2204 ~]# net=10.0.0.1;for i in &#123;1..254&#125;;do ping -c1 -W1 $net.$i &amp;&gt;/dev/null &amp;&amp; echo the $net.$i is up || echo the $net.$i is down;done; IP地址分类 类别 首字节范围（十进制） 二进制前缀 网络ID位数 主机ID位数 网络数量 每网络最大主机数 默认子网掩码 私有地址范围 示例 A类 1–126① 0xxxxxxx 8位 24位 126 &#x3D; 2⁷ - 2 16777214 &#x3D; 2²⁴ - 2 255.0.0.0 10.0.0.0 – 10.255.255.255 114.114.114.114, 8.8.8.8, 1.1.1.1 B类 128–191 10xxxxxx 16位 16位 16384 &#x3D; 2¹⁴ 65534 &#x3D; 2¹⁶ - 2 255.255.0.0 172.16.0.0 – 172.31.255.255 180.76.76.76, 172.16.0.1 C类 192–223 110xxxxx 24位 8位 2097152 &#x3D; 2²¹ 254 &#x3D; 2⁸ - 2 255.255.255.0 192.168.0.0 – 192.168.255.255 223.6.6.6, 223.5.5.5 D类 224–239 1110xxxx ——（多播） —— —— —— —— —— 多播（组播）地址 E类 240–255 1111xxxx ——（保留） —— —— —— —— 公共和私有IP地址公共IP地址：互联网上设备拥有的唯一地址 私有IP地址：不直接用于互联网，通常在局域网中使用 1234567891011A类私有：10.0.0.0 -- 10.255.255.255公有：1.0.0 -- 9.255.255.255; 1.0.0.0 -- 126.255.255.255B类私有：172.16.0.0 -- 172.31.255.255公有：128.0.0.0 -- 172.15.255.255; 172.32.0.0 -- 191.255.255.255C类私有：192.168.0.0 -- 192.168.255.255公有：192.0.0.0 -- 192.167.255.255; 192.169.0.0 -- 223.255.255.255 特殊地址 IP 地址 &#x2F; 范围 类型 含义与用途 是否可路由 备注 0.0.0.0 特殊地址 - 表示“任意地址”或“未知网络&#x2F;主机”- 常用于默认路由（如 0.0.0.0/0）- 在服务器绑定中表示监听所有网络接口 ❌ 不用于通信 不是有效主机地址，仅用于配置或通配 255.255.255.255 限制广播地址 - 本网段内的广播地址- 发送到该地址的数据包会被本广播域内所有主机接收- 路由器不会转发此广播 ❌ 仅限本地广播域 又称“有限广播地址” 127.0.0.1 ~ 127.255.255.254（即 127.0.0.0/8） 回环地址（Loopback） - 用于本机内部通信- 测试 TCP&#x2F;IP 协议栈是否正常- 本地服务间通信（如数据库、Web 服务）- 数据包不会离开主机，不经过物理网卡 ❌ 仅限本机 - 常用 127.0.0.1 ping 测试网络协议- 虚拟接口，永不宕机 ::1（IPv6） IPv6 回环地址 IPv6 中的回环地址，功能同 127.0.0.1 ❌ 仅限本机 零压缩表示为 ::1 224.0.0.0 ~ 239.255.255.255 组播（Multicast）地址 - 用于一点对多点的数据传输- 常见于视频会议、流媒体、路由协议等 ✅ 可跨网络（需组播路由支持） D类地址，也称“多播地址” 224.0.0.1 组播地址 所有支持组播的主机 ✅ 本地子网范围 224.0.0.2 组播地址 所有支持组播的路由器 ✅ 本地子网范围 224.0.0.5 组播地址 OSPF 路由协议使用的组播地址 ✅ 用于 OSPF 路由器间通信 169.254.x.x（169.254.0.0/16） 链路本地地址（Link-Local） - 当主机使用 DHCP 但无法获取 IP 时，Windows 自动分配此地址- 用于本地链路通信（仅限同一网段）- 表示“网络连接异常” ❌ 不能跨路由器 又称“自动私有 IP 地址”（APIPA） 概念 说明 回环地址工作原理 数据包在本机网络层处理，不经过物理接口。用于服务自测、本地通信，如 localhost。 组播地址特点 不同于广播（发给所有人），组播是“有选择的广播”——只有加入特定组的主机才会接收。 APIPA（169.254.x.x） 是 Windows 的容错机制。若看到此地址，说明 DHCP 故障或网络不通。 0.0.0.0 的常见用途 - 路由表中的默认路由：0.0.0.0/0- 服务器监听所有接口：0.0.0.0:80 保留地址在一个IP地址中，如果主机ID全为0，或主机ID全为1，则该地址是保留地址 如在B类127.16 网段中，172.16.0.0 和 172.16.255.255 为保留地址 子网掩码CIDR：无类域间路由，目前的网络已不再按A，B，C类划分网段，可以任意指定网段的范围 CIDR 无类域间路由表示法：IP&#x2F;网络ID位数，如：172.16.0.100&#x2F;16 子网掩码的八位 12345678900000000 010000000 12811000000 19211100000 22411110000 24011111000 24811111100 25211111110 25411111111 255 范例 123IP地址 172.16.0.0子网掩码 11111111.11111111.00000000.00000000子网掩码十进制表示 255.255.0.0 相关公式： 一个网络的最多的主机数 ＝2 ^ 主机ID位数 - 2 网络（段）数 &#x3D; 2 ^ 网络ID中可变的位数 网络ID &#x3D; IP 与 netmask 与运算 1234560与0=00与1=01与0=01与1=1任何数与0都为0任何数与1保留原值 判断对方主机是否在同一个网段： 用自已的子网掩码分别和自已的IP及对方的IP相与，比较结果，相同则同一网络，不同则不同网段 范例：判断A和B是否在网一个网段? 123456789101112A:10.0.1.1/16 B:10.0.2.2/24 如果A访问B，则A和A自已的netmask相与 10.0.0.0/16B和A的netmask相与 10.0.0.0/16两个结果相比较,结果相同如果B访问A，则B和B自已的netmask相与 10.0.2.0/24A和B的netmask相与 10.0.1.0/24两个结果相比较,结果不相同，不在同一个网络 范例：一个主机：220.100.199.0&#x2F;22，求主机数量，最小IP，最大IP 123456789101112131415#网络ID11011100.01100100.11000111.00000000 IP11111111.11111111.11111100.00000000 network11011100.01100100.11000100.00000000 网络ID 220.100.196.0#主机数量2^(32-22)-2=2^10-2=1024-2=1022 32-22 表示32位减去22位网络ID，剩下主机位ID数#最小IP和最大IP220.100.196.1220.100.196196=128+64+4=11000100前22位属于网络ID 220.100.110001 00.00000000则最大是 220.100.110001 11.11111111 = 220.100.199.254 划分子网划分子网：将一个大的网络（主机数多）划分成多个小的网络（主机数少），主机ID位数变少，网络ID位数变多，网络ID位向主机ID位借n位,将划分2^n个子网 子网划分核心：就是控制子网掩码的长短来让ip地址分散到不同的网段&#x2F;子网里 划分子网数&#x3D;2^(网络ID向主机ID借的位数) 123456789101112131415161718192021222324252627282930313233343536#10.0.0.0/8#主机数 2^24-2=16777214#10.0.0.1 -- 10.255.255.254#网络ID向主机ID借一位，能划分成两个子网10.0 0000000.00000000.00000000 10.0.0.0/9 10.1 0000000.00000000.00000000 10.128.0.0/9#网络ID向主机ID借两位，能划分成四个子网10.00 000000.00000000.00000000 10.0.0.0/1010.01 000000.00000000.00000000 10.64.0.0/1010.10 000000.00000000.00000000 10.128.0.0/1010.11 000000.00000000.00000000 10.192.0.0/10#划分成32个子网 2^5=32，所以借5位10.00000 000.00000000.00000000 10.0.0.0/13......10.11111 000.00000000.00000000 10.248.0.0/1311000000.10101000.01000111.00000000 ---&gt; 192.168.71.011000000.10101000.01000111.00000001 ---&gt; 192.168.71.111000000.10101000.01000111.00000011 ---&gt; 192.168.71.2........11000000.10101000.01000111.01111111 ---&gt; 192.168.71.127 一直到127为止计算出的网络地址都是192.168.71.011111111.11111111.11111111.10000000 ---&gt; 25位子网掩码11000000.10101000.01000111.00000000 ---&gt; 192.168.71.0 11000000.10101000.01000111.10000000 ---&gt; 192.168.71.128 11000000.10101000.01000111.10000001 ---&gt; 192.168.71.129 11000000.10101000.01000111.10000010 ---&gt; 192.168.71.130........11000000.10101000.01000111.11111111 ---&gt; 192.168.71.255 一直到127为止计算出的网络地址都是192.168.71.12811111111.11111111.11111111.10000000 ---&gt; 25位子网掩码11000000.10101000.01000111.10000000 ---&gt; 192.168.71.128 在ip层面来说，他们是属于不同的网段，但是在物理层面，交换机是认为他们在同一网段的。假如两台服务器连接到同一个交换机，即使属于不同网段，192.168.71.2发的广播包，192.168.71.129也是会收到的 那么如何使交换机也可以隔离呢？VLAN技术 虚拟局域网，通过虚拟技术把一个交换机分成多个广播域去用，一个广播域就是一个小的局域网 一个局域网内的广播包与另外一个局域网是隔离 物理端口 Access端口：连接终端设备，仅允许单个VLAN流量通过 Trunk端口：连接交换机或路由器，允许多个VLAN流量通过 优化IP地址分配合并超网：将多个小网络合并成一个大网，主机ID位向网络ID位借位，主要实现路由聚合功能 1234567891011121314151617181920#8个C类网段220.78.168.0/24220.78.169.0/24220.78.170.0/24220.78.171.0/24220.78.172.0/24220.78.173.0/24220.78.174.0/24220.78.175.0/24#主机ID向网络ID借3位，网络ID变成21位 168=128+32+8220.78.10101 000.0 220.78.168.0/24220.78.10101 001.0 220.78.169.0/24220.78.10101 010.0 220.78.170.0/24......220.78.10101 110.0 220.78.174.0/24220.78.10101 111.0 220.78.175.0/24#合并成一个大网220.78.168.0/21 四、GRE和VXLAN基于vlan模式来构建虚拟机跨宿主机通信的网络有两点问题 vlan id采用12bit位标识，意味着最多也就4000多个网络，会限制网络的规模 物理节点必须处于一个二层网络 基于gre与vxlan技术就是用来突破上述两点限制的，其实gre与vxlan两种协议的基本原理都是利用已有协议来封装自己新的东西 vxlan特点： 基于udp协议进行分发，所以vxlan是无状态的 支持组播 gre特点： 通过是基于ip协议就信息分发，所以gre是有状态的 不支持组播 每新增与一个节点，所有相关节点都需要与其建立GRE隧道链接 GRE技术本身还是存在一些不足之处： （1）Tunnel 的数量问题 GRE 是一种点对点（point to point）标准。Neutron 中，所有计算和网络节点之间都会建立 GRE Tunnel。当节点不多的时候，这种组网方法没什么问题。但是，当你在你的很大的数据中心中有 40000 个节点的时候，又会是怎样一种情形呢？使用标准 GRE的话，将会有 780 millions 个 tunnels。 （2）扩大的广播域 GRE 不支持组播，因此一个网络（同一个 GRE Tunnel ID）中的一个虚机发出一个广播帧后，GRE 会将其广播到所有与该节点有隧道连接的节点。 （3）GRE 封装的IP包的过滤和负载均衡问题 目前还是有很多的防火墙和三层网络设备无法解析 GRE Header，因此它们无法对 GRE 封装包做合适的过滤和负载均衡。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"IO模型","slug":"computer-basics/operating-system/IO-model","date":"2025-08-21T02:42:26.000Z","updated":"2025-08-28T12:33:05.406Z","comments":true,"path":"computer-basics/operating-system/IO-model/","permalink":"https://aquapluto.github.io/computer-basics/operating-system/IO-model/","excerpt":"","text":"一、IO的分类1.1 磁盘IO和网络IO磁盘I&#x2F;O处理过程 进程向内核发起系统调用，请求磁盘上的某个资源比如是html 文件或者图片 然后内核通过相应的驱动程序将目标文件加载到内核的内存空间 加载完成之后把数据从内核内存再复制给进程内存，如果是比较大的数据也需要等待时间。 网络I&#x2F;O 处理过程 获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求 构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成 返回数据，服务器将已构建好的响应再通过内核空间的网络 I&#x2F;O 发还给客户端 不论磁盘和网络I&#x2F;O，每次I&#x2F;O，都要经由两个阶段： 第一步：将数据从文件先加载至内核内存空间（缓冲区），等待数据准备完成，时间较长 第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短 1.2 同步IO和异步IO函数或方法被调用的时候，调用者是否得到最终结果的。 直接得到最终结果结果的，就是同步调用； 不直接得到最终结果的，就是异步调用。 1.3 阻塞IO和非阻塞IO函数或方法调用的时候，是否立刻返回。 立即返回就是非阻塞调用； 不立即返回就是阻塞调用。 1.3.1 阻塞I&#x2F;O (Blocking I&#x2F;O)当一个进程发起一个I&#x2F;O请求时，它会暂停执行，直到I&#x2F;O操作完成。 这是最常见的I&#x2F;O模型，例如当你打开一个文件进行读取时。 1.3.2 非阻塞I&#x2F;O (Non-blocking I&#x2F;O)在非阻塞模式下，当进程尝试发起I&#x2F;O操作时，如果操作不能立即完成，则会立即返回一个错误或特定值，而不是等待。 进程需要不断地轮询检查I&#x2F;O操作的状态，这称为“忙等”(busy-waiting)。 1.4 联系同步阻塞，我啥事不干，就等你打饭打给我。打到饭是结果，而且我啥事不干一直等，同步加阻塞。 同步非阻塞，我等着你打饭给我，饭没好，我不等，但是我无事可做，反复看饭好了没有。打饭是结果，但是我不一直等。 异步阻塞，我要打饭，你说等叫号，并没有返回饭给我，我啥事不干，就干等着饭好了你叫我。例如，取了号什么不干就等叫自己的号。 异步非阻塞，我要打饭，你给我号，你说等叫号，并没有返回饭给我，我去看电视、玩手机，饭打好了叫我。 1.5 总结同步与异步：任务的启动&#x2F;调用方式 同步：多个任务是同步执行的指的是启动一个任务之后，必须在原地等待该任务运行完毕之后，才能启动下一个任务并且运行 异步：提交完一个任务之后，不用在原地等待该任务运行完毕，就能立即提交下一个任务执行 并发&#x2F;并行与串行：指的是任务给人展现出的运行的效果 并发&#x2F;并行：多个任务是”同时“运行的 串行：一个任务运行完毕，才能运行下一个 阻塞与非阻塞：任务在操作系统中的运行状态 会引起阻塞的事项 硬盘IO 网络IO sleep read命令 二、同步IO模型2.1 阻塞IO模型进程等待（阻塞），直到读写完成。（全程等待） read() write() recv() send() accept() connect() 等…都是阻塞IO 当用户调用了read()，kernel 就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据在一开始还没有达到（比如，还没有收到一个完整的数据包），这个时候kernel 就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel 一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来 所以，阻塞IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被阻塞了。这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够 2.2 非阻塞IO模型进程调用recvfrom操作，如果IO设备没有准备好，立即返回ERROR，进程不阻塞。用户可以再次发起系统调用（可以轮询），如果内核已经准备好，就阻塞，然后复制数据到用户空间。可防止进程阻塞在IO操作上，需要轮询。 第一阶段数据没有准备好，可以先忙别的，等会再来看看。检查数据是否准备好了的过程是非阻塞的。 第二阶段是阻塞的，即内核空间和用户空间之间复制数据是阻塞的。 淘米、蒸饭我不阻塞等，反复来询问，一直没有拿到饭。盛饭过程我等着你装好饭，但是要等到盛好饭才算完事，这是同步的，结果就是盛好饭。 所以，在非阻塞式 IO 中，用户进程其实是需要不断的主动询问（轮询） kernel 数据准备好了没有。 轮询的时间不好把握，这里是要猜多久之后数据才能到。等待时间设的太长，程序响应延迟就过大；设的太短，就会造成过于频繁的重试，干耗CPU而已，是比较浪费CPU的方式。 2.3 多路复用IO模型以前一个应用程序需要对多个网络连接进行处理，传统的方法是使用多线程或多进程模型，为每个连接创建一个线程或进程进行处理。这种方法存在一些问题，例如线程或进程的创建和销毁需要消耗大量的系统资源，且容易导致线程或进程的数量过多，进而导致系统崩溃或运行缓慢。所以便出现了IO多路复用。 多路复用思想是将操作的所有文件描述符保存在一张文件描述符表中，然后将文件描述符表交给内核，让内核检测当前是否有准备就绪的文件描述符（例如有数据可读或可写），如果有则通知应用程序，操作就绪的文件描述符。这种方式可以让一个进程处理多个并发的IO操作，而不需要为每个IO操作创建一个独立的线程或进程。 以select为例，当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 相比非阻塞IO 在非阻塞IO模型中，如果一个文件描述符还没有准备好进行读写操作，应用程序需要不断地轮询该描述符的状态（即不断调用read()或write()）。这会导致较高的CPU使用率，因为即使在没有数据的情况下，程序也需要不断地执行这些系统调用。 相比之下，使用IO多路复用（如select(), poll(), 或 epoll()），程序只需要在一个调用中指定多个文件描述符，然后等待至少有一个描述符准备就绪。这减少了CPU的轮询开销。 2.3.1 select这是最早的多路复用函数之一，它可以监控多个文件描述符，并且在任何一个描述符上有事件发生时返回。但是它的最大限制是文件描述符的数量受限于系统定义的最大值。 通过将已连接的Socket放入一个文件描述符集合中，然后调用select函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生。然而，select存在一些缺点，如每次调用select都需要将fd集合从用户态拷贝到内核态，且仅仅返回可读文件描述符的个数，具体哪个可读还需要用户自己以轮询的方式线性扫描，效率不高。 2.3.2 poll与select()类似，但没有文件描述符数量的限制。poll()使用链表来跟踪描述符的状态变化。 修复了select的一些问题，不再使用BitsMap来存储所关注的文件描述符，改用动态数组，以链表形式来组织，突破了select的文件描述符个数限制。然而，poll和select并没有太大的本质区别，都是使用线性结构存储进程关注的Socket集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket。 2.3.3 epoll这是Linux系统提供的一个更为高效的多路复用接口，它可以高效地处理大量的文件描述符。epoll使用事件驱动的方式，只有当事件发生时才会通知应用程序。 它针对select和poll的缺点进行了优化。epoll在内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分。内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步I0事件唤醒。这使得epoll在处理大量并发连接时具有更高的性能和效率。 2.4 信息驱动IO模型进程在IO访问时，先通过sigaction系统调用，提交一个信号处理函数，立即返回，进程不阻塞。当内核准备好数据后，产生一个SIGIO信号并投递给信号处理函数（由内核通知，发送信号）。可以在此函数中调用recvfrom函数操作数据从内核空间复制到用户空间，这段过程进程阻塞。 此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知。但是信号 I&#x2F;O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知。 三、异步IO模型进程发起异步IO请求，立即返回。内核完成IO的两个阶段，内核给进程发一个信号。异步I&#x2F;O允许进程发起一个I&#x2F;O操作后继续执行其他任务，当I&#x2F;O操作完成时，操作系统会通知进程。所以IO两个阶段，进程都是非阻塞的。 异步I&#x2F;O 与 信号驱动I&#x2F;O最大区别在于，信号驱动是内核通知用户进程何时开始一个I&#x2F;O操作，而异步I&#x2F;O是由内核通知用户进程I&#x2F;O操作何时完成。 但是Linux的 aio 的系统调用，内核是从版本2.6开始支持，只用在磁盘IO读写操作，不用于网络IO。 四、IO模型总结","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://aquapluto.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"进程与线程","slug":"computer-basics/operating-system/processes-threads","date":"2025-08-21T02:42:21.000Z","updated":"2025-08-28T12:33:05.411Z","comments":true,"path":"computer-basics/operating-system/processes-threads/","permalink":"https://aquapluto.github.io/computer-basics/operating-system/processes-threads/","excerpt":"","text":"一、进程 进程：进程是具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。可以理解为是程序的实际执行实例，当程序在计算机上运行时，操作系统会为它创建一个进程，分配资源（如内存、CPU时间、文件描述符等），并在计算机上执行程序的指令。 1.1 进程分类1.1.1 操作系统分类协作式多任务：早期 windows 系统使用，即一个任务得到了 CPU 时间，除非它自己放弃使用CPU，否则将完全霸占 CPU ，所以任务之间需要协作——使用一段时间的 CPU ，主动放弃使用。 抢占式多任务：Linux内核，CPU的总控制权在操作系统手中，操作系统会轮流询问每一个任务是否需要使用 CPU ，需要使用的话就让它用，不过在一定时间后，操作系统会剥夺当前任务的 CPU使用权，把它排在询问队列的最后，再去询问下一个任务。 1.1.2 进程类型守护进程: daemon，在系统引导过程中启动的进程，和终端无关进程（后台执行，ps aux中TTY为?的） 前台进程：跟终端相关，通过终端启动的进程（占用终端资源） 注意：两者可相互转化 1.1.3 进程资源使用的分类CPU-Bound：CPU 密集型，非交互 IO-Bound：IO 密集型，交互 1.2 进程与进程之间的关系在操作系统中，不同进程之间可以有多种关系和交互方式。以下是一些常见的进程之间的关系： 父子进程关系：在某些操作系统中，一个进程可以创建其他进程（通过 fork() 系统调用来创建），这些创建的进程被称为子进程，而创建它们的进程称为父进程。子进程通常继承父进程的一些属性，如文件描述符、环境变量等。父子进程之间可以通过进程间通信机制来交换数据和信息。 兄弟进程关系： 兄弟进程是指由同一个父进程创建的多个子进程。这些兄弟进程通常是独立运行的，但它们可以共享某些资源，如父进程创建的文件描述符或共享内存区域。 并发进程关系： 并发进程是指在系统中同时运行的多个独立进程，它们可以在不同的处理器核心（比如多核服务器）上并行执行，以提高系统性能。 竞争条件和同步关系： 当多个进程试图同时访问共享资源时，可能会发生竞争条件。为了避免数据损坏和不一致性，需要使用同步机制来确保进程之间的顺序执行或互斥访问共享资源。 进程间通信关系： 进程之间可以通过进程间通信（Inter-Process Communication，IPC）机制来交换数据和信息。常见的 IPC 方式包括管道、消息队列、信号、套接字、共享内存等。 进程间协作关系： 进程可以协作来完成复杂的任务。这种协作可以通过共享数据、互相通知、等待其他进程完成某些操作等方式来实现。 进程间客户端-服务器关系： 在分布式系统中，进程之间可以扮演客户端和服务器的角色。客户端进程请求服务并与服务器进程通信，以实现分布式应用程序的功能。 1.3 进程的状态和转换1.3.1 状态分类创建状态：进程在创建时会首先完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行。在这个状态下，进程只是被初始化，但尚未分配 CPU 资源。 就绪状态：进程已准备好，已分配到所需资源，只要分配到CPU就能够立即运行，其实就是进入了任务队列，在就绪状态下，进程等待操作系统的调度以获得 CPU 时间片来执行。 运行状态：当操作系统调度进程并将其分配到 CPU 时，进程进入运行状态。在运行状态下，进程将会执行其指令和代码。 阻塞状态：如果一个进程在执行过程中需要等待某些事件（I&#x2F;O操作完成，申请缓存区失败，等待资源释放）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用，在阻塞状态下，进程不会消耗CPU时间，直到等待的事件发生。 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行，在终止状态下，进程的所有资源被释放。 睡眠态：进程需要等待某种资源而进入的状态，要等的资源可以是一个信号量Semaphore）, 或者是磁盘 I&#x2F;O，这个状态的进程会被放入到 wait queue 队列里。分为两种，可中断：interruptable，不可中断：uninterruptable 可中断睡眠态的进程在睡眠状态下等待特定事件发生，即使特定事件没有产生，也可以通过其它手段唤醒该进程，比如，发信号，释放某些资源等 不可中断睡眠态的进程在也是在睡眠状态下等待特定事件发生，但其只能被特定事件唤醒，发信号或其它方法都无法唤醒该进程。 停止态：stopped，暂停于内存，但不会被调度，除非手动启动 僵死态：zombie，僵尸态。父进程结束前，子进程关闭，杀死父进程可以关闭僵死态的子进程 1.3.2 状态转换运行——&gt;就绪 主要是进程占用CPU的时间过长，而系统分配给该进程占用CPU的时间是有限的；在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行时，该进程就被迫让出CPU，该进程便由执行状态转变为就绪状态 就绪——&gt;运行 运行的进程的时间片用完，调度就转到就绪队列中选择合适的进程分配CPU 运行——&gt;阻塞 正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如发生了I&#x2F;O请求 阻塞——&gt;就绪 进程所等待的事件已经结束，就进入就绪队列 以下两种状态是不可能发生的： 阻塞——&gt;运行：即使给阻塞进程分配CPU，也无法执行，操作系统在进行调度时不会从阻塞队列进行挑选，而是从就绪队列中选取 就绪——&gt;阻塞：就绪态根本就没有执行，谈不上进入阻塞态 1.3.3 总结1.3.3.1 活着的状态运行着的 ——-》R 正在执行：手里拿着cpu正在运行 就绪（随时可以投入运行）：正在等待操作系统分配cpu，一旦分配到，就可以立即投入运行 阻塞的 —-》S或D S：可中断的睡眠 等待某个资源而进入的状态，执行的IO操作可以得到硬件设备的相应 可以用例如 ctrl+c, kill -9 pid号 命令来终止 类似python中执行 input 代码，shell语言中的 read -p &quot;请输入xxx：&quot; x D: 不可中断睡眠 执行的IO操作不可以得到硬件设备的相应（可能是因为存储设备太忙了响应不过来了） 因此导致内存中的数据无法及时刷入磁盘，所以不可以被中止（linux系统为了防止数据丢失的一种保护机制） 但是要注意的是，只有R和D才属于活跃的进程，一个进程内要做的事可以分为两大类 计算任务 —&gt; cpu负责运行 IO任务 —&gt; 磁盘、网卡负责处理 只要该进程正在被处理着，那它就属于活跃的进程，cpu在执行该进程的计算机任务，肯定属于活跃；磁盘在处理该进程的IO任务，那肯定也属于活跃，总之有事做就属于活跃，而S状态，在等待用户输入内容，而此时用户什么也没有输，即IO操作啥事也没做，计算任务也肯定没有，整个进程就是不活跃的 1.3.3.2 死了的状态僵尸进程 —–》Z 僵尸进程是操作系统的一种优化机制 一个进程死掉之后，会把其占用的cpu、内存资源都释放掉，但是会保留该进程的状态信息，例如pid号、存在过的一些运行信息，这些保留下来的信息都是操作系统给父进程准备的 每个进程死掉之前都会进入僵尸进程的状态 僵尸进程通常由父进程来回收 退出的进程 —》X几乎看不到 1.4 僵尸进程和孤儿进程1.4.1 僵尸进程子进程已经结束，但父进程可能处于停止状态，未回收其资源导致的状态，所以这个子进程被称为”僵尸”。僵尸进程不占用系统资源，但在系统中存在时，会占用进程号（PID）等资源，影响系统性能。僵尸进程通常发生在子进程已经结束运行 应用程序运行在某个系统上速度特别慢，通过top命令发现系统中有几个僵尸进程存在，问当前问题是否是僵尸进程的锅，我能否直接杀死僵尸进程来解决这个问题，说说你的理由？ 僵尸进程不是应用程序变慢的根本原因，僵尸进程已经死了，无法被进一步杀死，kill命令发送信号给进程，但僵尸进程已经被终止不会处理信号。运行速度特别慢应该用top命令查看%wa是否有I&#x2F;O等待，查看%CPU情况判断是否有进程长期占用cpu，查看%MEM判断是否因内存不足触发频繁交换。 要处理僵尸进程，需要找到僵尸程序的父进程，让父进程去回收这些僵尸进程，如果要杀死僵尸进程，则需要终止父进程，这些僵尸进程会被init进程接管，并由init来负责回收 1.4.2 孤儿进程指子进程的父进程自己先提前退出或异常终止，导致子进程失去了父进程。这时候，孤儿进程会被操作系统的init进程（通常具有PID 1）接管。init进程会成为孤儿进程的新父进程，负责收养和管理它们。以避免它们变成僵尸进程。 1.5 进程之间的通信&#x3D;&#x3D;管道（pipe）&#x3D;&#x3D; 单向传输，只能用于父子进程（有亲缘关系）之间的通信，允许一个进程将数据写入管道，另一个进程从管道中读取数据，随进程的创建而建立，随进程的结束而销毁。 在linux中，管道符“|”主要连接左右两个命令，左侧命令执行时是一个进程，他的标准输出（数据）写入管道，右边命令（进程）从管理读取数据，作为其标准输入 &#x3D;&#x3D;命名管道（FIFO）&#x3D;&#x3D; 允许无亲缘关系进程间的通信，不适合进程间频繁地交换数据。 &#x3D;&#x3D;消息队列（MessageQueue）&#x3D;&#x3D; 解决了FIFO的缺点。消息队列实际上是链表，链表的每个节点都是一条消息。每一条消息都有自己的消息类型，用整数来表示，而且必须大于 0，但不适合比较大的数据的传输。读取和写入的过程，都会发生用户态与内核态之间的消息拷贝过程。 &#x3D;&#x3D;共享内存（SharedMemory）&#x3D;&#x3D; 共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。 每个进程都会维护一个从内存地址到虚拟内存页面之间的映射关系。尽管每个进程都有自己的内存地址，不同的进程可以同时将同一个内存页面映射到自己的地址空间中，从而达到共享内存的目的。 比如a把数据全都丢到共享内存里面，b去共享内存拿数据，而且b可以按需选择拿哪些数据。 &#x3D;&#x3D;信号（sinal）&#x3D;&#x3D; 用于通知接收进程某个事件已经发生。 &#x3D;&#x3D;信号量（Semaphore）&#x3D;&#x3D; 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 &#x3D;&#x3D;套接字（Socket）&#x3D;&#x3D; 套接字文件，双工通信，网络进程间通信，比如A与B要通信，需要A将数据发生给套接字文件，B从套接字文件接收，或者B发A收。 它既解决了管道只能在相关进程间单向通信的问题，又解决了网络上不同主机之间无法通信的问题。 1.6 进程优先级首先要清楚，Linux 是一个多用户多任务的操作系统，如何理解多用户和多任务？ 多用户： 即 Linux 系统允许多个用户同时访问和使用系统资源，每个用户有自己的用户账户（用于身份验证和授权），且每个用户账户通常有自己的家目录，用于存储个人文件和配置。 多任务： 多任务是指操作系统能够同时运行多个程序或进程，而不仅仅是一个程序在运行，这使得多个任务可以并发执行。在 Linux 系统中，每个任务通常是一个独立的进程或线程。这些任务可以是用户启动的应用程序、系统服务、后台进程等。所有的任务都放在一个队列中，操作系统通过分时调度算法来分配 CPU 时间片，以便在多个任务之间切换，从而实现并发执行。 对于单 CPU 多任务操作系统而言，CPU 通过分配时间片以并发的方式来执行多任务（串行执行——即在某个时间点只能执行一个任务）；而对于多 CPU 多任务操作系统而言，CPU 既可以通过分配时间片以并发的方式来执行多任务，也可以在某个时间点并行执行多个任务，这就是多核 CPU 比单核 CPU 处理性能高的原因。 那在队列中的这些任务谁先会被 CPU 执行呢？是随机的吗？于是就涉及到了进程优先级与 nice 值的相关概念了。在操作系统中，通常存在两种类型的进程优先级：动态优先级和静态优先级。这两种优先级概念用于进程调度和资源分配，但它们有不同的性质和影响。 静态优先级（Static Priority）： 静态优先级是在进程创建时分配的，并且在进程的整个生命周期内保持不变。 静态优先级通常由用户或程序员明确设置，以反映进程的重要性或性能需求。这通常通过操作系统提供的API或命令来实现。 进程的静态优先级在进程的整个生命周期中不会改变，除非明确修改。 动态优先级（Dynamic Priority）： 动态优先级是在运行时根据系统负载和其他因素动态调整的优先级。 动态优先级的调整可以根据进程的行为、CPU利用率、等待时间等因素进行，以便更好地响应系统的需求。 操作系统的调度算法通常会考虑动态优先级来决定哪个进程在给定时刻获得CPU时间。 linux2.6内核将任务优先级进行了一个划分，实时优先级范围是0-99，而普通进程的静态优先级范围是100-139 优先级范围 描述 0-99 实时进程 100-139 非实时进程 CentOS 优先级 系统优先级：0-139, 数字越小，优先级越高,各有140个运行队列和过期队列 实时优先级: 99-0 值最大优先级最高 nice值：-20到19，对应系统优先级100-139 1.7 进程切换操作系统基于多道技术控制着cpu在多个任务&#x2F;进程之间切换，每种切换对效率的影响是什么？ （1）时间片耗尽 效率影响：公平性高，但频繁切换导致 上下文切换开销增大 （2）进程阻塞 效率影响：提升 CPU 利用率，频繁 I&#x2F;O 切换可能导致 吞吐量下降 （3）中断处理 效率影响：及时处理外部事件，频繁中断导致用户进程执行时间碎片化 （4）优先级调整 效率影响：关键任务响应及时，但可能打断长任务执行，增加调度延迟 二、线程在早期的操作系统中并没有线程的概念，后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程。 线程是程序执行的最小单位，是进程内的一个执行单元，一个进程可以有一个或多个线程，各个线程之间共享进程的内存空间。 2.1 线程的状态和转换就绪(Ready)：线程能够运行，但在等待被调度。可能线程刚刚创建启动，或刚刚从阻塞中恢复，或者被其他线程抢占 运行(Running) ：线程正在运行 阻塞(Blocked) ：线程等待外部事件发生而无法运行，如I&#x2F;O等待操作 终止(Terminated)：线程完成，或退出，或被取消 2.2 进程与线程的区别&#x3D;&#x3D;在概念上&#x3D;&#x3D; 进程是操作系统分配资源的最小单位；线程是程序执行的最小单位；一个进程由一个或多个线程组成。 &#x3D;&#x3D;在资源分配上&#x3D;&#x3D; 进程是独立的资源拥有单位，每个进程都有独立的地址空间和系统资源，某进程内的线程在其它进程不可见；而线程是共享所属进程的资源，多个线程共享同一个地址空间和系统资源，包括内存、文件和其他系统资源。 &#x3D;&#x3D;在创建和销毁上&#x3D;&#x3D; 进程的开销通常比线程大，因为进程需要为其分配独立的内存空间和资源；而线程的创建和销毁开销相对较小，因为它们共享了进程的资源。 &#x3D;&#x3D;在通信上，也是在并发性上&#x3D;&#x3D; 线程之间的通信和同步相对容易，并发性较高，因为它们共享同一地址空间；而进程之间的通信和同步则需要额外的机制，如管道、消息队列等，并发性较低，因为它们通常是相互独立的。 三、多进程和多线程多进程：多进程是指在一个应用程序中同时运行多个进程，每个进程都有独立的地址空间和资源，可以较充分地利用多处理器。 多线程：顾名思义，多个线程，一个进程中如果有多个线程运行，就是多线程，实现一种并发。 3.1 并行和并发并行：指的是多个任务真正地在同一时刻执行，通常需要多个处理器核心来实现。 并发：指的是多个任务在同一时间段内交替执行，但并不一定是同时执行。操作系统通过时间片轮转等调度机制使得多个任务看起来像是同时进行的。 单核CPU：无论是多进程还是多线程，都是通过时间片轮转的方式实现并发，不能实现真正的并行执行。 多核CPU：可以实现真正的并行执行，即多个进程或线程可以在不同的核心上同时执行，从而提高系统的性能和效率。 3.2 python中的GIL锁GIL 保证CPython进程中，只有一个线程执行字节码。甚至是在多核CPU的情况下，也只允许同时只能有一个CPU核心上运行该进程的一个线程。所以python中的多线程是假并行。 3.3 CPU密集型和IO密集型CPU密集型任务： 指那些需要大量CPU计算时间的任务，例如视频编码、图像处理、科学计算等。这类任务主要消耗的是CPU资源。 适用模型：多进程 因为其主要依赖于CPU计算能力，用多进程可以充分利用多核CPU的优势，实现真正的并行计算；而使用多线程可能不会带来显著的性能提升，因为在Python中有GIL（全局解释器锁）。 IO密集型任务： 指那些花费大量时间等待外部资源响应的任务，例如读写文件、网络请求、数据库查询等。这类任务大部分时间都在等待I&#x2F;O操作完成，而非占用CPU资源。 适用模型：多线程或多协程 当一个线程执行 I&#x2F;O 操作（如网络请求、文件读写等）时，CPython 会检测到这是一个 I&#x2F;O 操作，并允许该线程暂时释放 GIL。这使得其他线程有机会获取 GIL 并执行它们的 Python 字节码。一旦 I&#x2F;O 操作完成，线程重新获取 GIL 并继续执行后续代码。这种机制对于 I&#x2F;O 密集型任务非常重要，因为它允许在等待 I&#x2F;O 的时候让出 CPU 给其他线程使用，从而提高程序的整体效率和响应速度。 四、协程是一种用户级别的轻量级线程，由程序员显式控制其执行流程。协程可以在特定点暂停（yield），然后在之后恢复执行，而且无需内核态与用户态之间的转换，这使得它非常适合于异步编程模型。例如可以使用Python中的asyncio模块来实现。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://aquapluto.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统的概念","slug":"computer-basics/operating-system/concept","date":"2025-08-21T02:42:14.000Z","updated":"2025-08-28T12:33:05.410Z","comments":true,"path":"computer-basics/operating-system/concept/","permalink":"https://aquapluto.github.io/computer-basics/operating-system/concept/","excerpt":"","text":"一、操作系统的概念操作系统是一个协调、管理、控制计算机硬件资源给应用程序使用的一种控制程序 计算机三层体系 应用程序：图形界面，命令解释器 操作系统：windows操作系统 linux 计算机硬件（cpu、内存、硬盘） 操作系统与应用程序的区别 为了方便上层的应用程序开发（操作系统把复杂的硬件控制的代码都给写好了，然后对上层提供简单的功能） 操作系统是负责控制硬件的程序，给上层应用程序来调用 应用程序是给用户使用的程序 进程与程序 程序：就是一个或者一系列代码文件—》静态 进程：就是一个程序的运行过程——–》动态 进程代表的是程序的运行过程，而负责运行整个过程是操作系统，所以进程是操作系统的最核心的概念 二、操作系统的构成操作系统由两部分构成 系统调用接口：为上层的应用程序提供的一系列的功能 内核：负责控制硬件的运行的 操作系统的两种工作状态 用户态：执行的是系统调用接口层的代码，负责跟上层的应用程序打交道 内核态：执行的是内核某部分代码，负责跟底层的硬件打交道 操作系统的整个运行过程会频繁发生用户态与内核态的切换 操作系统启动之后，应用程序又是如何启动&#x2F;运行的？ 操作系统接到启动程序的指令 操作系统会控制硬件来运行某个应用程序 操作系统控制硬盘把程序的代码文件读入内存 操作系统控制cpu去内存里读取程序的指令来运行 双击快捷方式——-》图形界面——-》windows系统————》硬件 执行某个命令——-》命令解释器bash——-》linux系统————》硬件 操作系统的功能 隐藏了丑陋的硬件调用接口，为应用程序员提供调用硬件资源的更好，更简单，更清晰的模型（系统调用接口）。应用程序员有了这些接口后，就不用再考虑操作硬件的细节，专心开发自己的应用程序即可。 操作系统提供了文件这个抽象概念，对文件的操作就是对磁盘的操作，有了文件我们无需再去考虑关于磁盘的读写控制（比如控制磁盘转动，移动磁头读写数据等细节） 将应用程序对硬件资源的竞态请求变得有序化 很多应用软件其实是共享一套计算机硬件，比方说有可能有三个应用程序同时需要申请打印机来输出内容，那么a程序竞争到了打印机资源就打印，然后可能是b竞争到打印机资源，也可能是c，这就导致了无序，打印机可能打印一段a的内容然后又去打印c…,操作系统的一个功能就是将这种无序变得有序 三、多道技术多道技术是操作系统的核心技术，控制多个&#x2F;多道程序看起来是同时运行，多道技术的实现是为了解决多个程序竞争或者说共享同一个资源（比如cpu）的有序调度问题，解决方式即多路复用，多路复用分为时间上的复用和空间上的复用。 空间上的复用 复用的是内存，指的是多个程序能够同时读入内存里 空间上的复用必须注意一个点：加载到内存中的多个程序所占用的内存空间必须是隔离的才行 时间上的复用 复用的是cpu的时间，指的是cpu在多个内存中的程序之间快速的切换 什么情况切换 遇到 IO 操作一定会切换 没有遇到 IO 操作，也要切换，因为要让cpu能够雨露均沾（Linux操作系统） 一个cpu同一时间只能做一件事 并发：多个任务看起来是同时运行的，只有单核也能实现并发 并行：多个任务是真正意义上的同时运行的，只能多核才能实现并行 四、操作系统的安装原理驱动程序：是硬件厂商专门为自己的某款硬件设备开发的，用于驱动该硬件运行的专项程序（必须遵循操作系统的标准） 安装的操作的核心原理简介：操作系统本质就是一种程序。从大的层面看安装程序的本质就是把这个程序的文件存入硬盘 操作系统的iso包（又称之为操作系统镜像）：iso的本质就是一个压缩包，里面放着一堆操作的代码文件 安装原理详解 用另外一台机器从网上下载一个iso镜像包，将该iso包存入移动硬盘、光盘、U盘中—》得到一个启动盘 把启动盘插入你的计算机中（接下来要做的事情，是把启动盘里的操作系统数据拷贝到你自己的电脑的硬盘里） 按下电源键，启动计算机，固定先启动bios程序（basic input output system） bios启动之后，会根据配置去某些地方加载真正的操作系统代码，bios的配置信息是存放于CMOS中的 找到启动盘后，bios会将启动盘里的操作系统读入内存，然后bios会控制cpu去内存中执行代码，然后真正的操作系统就运行起来 接下来负责掌管硬件运行的就是真正的操作系统了，bios就可以退出舞台 把启动盘里的操作系统拷贝到本地硬盘 五、操作系统的启动流程 按电源键，通电 先执行bios程序，由bios程序临时接管整个硬件的控制 bios会读取自己的配置项（CMOS），找到一个启动盘（存放有操作系统的硬盘、光盘、移动u盘） 找到启动盘之后，会先读取启动盘的第一个扇区的数据512Byte拉起bootloader程序（前446引导信息，64是分区信息，后2位是结束的标志位） 446字节的引导程序又称之为bootloader（grub程序是我们常用的一种bootloader） bootloader程序启动之后，负责把操作系统后续的代码都加载到内存中，然后运行起来 接下来就由真正的操作系统掌握整个计算机的运行 bios操作会去检查各个驱动程序、硬件是否正常，反馈给真正的操作系统，然后就可以退出舞台 六、用户空间和内核空间用户空间：指的是操作系统为用户程序分配的内存区域。每个运行在用户空间的应用程序都有其独立的地址空间，这有助于保护系统免受恶意或错误代码的影响。用户空间的应用程序不能直接访问硬件资源或关键的操作系统数据结构。当程序以用户态运行时，它只能访问属于自己的那部分用户空间内存，而不能直接访问内核空间或其他进程的空间。 内核空间：是操作系统内核使用的内存区域。这里存放了内核代码、设备驱动程序、以及所有需要直接访问硬件资源的数据结构等。内核空间允许直接操作硬件资源和管理整个系统的状态。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://aquapluto.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"硬盘","slug":"computer-basics/computer-composition/hard-disk","date":"2025-08-21T02:38:40.000Z","updated":"2025-08-28T12:33:05.365Z","comments":true,"path":"computer-basics/computer-composition/hard-disk/","permalink":"https://aquapluto.github.io/computer-basics/computer-composition/hard-disk/","excerpt":"","text":"一、概念磁盘里存放的是磁信号，固态硬盘里存放的电子，断电数据都不会丢失，相当于人把事物记录到本子上，肯定不会忘记了。程序运行过程中产生的数据一定是先存放于内存中的，若想永久保存，必须由内存刷如硬盘。硬盘上也有缓存芯片 磁盘上是一连串的2进制位（称为bit位），为了统计方法，8个bit称为一个字节bytes，1024bytes&#x3D;1k，1024k&#x3D;1M，1024M&#x3D;1G,所以我们平时所说的磁盘容量最终指的就是磁盘能写多少个2进制位。 1234567891B= 8bit1KB=2(10)B=1024B；括号中的数字为2的指数(即多少次方) 1MB=2(10)KB=1024KB=2(20)B； 1GB=2(10)MB=1024MB=2(30)B。 1TB=2(10)GB=1024GB=2(40)B 1PB=2(10)TB=1024TB=2(50)B 1EB=2(10)PB=1024PB=2(60)B 1ZB=2(10)EB=1024EB=2(70)B 1YB=2(10)ZB=1024ZB=2(80)B 虽然计算机上存放的都是一个个的bit位，但是计算机存取硬盘的单位都是一个扇区，一个扇区512个字节。数据都存放于一段一段的扇区，从磁盘读取一段数据需要经历寻道时间和延迟时间 平均寻道时间： 机械手臂上的磁头找到存储数据的那一圈磁道所花费的时间 平均延迟时间： 磁盘转半圈的速度 站在硬盘的角度最小读写单位是一个扇区；站在操作系统的角度最小的读写单位一个block块（默认是由8个扇区） 二、磁盘类型硬盘接口类型 IDE：133MB&#x2F;s，并行接口，早期家用电脑 SCSI：640MB&#x2F;s，并行接口，早期服务器 SCSI 是常用且重要的数据传输协议之一，它支撑着操作系统对外部设备的i&#x2F;o操作。实际应用场景中，在linux系统上添加一个新的 scsi 磁盘是不需要重启的，一般可以通过扫描发现的操作来识别就绪设备 SATA：6Gbps，SATA数据端口与电源端口是分开的，即需要两条线，一条数据线，一条电源线 SAS：6Gbps，SAS是一整条线，数据端口与电源端口是一体化的，SAS中是包含供电线的，而SATA中不包含供电线。SATA标准其实是SAS标准的一个子集，二者可兼容，SATA硬盘可以插入SAS主板上，反之不行 USB：480MB&#x2F;s M.2： 注意：速度不是由单纯的接口类型决定，支持Nvme协议硬盘速度是最快的 服务器硬盘大小 LFF：3.5寸，一般见到的那种台式机硬盘的大小 SFF：Small Form Factor 小形状因数，2.5寸，注意不同于2.5寸的笔记本硬盘 L、S分别是大、小的意思，目前服务器或者盘柜采用sff规格的硬盘主要是考内虑增大单位密度内的磁盘容量、增强散热、减小功耗 三、机械硬盘和固态硬盘机械硬盘（HDD）：Hard Disk Drive，即是传统普通硬盘，主要由：盘片，磁头，盘片转轴及控制电机，磁头控制器，数据转换器，接口，缓存等几个部分组成。机械硬盘中所有的盘片都装在一个旋转轴上，每张盘片之间是平行的，在每个盘片的存储面上有一个磁头，磁头与盘片之间的距离比头发丝的直径还小，所有的磁头联在一个磁头控制器上，由磁头控制器负责各个磁头的运动。磁头可沿盘片的半径方向运动，加上盘片每分钟几千转的高速旋转，磁头就可以定位在盘片的指定位置上进行数据的读写操作。数据通过磁头由电磁流来改变极性方式被电磁流写到磁盘上，也可以通过相反方式读取。硬盘为精密设备，进入硬盘的空气必须过滤 固态硬盘（SSD）：Solid State Drive，用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上也与普通硬盘一致 相较于HDD，SSD在防震抗摔、传输速率、功耗、重量、噪音上有明显优势，SSD传输速率性能是HDD的2倍 相较于SSD，HDD在价格、容量占有绝对优势 硬盘有价，数据无价，目前SSD不能完全取代HHD 四、硬盘存储方式在计算机存储系统中，硬盘是主要的数据存储设备之一，数据被存储在硬盘的表面上，而硬盘表面被划分为许多扇区，每个扇区都是数据存储和访问的最小单位。但实际中操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是 4KB，即连续八个 sector 组成一个 block。以下是磁盘和扇区之间的关系的要点 硬盘存储术语 CHS 硬盘驱动器：硬盘驱动器是计算机中的存储设备，它包含一个或多个磁盘盘片。这些盘片上有一个或多个磁性涂层，用于存储数据。 磁头head：一个盘面对应一个磁头，磁头数&#x3D;盘面数，硬盘驱动器上有多个读&#x2F;写头，它们位于磁盘的顶部和底部，用于读取和写入数据。磁头可以移动到不同的磁道上，以读取或写入数据。 磁道track：盘面上的每一圈就是一个磁道，磁道&#x3D;柱面数。磁盘表面被划分为一个个同心圆环，每个环被称为一个磁道（track）。数据通常存储在这些磁道上。 扇区sector：把每个磁道按512bytes大小再进行划分，这就是扇区，每个磁道上的扇区数量是不一样的。每个磁道被分为若干个扇区（sector），扇区是存储数据的最小物理单位。通常，每个扇区的大小为512字节或4K字节。 柱面cylinder：磁头移动的时候，是一起移动的，如果是6个盘面，则6个磁头对应的磁道是一致的，这就是柱面，柱面 1柱面&#x3D;512 * sector数&#x2F;trackhead数&#x3D;51263*255&#x3D;7.84M。柱面（cylinder）是垂直堆叠在多个盘片上的同心圆磁道的集合。在磁盘驱动器上，读&#x2F;写头可以同时访问相同柱面上的多个磁道。 数据在磁盘上的存储和检索过程通常涉及到读&#x2F;写头移动到正确的柱面和磁道上，然后在相应的扇区上进行数据传输。操作系统和文件系统管理这些硬件细节，以便应用程序可以读取和写入文件，而无需关心底层硬件的物理结构。 在Linux系统中，CentOS 5 之前版本 Linux 以柱面的整数倍划分分区，CentOS 6之后可以支持以扇区划分分区，CentOS7之后，就只显示扇区信息了 五、磁盘上寻址的两种方式CHS CHS采用 24 bit位寻址 其中前10位表示cylinder，中间8位表示head，后面6位表示sector 最大寻址空间 8 GB LBA LBA是一个整数，通过转换成 CHS 格式完成磁盘具体寻址 ATA-1规范中定义了28位寻址模式，以每扇区512位组来计算，ATA-1所定义的28位LBA上限达到128 GiB。2002年ATA-6规范采用48位LBA，同样以每扇区512位组计算容量上限可达128Petabytes 由于CHS寻址方式的寻址空间在大概8GB以内，所以在磁盘容量小于大概8GB时，可以使用CHS寻址方式或是LBA寻址方式；在磁盘容量大于大概8GB时，则只能使用LBA寻址方式 六、文件的 I&#x2F;O 模式Buffer I&#x2F;O (标准 I&#x2F;O) 原理：数据先写入内核的缓冲区（页面缓存），内核异步将缓冲区的脏数据写入磁盘。 优点： 读操作：大多数情况下直接从 RAM 缓存读取数据，速度快。 写操作：页面缓存减少磁盘 I&#x2F;O 次数，提高写性能。 缺点： 可能存在数据丢失风险，如系统崩溃或断电。 缓存溢出可能导致性能问题。 适用场景：适合大多数场景，尤其是读操作较多的应用。 Direct I&#x2F;O (直接 I&#x2F;O) 原理：数据直接写入磁盘，绕过页面缓存。 优点：避免缓冲区数据丢失的风险。 缺点：性能较低，因为每次写操作都需要直接与磁盘交互。 适用场景：适合对数据安全性要求较高的应用，如数据库系统。 七、磁盘 I&#x2F;O 调度策略在 Linux 中，磁盘 I&#x2F;O 调度策略用于决定磁盘上的 I&#x2F;O 请求的执行顺序，以最大程度地提高系统性能和吞吐量。不同的磁盘 I&#x2F;O 调度策略采用不同的算法来管理 I&#x2F;O 请求队列。以下是一些常见的Linux磁盘I&#x2F;O调度策略： CFQ（Completely Fair Queuing） CFQ 调度器旨在提供公平性，确保每个进程都能公平地访问磁盘。它为每个进程维护一个 I&#x2F;O 请求队列，并使用时间片轮转的方式为各个队列提供服务。在 Linux 2.6 内核上默认采用的就是该调度策略。 Deadline Deadline 调度器着重于 I&#x2F;O 请求的响应时间。它将 I&#x2F;O 请求分为两类：读取请求和写入请求，然后按照截止时间来排序。读取请求通常具有较短的截止时间，以减少读取延迟，而写入请求通常具有较长的截止时间，以优化写入性能。其核心就是在于保证每个 I&#x2F;O 请求在一定时间内一定要被服务到，避免某个请求饥饿。在 Linux 3.x 内核上默认采用的就是该调度策略。 NOOP NOOP 调度器是一个简单的 FIFO（先进先出）队列，不执行任何排序或优化。它通常用于高性能存储设备，如固态硬盘（SSD），因为这些设备通常具有较低的访问延迟。 BFQ（Budget Fair Queueing） BFQ 调度器旨在提供更好的磁盘 I&#x2F;O 吞吐量和响应时间。它采用基于权重的算法，为每个进程分配预算，然后根据预算来调度I&#x2F;O请求。BFQ 适用于需要更好响应时间的多任务工作负载。 Kyber Kyber 调度器是一个新的 I&#x2F;O 调度器，旨在兼顾低延迟和高吞吐量。它使用一种称为 Kyber Deadline 的方式来管理 I&#x2F;O 请求，尽量减少延迟并提高性能。 MQ-DEADLINE MQ-DEADLINE 是一种多队列版本的 Deadline 调度器，它在多核系统中更有效地管理 I&#x2F;O 请求队列。 如何查看 Linux 的磁盘 I&#x2F;O 调度策略？ 12345678[root@rocky8 ~]#cat /sys/block/sda/queue/scheduler[mq-deadline] kyber bfq none[root@ubuntu2004 ~]#cat /sys/block/sda/queue/scheduler[mq-deadline] none[mq-deadline]：表示当前的默认策略（但当前未激活）kyber bfq none：表示可选策略 八、衡量硬盘性能的常见指标IOPS（每秒 I&#x2F;O 操作次数） 定义：每秒磁盘完成的读或写操作次数。 计算公式：IOPS &#x3D; 1000 ms &#x2F; (寻道时间 + 旋转延迟)。 BPS（每秒 I&#x2F;O 流量） 定义：一秒内磁盘写入和读出的数据总量，单位为 MB&#x2F;s。 计算公式：BPS &#x3D; IOPS × 数据块大小 IO 操作的基本单位 扇区：硬盘的最小读写单位，默认大小为 512Bytes。 12345678~# fdisk -l磁盘 /dev/sda: 21.5 GB, 21474836480 字节, 41943040 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理): 512 字节 / 512 字节I/O 大小(最小/最佳): 512 字节 / 512 字节磁盘标签类型: dos磁盘标识符: 0x0009ecfa 块：操作系统的最小读写单位，通常指文件系统的逻辑块。(4096Bytes) 123456789~# stat /dev/sda3文件: &quot;/dev/sda3&quot;大小: 0 块: 0 IO 块: 4096 块特殊文件设备: 5h/5d Inode: 10432 硬链接: 1 设备类型: 8,3权限: (0660/brw-rw----) Uid: ( 0/ root) Gid: ( 6/ disk)最近访问: 2025-01-30 22:29:32.161000073 +0800最近更改: 2025-01-30 22:29:32.161000073 +0800最近改动: 2025-01-30 22:29:32.161000073 +0800创建时间: - 九、实际读写硬盘涉及的因素在实际读写硬盘的过程中，性能和行为会受到多个因素的影响，包括应用程序、操作系统和硬盘本身的特性。 应用程序并发任务数 定义：应用程序同时发起的 I&#x2F;O 请求数量。 影响： 并发任务数越高，磁盘的负载越大。 如果并发任务数超过磁盘的最大 IOPS 能力，会导致性能下降，甚至出现 I&#x2F;O 队列积压。 提交方式 同步提交 定义：应用程序提交一个 I&#x2F;O 请求后，会等待该请求完成后再提交下一个请求。 影响： 适合顺序读写操作。 性能较低，因为每次 I&#x2F;O 操作都需要等待完成。 异步提交 定义：应用程序提交一个 I&#x2F;O 请求后，不需要等待该请求完成，可以直接提交下一个请求。 影响： 适合高并发场景。 性能较高，因为可以充分利用磁盘的并行处理能力。 操作系统调度算法：操作系统使用的调度算法会影响 I&#x2F;O 请求的处理顺序和效率。 缓存机制：操作系统中的缓存机制（如 page cache）可以提高读写性能，但也可能导致数据一致性问题。 文件系统：不同的文件系统（如 ext4、xfs 等）有不同的性能特性和优化策略。 文件 IO 模式：选择合适的 IO 模式可以平衡性能和数据安全性。 硬盘本身类型：不同类型的硬盘（如 HDD、SSD）有不同的性能特点。HDD 通常具有较高的寻道时间和旋转延迟，而 SSD 则具有较低的延迟和更高的 IOPS。 容量：硬盘的容量大小也会影响其性能。大容量硬盘可能需要更长的时间来寻道和旋转。 接口：硬盘接口（如 SATA、SAS、NVMe）也会影响其传输速率和延迟。 磁盘访问方式 随机访问 定义：每次 I&#x2F;O 操作访问的逻辑块地址不连续。 影响： 性能较低，因为每次访问都需要经历平均延迟和平均寻道时间。 适合需要频繁随机读写的应用，如数据库查询。 顺序访问 定义：每次 I&#x2F;O 操作访问的逻辑块地址连续。 影响： 性能较高，因为只需要经历一次平均延迟和平均寻道时间，后续的块可以连续读取。 适合需要大量顺序读写的应用，如文件传输。 十、RAID硬盘分区痛点：一个硬盘损坏，其下所有分区全坏，解决需要用到RAID技术，优化磁盘文件系统 独立硬盘冗余阵列，旧称廉价磁盘冗余阵列，简称磁盘阵列。利用虚拟化存储技术把多个硬盘组合起来，成为一个或多个硬盘阵列组，目的为提升性能或数据冗余，或是两者同时提升。 RAID存储通过将数据重复或重新创建，并将其存储在附加的驱动器上来防止磁盘驱动器数据的完全丢失，这个过程也被称为数据冗余。 提供数据丢失保护的配置被称为“容错”配置，这意味着即使磁盘驱动器发生故障，阵列仍然可以成功运行并提供可恢复的数据。 磁盘冗余阵列（RAID）是一种用于提高数据存储可靠性和性能的技术。RAID 将多个硬盘驱动器组合在一起，以创建一个单一的逻辑存储单元，数据会分散存储在这些驱动器上，不同的 RAID 级别提供不同级别的冗余和性能。 RAID 层级不同，数据会以多种模式分散于各个硬盘，RAID 层级的命名会以 RAID 开头并带数字，例如：RAID 0、RAID 1、RAID 5、RAID 6、RAID 7、RAID 01、RAID 10、RAID 50、RAID 60。每种等级都有其理论上的优缺点，不同的等级在两个目标间获取平衡，分别是增加数据可靠性以及增加存储器（群）读写性能。 简单来说，RAID把多个硬盘组合成为一个逻辑硬盘，因此，操作系统只会把它当作一个实体硬盘。RAID常被用在服务器电脑上，并且常使用完全相同的硬盘作为组合。由于硬盘价格的不断下降与RAID功能更加有效地与主板集成，它也成为普通用户的一个选择，特别是需要大容量存储空间的工作，如：视频与音频制作。 条带化阵列是一种将数据分割并跨多个磁盘存储的技术，用以提高数据的读写性能。条带化（Striping）是RAID（Redundant Array of Independent Disks，独立磁盘冗余阵列）技术中的一种，它通过将连续的数据分割成相同大小的数据块，并将这些数据块分别写入到阵列中的不同磁盘上的方法来操作。条带化的主要目的是实现I&#x2F;O（输入&#x2F;输出）负载均衡和提高数据传输速度 RAID功能实现 提高IO能力,磁盘并行读写 提高耐用性,磁盘冗余算法来实现 RAID实现的方式 外接式磁盘阵列：通过扩展卡提供适配能力 内接式RAID：主板集成RAID控制器，安装OS前在BIOS里配置 软件RAID：通过OS实现，比如：群晖的NAS RAID-0RAID 0 也称为条带化（striping）阵列，它将数据块分成多个条带并将这些条带分散存储在多个硬盘上。RAID 0 提供了更高的性能，因为数据可以并行读取和写入多个驱动器。然而，RAID 0 没有冗余，如果一个驱动器故障，所有数据都会丢失。因此，如果你的程序读写数据频繁、且对数据安全性一般的话，就可采用 RAID 0 以 chunk 单位（大小可以指定）读写数据，因为读写时可以并行处理，所以在所有的级别中，RAID 0的速度是最快的。但是RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失 每块硬盘的大小要一样，不管多少块硬盘，Linux上会认为是一个硬盘(&#x2F;dev&#x2F;sda)；比如现在有100M的文件，chunk&#x3D;64K，那么100M的文件就会分成若干个64K，第一个chunk放在A1，第二个放在A2…..均匀存放（n块硬盘，各有1&#x2F;n） 读、写性能提升 可用空间：N*min(S1,S2,…) 无容错能力 最少磁盘数：1+ RAID-1RAID 1 是镜像（mirroring）阵列，它将相同的数据复制到两个或更多硬盘上。因此 RAID 1 提供了数据冗余，如果一个驱动器故障，数据仍然可用。RAID 1 通常用于重要数据的备份。RAID 1 需要至少两个硬盘驱动器。 也称为镜像, 两组以上的N个磁盘相互作镜像，在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，与 RAID-0相同。另外写入速度有微小的降低，但解决了硬盘损坏时出现的问题 读性能提升、写性能略有下降 可用空间：1*min(S1,S2,…) 磁盘利用率 50%（因为两块硬盘一块是存放数据，一块是备份数据） 有冗余能力（可防止磁盘损坏带来的数据丢失，防止不了人为的删除，因为两边是同时操作的，不能代替传统的备份） 最少磁盘数：2+ RAID-4100M的文件，chunk&#x3D;64K，第一个放在A1，第二个放在A2，第三个放在A3，然后A1+A2+A3&#x3D;Ap（校验位），以此类推，好处就是假如其中一个硬盘坏了，可以通过校验位找回来（不能坏两块以上），但是万一放校验位的硬盘坏了，就都没有了，所以RAID-5解决这个问题 多块数据盘异或运算值存于专用校验盘（校验位都在一个硬盘） 磁盘利用率 (N-1)&#x2F;N 有冗余能力 至少3块硬盘才可以实现 RAID-5RAID 5 使用条带化和奇偶校验来提供数据冗余和性能。数据被分成多个条带，并且奇偶校验信息分布在不同的驱动器上。如果一个驱动器故障，可以通过奇偶校验信息恢复数据。RAID 5 需要至少三个硬盘驱动器。 每个硬盘都有校验位 读、写性能提升 可用空间：(N-1)*min(S1,S2,…) 有容错能力：允许最多1块磁盘损坏 最少磁盘数：3, 3+ RAID-6RAID 6 类似于 RAID 5，但提供更高级别的冗余。它使用两组奇偶校验信息来保护数据，因此可以容忍两个驱动器的故障。RAID 6 需要至少四个硬盘驱动器。 双份校验位,算法更复杂 读、写性能提升 可用空间：(N-2)*min(S1,S2,…) 有容错能力：允许最多2块磁盘损坏 最少磁盘数：4, 4+ RAID-10RAID 10 是RAID 1+0 的组合，它将数据复制到多个驱动器上，并使用条带化提供更高的性能。RAID 10提供了很高的性能和冗余，但需要至少四个硬盘驱动器。 读、写性能提升 可用空间：N*min(S1,S2,…)&#x2F;2 有容错能力：每组镜像最多只能坏一块 最少磁盘数：4, 4+ 容错性失败几率1&#x2F;3 RAID-01多块磁盘先实现RAID0,再组合成RAID1 容错性失败几率2&#x2F;3 RAID-50多块磁盘先实现RAID5,再组合成RAID0 RAID-60安全性高，提升数据安全 RAID 总结 RAID等级 最少硬盘 最大容错 可用容量 读取性能 写入性能 安全性 目的 应用场景 0 1 0 n n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 影片剪接，缓存用途 1 2 n-1 1 n 1 高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 n-1 n-1 n-1 高 追求最大容量、最小预算 个人、企业备份 6 4 2 n-2 n-2 n-2 安全性较RAID5高 同RAID 5，但较安全 个人、企业备份 10 4 高 综合RAID 0&#x2F;1优点，理论速度较快 大型数据库、服务器 50 6 高 提升数据安全 60 8 高 提升数据安全 要在 Linux 上设置 RAID，通常需要硬件支持或使用软件 RAID。软件 RAID 使用 Linux 内核中的软件驱动程序来管理 RAID 阵列，而硬件 RAID 依赖于专用 RAID 控制器。在 Linux 中，可以使用工具如 mdadm（用于软件 RAID 管理）或硬件 RAID 控制器的管理工具来创建、管理和监控 RAID 阵列。配置 RAID 阵列时，请确保备份重要数据，因为 RAID 虽然提供了一定程度的数据冗余，但并不是绝对可靠的备份解决方案。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}]},{"title":"内存","slug":"computer-basics/computer-composition/memory","date":"2025-08-21T02:38:36.000Z","updated":"2025-08-28T12:33:05.379Z","comments":true,"path":"computer-basics/computer-composition/memory/","permalink":"https://aquapluto.github.io/computer-basics/computer-composition/memory/","excerpt":"","text":"一、概念内存里存放的都是电信号，断电数据则丢失，相当于人脑失去记忆 cpu是从内存中取出指令来运行的，运行指令产生的数据也会放入内存中，所以内存又称之为主存，因为程序运行过程中产生的数据都是先存放于内存中 二、物理地址空间和虚拟地址空间MMU：Memory Management Unit 负责虚拟地址转换为物理地址 程序在访问一个内存地址指向的内存时，CPU不是直接把这个地址送到内存总线上，而是被送到MMU（Memory Management Unit),然后把这个内存地址映射到实际的物理内存地址上，然后通过总线再去访问内存，程序操作的地址称为虚拟内存地址 TLB：Translation Lookaside Buffer 翻译后备缓冲区，用于保存虚拟地址和物理地址映射关系的缓存 扩展物理地址空间：插内存条按照奇数或偶数的插，不要按着1234的顺序插 三、物理内存与虚拟内存每个进程在执行时都有自己的地址空间，这个地址空间其实就是 Linux 内核根据需要给进程分配的一个内存空间（区域）来作为当前进程的工作区，也称为进程的内存空间。这个地址空间包括了程序的指令、数据、堆栈、共享库和其他资源。操作系统负责分配和管理每个进程的地址空间，确保进程之间不会相互干扰。 当操作系统启动一个进程时，它会将进程的可执行文件加载到进程的地址空间中，使进程能够执行其中的指令。这包括将程序的代码段加载到内存中，为进程分配数据段和堆栈，以及加载所需的共享库等。尽管进程的地址空间通常是隔离的，但操作系统也允许进程之间共享内存区域，以便进行进程间通信（IPC）。这种共享可以通过共享内存、内存映射文件等机制来实现。 然而内存又涉及到两个概念，物理内存（Physical Memory）与虚拟内存（Virtual Memory）。所谓的物理内存就是计算机系统中实际存在的硬件内存，通常是 RAM（随机访问存储器）的形式。它是计算机用于存储和访问数据、指令和程序的物理硬件。在 Linux 系统中还有一个逻辑内存的概念，逻辑内存是为了满足物理内存不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存区域，被用作逻辑内存的这块磁盘空间我们称之为交换空间（Swap Space）。 但在 Linux 系统中，不管是物理内存还是逻辑内存，都会被映射为虚拟内存，这样的话，应用程序在使用内存时，就需要向 Linux 内核申请一个特定大小的内存映射，并且会收到其申请的虚拟内存的映射。因此，应用程序申请到的这个虚拟内存不一定是全部是物理内存的映射，还可能是逻辑内存的映射。然而，这种虚拟内存管理机制对用户和程序来说通常是不可见的（由底层自动实现），但我们还是需要理解 Linux 内存架构、地址布局等。 外翻：TLB(Translation Lookaside Buffer)传输后备缓冲器是一个内存管理单元用于改进虚拟地址到物理地址转换速度的缓存。TLB是一个小的，虚拟寻址的缓存，其中每一行都保存着一个由单个PTE组成的块。如果没有TLB，则每次取数据都需要两次访问内存，即查页表获得物理地址和取数据 虚拟内存是为了满足物理内存不足而提出的策略，通过将内存地址空间划分为固定大小的块（通常称为页或页帧），并在需要时将这些页面从磁盘交换到物理内存中来工作。这使得每个进程都有自己的独立地址空间，而不需要直接管理物理内存的分配。 虚拟内存机制可以使计算机可以运行大于物理内存的程序，方法是将正在使用的程序放入内存取执行，而暂时不需要执行的程序放到磁盘的某块地方，这块地方成为虚拟内存，在linux中成为swap，这种机制的核心在于快速地映射内存地址，整个过程计算机的速度被降低，但是保证不崩溃，由cpu中的一个部件负责，成为存储器管理单元 当运行某个大程序、大游戏，需要的内存超过空闲内存但小于物理内存总量时，会暂时把内存里这些数据放到磁盘上的虚拟内存里，空出物理内存运行游戏。等退出游戏后，又会把虚拟内存里的东西读出来，放回物理内存。所以，虚拟内存并不是用来虚拟物理内存的，而是暂存数据的。所以虚拟内存不是代替物理内存来运行程序的。 四、页高速缓存与页写回机制页高速缓存在当今的计算机系统中，处理器的运行速度是非常快的，但 RAM 和磁盘并没有质的飞跃（尤其是磁盘读写速度），这就导致了系统整体性能并没有因为处理器速度的提升而提升。于是就使用到了缓存技术（其实就是内存缓存的技术），通过缓存机制解决了处理器和磁盘直接速度的不平衡。 页高速缓存通常以页面的单位来存储数据，因此被称为”页”高速缓存。页高速缓存是操作系统在物理内存中维护的一个缓存，用于存储磁盘上的文件数据的副本。Linux 系统中当一个文件的数据（内容）被读取时，操作系统将数据从磁盘读取到页高速缓存中，以便后续的读取操作可以直接去内存中读取数据，更快速地访问数据。 因此页高速缓存提高了文件的读取性能，因为它允许频繁访问的数据保留在快速的内存中，而不是每次都从慢速的磁盘中读取。 页写回机制脏数据 (Dirty Pages)：缓冲区中未被写入磁盘的数据，称为脏数据。用于提高写性能，减少磁盘 I&#x2F;O 次数。 页写回机制是一种优化技术，用于减少文件写入操作对性能的影响，提高磁盘I&#x2F;O的性能。当文件数据被修改并需要写回磁盘时，操作系统通常不会立即将数据写回磁盘，而是将数据标记为”脏”，并将其保留在页高速缓存中。操作系统通过一种策略，例如延迟写回或按需写回，决定何时将脏数据写回磁盘。这允许操作系统将多个写操作合并，以减少磁盘写入的次数，提高性能。 页写回机制可以防止频繁的磁盘写入操作对系统性能造成明显的影响，因为它允许系统在更高效的时间进行磁盘写入，而不是在每个写操作之后立即进行。 linux中的脏数据落盘机制 落盘工具：Linux 内核中的 kworker&#x2F;flush 线程负责将脏数据写入磁盘。 落盘时机： 当脏数据比例超过 vm.dirty_background_ratio 时，开始异步写入。 当脏数据比例超过 vm.dirty_ratio 时，同步阻塞写入。 脏数据存活时间超过 vm.dirty_expire_centisecs 时，会强制落盘。 内核定期 (vm_dirty_writeback_centisecs 时间间隔) 唤醒 flush 线程处理脏数据。 五、Swap SpaceSwap Space（交换空间）是 Linux 中虚拟内存的一个实现方式，除了填补因物理内存不足的空缺外，还将会在适当的时候将物理内存中不经常读写的数据块自动交换到 Swap 交换空间（这个交换的操作是由 Linux 内核来执行的），从而侧面将经常读写的数据保留在了物理内存。 说白了就是，它为什么叫交换空间，就是要实现数据的交换（将不常用数据交换到作为逻辑内存的磁盘空间，而保留常用数据在真正的物理内存空间中）。这个交换的策略由 Linux 系统内核定时执行，目的就是为了保持尽可能多的空闲物理内存。 那什么叫做在适当的时候会进行数据交换，我们所说的适当时间其实是 Linux 内核根据“最近最经常使用”算法（LRU 算法），定时地将一些不经常使用的页面文件（其实就是文件数据，因为内存是以页面存储数据的）交换到 Swap。 有时候会发现：Linux 物理内存还有很多，而 Swap 的数据占用却很大，这是什么原因呢？其实这是正常现象。如果一个内存占用很大的进程正在运行，必然就会耗费大量的内存资源，此时 Linux 内核就会将一些不常用的页面文件交换到 Swap Space 中。当该进程终止后，Linux 就会释放该进程占用的大量内存资源，而此时被交换出去的页面文件数据并不会自动又交换到物理内存中来（除非有这个必要），那此时看到的就是物理内存空间空闲，Swap Space 占用较大的现象了。 六、页面缺失和页面调度程序要读虚拟内存中的某个页面数据时，而恰好这个页面数据位于 Swap Space 中。那此时的流程就是：交换空间（Swap Space）中的数据在被读取时通常会首先被交换到物理内存，然后才能被程序访问。 页面缺失（Page Fault）：当程序尝试访问一个在物理内存中不存在的内存页时，会触发一个页面缺失。这可能是因为该页已经被交换到了交换空间中，或者是因为程序首次访问该页。在任何情况下，操作系统会注意到页面缺失。 页面调度（Page Scheduling）：操作系统负责页面调度，决定哪些页面从交换空间加载到物理内存中以满足程序的需求。通常，操作系统会使用一种页面替换算法（例如LRU - 最近最少使用）来选择哪些页从交换空间中加载，以便最大限度地减少性能开销。一旦数据加载到物理内存中，操作系统会更新进程的页表，以指示这些页面现在位于物理内存中，程序可以访问它们。页表是一个数据结构，用于映射虚拟地址到物理地址。 七、进程使用内存问题内存泄漏：Memory Leak指程序中用malloc或new申请了一块内存，但是没有用free或delete将内存释放，导致这块内存一直处于占用状态 内存溢出：Memory Overflow指程序申请了10M的空间，但是在这个空间写入10M以上字节的数据，就是溢出,类似红杏出墙，比如10M的空间，我存放20M的数据，那么就会有10M存放到别的内存空间，而别的内存空间是由其他用户运行的，如果那个20M的数据是恶意代码，就会破坏其他用户的内存空间 内存不足：OOMOOM 即 Out Of Memory，“内存用完了”，这情况在java程序中比较常见。系统会选一个进程将之杀死，在日志messages中看到类似下面的提示 Jul 10 10:20:30 kernel: Out of memory: Kill process 9527 (java) score 88 or sacrifice child 当 JVM 因为没有足够的内存来为对象分配空间并且垃圾回收器也已经没有空间可回收时，就会抛出这个error，因为这个问题已经严重到不足以被应用处理。 原因： 给应用分配内存太少：比如虚拟机本身可使用的内存（一般通过启动时的VM参数指定）太少。 应用用的太多，并且用完没释放，浪费了。此时就会造成内存泄露或者内存溢出。 使用的解决办法： 限制 java进程的max heap，并且降低 java程序的worker数量，从而降低内存使用 给系统增加swap空间 Linux中可以设置内核参数 八、大页内存https://egonlin.com/?p=7401","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}]},{"title":"CPU","slug":"computer-basics/computer-composition/CPU","date":"2025-08-21T02:38:31.000Z","updated":"2025-08-28T12:33:05.365Z","comments":true,"path":"computer-basics/computer-composition/CPU/","permalink":"https://aquapluto.github.io/computer-basics/computer-composition/CPU/","excerpt":"","text":"一、概念中央处理器CPU由控制器 + 运算器组成，从内存中取指令-&gt;解码-&gt;执行，周而复始，直至整个程序被执行完成。所以CPU读取的数据都是从内存中来的 CPU读取的数据都是从主存储器（内存）来的！主存储器内的数据则是从输入单元所传输进来！而CPU处理完毕的数据也必须先写回主存储器中，最后数据才从主存储器传输到输出单元。 2核4线程 &#x3D;》真2核假4核 4核 &#x3D;》真4核 二、X86架构和64位x86架构：是针对cpu的型号或者说架构的一种统称，指明cpu的指令集是复杂指令集 64位：表示cpu一次性能够从内存中取出多少位二进制数(bit)，64bit指的是一次性能从内存中取出64位二进制指令，64位的cpu可以运行64位、32位的程序；而32位的cpu只能运行32位的程序 三、CPU的两种工作状态：内核态和用户态除了在嵌入式系统中的非常简答的CPU之外，多数CPU都有两种模式，即内核态与用户态。通常，PSW中有一个二进制位控制这两种模式。 内核态： 当cpu在内核态运行时，cpu可以执行指令集中所有的指令，很明显，所有的指令中包含了使用硬件的所有功能，（操作系统在内核态下运行，从而可以访问整个硬件） 用户态： 用户程序在用户态下运行，仅仅只能执行cpu整个指令集的一个子集，该子集中不包含操作硬件功能的部分，因此，一般情况下，在用户态中有关I&#x2F;O和内存保护（操作系统占用的内存是受保护的，不能被别的程序占用），当然，在用户态下，将PSW中的模式设置成内核态也是禁止的。 内核态与用户态切换： 用户态下工作的软件不能操作硬件，但是我们的软件比如暴风影音，一定会有操作硬件的需求，比如从磁盘上读一个电影文件，那就必须经历从用户态切换到内核态的过程，为此，用户程序必须使用系统调用（system call），系统调用陷入内核并调用操作系统，TRAP指令把用户态切换成内核态，并启用操作系统从而获得服务。 为什么要区分用户态和内核态？ 在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。 所以，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。 如此设计的本质意义是进行权限保护。 限定用户的程序不能乱搞操作系统，如果人人都可以任意读写任意地址空间软件管理便会乱套。 四、CPU的使用率和负载CPU时间片： 我们现在所使用的Windows、Linux、Mac OS都是“多任务操作系统”，就是说他们可以“同时”运行多个程序，比如一边打开Chrome浏览器浏览网页还能一边听音乐。 但是，实际上一个CPU内核在同一时刻只能干一件事，那操作系统是如何实现“多任务”的呢？大概的方法是让多个进程轮流使用CPU一小段时间，由于这个“一小段时间”很短(在linux上为5ms-800ms之间)，用户感觉不到，就好像是几个程序同时在运行了。上面提到的“一小段时间”就是我们所说的CPU时间片，CPU的现代分时多任务操作系统对CPU都是分时间片使用的。 CPU利用率： 就是程序对CPU时间片的占用情况，即CPU使用率 &#x3D; CPU时间片被程序使用的时间 &#x2F; 总时间。比如A进程占用10ms，然后B进程占用30ms，然后空闲60ms，再又是A进程占10ms，B进程占30ms，空闲60ms，如果在一段时间内都是如此，那么这段时间内的CPU占用率为40%。CPU利用率显示的是程序在运行期间实时占用的CPU百分比。 CPU负载： 指的是一段时间内正在使用和等待使用CPU的任务数。简单理解，CPU利用率是CPU的实时使用情况，CPU负载是CPU的当前以及未来一段时间的使用情况。举例来说：如果我有一个程序它需要一直使用CPU的运算功能，那么此时CPU的使用率可能达到100%，但是CPU的工作负载则是趋近于“1”，因为CPU仅负责一个工作嘛！如果同时执行这样的程序两个呢？CPU的使用率还是100%，但是工作负载则变成2了。所以也就是说，CPU的工作负载越大，代表CPU必须要在不同的工作之间进行频繁的工作切换。无论CPU的利用率是高是低，跟后面有多少任务在排队(CPU负载)没有必然关系。 总结： load average平均负载（负载指的是几个活跃的活要干）：在一段时间内，处于R状态的进程数+不可中断D睡眠的进程数 平均负载是用来要衡量系统的繁忙程度 cpu的使用率：反应的是cpu的使用情况 如果一个进程（包括用户态us和内核态sy）的cpu使用率为100%，说明占了一个cpu核心 如果为200%，说明占了两个cpu核心 4个cpu 平均负载为3，代有个3个活跃进程，—》低负载 平均负载为4，代有个4个活跃进程，—》满负载 平均负载&gt;4， —》超负载 如果cpu利用率不高，但是平均负载高，说明不可中断睡眠的进程比较多，因为R状态进程一定会提高cpu的使用率，那么这时候就可以考虑进行IO的优化 如果cpu利用率高、平均负载也高，说明 cpu密集型进程多 进程同时消耗cpu和进行I&#x2F;O等待操作 进程竞争cpu资源 中断处理过多 大量短时进程，如短时间频繁创建&#x2F;销毁进程","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}]},{"title":"计算机硬件组成","slug":"computer-basics/computer-composition/hardware-composition","date":"2025-08-21T02:38:26.000Z","updated":"2025-08-28T12:33:05.378Z","comments":true,"path":"computer-basics/computer-composition/hardware-composition/","permalink":"https://aquapluto.github.io/computer-basics/computer-composition/hardware-composition/","excerpt":"","text":"计算机硬件的核心由五大部分组成 控制器：是计算机的指挥系统，负责控制所有其他硬件的运行 运算器：数学运算+逻辑运算 存储器：是计算机用来存放所有数据和程序的记忆部件。按指定的地址写入或者读取信息。 内存&#x2F;主存 RAM：基于电信号来存储数据 优点：存取速度都快 缺点：没有办法持久存储，断电数据就全部丢失 外存：机械磁盘基于磁信号来存储数据 优点：可以持久保存数据 缺点：存储速度都慢 CMOS：与内存一样断电数据就丢，但特点是耗电量非常低，由主板上的电池负责供电 输入设备 键盘、鼠标 输出设备 显示器、音响、打印机 站在计算机硬件的角度：一个程序在计算机中是怎么运行起来的？ 在运行程序之前：程序最先一定是先存放于硬盘中的（程序的安装本质也就是把一堆代码文件放到硬盘的各个位置） 程序开始运行分两个阶段 加载阶段&#x2F;启动阶段：把程序的指令或数据从硬盘读入内存 执行阶段：cpu从内存中取出指令来运行","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}]},{"title":"脚本相关工具","slug":"Linux/shell/script-tools","date":"2025-08-20T10:29:56.000Z","updated":"2025-08-28T12:33:05.358Z","comments":true,"path":"Linux/shell/script-tools/","permalink":"https://aquapluto.github.io/Linux/shell/script-tools/","excerpt":"","text":"信号捕捉traptrap 命令可以捕捉信号,修改信号原来的功能,实现自定义功能 1234567891011121314151617#查看信号trap -l#进程收到系统发出的指定信号后，将执行自定义指令，而不会执行原操作trap &#x27;触发指令&#x27; 信号#忽略信号的操作trap &#x27;&#x27; 信号#恢复原信号的操作trap &#x27;-&#x27; 信号#列出自定义信号操作trap -p#当脚本退出时，执行finish函数trap finish EXIT 信号的三种表示方法 123453) SIGQUIT3 #信号IDSIGQUIT #完整写法，大小写都支持QUIT #简短写法，大小写都支持 范例 123456789101112131415161718192021#!/bin/bashtrap &quot;echo &#x27;Press ctrl+c or ctrl+\\ &#x27;&quot; int quittrap -pfor((i=0;i&lt;=10;i++));do sleep 1 echo $idonetrap &#x27;&#x27; inttrap -pfor((i=11;i&lt;=20;i++));do sleep 1 echo $idonetrap &#x27;-&#x27; inttrap -pfor((i=21;i&lt;=30;i++)); do sleep 1 echo $idone 范例: 当脚本正常或异常退出时,也会执行finish函数 12345678finish()&#123;echo finish| tee -a /root/finish.log&#125;trap finish exitwhile true ;doecho runningsleep 1done 创建临时文件mktempmktemp 命令用于创建并显示临时文件，可避免冲突 格式 12345mktemp [OPTION]... [TEMPLATE]说明：TEMPLATE: filenameXXX，X至少要出现三个，X会被替换成随机串-d #创建临时目录-p DIR或--tmpdir=DIR #指明临时文件所存放目录位置 范例 12345678910111213141516171819202122[root@ubuntu2204 ~]# mktemp/tmp/tmp.YQXxc3bHdI[root@ubuntu2204 ~]# mktemp XXXXUYtW#如果指定了文件名，则后面一定要有X，至少要3个，X会被替换成随机串[root@ubuntu2204 ~]# mktemp testmktemp: too few X&#x27;s in template ‘test’[root@ubuntu2204 ~]# mktemp testXXXtest19C#创建并赋值给变量[root@ubuntu2204 ~]# tmp=`mktemp`[root@ubuntu2204 ~]# echo $tmp/tmp/tmp.wQAdrqn1UR#创建目录[root@ubuntu2204 ~]# mktemp -d/tmp/tmp.2iLac1ruHt[root@ubuntu2204 ~]# ll /tmp/tmp.2iLac1ruHt/total 0 范例：实现文件垃圾箱 12345678910#方法1:脚本实现[root@centos8 ~]#cat /data/scripts/rm.sh#!/bin/bashDIR=`mktemp -d /tmp/trash-$(date +%F_%H-%M-%S)XXXXXX`mv $* $DIRecho $* is move to $DIR[root@centos8 ~]#alias rm=/data/scripts/rm.sh#方法2:函数实现[root@centos8 ~]#function rm () &#123; local trash=`mktemp -d /tmp/trashXXXX`;mv $* $trash; &#125; 安装复制文件 installinstall 功能相当于cp，chmod，chown，chgrp ,mkdir 等相关工具的集合，默认加执行权限 格式 1234567891011121314151617install [OPTION]... [-T] SOURCE DEST 单文件install [OPTION]... SOURCE... DIRECTORYinstall [OPTION]... -t DIRECTORY SOURCE...install [OPTION]... -d DIRECTORY... #创建空目录-m MODE，默认755-o OWNER-g GROUP-d DIRNAME 目录#复制并默认加执行权限[root@centos8 ~]#install /etc/hosts /data/hosts#复制后并修改权限和所有者，所属组[root@centos8 ~]#install -m 600 -o wu -g bin /etc/hosts /data/hosts#创建文件夹[root@centos8 ~]#install -d /data/etc 交互式转化批处理工具 expect主要应用于自动化交互式操作的场景，借助 expect 处理交互的命令，可以将交互过程如：ssh登录，ftp登录等写在一个脚本上，使之自动化完成。尤其适用于需要对多台服务器执行相同操作的环境中，可以大大提高系统管理人员的工作效率 1234expect [选项] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ]-c：从命令行执行expect脚本，默认expect是交互地执行的-d：可以调试信息 expect的子命令 spawn 启动新的进程，后面跟一个执行命令 expect 从进程接收字符串，如果有符合的字符串立即返回，否则就等待超时时间后返回 send 用于向进程发送字符串 interact 允许用户交互，在目标用户保持交互状态，不会退回原用户 expect eof 交互结束，退回到原用户 set timeout 20 设置超时时间，默认为10秒，若为-1则不限制超时时间 exp_continue 匹配多个字符串在执行动作后加此命令，附加于某个expect判断项之后，可以使该项被匹配后，还能继续匹配该expect-判断语句内的其他项。exp_continue类似于控制语句中的continue 语句。表示允许expect继续向下执行指令 单一分支模式语法： 123456[root@centos8 test]#expectexpect1.1&gt; expect &quot;hi&quot; &#123;send &quot;You said hi\\n&quot;&#125;hahahixixiYou said hi#匹配到hi后，会输出“you said hi”，并换行 多分支模式语法： 123456789101112131415161718192021222324252627282930[root@centos8 ~]#expectexpect1.1&gt; expect &quot;hi&quot; &#123; send &quot;You said hi\\n&quot; &#125; &quot;hehe&quot; &#123; send &quot;Hehe yourself\\n&quot;&#125; &quot;bye&quot; &#123; send &quot;Good bye\\n&quot; &#125;heheHehe yourselfexpect1.2&gt; expect &quot;hi&quot; &#123; send &quot;You said hi\\n&quot; &#125; &quot;hehe&quot; &#123; send &quot;Hehe yourself\\n&quot;&#125; &quot;bye&quot; &#123; send &quot;Good bye\\n&quot; &#125;byeGood byeexpect1.3&gt; expect &quot;hi&quot; &#123; send &quot;You said hi\\n&quot; &#125; &quot;hehe&quot; &#123; send &quot;Hehe yourself\\n&quot;&#125; &quot;bye&quot; &#123; send &quot;Good bye\\n&quot; &#125;hiYou said hiexpect1.4&gt;匹配hi,hello,bye任意字符串时，执行相应输出。等同如下：expect &#123; &quot;hi&quot; &#123; send &quot;You said hi\\n&quot;&#125; &quot;hehe&quot; &#123; send &quot;Hehe yourself\\n&quot;&#125; &quot;bye&quot; &#123; send &quot; Good bye\\n&quot;&#125;&#125;[root@centos8 ~]#expectexpect1.1&gt; expect &#123;+&gt; &quot;hi&quot; &#123; send &quot;You said hi\\n&quot;&#125;+&gt; &quot;hehe&quot; &#123; send &quot;Hehe yourself\\n&quot;&#125;+&gt; &quot;bye&quot; &#123; send &quot; Good bye\\n&quot;&#125;+&gt; &#125;byeGood byeexpect1.2&gt; expect脚本 12345命名：expect1/2/3...开头段：#!/usr/bin/expect 执行：先加执行权限，后执行chmod +x expect1./expect1 范例1：非交互式复制文件 1234567#!/usr/bin/expect spawn scp /etc/redhat-release 10.0.0.7:/dataexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;magedu\\n&quot; &#125;&#125;expect eof 范例2：自动登录 1234567#!/usr/bin/expectspawn ssh 10.0.0.7expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;magedu\\n&quot; &#125;&#125;interact 范例3：expect 变量 1234567891011#!/usr/bin/expectset ip 10.0.0.7 #set设置变量set user rootset password mageduset timeout 10spawn ssh $user@$ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;interact 范例4：expect 位置参数 123456789101112131415161718[root@centos8 ~]#cat expect4#!/usr/bin/expectset ip [lindex $argv 0] #[lindex $argv 0]相当于$1set user [lindex $argv 1]set password [lindex $argv 2]spawn ssh $user@$ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;interact[root@centos8 ~]#./expect4 10.0.0.7 root mageduspawn ssh root@10.0.0.7root@10.0.0.7&#x27;s password:Last login: Wed Apr 29 15:34:14 2020 from 10.0.0.8[root@centos7 ~]#exitlogoutConnection to 10.0.0.7 closed. 范例5：expect 执行多个命令 123456789101112131415#!/usr/bin/expectset ip [lindex $argv 0]set user [lindex $argv 1]set password [lindex $argv 2]set timeout 10spawn ssh $user@$ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; #如果没有exp_continue，就不会判断yes/no，去判断password &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;expect &quot;]#&quot; &#123; send &quot;useradd haha\\n&quot; &#125; #远程登陆成功后创建用户hahaexpect &quot;]#&quot; &#123; send &quot;echo magedu |passwd --stdin haha\\n&quot; &#125; #修改密码send &quot;exit\\n&quot; #执行完之后退出expect eof#./ssh4.exp 10.0.0.7 root magedu 范例6：shell脚本调用 expect 1234567891011121314151617#!/bin/baship=$1user=$2password=$3 expect &lt;&lt;EOF #expect是交互式命令，所以可以用重定向 set timeout 20 spawn ssh $user@$ip expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125; &#125; expect &quot;]#&quot; &#123; send &quot;useradd hehe\\n&quot; &#125; expect &quot;]#&quot; &#123; send &quot;echo magedu |passwd --stdin hehe\\n&quot; &#125; expect &quot;]#&quot; &#123; send &quot;exit\\n&quot; &#125; expect eof EOF#./ssh5.sh 192.168.8.10 root magedu 范例7: shell脚本利用循环调用expect在CentOS和Ubuntu上批量创建用户 1234567891011121314151617181920212223#!/bin/bashNET=10.0.0user=rootpassword=mageduIPLIST=&quot;718101&quot;for ID in $IPLIST;doip=$NET.$IDexpect &lt;&lt;EOFset timeout 20spawn ssh $user@$ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;expect &quot;#&quot; &#123; send &quot;useradd test\\n&quot; &#125;expect &quot;#&quot; &#123; send &quot;exit\\n&quot; &#125;expect eofEOFdone 范例8：实现多个主机初始化 1234567891011121314151617181920212223#!/bin/bashNET=10.0.0user=rootpassword=mageduIPLIST=&quot;718&quot;for ID in $IPLIST ;doip=$NET.$IDexpect &lt;&lt;EOFset timeout 20spawn ssh $user@$ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;expect &quot;#&quot; &#123; send &quot;sed -i &#x27;s/^SELINUX=enforcing/SELINUX=disabled/&#x27;/etc/selinux/config\\n&quot; &#125;expect &quot;#&quot; &#123; send &quot;setenforce 0\\n&quot; &#125; #永久关闭SELINUXexpect &quot;#&quot; &#123; send &quot;exit\\n&quot; &#125;expect eofEOFdone 随机生成mkpassed来自expect包 1234567[root@centos8 ~]#yum -y install expect#随机生成[root@centos8 ~]#mkpasswd#随机生成15位字符，其中3个数字，5个大写字母，2个小写字母，剩下的随意[root@centos8 ~]#mkpasswd -l 15 -d 3 -C 5 -c 2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"字符串","slug":"Linux/shell/string","date":"2025-08-20T10:29:48.000Z","updated":"2025-08-28T12:33:05.359Z","comments":true,"path":"Linux/shell/string/","permalink":"https://aquapluto.github.io/Linux/shell/string/","excerpt":"","text":"字符串切片基于偏移量取字符串1234567891011121314151617#返回字符串变量var的字符的长度,一个汉字算一个字符$&#123;#var&#125;#返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，到最后的部分，offset的取值在0 到 $&#123;#var&#125;-1 之间(bash4.2后，允许为负值)$&#123;var:offset&#125;#返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，长度为number的部分$&#123;var:offset:number&#125;#取字符串的最右侧几个字符,取字符串的最右侧几个字符, 注意：冒号后必须有一空白字符$&#123;var: -length&#125;#从最左侧跳过offset字符，一直向右取到距离最右侧lengh个字符之前的内容,即:掐头去尾$&#123;var:offset:-length&#125;#先从最右侧向左取到length个字符开始，再向右取到距离最右侧offset个字符之间的内容,注意：-length前空格,并且length必须大于offset$&#123;var: -length:-offset&#125; 范例 1234567891011121314151617181920212223[root@centos8 script40]#str=abcdef我你他[root@centos8 script40]#echo $&#123;#str&#125;9[root@centos8 script40]#echo $&#123;str:2&#125;cdef我你他[root@centos8 script40]#echo $&#123;str:2:3&#125;cde[root@centos8 script40]#echo $&#123;str:-3&#125;abcdef我你他[root@centos8 script40]#echo $&#123;str: -3&#125;我你他[root@centos8 script40]#echo $&#123;str:2:-3&#125;cdef[root@centos8 script40]#echo $&#123;str: -2:-3&#125;-bash: -3: substring expression &lt; 0[root@centos8 script40]#echo $&#123;str: -3:-2&#125;我[root@centos8 script40]#echo $&#123;str:-3:-2&#125;abcdef我你他[root@centos8 script40]#echo $&#123;str: -3:-2&#125;我[root@centos8 script40]#echo $&#123;str: -5:-2&#125;ef我 基于模式取子串123456789#其中word可以是指定的任意字符,自左而右，查找var变量所存储的字符串中，第一次出现的word, 删除字符串开头至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以第一个word为界删左留右$&#123;var#*word&#125;#从var变量的值中删除以word开头的部分$&#123;var#word&#125;#同上，贪婪模式，不同的是，删除的是字符串开头至最后一次由word指定的字符之间的所有内容,即贪婪模式,以最后一个word为界删左留右$&#123;var##*word&#125;$&#123;var##word&#125; 范例 123456789101112[root@centos8 ~]#file=&quot;var/log/messages&quot;[root@centos8 ~]#echo $&#123;file#*/&#125;log/messages[root@centos8 ~]#echo $&#123;file##*/&#125;messages#其中word可以是指定的任意字符,功能：自右而左，查找var变量所存储的字符串中，第一次出现的word,删除字符串最后一个字符向左至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以从右向左的第一个word为界删右留左$&#123;var%word*&#125;$&#123;var%word&#125;#同上，只不过删除字符串最右侧的字符向左至最后一次出现word字符之间的所有字符,即贪婪模式,以从右向左的最后一个word为界删右留左$&#123;var%%word*&#125;$&#123;var%%word&#125; 范例 1234567891011[root@centos8 ~]#file=&quot;var/log/messages&quot;[root@centos8 ~]#echo $&#123;file%/*&#125;var/log[root@centos8 ~]#echo $&#123;file%%/*&#125;var[root@centos8 ~]#url=http://www.magedu.com:8080[root@centos8 ~]#echo $&#123;url##*:&#125;8080[root@centos8 ~]#echo $&#123;url%%:*&#125;http 查找替换1234567891011#查找var所表示的字符串中，第一次被pattern所匹配到的字符串，以substr替换之$&#123;var/pattern/substr&#125;#查找var所表示的字符串中，所有能被pattern所匹配到的字符串，以substr替换之$&#123;var//pattern/substr&#125;#查找var所表示的字符串中，行首被pattern所匹配到的字符串，以substr替换之$&#123;var/#pattern/substr&#125;#查找var所表示的字符串中，行尾被pattern所匹配到的字符串，以substr替换之$&#123;var/%pattern/substr&#125; 查找并删除1234567891011#删除var表示的字符串中第一次被pattern匹配到的字符串$&#123;var/pattern&#125;#删除var表示的字符串中所有被pattern匹配到的字符串$&#123;var//pattern&#125;#删除var表示的字符串中所有以pattern为行首匹配到的字符串$&#123;var/#pattern&#125;#删除var所表示的字符串中所有以pattern为行尾所匹配到的字符串$&#123;var/%pattern&#125; 字符大小写切换12345#把var中的所有小写字母转换为大写$&#123;var^^&#125;#把var中的所有大写字母转换为小写$&#123;var,,&#125; 变量扩展123#扩展以所有prefix开头的变量$&#123;!prefix*&#125;$&#123;!prefix@&#125; 范例 1234567[root@centos8 ~]#file1=a.txt[root@centos8 ~]#file2=b.txt[root@centos8 ~]#file3=c.txt[root@centos8 ~]#echo $&#123;!file*&#125;file1 file2 file3[root@centos8 ~]#echo $&#123;!file@&#125;file1 file2 file3","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"数组","slug":"Linux/shell/array","date":"2025-08-20T10:29:40.000Z","updated":"2025-08-28T12:33:05.357Z","comments":true,"path":"Linux/shell/array/","permalink":"https://aquapluto.github.io/Linux/shell/array/","excerpt":"","text":"声明数组1234#普通数组可以不事先声明,直接使用（索引的编号从0开始，属于数值索引:title[0]）declare -a ARRAY_NAME#关联数组必须先声明,再使用（索引可支持使用自定义的格式:title[num]）declare -A ARRAY_NAME 注意：两者不可相互转换 数组赋值数组元素的赋值 (1) 一次只赋值一个元素 1234ARRAY_NAME[INDEX]=VALUEweekdays[0]=&quot;Sunday&quot;weekdays[4]=&quot;Thursday&quot; (2) 一次赋值全部元素 123456ARRAY_NAME=(&quot;VAL1&quot; &quot;VAL2&quot; &quot;VAL3&quot; ...)title=(&quot;ceo&quot; &quot;coo&quot; &quot;cto&quot;)num=(&#123;0..10&#125;)alpha=(&#123;a..g&#125;)file=( *.sh ) (3) 只赋值特定元素 1ARRAY_NAME=([0]=&quot;VAL1&quot; [3]=&quot;VAL2&quot; ...) (4) 交互式数组值对赋值 1read -a ARRAY 范例: 123456789101112131415161718[root@centos8 ~]#declare -A course[root@centos8 ~]#declare -a course-bash: declare: course: cannot convert associative to indexed array[root@centos8 ~]#file=( *.sh )[root@centos8 ~]#declare -A file-bash: declare: file: cannot convert indexed to associative array[root@ubuntu1804 ~]#i=a[root@ubuntu1804 ~]#j=1[root@ubuntu1804 ~]#declare -A arr[root@ubuntu1804 ~]#arr[$i$j]=mage[root@ubuntu1804 ~]#j=2[root@ubuntu1804 ~]#arr[$i$j]=wang[root@ubuntu1804 ~]#echo $&#123;arr[*]&#125;wang mage[root@ubuntu1804 ~]#echo $&#123;arr[a1]&#125;mage[root@ubuntu1804 ~]#echo $&#123;arr[a2]&#125;wang 显示所有数组1declare -a 引用数组引用特定的数组元素 1234567891011$&#123;ARRAY_NAME[INDEX]&#125;#如果省略[INDEX]表示引用下标为0的元素[root@centos8 ~]#declare -a title=([0]=&quot;ceo&quot; [1]=&quot;coo&quot; [2]=&quot;cto&quot;)[root@centos8 ~]#echo $&#123;title[1]&#125;coo[root@centos8 ~]#echo $&#123;title&#125;ceo[root@centos8 ~]#echo $&#123;title[2]&#125;cto[root@centos8 ~]#echo $&#123;title[3]&#125; 引用数组所有元素 1234567$&#123;ARRAY_NAME[*]&#125;$&#123;ARRAY_NAME[@]&#125;[root@centos8 ~]#echo $&#123;title[@]&#125;ceo coo cto[root@centos8 ~]#echo $&#123;title[*]&#125;ceo coo cto 数组的长度，即数组中元素的个数 12345$&#123;#ARRAY_NAME[*]&#125;$&#123;#ARRAY_NAME[@]&#125;[root@centos8 ~]#echo $&#123;#title[*]&#125;3 数组的所有下标 12345678$&#123;!ARRAY_NAME[*]&#125;$&#123;!ARRAY_NAME[@]&#125;[root@centos8 ~]#declare -a title=([0]=&quot;ceo&quot; [1]=&quot;coo&quot; [2]=&quot;cto&quot;)[root@centos8 ~]#echo $&#123;!title[@]&#125;0 1 2[root@centos8 ~]#echo $&#123;!title[*]&#125;0 1 2 删除数组删除数组中的某元素，会导致稀疏格式 1234567unset ARRAY[INDEX][root@centos8 ~]#echo $&#123;title[*]&#125;ceo coo cto[root@centos8 ~]#unset title[1][root@centos8 ~]#echo $&#123;title[*]&#125;ceo cto 删除整个数组 12345unset ARRAY[root@centos8 ~]#unset title[root@centos8 ~]#echo $&#123;title[*]&#125;[root@centos8 ~]# 数组数据处理数组切片： 12345678910111213$&#123;ARRAY[@]:offset:number&#125;$&#123;ARRAY[*]:offset:number&#125;offset #要跳过的元素个数number #要取出的元素个数#取偏移量之后的所有元素&#123;ARRAY[@]:offset&#125;&#123;ARRAY[*]:offset&#125;[root@centos8 ~]#num=(&#123;0..10&#125;)[root@centos8 ~]#echo $&#123;num[*]:2:3&#125;2 3 4[root@centos8 ~]#echo $&#123;num[*]:6&#125;6 7 8 9 10 向数组中追加元素： 12345678ARRAY[$&#123;#ARRAY[*]&#125;]=valueARRAY[$&#123;#ARRAY[@]&#125;]=value[root@centos8 ~]#num[$&#123;#num[@]&#125;]=11[root@centos8 ~]#echo $&#123;#num[@]&#125;12[root@centos8 ~]#echo $&#123;num[@]&#125;0 1 2 3 4 5 6 7 8 9 10 11 关联数组12declare -A ARRAY_NAMEARRAY_NAME=([idx_name1]=&#x27;val1&#x27; [idx_name2]=&#x27;val2‘...) 注意：关联数组必须先声明再调用 范例: 1234567891011121314151617181920212223242526[root@centos8 ~]#name[ceo]=mage[root@centos8 ~]#name[cto]=wang[root@centos8 ~]#name[coo]=zhang[root@centos8 ~]#echo $&#123;name[ceo]&#125;zhang[root@centos8 ~]#echo $&#123;name[cto]&#125;zhang[root@centos8 ~]#echo $&#123;name[coo]&#125;zhang[root@centos8 ~]#echo $&#123;name&#125;zhang[root@centos8 ~]#declare -A name-bash: declare: name: cannot convert indexed to associative array[root@centos8 ~]#unset name[root@centos8 ~]#declare -A name[root@centos8 ~]#name[ceo]=mage[root@centos8 ~]#name[cto]=wang[root@centos8 ~]#name[coo]=zhang[root@centos8 ~]#echo $&#123;name[coo]&#125;zhang[root@centos8 ~]#echo $&#123;name[ceo]&#125;mage[root@centos8 ~]#echo $&#123;name[cto]&#125;wang[root@centos8 ~]#echo $&#123;name[*]&#125;mage wang zhang 范例范例：生成10个随机数保存于数组中，并找出其最大值和最小值 123456789101112#!/bin/bashdeclare -i min max #声明min和max两个变量，i表示数字declare -a numsfor ((i=0;i&lt;10;i++));do nums[$i]=$RANDOM [ $i -eq 0 ] &amp;&amp; min=$&#123;nums[0]&#125; &amp;&amp; max=$&#123;nums[0]&#125;&amp;&amp; continue [ $&#123;nums[$i]&#125; -gt $max ] &amp;&amp; max=$&#123;nums[$i]&#125; &amp;&amp; continue [ $&#123;nums[$i]&#125; -lt $min ] &amp;&amp; min=$&#123;nums[$i]&#125;doneecho &quot;All numbers are $&#123;nums[*]&#125;&quot;echo Max is $maxecho Min is $min 范例：编写脚本，定义一个数组，数组中的元素对应的值是&#x2F;var&#x2F;log目录下所有以.log结尾的文件；统计出其下标为偶数的文件中的行数之和 1234567891011#!/bin/bash#declare -a filesfiles=(/var/log/*.log)declare -i lines=0for i in $(seq 0 $[$&#123;#files[*]&#125;-1]); do if [ $[$i%2] -eq 0 ];thenlet lines+=$(wc -l $&#123;files[$i]&#125; | cut -d&#x27; &#x27; -f1) fidoneecho &quot;Lines: $lines&quot;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"函数","slug":"Linux/shell/function","date":"2025-08-20T10:29:36.000Z","updated":"2025-08-28T12:33:05.358Z","comments":true,"path":"Linux/shell/function/","permalink":"https://aquapluto.github.io/Linux/shell/function/","excerpt":"","text":"定义函数1234567891011121314#语法一：func_name （）&#123;...函数体...&#125;#语法二：function func_name &#123;...函数体...&#125;#语法三：function func_name （） &#123;...函数体...&#125; 范例： 12345678[root@centos scripts]#cat hello.sh hello() &#123; echo &quot;hello&quot;&#125;hello[root@centos scripts]#bash hello.sh hello 查看函数1234567891011#查看当前已定义的函数名declare -F#查看当前已定义的函数定义declare -f#查看指定当前已定义的函数名declare -f func_name#查看当前已定义的函数名定义declare -F func_name 删除函数1unset func_name 函数调用函数的调用方式 可在交互式环境下定义函数 可将函数放在脚本文件中作为它的一部分 可放在只包含函数的单独文件中 调用：函数只有被调用才会执行，通过给定函数名调用函数，函数名出现的地方，会被自动替换为函数代码 函数的生命周期：被调用时创建，返回时终止 交互式环境调用1234567891011121314[root@centos8 ~]#dir() &#123;&gt; ls -l&gt; &#125;[root@centos8 ~]#dirtotal 4-rw-------. 1 root root 1559 Nov 7 19:33 anaconda-ks.cfg #范例:实现判断CentOS的主版本[root@centos8 ~]#centos_version() &#123;&gt; sed -rn &#x27;s#^.* +([0-9]+)\\..*#\\1#p&#x27; /etc/redhat-release&gt; &#125;[root@centos8 ~]#centos_version8 在脚本中定义及使用函数在使用前必须定义，因此应将函数定义放在脚本开始部分，直至shell首次发现它后才能使用，调用函数仅使用其函数名即可 1234567891011121314[root@centos8 ~]#cat func1.sh#!/bin/bash#name:func1hello()&#123;echo &quot;Hello there today&#x27;s date is `date +%F`&quot;&#125;echo &quot;now going to the function hello&quot;helloecho &quot;back from the function&quot;[root@centos8 ~]#./func1.shnow going to the function helloHello there today&#x27;s date is 2019-12-18back from the function 范例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/bin/bashdisable_selinux()&#123; sed -i.bak &#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27; /etc/selinux/config echo &quot;SElinux已禁用,重新启动后才可生效&quot;&#125;disable_firewall()&#123; systemctl disable --now firewalld &amp;&gt; /dev/null echo &quot;防火墙已禁用&quot;&#125;set_ps1() &#123; echo &quot;PS1=&#x27;\\[\\e[1;35m\\][\\u@\\h \\W]\\\\$\\[\\e[0m\\]&#x27;&quot; &gt; /etc/profile.d/reset.sh echo &quot;提示符已修改成功,请重新登录生效&quot;&#125;set_eth()&#123; sed -i.bak &#x27;/GRUB_CMDLINE_LINUX=/s#&quot;$# net.ifnames=0&quot;#&#x27; /etc/default/grub grub2-mkconfig -o /boot/grub2/grub.cfg &amp;&gt; /dev/null echo &quot;网络名称已修改成功,请重新启动才能生效&quot;&#125;PS3=&quot;请选择相应的编号(1-6): &quot;MENU=&#x27;禁用SELinux关防火墙修改提示符修改网卡名以上全实现退出&#x27;select M in $MENU ;docase $REPLY in1) disable_selinux ;;2) disable_firewall ;;3) set_ps1 ;;4) set_eth ;;5) disable_selinux disable_firewall set_ps1 set_eth ;;6) break ;;*) echo &quot;请输入正确的数字&quot;esacdone 使用函数文件可以将经常使用的函数存入一个单独的函数文件，然后将函数文件载入shell，再进行调用函数 函数文件名可任意选取，但最好与相关任务有某种联系，例如：functions 一旦函数文件载入shell，就可以在命令行或脚本中调用函数。可以使用delcare -f 或set 命令查看所有定义的函数，其输出列表包括已经载入shell的所有函数 若要改动函数，首先用unset命令从shell中删除函数。改动完毕后，再重新载入此文件 实现函数文件的过程： 创建函数文件，只存放函数的定义 在shell脚本或交互式shell中调用函数文件，格式如下： 12. filenamesource filename 范例 1234567891011121314[root@centos8 ~]#cat functions#!/bin/bash#functionshello()&#123; echo Run hello Function&#125;hello2()&#123; echo Run hello2 Function&#125;[root@centos8 ~]#. functions[root@centos8 ~]#helloRun hello Function[root@centos8 ~]#hello2Run hello2 Function 函数返回值函数的执行结果返回值： 使用echo等命令进行输出 函数体中调用命令的输出结果 函数的退出状态码： 默认取决于函数中执行的最后一条命令的退出状态码 自定义退出状态码，其格式为： return 从函数中返回，用最后状态命令决定返回值 return 0 无错误返回 return 1-255 有错误返回 环境函数类拟于环境变量，也可以定义环境函数，使子进程也可使用父进程定义的函数 定义环境函数： 12export -f function_namedeclare -xf function_name 查看环境函数： 12export -fdeclare -xf 函数参数函数可以接受参数： 传递参数给函数：在函数名后面以空白分隔给定参数列表即可，如：testfunc arg1 arg2 … 在函数体中当中，可使用1, 2, …调用这些参数；还可以使用@, *, $#等特殊变量 范例：阶乘 1234567891011#!/bin/bash#fact() &#123; if [ $1 -eq 1 ]; thenecho 1 elseecho $[$1*$(fact $[$1-1])] fi&#125;fact 100 #100对应的就是$1【fact $1】[root@centos8 ~]#bash bact.sh 100 范例：实现进度条功能 12345678910111213141516171819202122#!/bin/bashfunction print_chars()&#123; # 传入的第一个参数指定要打印的字符串 local char=&quot;$1&quot; # 传入的第二个参数指定要打印多少次指定的字符串 local number=&quot;$2&quot; local c for ((c = 0; c &lt; number; ++c)); do printf &quot;$char&quot; done&#125;COLOR=32declare -i end=50for ((i = 1; i &lt;= end; ++i)); do printf &quot;\\e[1;$&#123;COLOR&#125;m\\e[80D[&quot; print_chars &quot;#&quot; $i print_chars &quot; &quot; $((end - i)) printf &quot;] %3d%%\\e[0m&quot; $((i * 2)) sleep 0.1sdoneecho 函数变量变量作用域： 普通变量：只在当前shell进程有效，为执行脚本会启动专用子shell进程；因此，本地变量的作用范围是当前shell脚本程序文件，包括脚本中的函数 环境变量：当前shell和子shell有效 本地变量：函数的生命周期；函数结束时变量被自动销毁 注意： 如果函数中定义了普通变量，且名称和局部变量相同，则使用本地变量 由于普通变量和局部变量会冲突，建议在函数中只使用本地变量 在函数中定义本地变量的方法 1234567891011local NAME=VALUE#不会改变函数体外的变量，只改变函数内的变量[root@centos scripts]#name=wang;hello() &#123; name=wu;echo name=$name; &#125;;helloname=wu[root@centos scripts]#echo $namewu[root@centos scripts]#name=wang;hello() &#123; local name=wu;echo name=$name; &#125;;helloname=wu[root@centos scripts]#echo $namewang 函数递归函数递归：函数直接或间接调用自身，注意递归层数，可能会陷入死循环 递归特点: 函数内部自已调用自已 必须有结束函数的出口语句,防止死循环 范例: 无出口的递归函数调用 12[root@centos8 ~]#func () &#123; echo $i;echo &quot;run func&quot;;let i++; func; &#125;[root@centos8 ~]#func 范例：无限打印hello 123456789[root@centos scripts]#cat hello.sh #!/bin/bashhello() &#123; echo &quot;hello&quot; hello&#125;hello 范例：阶乘 123456789#!/bin/bashfact() &#123; if [ $1 -eq 1 ]; thenecho 1 elseecho $[$1*$(fact $[$1-1])] #一直递归fact函数，实现100*99*98...*1 fi&#125;fact 100 #100对应的就是$1 fork 炸弹是一种恶意程序，它的内部是一个不断在 fork 进程的无限循环，实质是一个简单的递归程序。由于程序是递归的，如果没有任何限制，这会导致这个简单的程序迅速耗尽系统里面的所有资源 12345678#函数实现:()&#123; :|:&amp; &#125;;:bomb() &#123; bomb | bomb &amp; &#125;; bomb#脚本实现cat Bomb.sh#!/bin/bash./$0|./$0&amp;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"流程控制","slug":"Linux/shell/process-control","date":"2025-08-20T10:29:31.000Z","updated":"2025-08-28T12:33:05.358Z","comments":true,"path":"Linux/shell/process-control/","permalink":"https://aquapluto.github.io/Linux/shell/process-control/","excerpt":"","text":"条件选择if语句格式： 1if COMMANDS; then COMMANDS; [ elif COMMANDS; then COMMANDS; ]... [ else COMMANDS; ] fi 单分支： 123if 判断条件;then 条件为真的分支代码fi 双分支： 12345if 判断条件; then 条件为真的分支代码else 条件为假的分支代码fi 多分支： 12345678910if 判断条件1; then 条件1为真的分支代码elif 判断条件2; then 条件2为真的分支代码elif 判断条件3; then 条件3为真的分支代码...else 以上条件都为假的分支代码fi 范例：身体质量指数 (BMI） 1234567891011121314151617181920#!/bin/bashread -p &quot;请输入身高(m为单位): &quot; HIGHif [[ ! &quot;$HIGH&quot; =~ ^[0-2](\\.[0-9]&#123;,2&#125;)?$ ]];then echo &quot;输入错误的身高!&quot; exit 1firead -p &quot;请输入体重(kg为单位): &quot; WEIGHTif [[ ! &quot;$WEIGHT&quot; =~ ^[0-9]&#123;1,3&#125;$ ]];then echo &quot;输入错误的体重!&quot;; exit 2; fiBMI=`echo $WEIGHT/$HIGH^2|bc`if [ $BMI -le 18 ] ;then echo &quot;太瘦了,多吃点!&quot;elif [ $BMI -lt 24 ] ;then echo &quot;身材很棒!&quot;else echo &quot;太胖了,注意节食,加强运动!&quot;fi case语句格式： 1234567891011121314case WORD in [PATTERN [| PATTERN]...) COMMANDS ;;]... esaccase 变量引用 inPAT1)分支1;;PAT2)分支2;;...*)默认分支;;esac case支持glob风格的通配符 1234* 任意长度任意字符? 任意单个字符[] 指定范围内的任意单个字符| 或者，如: a|b 范例 123456789101112131415161718192021222324252627#!/bin/bashread -p &quot;Do you agree(yes/no)? &quot; INPUTINPUT=`echo $INPUT | tr &#x27;A-Z&#x27; &#x27;a-z&#x27;`case $INPUT iny|yes) echo &quot;You input is YES&quot; ;;n|no) echo &quot;You input is NO&quot; ;;*) echo &quot;Input fales,please input yes or no!&quot;esac#!/bin/bashread -p &quot;Do you agree(yes/no)? &quot; INPUTcase $INPUT in[yY]|[Yy][Ee][Ss]) echo &quot;You input is YES&quot; ;;[Nn]|[Nn][Oo]) echo &quot;You input is NO&quot; ;;*) echo &quot;Input fales,please input yes or no!&quot; esac 范例: 文件后缀处理 1234567891011121314151617181920212223#!/bin/bashread -p &quot;please input a file: &quot; FILESUFFIX=`echo $FILE | grep -Eo &quot;[^.]+$&quot;`case $SUFFIX ingz) echo gzip ;;bz2) echo bzip2 ;;xz) echo xz ;;Z) echo compress ;;zip) echo zip ;;*) echo other ;;esac 范例：运维菜单实现版本2 1234567891011121314151617181920212223242526272829303132#!/bin/bashecho -en &quot;\\E[$[RANDOM%7+31];1m&quot;cat &lt;&lt;EOF请选择：1）备份数据库2）清理日志3）软件升级4）软件回滚5）删库跑路EOFecho -en &#x27;\\E[0m&#x27;read -p &quot;请输入上面数字1-5: &quot; MENUcase $MENU in1) echo &quot;执行备份数据库&quot; #./backup.sh ;;2) echo &quot;清理日志&quot; ;;3) echo &quot;软件升级&quot; ;;4) echo &quot;软件回滚&quot; ;;5) echo &quot;删库跑路&quot; ;;*) echo &quot;INPUT FALSE!&quot;esac 循环for循环格式1 123456789101112for NAME [in WORDS ... ] ; do COMMANDS; done#方式1for 变量名 in 列表;do 循环体done#方式2for 变量名 in 列表do 循环体done for 循环列表生成方式 直接给出列表 整数列表 12&#123;start..end&#125;$(seq [start [step]] end) 返回列表的命令 1$(COMMAND) 使用glob，如：***.**sh 变量引用，如：@，，$# 范例: 批量创建用户 123456#!/bin/bash[ $# -eq 0 ] &amp;&amp; &#123; echo &quot;Usage: createuser.sh USERNAME ...&quot; ;exit 1 ; &#125;for user ;do id $user &amp;&gt; /dev/null &amp;&amp; echo $user is exist || &#123; useradd $user ; echo $useris created; &#125;done 范例: 批量创建用户和并设置随机密码 12345678#!/bin/bashfor i in &#123;1..10&#125;;do useradd user$i PASS=`cat /dev/urandom | tr -dc &#x27;[:alnum:]&#x27; |head -c12` echo $PASS | passwd --stdin user$i &amp;&gt; /dev/null echo user$i:$PASS &gt;&gt; /data/user.log echo &quot;user$i is created&quot;done 范例: 九九乘法表 1234567891011121314#!/bin/bashfor i in &#123;1..9&#125;;do for j in `seq $i`;do echo -e &quot;$&#123;j&#125;x$&#123;i&#125;=$[j*i]\\t\\c&quot; done echodonefor((i=1;i&lt;=9;i++));do for((j=1;j&lt;=i;j++));do printf &quot;\\E[1;$[RANDOM%7+31]m$&#123;i&#125;x$&#123;j&#125;=$[i*j]\\E[0m\\t&quot; done printf &quot;\\n&quot;done 范例: 倒状的九九乘法表 1234567#!/bin/bashfor i in &#123;1..9&#125;;do for j in $(seq `echo $[10-$i]`);do echo -ne &quot;$&#123;j&#125;x`echo $[10-i]`=$(((10-i)*j))\\t&quot; done echodone 生产案例：将指定目录下的文件所有文件的后缀改名为 bak 后缀 1234567891011#!/bin/bashDIR=/data/testcd $DIR || &#123; echo 无法进入 $DIR;exit 1; &#125;for FILE in * ;doPRE=`echo $FILE|grep -Eo &quot;.*\\.&quot;` mv $FILE $&#123;PRE&#125;bak# PRE=`echo $FILE|rev|cut -d. -f 2-|rev`# PRE=`echo $FILE | sed -nr &#x27;s/(.*)\\.([^.]+)$/\\1/p&#x27;# SUFFIX=`echo $FILE | sed -nr &#x27;s/(.*)\\.([^.]+)$/\\2/p&#x27;`# mv $FILE $PRE.bakdone 格式2 123456for ((: for (( exp1; exp2; exp3 )); do COMMANDS; donefor ((控制变量初始化;条件判断表达式;控制变量的修正表达式))do 循环体done 范例 123456789#!/bin/bashfor((sum=0,i=1;i&lt;=100;i++));do let sum+=idoneecho sum=$sumfor((sum=0,i=1;i&lt;=100;sum+=i,i++));do truedoneecho sum=$sum 范例：等腰三角形 1234567891011#!/bin/bashread -p &quot;请输入三角形的行数: &quot; linefor((i=1;i&lt;=line;i++));do for((k=0;k&lt;=line-i;k++));do echo -e &#x27; \\c&#x27; done for((j=1;j&lt;=2*i-1;j++));do echo -e &#x27;*\\c&#x27; done echodone 范例：生成进度 12[root@centos8 ~]#for ((i = 0; i &lt;= 100; ++i)); do printf &quot;\\e[4D%3d%%&quot; $i;sleep 0.1s; done100%[root@centos8 ~]# 范例 12345678[root@centos8 ~]#for((;;));do echo for;sleep 1;doneforforforforforforfor while循环格式： 12345while COMMANDS; do COMMANDS; donewhile CONDITION; do 循环体done 无限循环 1234567while true; do 循环体donewhile : ; do 循环体done 范例 12[root@centos8 ~]#sum=0;i=1;while ((i&lt;=100));do let sum+=i;let i++;done;echo $sum5050 范例 1234567891011121314151617181920#配置发邮件的邮箱[root@centos8 ~]#cat .mailrcset from=29308620@qq.comset smtp=smtp.qq.comset smtp-auth-user=29308620@qq.comset smtp-auth-password=esvnhbnqocirbicfset smtp-auth=loginset ssl-verify=ignore[root@centos8 ~]#cat while_diskcheck.sh#!/bin/bashWARNING=80while :;do USE=`df | sed -rn &#x27;/^\\/dev\\/sd/s#.* ([0-9]+)%.*#\\1#p&#x27; |sort -nr|head -n1` if [ $USE -gt $WARNING ];then echo Disk will be full from `hostname -I` | mail -s &quot;disk warning&quot;29308620@qq.com fi sleep 10done 范例: 防止Dos攻击的脚本 1234567891011121314#!/bin/bashWARNING=10touch deny_hosts.txtwhile true;do ss -nt | sed -nr &#x27;1!s#.* ([0-9.]+):[0-9]+ *#\\1#p&#x27;|sort |uniq -c|sort |while read count ip;do if [ $count -gt $WARNING ];then echo $ip is deny grep -q &quot;$ip&quot; deny_hosts.txt || &#123; echo $ip &gt;&gt; deny_hosts.txt;iptables -A INPUT -s $ip -j REJECT; &#125; fi done sleep 10done 特殊用法：while read 遍历文件或文本的每一行 格式： 123while read line; do 循环体done &lt; /PATH/FROM/SOMEFILE 说明：依次读取&#x2F;PATH&#x2F;FROM&#x2F;SOMEFILE文件中的每一行，且将行赋值给变量line 范例 12345678910[root@centos8 ~]#echo magedu | while read X ; do echo $X;donemagedu[root@centos8 ~]#echo magedu | &#123; read X ; echo $X; &#125;magedu[root@centos8 ~]#echo magedu | ( read X ; echo $X )magedu[root@centos8 ~]#echo mage wang zhang | ( read X Y Z; echo $X $Y $Z )mage wang zhang[root@centos8 ~]#echo mage wang zhang | while read X Y Z; do echo $X $Y $Z;donemage wang zhang 范例:磁盘检测 12345678#!/bin/bashWARNING=80MAIL=root@wangxiaochun.comdf |sed -nr &quot;/^\\/dev\\/sd/s#^([^ ]+) .* ([0-9]+)%.*#\\1 \\2#p&quot;|while read DEVICE USE;do if [ $USE -gt $WARNING ] ;then echo &quot;$DEVICE will be full,use:$USE&quot; | mail -s &quot;DISK WARNING&quot; $MAIL fidone 范例:防止Dos攻击 12345678#!/bin/bashMAX=3lastb | sed -rn &#x27;/ssh:/s@.* ([0-9.]&#123;1,3&#125;&#123;3&#125;[0-9]&#123;1,3&#125;) .*@\\1@p&#x27;|sort |uniq -c|while read count ip ;do if [ $count -gt $MAX ];then iptables -A INPUT -s $ip -j REJECT fidone 范例：查看&#x2F;sbin&#x2F;nologin的shell类型的用户名和UID 1234567#!/bin/bashwhile read line ;do if [[ &quot;$line&quot; =~ /sbin/nologin$ ]] ;then echo $line | cut -d: -f1,3 fi done &lt; /etc/passwd until循环12345until COMMANDS; do COMMANDS; doneuntil CONDITION; do 循环体done 范例 12[root@centos8 ~]#sum=0;i=1;until ((i&gt;100));do let sum+=i;let i++;done;echo $sum5050 循环控制continuecontinue [N]：提前结束第N层的本轮循环，而直接进入下一轮判断；最内层为第1层 123456789while CONDITION1; do CMD1 ... if CONDITION2; then continue fi CMDn ...done 循环控制breakbreak [N]：提前结束第N层整个循环，最内层为第1层 123456789while CONDITION1; do CMD1 ... if CONDITION2; then break fi CMDn ...done 范例 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bashsum=0COLOR=&#x27;echo -e \\033[1;31m&#x27;COLOR2=&#x27;echo -e \\033[1;32m&#x27;END=&quot;\\033[0m&quot;while true;doecho -e &quot;\\033[33;1m\\c&quot;cat &lt;&lt;-EOF1) 鲍鱼2) 满汉全席3) 龙虾4) 燕窝5) 帝王蟹6) 点菜结束,结帐EOFecho -e &quot;\\033[0m&quot;read -p &quot;请点菜(1-6): &quot; MENUcase $MENU in1|4) $COLOR&#x27;菜价: $10&#x27;$END let sum+=10 ;;3|5) $COLOR&#x27;菜价: $20&#x27;$END let sum+=20 ;;2) $COLOR&#x27;菜价: $200000&#x27;$END let sum+=200000 ;;6) $COLOR2&quot;你点的菜总价格是 \\$$sum&quot;$END break ;;*) echo &quot;点错了,没有这道菜&quot; ;;esac$COLOR2&quot;你点的菜总价格是 \\$$sum&quot;$ENDdone 范例 123456789101112#!/bin/bashNUM=$[RANDOM%10]while read -p &quot;输入 0-9 之间的数字: &quot; INPUT ;do if [ $INPUT -eq $NUM ];then echo &quot;恭喜你猜对了!&quot; break elif [ $INPUT -gt $NUM ];then echo &quot;数字太大了,重新猜!&quot; else echo &quot;数字太小了,重新猜!&quot; fidone 循环控制shiftshift [n] 用于将参量列表 list 左移指定次数，缺省为左移一次。 参量列表 list 一旦被移动，最左端的那个参数就从列表中删除。while 循环遍历位置参量列表时，常用到 shift 123456789while [ &quot;$1&quot; ] ;do #判断$1是否为空 useradd $1 &amp;&amp; echo $1 is created shiftdone[root@centos scripts]#bash useradd.sh a b ca is createdb is createdc is created 范例 1234567891011121314151617181920212223242526#!/bin/bashif [ $# -eq 0 ];then echo &quot;Usage: `basename $0` user1 user2 ...&quot; exitfi while [ &quot;$1&quot; ];do if id $1 &amp;&gt; /dev/null;then echo $1 is exist else useradd $1 echo &quot;$1 is created&quot; fi shiftdoneecho &quot;All user is created&quot;[root@centos8 script40]#bash shift_batch_user.shUsage: shift_batch_user.sh user1 user2 ...[root@centos8 script40]#bash shift_batch_user.sh tom alice jacktom is existalice is existjack is createdAll user is created 循环与菜单select格式： 12345select NAME [in WORDS ... ;] do COMMANDS; doneselect NAME in list ;do 循环体命令done 说明： select 循环主要用于创建菜单，按数字顺序排列的菜单项显示在标准错误上，并显示 PS3 提示符，等待用户输入 用户输入菜单列表中的某个数字，执行相应的命令 用户输入菜单列表中的某个数字，会将对应的WORD值赋值给NAME变量 用户输入被保存在内置变量 REPLY 中 select 是个无限循环，因此要用 break 命令退出循环，或用 exit 命令终止脚本。也可以按 ctrl+c退出循环 select 经常和 case 联合使用 与 for 循环类似，可以省略 in list，此时使用位置参量 范例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@rocky8 ~]#cat select.sh#!/bin/bashsum=0PS3=&quot;请点菜(1-6): &quot;select MENU in 北京烤鸭 佛跳墙 小龙虾 羊蝎子 火锅 点菜结束;docase $REPLY in1)echo $MENU 价格是 100let sum+=100;;2)echo $MENU 价格是 88let sum+=88;;3)echo $MENU价格是 66let sum+=66;;4)echo $MENU 价格是 166let sum+=166;;5)echo $MENU 价格是 200let sum+=200;;6)echo &quot;点菜结束,退出&quot;break;;*)echo &quot;点菜错误，重新选择&quot;;;esacdoneecho &quot;总价格是: $sum&quot;[root@rocky8 ~]#bash select.sh 1) 北京烤鸭2) 佛跳墙3) 小龙虾4) 羊蝎子5) 火锅6) 点菜结束请点菜(1-6):","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"运算和条件测试","slug":"Linux/shell/operations-conditional","date":"2025-08-20T10:29:24.000Z","updated":"2025-08-28T12:33:05.358Z","comments":true,"path":"Linux/shell/operations-conditional/","permalink":"https://aquapluto.github.io/Linux/shell/operations-conditional/","excerpt":"","text":"算术运算bash 只支持整数，不支持小数 乘法符号有些场景中需要转义 123456789101112131415161718+ - * / % i++ i-- ++i --i = *= /= %= += -= &lt;&lt;= &gt;&gt;= &amp;= ^= |= - + ! ~ ** &lt;&lt; &gt;&gt; &lt;= &gt;= &lt; &gt; == != &amp; | ^ &amp;&amp; || expr?expr:expr expr1 , expr2 实现算术运算 1234567(1) let var=算术表达式(2) ((var=算术表达式)) 和上面等价(3) var=$[算术表达式](4) var=$((算术表达式))(5) var=$(expr arg1 arg2 arg3 ...)(6) declare -i var = 数值(7) echo &#x27;算术表达式&#x27; | bc 内建的随机数生成器变量 1$RANDOM 取值范围：0-32767 范例 12345#生成 0 - 49 之间随机数echo $[$RANDOM%50]#随机字体颜色[root@centos8 ~]#echo -e &quot;\\033[1;$[RANDOM%7+31]mhello\\033[0m&quot;magedu 逻辑运算与：&amp; 和0相与结果为0，和1相与结果保留原值, 一假则假,全真才真 12340 与 0 = 00 与 1 = 01 与 0 = 01 与 1 = 1 或：| 和1相或结果为1，和0相或结果保留原值,一真则真,全假才假 12340 或 0 = 00 或 1 = 11 或 0 = 11 或 1 = 1 非：！ 12! 1 = 0 ! true! 0 = 1 ! false 异或：^ 异或的两个值，相同为假，不同为真。两个数字X,Y异或得到结果Z，Z再和任意两者之一X异或，将得出另一个值Y 12340 ^ 0 = 00 ^ 1 = 11 ^ 0 = 11 ^ 1 = 0 范例: 变量互换 1234[root@centos8 ~]#x=10;y=20;temp=$x;x=$y;y=$temp;echo x=$x,y=$yx=20,y=10[root@centos8 ~]#x=10;y=20;x=$[x^y];y=$[x^y];x=$[x^y];echo x=$x,y=$yx=20,y=10 短路运算短路与 &amp;&amp; 1234CMD1 &amp;&amp; CMD2第一个CMD1结果为真(1)，第二个CMD2必须要参与运算，才能得到最终的结果第一个CMD1结果为假(0)，总的结果必定为0，因此不需要执行CMD2 短路或 || 1234CMD1 || CMD2第一个CMD1结果为真(1)，总的结果必定为1，因此不需要执行CMD2第一个CMD1结果为假(0)，第二个CMD2 必须要参与运算,才能得到最终的结果 短路与和或组合 123456CMD1 &amp;&amp; CMD2 || CMD3当CMD1执行成功时,会执行CMD2当CMD1执行失败时,会执行CMD3注意： CMD1 || CMD2 &amp;&amp; CMD3 逻辑不通,不使用 条件测试和组合条件测试判断某需求是否满足，需要由测试机制来实现，专用的测试表达式需要由测试命令辅助完成 测试过程，实现评估布尔声明，以便用在条件性环境下进行执行 若真，则状态码变量 $? 返回0 若假，则状态码变量 $? 返回1 条件测试命令 test EXPRESSION [ EXPRESSION ] 和test 等价，建议使用 [ ] [[ EXPRESSION ]] 相关于增强版的 [ ], 支持[]的用法,且支持扩展正则表达式和通配符 注意：EXPRESSION前后必须有空白字符 范例 123456[root@centos scripts]#n=80[root@centos scripts]#[$n -gt 60]bash: [80: command not found[root@centos scripts]#[ $n -gt 60 ][root@centos scripts]#echo $?0 范例 123456[root@centos scripts]#name=txt.sh;[[ $name =~ \\.sh$ ]][root@centos scripts]#echo $?0[root@centos scripts]#name=txt.ch;[[ $name =~ \\.sh$ ]][root@centos scripts]#echo $?1 变量测试12#判断 NAME 变量是否定义[ -v NAME ] 范例 12345678910111213141516171819[root@centos8 ~]#unset x[root@centos8 ~]#test -v x[root@centos8 ~]#echo $?1[root@centos8 ~]#x=10[root@centos8 ~]#test -v x[root@centos8 ~]#echo $?0[root@centos8 ~]#y=[root@centos8 ~]#test -v y[root@centos8 ~]#echo $?0#注意 [ ] 中需要空格，否则会报下面错误[root@centos8 ~]#[-v name]-bash: [-v: command not found[root@centos8 ~]#[ -v name ][root@centos8 ~]#echo $?0 数值测试123456-eq 是否等于（equal）-ne 是否不等于（not equal）-gt 是否大于（greater than）-ge 是否大于等于（greater than or equal）-lt 是否小于（less than）-le 是否小于等于（less than or equal） 范例 12345678[root@centos8 ~]#i=10[root@centos8 ~]#j=8[root@centos8 ~]#[ $i -lt $j ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ $i -gt $j ][root@centos8 ~]#echo $?0 算术表达式比较 123456== != &lt;=&gt;=&lt;&gt; 范例 123456789101112[root@centos8 ~]#x=10;y=10;(( x == y ));echo $?0[root@centos8 ~]#x=10;y=20;(( x == y ));echo $?1[root@centos8 ~]#x=10;y=20;(( x != y ));echo $?0[root@centos8 ~]#x=10;y=10;(( x != y ));echo $?1[root@centos8 ~]#x=10;y=20;(( x &gt; y ));echo $?1[root@centos8 ~]#x=10;y=20;(( x &lt; y ));echo $?0 字符串测试test和 [ ] 字符串测试用法 1234567-z STRING 字符串是否为空，没定义或空为真，不空为假，-n STRING 字符串是否不空，不空为真，空为假 STRING 同上STRING1 = STRING2 是否等于，注意 = 前后有空格STRING1 != STRING2 是否不等于&gt; ascii码是否大于ascii码&lt; 是否小于 [[]] 字符串测试用法 12345[[ expression ]] 用法== 左侧字符串是否和右侧的PATTERN相同 注意:此表达式用于[[ ]]中，PATTERN为通配符=~ 左侧字符串是否能够被右侧的正则表达式的PATTERN所匹配 注意: 此表达式用于[[ ]]中为扩展的正则表达式 建议：当使用正则表达式或通配符使用 [[ ]]，其它情况一般使用 [ ] 范例：使用 [ ] 123456789101112131415161718192021222324252627282930313233343536373839[root@centos8 ~]#unset str[root@centos8 ~]#[ -z &quot;$str&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#str=&quot;&quot;[root@centos8 ~]#[ -z &quot;$str&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#str=&quot; &quot;[root@centos8 ~]#[ -z &quot;$str&quot; ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ -n &quot;$str&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#unset str[root@centos8 ~]#[ -n &quot;$str&quot; ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ &quot;$str&quot; ][root@centos8 ~]#echo $?1[root@centos8 ~]#str=magedu[root@centos8 ~]#[ &quot;$str&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#str=magedu[root@centos8 ~]#[ &quot;$str&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#str1=magedu[root@centos8 ~]#str2=mage[root@centos8 ~]#[ $str1 = $str2 ][root@centos8 ~]#echo $?1[root@centos8 ~]#str2=magedu[root@centos8 ~]#[ $str1 = $str2 ][root@centos8 ~]#echo $?0 范例：在比较字符串时，建议变量放在 “ ” 中 123456789[root@centos8 ~]#[ &quot;$NAME&quot; ][root@centos8 ~]#NAME=&quot;I love linux&quot;[root@centos8 ~]#[ $NAME ]-bash: [: love: binary operator expected[root@centos8 ~]#[ &quot;$NAME&quot; ][root@centos8 ~]#echo $?0[root@centos8 ~]#[ I love linux ]-bash: [: love: binary operator expected 范例: [[ ]] 和通配符 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@centos8 ~]#FILE=&quot;a*&quot;[root@centos8 ~]#echo $FILEa*[root@centos8 ~]#[[ $FILE == a* ]][root@centos8 ~]#echo $?0[root@centos8 ~]#FILE=&quot;ab&quot;[root@centos8 ~]#[[ $FILE == a* ]][root@centos8 ~]#echo $?0[root@centos8 ~]#FILE=&quot;a*&quot;#[[]]中如果不想使用通配符*,只想表达*本身,可以用&quot; &quot;引起来[root@centos8 ~]#[[ $FILE == a&quot;*&quot; ]][root@centos8 ~]#echo $?0[root@centos8 ~]#FILE=&quot;ab&quot;[root@centos8 ~]#[[ $FILE == a&quot;*&quot; ]][root@centos8 ~]#echo $?1#[[]]中如果不想使用通配符*,只想表达*本身,也可以使用转义符[root@centos8 ~]#[[ $FILE == a\\* ]][root@centos8 ~]#echo $?1[root@centos8 ~]#FILE=&quot;a\\b&quot;[root@centos8 ~t]#[[ $FILE == a\\* ]][root@centos8 ~]#echo $?1[root@centos8 ~]#FILE=&quot;a*&quot;[root@centos8 ~]#[[ $FILE == a\\* ]][root@centos8 ~]#echo $?0#通配符?[root@centos8 script]#FILE=abc[root@centos8 script]#[[ $FILE == ??? ]][root@centos8 script]#echo $?0[root@centos8 script]#FILE=abcd[root@centos8 script]#[[ $FILE == ??? ]][root@centos8 script]#echo $?1#通配符[root@centos8 ~]#NAME=&quot;linux1&quot;[root@centos8 ~]#[[ &quot;$NAME&quot; == linux* ]][root@centos8 ~]#echo $?0[root@centos8 ~]#[[ &quot;$NAME&quot; == &quot;linux*&quot; ]][root@centos8 ~]#echo $?1[root@centos8 ~]#NAME=&quot;linux*&quot;[root@centos8 ~]#[[ &quot;$NAME&quot; == &quot;linux*&quot; ]][root@centos8 ~]#echo $?0#结论：[[ == ]] == 右侧的 * 做为通配符，不要加“”，只想做为*符号使用时, 需要加 “” 或转义 范例: 判断合理的考试成绩 123456789101112131415[root@centos8 script]#SCORE=101[root@centos8 script]#[[ $SCORE =~ 100|[0-9]&#123;1,2&#125; ]][root@centos8 script]#echo $?0[root@centos8 script]#[[ $SCORE =~ ^(100|[0-9]&#123;1,2&#125;)$ ]][root@centos8 script]#echo $?1[root@centos8 script]#SCORE=10[root@centos8 script]#[[ $SCORE =~ ^(100|[0-9]&#123;1,2&#125;)$ ]][root@centos8 script]#echo $?0[root@centos8 script]#SCORE=abc[root@centos8 script]#[[ $SCORE =~ ^(100|[0-9]&#123;1,2&#125;)$ ]][root@centos8 script]#echo $?1 范例：使用 [[ ]] 判断文件后缀 123456789101112131415161718192021#通配符[root@centos8 ~]#FILE=test.log[root@centos8 ~]#[[ &quot;$FILE&quot; == *.log ]][root@centos8 ~]#echo $?0[root@centos8 ~]#FILE=test.txt[root@centos8 ~]#[[ &quot;$FILE&quot; == *.log ]][root@centos8 ~]#echo $?1[root@centos8 ~]#[[ &quot;$FILE&quot; != *.log ]][root@centos8 ~]#echo $?0#正则表达式[root@centos8 ~]#[[ &quot;$FILE&quot; =~ \\.log$ ]][root@centos8 ~]#echo $?1[root@centos8 ~]#FILE=test.log[root@centos8 ~]#[[ &quot;$FILE&quot; =~ \\.log$ ]][root@centos8 ~]#echo $?0 范例: 判断合法的非负整数 12345678[root@centos8 ~]#N=100[root@centos8 ~]#[[ &quot;$N&quot; =~ ^[0-9]+$ ]][root@centos8 ~]#echo $?0[root@centos8 ~]#N=Magedu10[root@centos8 ~]#[[ &quot;$N&quot; =~ ^[0-9]+$ ]][root@centos8 ~]#echo $?1 范例: 判断合法IP 123456789101112[root@centos8 ~]#IP=1.2.3.4[root@centos8 ~]#[[ &quot;$IP&quot; =~ ^([0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;$ ]][root@centos8 ~]#echo $?0[root@centos8 ~]#IP=1.2.3.4567[root@centos8 ~]#[[ &quot;$IP&quot; =~ ^([0-9]&#123;1,3&#125;.)&#123;3&#125;[0-9]&#123;1,3&#125;$ ]][root@centos8 ~]#echo $?1[root@centos8 ~]#[[ $IP =~ ^(([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])$ ]][root@centos8 ~]#echo $?1 范例 1234[root@centos7 ~]#cat check_ip.sh#!/bin/bashIP=$1[[ $IP =~ ^(([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])$ ]] &amp;&amp; echo $IP is valid || echo $IP is invalid 文件测试存在性测试 123456789-a FILE：同 -e-e FILE: 文件存在性测试，存在为真，否则为假-b FILE：是否存在且为块设备文件-c FILE：是否存在且为字符设备文件-d FILE：是否存在且为目录文件-f FILE：是否存在且为普通文件-h FILE 或 -L FILE：存在且为符号链接文件-p FILE：是否存在且为命名管道文件-S FILE：是否存在且为套接字文件 范例： -e和-a 表示判断文件的存在性，建议使用-e 12345678910111213141516171819202122232425262728293031323334353637383940414243#文件是否不存在[root@centos8 ~]#[ -a /etc/nologin ][root@centos8 ~]#echo $?1[root@centos8 ~]#! [ -a /etc/nologin ][root@centos8 ~]#echo $?0#文件是否存在[root@centos8 ~]# [ -a /etc/issue ][root@centos8 ~]#echo $?0#取反后结果却没有变化[root@centos8 ~]# [ ! -a /etc/issue ][root@centos8 ~]#echo $?0[root@centos8 ~]#! [ -a /etc/issue ][root@centos8 ~]#echo $?1#文件是否存在[root@centos8 ~]#! [ -e /etc/issue ][root@centos8 ~]#echo $?1#此为推荐写法[root@centos8 ~]#[ ! -e /etc/issue ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ -d /etc ][root@centos8 ~]#echo $?0[root@centos8 ~]#[ -d /etc/issue ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ -L /bin ][root@centos8 ~]#echo $?0[root@centos8 ~]#[ -L /bin/ ][root@centos8 ~]#echo $?1 文件权限测试 123456-r FILE：是否存在且可读-w FILE: 是否存在且可写-x FILE: 是否存在且可执行-u FILE：是否存在且拥有suid权限-g FILE：是否存在且拥有sgid权限-k FILE：是否存在且拥有sticky权限 注意：最终结果由用户对文件的实际权限决定，而非文件属性决定 范例 12345678910111213141516171819[root@centos8 ~]#[ -w /etc/shadow ][root@centos8 ~]#echo $?0[root@centos8 ~]#[ -x /etc/shadow ][root@centos8 ~]#echo $?1[root@centos8 ~]#[ -w test.txt ][root@centos8 ~]#echo $?0[root@centos8 ~]#chattr +i test.txt[root@centos8 ~]#lsattr test.txt----i-------------- nianling.txt[root@centos8 ~]#[ -w test.txt ][root@centos8 ~]#echo $?1[root@centos8 ~]#chattr -i test.txt[root@centos8 ~]#[ -w test.txt ][root@centos8 ~]#echo $?0 文件属性测试 12345678-s FILE #是否存在且非空-t fd #fd 文件描述符是否在某终端已经打开-N FILE #文件自从上一次被读取之后是否被修改过-O FILE #当前有效用户是否为文件属主-G FILE #当前有效用户是否为文件属组FILE1 -ef FILE2 #FILE1是否是FILE2的硬链接FILE1 -nt FILE2 #FILE1是否新于FILE2（mtime）FILE1 -ot FILE2 #FILE1是否旧于FILE2 组合测试条件第一种方式 12345[ EXPRESSION1 -a EXPRESSION2 ] #并且，EXPRESSION1和EXPRESSION2都是真，结果才为真[ EXPRESSION1 -o EXPRESSION2 ] #或者，EXPRESSION1和EXPRESSION2只要有一个真，结果就为真[ ! EXPRESSION ] #取反说明： -a 和 -o 需要使用测试命令进行，[[ ]] 不支持 范例 1234567891011121314151617181920212223242526272829303132[root@centos8 ~]#FILE=&quot;/data/scrips/test.sh&quot;[root@centos8 ~]#ll /data/scrips/test.sh-rw-r--r-- 1 root root 382 Dec 23 09:32 /data/scripts/test.sh[root@centos8 ~]#[ -f $FILE -a -x $FILE ][root@centos8 ~]#echo $?1[root@centos8 ~]#chmod +x /data/scripts/test.sh[root@centos8 ~]#ll /data/scripts/test.sh-rwxr-xr-x 1 root root 382 Dec 23 09:32 /data/script40/test.sh#并且[root@centos8 ~]#[ -f $FILE -a -x $FILE ][root@centos8 ~]#echo $?0[root@centos8 ~]#chmod -x /data/scripts/test.sh[root@centos8 ~]#ll /data/scripts/test.sh-rw-r--r-- 1 root root 382 Dec 23 09:32 /data/scripts/test.sh#或者[root@centos8 ~]#[ -f $FILE -o -x $FILE ][root@centos8 ~]#echo $?0[root@centos8 ~]#[ -x $FILE ][root@centos8 ~]#echo $?1#取反[root@centos8 ~]#[ ! -x $FILE ][root@centos8 ~]#echo $?0[root@centos8 ~]#! [ -x $FILE ]0 第二种方式 12345678910COMMAND1 &amp;&amp; COMMAND2 #并且，短路与，代表条件性的AND THEN如果COMMAND1 成功,将执行COMMAND2,否则,将不执行COMMAND2COMMAND1 || COMMAND2 #或者，短路或，代表条件性的OR ELSE如果COMMAND1 成功,将不执行COMMAND2,否则,将执行COMMAND2COMMAND1 &amp;&amp; COMMAND2 || COMMAND3如果COMMAND1 成功,将执行COMMAND2，否则,将执行COMMAND3! COMMAND #非,取反 范例：&amp;&amp; 和 || 组合使用 1234567891011121314151617[root@centos8 ~]#NAME=wang; id $NAME &amp;&gt; /dev/null &amp;&amp; echo &quot;$NAME is exist&quot;wang is exist[root@centos8 ~]#NAME=wange; id $NAME &amp;&gt; /dev/null || echo &quot;$NAME is notexist&quot;wange is not exist[root@centos8 ~]#NAME=wange; id $NAME &amp;&gt; /dev/null &amp;&amp; echo &quot;$NAME is exist&quot; ||echo &quot;$NAME is not exist&quot;wange is not exist[root@centos8 ~]#NAME=wang; id $NAME &amp;&gt; /dev/null &amp;&amp; echo &quot;$NAME is exist&quot; ||echo &quot;$NAME is not exist&quot;wang is exist[root@centos8 ~]#NAME=wang; id $NAME &amp;&gt; /dev/null &amp;&amp; echo &quot;$NAME is exist&quot; ||echo &quot;$NAME is not exist&quot;wang is exist[root@centos8 ~]#NAME=wang; id $NAME &amp;&gt; /dev/null || echo &quot;$NAME is not exist&quot;&amp;&amp; echo &quot;$NAME is exist&quot;wang is exist[root@centos8 ~]#NAME=wange; id $NAME &amp;&gt; /dev/null || echo &quot;$NAME is notexist&quot; &amp;&amp; echo &quot;$NAME is exist&quot;wange is not existwange is exist#结论：如果&amp;&amp; 和 || 混合使用，&amp;&amp; 要在前，|| 放在后 范例：网络状态判断 123456789[root@centos8 ~]#cat /data/scripts/ping.sh#!/bin/bashIP=172.16.0.1ping -c1 -W1 $IP &amp;&gt; /dev/null &amp;&amp; echo &quot;$IP is up&quot; || &#123; echo &quot;$IP is unreachable&quot;; exit; &#125;echo &quot;Script is finished&quot;[root@centos8 ~]#bash /data/scripts/ping.sh172.16.0.1 is upScript is finished 范例：磁盘空间的判断 12345[root@centos8 ~]#cat /data/script/disk_check.sh#!/bin/bashWARNING=80SPACE_USED=`df|grep &#x27;^/dev/sd&#x27;|tr -s &#x27; &#x27; %|cut -d% -f5|sort -nr|head -1`[ &quot;$SPACE_USED&quot; -ge $WARNING ] &amp;&amp; echo &quot;disk used is $SPACE_USED,will be full&quot; | mail -s diskwaring root 范例：磁盘空间和Inode号的检查脚本 123456[root@centos8 scripts]#cat disk_check.sh#!/bin/bashWARNING=80SPACE_USED=`df | grep &#x27;^/dev/sd&#x27;|grep -oE &#x27;[0-9]+%&#x27;|tr -d %| sort -nr|head -1`INODE_USED=`df -i | grep &#x27;^/dev/sd&#x27;|grep -oE &#x27;[0-9]+%&#x27;|tr -d %| sort -nr|head-1`[ &quot;$SPACE_USED&quot; -gt $WARNING -o &quot;$INODE_USED&quot; -gt $WARNING ] &amp;&amp; echo &quot;DISKUSED:$SPACE_USED%, INODE_USED:$INODE_USED,will be full&quot; | mail -s &quot;DISK Warning&quot;root@wangxiaochun.com 关于 () 和 {}(CMD1;CMD2;...)和 &#123; CMD1;CMD2;...; &#125; 都可以将多个命令组合在一起，批量执行 (list) 会开启子shell,并且list中变量赋值及内部命令是临时性的，执行后将不再影响后续的环境 12345678910[root@centos scripts]#name=wujunlin[root@centos scripts]#(name=magedu;echo $name)magedu[root@centos scripts]#echo $namewujunlin[root@centos scripts]#name=wu;(echo $name;name=mage;echo $name);echo $namewumagewu &#123; list; &#125; 不会开启子shell, 在当前shell中运行,会影响当前shell环境 1234[root@centos scripts]#name=wu;&#123; echo $name;name=mage;echo $name; &#125;;echo $namewumagemage 邮件报警安装软件 1yum -y install mailx 申请QQ的授权信息 （1）登陆邮箱 （2）“设置”——“账户”——“POP3&#x2F;IMAP&#x2F;SMTP&#x2F;Exchange&#x2F;CardDAV&#x2F;CalDAV服务”——设置开启——生成授权码 打开文件 1vim /etc/mail.rc 在文件最后填写你QQ申请下来的授权信息 1234set from=298155013@qq.comset smtp=smtp.qq.comset smtp-auth-user=298155013@qq.comset smtp-auth-password=授权码 执行 1echo test | mail -s hello xxxxxxx@qq.com 磁盘空间检测脚本 123USE=`df | grep &#x27;^/dev&#x27; | sed -rn &#x27;s/.* ([0-9]+)%.*/\\1/p&#x27; | sort -nr | head -1`WARNING=80[ $USE -gt $WARNING] &amp;&amp; echo &quot;Disk well be full&quot; | mail -s &quot;Disk Warning&quot; 298155013@qq.com 使用read命令接受输入使用read来把输入值分配给一个或多个shell变量，read从标准输入中读取值，给每个单词分配一个变量，所有剩余单词都被分配给最后一个变量，如果变量名没有指定，默认标准输入的值赋值给系统内置变量REPLY 格式 1234567read [options] [name ...]-p 指定要显示的提示-s 静默输入，一般用于密码-n N 指定输入的字符长度N-d &#x27;字符&#x27; 输入结束符-t N TIMEOUT为N秒 范例 1234567891011121314151617181920212223[root@centos8 ~]#readwangxiaochun[root@centos8 ~]#echo $REPLYwangxiaochun[root@centos8 ~]#read NAME TITLEwang cto[root@centos8 ~]#echo $NAMEwang[root@centos8 ~]#echo $TITLEcto[root@Rocky scripts]#read -p &quot;Are you ok?&quot; ANWNERAre you ok?OK[root@Rocky scripts]#echo hello | &#123; read name ; echo $name; &#125;hello[root@centos8 ~]#read x y z &lt;&lt;&lt; &quot;I love you&quot;[root@centos8 ~]#echo $xI[root@centos8 ~]#echo $ylove[root@centos8 ~]#echo $zyou 范例：判断用户输入的是否为 YES 123456789101112131415161718#第一种#!/bin/bashread -p &quot;Are you rich?yes or no: &quot; ANSWER[[ $ANSWER =~ ^([Yy]|[Yy][Ee][Ss])$ ]] &amp;&amp; echo &quot;You are rich&quot; || echo &quot;Good Good Study,Day Day Up!&quot;#第二种#!/bin/bashread -p &quot;Please input yes or no: &quot; inputanswer=`echo $input| tr &#x27;A-Z&#x27; &#x27;a-z&#x27;`[ $answer = &#x27;yes&#x27; -o $answer = &#x27;y&#x27; ] &amp;&amp; echo YES[ $answer = &#x27;no&#x27; -o $answer = &#x27;n&#x27; ] &amp;&amp; echo NO#第三种#!/bin/bashread -p &quot;Please input yes or no: &quot; input[[ $input =~ ^([Yy][Ee][Ss]|[Yy])$ ]] &amp;&amp; echo YES[[ $input =~ ^([Nn][Oo]|[Nn])$ ]] &amp;&amp; echo NO 范例: 检查主机的网络状态 123#!/bin/bashread -p &quot;Please input a IP: &quot; IP[[ &quot;$IP&quot; =~ ^(([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])$ ]] || &#123; echo &quot;IP is invalid&quot;;exit; &#125;ping -c1 -W1 $IP &amp;&gt; /dev/null &amp;&amp; echo $IP is up || echo $IP is down 范例：实现运维工作菜单 123456789101112131415161718#!/bin/bash. /etc/init.d/functionsecho -en &quot;\\E[$[RANDOM%7+31];1m&quot;cat &lt;&lt;EOF请选择：1）备份数据库2）清理日志3）软件升级4）软件回滚5）删库跑路EOFecho -en &#x27;\\E[0m&#x27;read -p &quot;请选择上面项对应的数字1-5: &quot; MENU[ $MENU -eq 1 ] &amp;&amp; ./backup.sh[ $MENU -eq 2 ] &amp;&amp; action &quot;清理日志&quot;[ $MENU -eq 3 ] &amp;&amp; action &quot;软件升级&quot;[ $MENU -eq 4 ] &amp;&amp; action &quot;软件回滚&quot;[ $MENU -eq 5 ] &amp;&amp; action &quot;删库跑路&quot;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"变量","slug":"Linux/shell/variable","date":"2025-08-20T10:29:12.000Z","updated":"2025-08-28T12:33:05.359Z","comments":true,"path":"Linux/shell/variable/","permalink":"https://aquapluto.github.io/Linux/shell/variable/","excerpt":"","text":"变量类型变量类型： 内置变量，如：PS1，PATH，UID，HOSTNAME，$，BASHPID，PPID，?，HISTSIZE 用户自定义变量 不同的变量存放的数据不同，决定了以下 数据存储方式 参与的运算 表示的数据范围 变量数据类型： 字符 数值：整型、浮点型,bash 不支持浮点数 变量命令规则命名要求 区分大小写 不能使程序中的保留字和内置变量：如：if, for 只能使用数字、字母及下划线，且不能以数字开头，注意：不支持短横线 “ - ”，和主机名相反 命名习惯 见名知义，用英文单词命名，并体现出实际作用，不要用简写，如：ATM 变量名大写 局部变量小写 函数名小写 大驼峰StudentFirstName,由多个单词组成，且每个单词的首字母是大写，其它小写 小驼峰studentFirstName ,由多个单词组成，第一个单词的首字母小写，后续每个单词的首字母是大写，其它小写 下划线: student_name 变量的生效范围 普通变量：生效范围为当前shell进程；对当前shell之外的其它shell进程，包括当前shell的子shell进程均无效 环境变量：生效范围为当前shell进程及其子进程 本地变量：生效范围为当前shell进程中某代码片断，通常指函数 变量进程说明查看进程 1pstree -p 查看在当前哪个进程 1echo $BASHPID 回到上一级进程 1exit 说明 bash命令执行会开启一个子进程，进程编号就变了 . 执行不会开启一个子进程，还是在当前进程中 父进程上创建的变量是不能给子进程用的，要想继承，用环境变量 每一个变量的生效范围是在当前的进程内部有效，在下级进程是无效的 1234567891011121314151617[root@Rocky scripts]#echo $BASHPID20456[root@Rocky scripts]#NAME=id_20456[root@Rocky scripts]#bashbash: 0a: 没有那个文件或目录[root@Rocky scripts]#echo $BASHPID26244[root@Rocky scripts]#pstree -pbash(20456)───bash(26244)[root@Rocky scripts]#echo $NAME[root@Rocky scripts]#exitexit#26244是20456的子进程，NAME是在20456进程中创建的，所以在26244进程下是输出不了NAME的 变量赋值1name=&#x27;value&#x27; value 可以是以下多种形式： 直接字串：name&#x3D;’root’ 变量引用：name&#x3D;”$USER” 命令引用：name&#x3D;COMMAND 或者 name&#x3D;$(COMMAND) 注意：变量赋值是临时生效，当退出终端后，变量会自动删除，无法持久保存，脚本中的变量会随着脚本结束，也会自动删除 变量引用12$name$&#123;name&#125; 弱引用和强引用 “$name” 弱引用，其中的变量引用会被替换为变量值 ‘$name’ 强引用，其中的变量引用不会被替换为变量值，而保持原字符串 范例：变量的各种赋值方式和引用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@centos8 ~]#TITLE=&#x27;cto&#x27;[root@centos8 ~]#echo $TITLEcto[root@centos8 ~]#echo I am $TITLEI am cto[root@centos8 ~]#echo &quot;I am $TITLE&quot;I am cto[root@centos8 ~]#echo &#x27;I am $TITLE&#x27;I am $TITLE[root@centos8 ~]#NAME=$USER[root@centos8 ~]#echo $NAMEroot[root@centos8 ~]#USER=`whoami`[root@centos8 ~]#echo $USERroot[root@centos8 ~]#FILE=`ls /run`[root@centos8 ~]#echo $FILEagetty.reload atd.pid auditd.pid autofs.fifo-misc autofs.fifo-net consolecron.reboot cryptsetup dbus faillock fsck initctl initramfs lock log mountNetworkManager plymouth rsyslogd.pid screen sepermit setrans sshd.pid sssd.pidsudo systemd tmpfiles.d tuned udev user utmp vmware[root@centos8 ~]#FILE=/etc/*[root@centos8 ~]#echo $FILE/etc/adjtime /etc/aliases /etc/alternatives /etc/anacrontab /etc/at.deny/etc/audit /etc/authselect /etc/autofs.conf /etc/autofs_ldap_auth.conf[root@centos8 ~]#seq 1012345678910[root@centos8 ~]#NUM=`seq 10`[root@centos8 ~]#echo $NUM1 2 3 4 5 6 7 8 9 10[root@centos8 ~]#echo &quot;$NUM&quot;12345678910[root@centos8 ~]#NAMES=&quot;wang&gt; zhang&gt; zhao&gt; li&quot;[root@centos8 ~]#echo $NAMESwang zhang zhao li[root@centos8 ~]#echo &quot;$NAMES&quot;wangzhangzhaoli 范例：变量引用 1234567891011121314[root@centos8 data]#NAME=mage[root@centos8 data]#AGE=20[root@centos8 data]#echo $NAMEmage[root@centos8 data]#echo $AGE20[root@centos8 data]#echo $NAME $AGEmage 20[root@centos8 data]#echo $NAME$AGEmage20[root@centos8 data]#echo $NAME_$AGE20[root@centos8 data]#echo $&#123;NAME&#125;_$AGEmage_20 范例：变量的间接赋值和引用 123456789101112[root@centos8 ~]#TITLE=cto[root@centos8 ~]#NAME=wang[root@centos8 ~]#TITLE=$NAME[root@centos8 ~]#echo $NAMEwang[root@centos8 ~]#echo $TITLEwang[root@centos8 ~]#NAME=mage[root@centos8 ~]#echo $NAMEmage[root@centos8 ~]#echo $TITLEwang 范例：变量追加值 1234[root@centos8 ~]#TITLE=CTO[root@centos8 ~]#TITLE+=:wang[root@centos8 ~]#echo $TITLECTO:wang 范例：利用变量实现动态命令 123[root@centos8 ~]#CMD=hostname[root@centos8 ~]#$CMDcentos8.wangxiaochun.com 范例：颜色变量 12345678910echo -e &quot;\\E[1;32mStarting backup...\\E[0m&quot;tar zcf /root/backup/data-`date +%F_%s`.tar.gz /data/ &amp;&gt; /dev/nullecho -e &quot;\\E[1;32mBackup is finished\\E[0m&quot;COLOR=&#x27;echo -e \\E[1;32m&#x27;END=&#x27;\\E[0m&#x27;$COLOR&quot;Backup is starting...&quot;$ENDtar zcf /root/backup/data-`date +%F_%s`.tar.gz /data/ &amp;&gt; /dev/null$COLOR&quot;Backup is finished!&quot;$END 显示已定义的所有变量1set 删除变量1unset name 范例 123456[root@centos8 ~]#NAME=mage[root@centos8 ~]#TITLE=ceo[root@centos8 ~]#echo $NAME $TITLEmage ceo[root@centos8 ~]#unset NAME TITLE[root@centos8 ~]#echo $NAME $TITLE 环境变量 可以使子进程（包括孙子进程）继承父进程的变量，但是无法让父进程使用子进程的变量 一旦子进程修改从父进程继承的变量，将会新的值传递给孙子进程 一般只在系统配置文件中使用，在脚本中较少使用 指在操作系统中用来指定操作系统运行环境的一些参数 环境变量的主要用途： 身份认证 动态库查找 保存工作路径(pwd) 特定路径查找 保存特定变量值 环境变量分类 按生命周期分： 永久的：在环境变量脚本文件中配置，用户每次登录时会自动执行这些脚本，相当于永久生效。 临时的：用户利用export命令，在当前终端下声明环境变量，关闭Shell终端失效。 按作用域分： 系统环境变量：公共的，对全部的用户都生效。 用户环境变量：用户私有的、自定义的个性化设置，只对该用户生效。 变量声明和赋值 1234567#声明并赋值export name=VALUEdeclare -x name=VALUE#或者分两步实现name=VALUEexport name 显示所有环境变量 1234envprintenvexportdeclare -x 查看指定进程的环境变量 1cat /proc/$PID/environ 范例: 查看进程的环境变量 1234567891011121314151617[root@centos8 ~]#cat /proc/1235/environUSER=rootLOGNAME=rootHOME=/rootPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/binSHELL=/bin/bashTERM=linuxSSH_AUTH_SOCK=/tmp/ssh-iIeuAxdLiY/agent.1234XDG_SESSION_ID=1XDG_RUNTIME_DIR=/run/user/0DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/0/busSSH_CLIENT=10.0.0.1 13258 22SSH_CONNECTION=10.0.0.1 13258 10.0.0.8 22SSH_TTY=/dev/pts/0[root@centos8 ~]#cat /proc/1235/environ |tr &#x27;\\0&#x27; &#x27;\\n&#x27;USER=rootLOGNAME=rootHOME=/rootPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/binSHELL=/bin/bashTERM=linuxSSH_AUTH_SOCK=/tmp/ssh-iIeuAxdLiY/agent.1234XDG_SESSION_ID=1XDG_RUNTIME_DIR=/run/user/0DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/0/busSSH_CLIENT=10.0.0.1 13258 22SSH_CONNECTION=10.0.0.1 13258 10.0.0.8 22SSH_TTY=/dev/pts/0 局部变量在shell脚本中，local是用于定义局部变量的关键字。定义局部变量后，该变量只能在当前函数或代码块中使用，其他函数或代码块无访问该变量。下面是一个使用local定义局部变量的例子 12345678910#!/bin/bashfunction test &#123; local name=&quot;liwenchao&quot; echo &quot;局部变量name的值为：$name&quot;&#125;name=&quot;global&quot;echo &quot;全局变量name的值为：$name&quot;testecho &quot;函数执行后全局变量name的值为：$name&quot; 在上面的例子中，我们定义了一个名为test的函数，在函数中使用local定义了一个名为name的局部变量。在函数外部，我们定义了一个名为name的全局变量。当我们执行test函数时，函数内部的name变量的值为liwenchao，而函数外部的name变量的值仍为global。这说明local定义的变量只在函数内部有效 只读变量只读变量：只能声明定义，但后续不能修改和删除，即常量 声明只读变量 12readonly namedeclare -r name 查看只读变量 12readonly [-p]declare -r 范例 1234567891011121314[root@centos8 ~]#readonly PI=3.14159[root@centos8 ~]#echo $PI3.14159[root@centos8 ~]#PI=3.14-bash: PI: readonly variable[root@centos8 ~]#unset PI-bash: unset: PI: cannot unset: readonly variable[root@centos8 ~]#echo $PI3.14159[root@centos8 ~]#exitlogout[root@centos8 ~]#echo $PI[root@centos8 ~]# 位置变量在bash shell中内置的变量, 在脚本代码中调用通过命令行传递给脚本的参数 1234567$1, $2, ... 对应第1个、第2个等参数，shift [n]换位置$0 命令本身,包括路径$* 传递给脚本的所有参数，全部参数合为一个字符串$@ 传递给脚本的所有参数，每个参数为独立字符串$# 传递给脚本的参数的个数注意：$@ $* 只在被双引号包起来的时候才会有差异 清空所有位置变量 1set -- 范例 12color.sh a b c $1=a $2=b $3=c 范例 12345678910111213141516171819#!bin/bashecho 1st is $1echo 2ed is $2echo 3rd is $3echo 10th is $&#123;10&#125;echo all args are $*echo all args are $@echo the number is $#echo the scriptsname is $0[root@centos scripts]#bash color.sh &#123;a..z&#125;1st is a2ed is b3rd is c10th is jall args are a b c d e f g h i j k l m n o p q r s t u v w x y zall args are a b c d e f g h i j k l m n o p q r s t u v w x y zthe number is 26the scriptsname is color.sh 范例：删库跑路之命令rm的安全实现 12345678910[root@centos8 ~]#cat /data/scripts/rm.shWARNING_COLOR=&quot;echo -e \\E[1;31m&quot;END=&quot;\\E[0m&quot;DIR=/tmp/`date +%F_%H-%M-%S`mkdir $DIRmv $* $DIR$&#123;WARNING_COLOR&#125;Move $* to $DIR $END[root@centos8 ~]#chmod a+x /data/scripts/rm.sh[root@centos8 ~]#alias rm=&#x27;/data/scripts/rm.sh&#x27; 范例 123456#!bin/bashcolor=$1echo -e &quot;\\E[1;$&#123;color&#125;m生日快乐\\E[0m&quot;（echo -e &quot;\\E[1;$1m生日快乐\\E[0m&quot;）[root@centos scripts]#bash color.sh 34生日快乐 范例：利用软链接实现同一个脚本不同功能 12345678910111213141516171819[root@centos7 dir]#vim text.sh#!bin/bashbasename $0[root@centos scripts]#ln -s text.sh text2.sh [root@centos scripts]#ln -s text.sh text3.sh [root@centos scripts]#chmod +x text.sh [root@centos scripts]#lltotal 8-rw-r--r--. 1 root root 62 Aug 19 20:12 color.shlrwxrwxrwx. 1 root root 7 Aug 19 20:37 text2.sh -&gt; text.shlrwxrwxrwx. 1 root root 7 Aug 19 20:37 text3.sh -&gt; text.sh-rwxr-xr-x. 1 root root 27 Aug 19 20:36 text.sh[root@centos7 dir]#./test2.sh test2.sh[root@centos7 dir]#./test3.sh test3.sh#起不同的软链接名，虽然脚本名是同一个，但是软链接名不一样，就可以做到功能不一样 退出状态码变量当我们浏览网页时，有时会看到下图所显示的数字，表示网页的错误信息，我们称为状态码，在shell脚本中也有相似的技术表示程序执行的相应状态 进程执行后，将使用变量 ? 保存状态码的相关数字，不同的值反应成功或失败，?取值范例 0-255 12$?的值为0 #代表成功$?的值是1到255 #代表失败 范例 123[root@centos8 ~]#curl -fs http://www.wangxiaochun.com &gt;/dev/null[root@centos8 ~]#echo $?0 用户可以在脚本中使用以下命令自定义退出状态码 1exit [n] 注意： 脚本中一旦遇到exit命令，脚本会立即终止；终止退出状态取决于exit命令后面的数字 如果exit后面无数字,终止退出状态取决于exit命令前面命令执行结果 如果没有exit命令, 即未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 展开命令行展开命令执行顺序 123456789把命令行分成单个命令词展开别名展开大括号的声明&#123;&#125;展开波浪符声明 ~命令替换$() 和 ``再次把命令行分成命令词展开文件通配符*、?、[abc]等等准备I/0重导向 &lt;、&gt;运行命令 防止扩展 1反斜线（\\）会使随后的字符按原意解释 范例 12345[root@centos8 ~]#echo Your cost: \\$5.00Your cost: $5.00[root@rocky8 ~]#echo &quot;The book&#x27;s price is \\$10&quot;The book&#x27;s price is $10 加引号来防止扩展 12单引号（’’）防止所有扩展双引号（”“）也可防止扩展，但是以下情况例外：$（美元符号） 变量扩展 123`` ： 反引号，命令替换\\：反斜线，禁止单个字符扩展!：叹号，历史命令替换 脚本安全set 命令实现脚本安全（在工作中为了安全脚本加上set -e -u） 1234567-u 在扩展一个没有设置的变量时，显示错误信息， 等同set -o nounset-e 如果一个命令返回一个非0退出状态值(失败)就退出， 等同set -o errexit-o option 显示，打开或者关闭选项 显示选项：set -o 打开选项：set -o 选项 关闭选项：set +o 选项-x 当执行命令时，打印命令及其参数,类似 bash -x $- 变量 h：hashall，打开选项后，Shell 会将命令所在的路径hash下来，避免每次都要查询。通过set +h将h选项关闭 i：interactive-comments，包含这个选项说明当前的 shell 是一个交互式的 shell。所谓的交互式shell,在脚本中，i选项是关闭的 m：monitor，打开监控模式，就可以通过Job control来控制进程的停止、继续，后台或者前台执行等 B：braceexpand，大括号扩展 H：history，H选项打开，可以展开历史列表中的命令，可以通过!感叹号来完成，例如“!!”返回上最近的一个历史命令，“!n”返回第 n 个历史命令 范例 12345678910111213141516171819#关闭hash缓存功能[root@centos8 ~]#echo $-himBHs[root@centos8 ~]#set +h[root@centos8 ~]#echo $-imBHs[root@centos8 ~]#hash-bash: hash: hashing disabled#关闭大括号展开[root@centos8 ~]#echo &#123;1..10&#125;1 2 3 4 5 6 7 8 9 10[root@centos8 ~]#echo $-imBHs[root@centos8 ~]#set +B[root@centos8 ~]#echo $-imHs[root@centos8 ~]#echo &#123;1..10&#125;&#123;1..10&#125; 范例：限制使用没声明的变量 123456789[root@ubuntu2204 ~]# cat set2.sh#!/bin/bashset -uDIR=/testrm -rf $&#123;DIr&#125;/* #这个变量其实不存在，如果没有 set -u 选项，则会删除根目录rm -rf /*[root@ubuntu2204 ~]# bash set2.shset2.sh: line 17: DIr: unbound variable 范例：遇到错误终止 123456789101112[root@ubuntu2204 ~]# vim set3.sh#!/bin/bashset -eecho 123cd /test2/ #这个目录不存在，如果没有 set -e，则也会删根rm -rf *echo 456#遇到错误行就终止[root@ubuntu2204 ~]# bash set3.sh123set3.sh: line 17: cd: /test2/: No such file or directory 格式化输出printf格式 1printf &quot;指定的格式&quot; &quot;文本1&quot; ”文本2“…… 常用格式替换符 替换符 功能 %d，%i 十进制整数 %f 浮点 %c ASCII字符，即显示对应参数的第一个字符 %s 字符串 %% 表示%本身 %b 相对应的参数中包含转义字符时，可以使用此替换符进行替换，对应的转义字符会被转义 %o 八进制值 %u 不带正负号的十进制值 %x，%X 十六进制值（a-f），（A-F） 说明： %#s 中的数字代表此替换符中的输出字符宽度，不足补空格，默认是右对齐,%-10s表示10个字符宽，- 表示左对齐 %03d 表示3位宽度,不足前面用0补全,超出位数原样输出 %.2f 中的2表示小数点后显示的小数位数 常用转义字符 转义符 功能 \\a 警告字符，通常为ASCII的BEL字符 \\n 换行 \\t 水平制表符 \\v 垂直制表符 \\r 回车 \\ 表示\\本身 \\b 后退 \\f 换页 范例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@centos8 ~]#printf &quot;%s&quot; 1 2 3 41234[root@centos8 ~]#[root@centos8 ~]#printf &quot;%s\\n&quot; 1 2 3 41234[root@centos8 ~]#printf &quot;%f\\n&quot; 1 2 3 41.0000002.0000003.0000004.000000#.2f 表示保留两位小数[root@centos8 ~]#printf &quot;%.2f\\n&quot; 1 2 3 41.002.003.004.00[root@centos8 ~]#printf &quot;(%s)&quot; 1 2 3 4;echo(1)(2)(3)(4)[root@centos8 ~]#printf &quot; (%s) &quot; 1 2 3 4;echo &quot;&quot;(1) (2) (3) (4)[root@centos8 ~]#printf &quot;(%s)\\n&quot; 1 2 3 4(1)(2)(3)(4)[root@centos8 ~]#printf &quot;%s %s\\n&quot; 1 2 3 41 23 4[root@centos8 ~]#printf &quot;%s %s %s\\n&quot; 1 2 3 41 2 34 #%-10s 表示宽度10个字符，左对齐[root@centos8 ~]#printf &quot;%-10s %-10s %-4s %s \\n&quot; 姓名 性别 年龄 体重 小明 男 20 70 小红 女 18 50姓名 性别 年龄 体重小明 男 20 70小红 女 18 50#将十进制的17转换成16进制数[root@centos8 ~]#printf &quot;%X&quot; 1711[root@centos8 ~]##将十六进制C转换成十进制[root@centos8 ~]#printf &quot;%d\\n&quot; 0xC12[root@centos8 ~]#VAR=&quot;welcome to Magedu&quot;;printf &quot;\\033[1;32m%s\\033[0m\\n&quot; $VARwelcometoMagedu 高级变量高级变量赋值$str 为变量名，expr 为具体字符串 这些组合可以省掉一些 if，else 的判断代码 变量配置方式 str没有配置 str为空字符串 str己配置为非空字符串 var&#x3D;${str-expr} var&#x3D;expr var&#x3D; var&#x3D;$str var&#x3D;${str:expr} var&#x3D;expr var&#x3D;expr var&#x3D;$str var&#x3D;${str+expr} var&#x3D; var&#x3D;expr var&#x3D;expr var&#x3D;${str:+expr} var&#x3D; var&#x3D; var&#x3D;expr var&#x3D;${str&#x3D;expr} str&#x3D;expr; var&#x3D;expr str不变; var&#x3D; str不变; var&#x3D;$str var&#x3D;${str:&#x3D;expr} str&#x3D;expr; var&#x3D;expr str&#x3D;expr; var&#x3D;expr str不变; var&#x3D;$str var&#x3D;${str?expr} expr 输出至 stderr var&#x3D; var&#x3D;$str var&#x3D;${str:?expr} expr 输出至 stderr expr 输出至 stderr var&#x3D;$str 范例 12345678910111213141516171819202122232425262728[root@centos8 ~]#title=ceo[root@centos8 ~]#name=$&#123;title-mage&#125;[root@centos8 ~]#echo $nameceo[root@centos8 ~]#title=[root@centos8 ~]#name=$&#123;title-mage&#125;[root@centos8 ~]#echo $name[root@centos8 ~]#unset title[root@centos8 ~]#name=$&#123;title-mage&#125;[root@centos8 ~]#echo $namemage[root@centos8 ~]#title=ceo[root@centos8 ~]#name=$&#123;title:-mage&#125;[root@centos8 ~]#echo $nameceo[root@centos8 ~]#title=[root@centos8 ~]#name=$&#123;title:-mage&#125;[root@centos8 ~]#echo $namemage[root@centos8 ~]#unset title[root@centos8 ~]#name=$&#123;title:-mage&#125;[root@centos8 ~]#echo $namemage 高级变量用法-有类型变量Shell变量一般是无类型的，但是bash Shell提供了declare和typeset两个命令用于指定变量的类型，两个命令是等价的 12345678910111213141516declare [选项] 变量名#选项：-r #声明或显示只读变量-i #将变量定义为整型数-a #将变量定义为数组-A #将变量定义为关联数组-f #显示已定义的所有函数名及其内容-F #仅显示已定义的所有函数名-x #声明或显示环境变量和函数,相当于export-l #声明变量为小写字母 declare -l var=UPPER-u #声明变量为大写字母 declare -u var=lower-n #变量引用另外一个变量的值-p #显示每个变量的属性和值-t #声明或显示具有trace(追踪)属性的变量-x #显示环境变量和函数,相当于export 范例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#显示所有己定义的函数和函数体[root@ubuntu2204 ~]# declare -f#显示所有己定义的函数，仅函数名[root@ubuntu2204 ~]# declare -F#显示所有己定义的变量属性及值[root@ubuntu2204 ~]# declare -p#显示所有普通数组[root@ubuntu2204 ~]# declare -a#定义一个普通数组[root@ubuntu2204 ~]# declare -a arr1#显示所有关联数组[root@ubuntu2204 ~]# declare -A#定义一个关联数组[root@ubuntu2204 ~]# declare -A arr2#显示所有整型变量[root@ubuntu2204 ~]# declare -i#定义一个整型变量[root@ubuntu2204 ~]# declare -i int1[root@ubuntu2204 ~]# int1=abcd[root@ubuntu2204 ~]# echo $int10#显示所有小写变量[root@ubuntu2204 ~]# declare -l#定义一个小写变量[root@ubuntu2204 ~]# declare -l lower1[root@ubuntu2204 ~]# lower1=1234abcdABCD[root@ubuntu2204 ~]# echo $lower11234abcdabcd#变量引用[root@ubuntu2204 ~]# str1=1234[root@ubuntu2204 ~]# declare -n str2=str1[root@ubuntu2204 ~]# echo $str1 $str21234 1234#str2 会跟着改变[root@ubuntu2204 ~]# str1=abcd[root@ubuntu2204 ~]# echo $str1 $str2abcd abcd#str1 也会跟着改变[root@ubuntu2204 ~]# str2=xyz[root@ubuntu2204 ~]# echo $str1 $str2xyz xyz#显示所有只读变量[root@ubuntu2204 ~]# declare -r#只读变量在定义时就要赋值[root@ubuntu2204 ~]# declare -r r1[root@ubuntu2204 ~]# r1=123-bash: r1: readonly variable[root@ubuntu2204 ~]# declare -r r2=123[root@ubuntu2204 ~]# echo $r2123 变量间接引用eval命令eval命令将会首先扫描命令行进行所有的置换，然后再执行该命令。该命令适用于那些一次扫描无法实现其功能的变量,该命令对变量进行两次扫描 eval会对后面的命令进行两遍扫描，如果第一遍扫描后，命令是个普通命令，则执行此命令；如果命令中含有变量的间接引用，则保证间接引用的语义。也就是说，eval命令将会首先扫描命令行进行所有的置换，然后再执行该命令。因此，eval命令适用于那些一次扫描无法实现其功能的变量。 eval 执行以下两个步骤： 第一步，执行变量替换，类似与C语言的宏替代； 第二步，执行替换后的命令串 范例 1234567891011121314151617181920212223242526272829303132[root@centos8 ~]# CMD=whoami[root@centos8 ~]# echo $CMDwhoami[root@centos8 ~]# eval $CMDroot[root@centos8 ~]# n=10 [root@centos8 ~]# echo &#123;0..$n&#125; &#123;0..10&#125;[root@centos8 ~]# eval echo &#123;0..$n&#125;0 1 2 3 4 5 6 7 8 9 10[root@centos8 ~]#for i in `eval echo &#123;1..$n&#125;` ;do echo i=$i ;donei=1i=2i=3i=4i=5i=6i=7i=8i=9i=10[root@centos8 ~]#i=a[root@centos8 ~]#j=1[root@centos8 ~]#$i$j=hello-bash: a1=hello: command not found[root@centos8 ~]#eval $i$j=hello[root@centos8 ~]#echo $i$ja1[root@centos8 ~]#echo $a1hello 范例：执行含有带字符串的命令 我们可以新建一个文件test，将字符串”HelloWorld!”写入文件中，把 cat test 赋值给变量 WORD,如果我们 echo WORD并不能地到 test 中的内容；然而 eval WORD 则能显示文件中的内容，因为 eval 命令对后面的命令进行了两次扫描，第一次将 WORD 替换为 cat test，第二次执行cat test。这些需要进行两次扫描的变量有时被称为复杂变量。不过这些变量本身并不复杂。eval命令不仅可以回显复杂变量，也可以用于回显简单变量。 范例：eval命令还可以获取传给shell的最后一个参数 如果我们知道参数个数，我们想要查看最后一个参数的内容可以使用echo直接显示，如输入 first last两个参数我们可以用echo 2 来查看最后一个参数；但是，如果我们不知道参数个数还想查看最后一个参数内容该怎么办呢？这是我们就想到使用 #”后显示的其实是参数个数，而使用eval echo “$#”才显示最后一个参数的内容。 范例：条件筛选 在file文件中写入两列数据，第一列对应KEY 、第二列为VALUE，使用eval命令将KEY与VALUE的值对应起来，从文件中读取： 注意： eval 不能获得函数处理结果。 eval 嵌套无意义，在其他语言中可以通过 eval(eval(“code”)) ，来执行（执行动态生成的 code 的返回），而由于shell 中 eval 将后面的 eval 命令简单当作命令字符串执行，失去了嵌套作用，嵌套被命令替换取代。 间接变量引用如果第一个变量的值是第二个变量的名字，从第一个变量引用第二个变量的值就称为间接变量引用variable1的值是variable2，而variable2又是变量名，variable2的值为value，间接变量引用是指通过variable1获得变量值value的行为 12345variable1=variable2variable2=value#示例:i=1$1=wang bash Shell提供了两种格式实现间接变量引用 123456789101112#方法1#变量赋值eval tempvar=\\$$variable1#显示值eval echo \\$$variable1eval echo &#x27;$&#x27;$variable1#方法2#变量赋值tempvar=$&#123;!variable1&#125;#显示值echo $&#123;!variable1&#125; 范例 1234567891011121314151617181920212223242526[root@centos8 ~]#ceo=name[root@centos8 ~]#name=mage[root@centos8 ~]#echo $ceoname[root@centos8 ~]#echo $$ceo33722ceo[root@centos8 ~]#echo $$33722[root@centos8 ~]#echo \\$$ceo$name[root@centos8 ~]#eval echo \\$$ceomage[root@centos8 ~]#eval tmp=\\$$ceo[root@centos8 ~]#echo $tmpmage[root@centos8 ~]#echo $&#123;!ceo&#125; #ceo=name,$&#123;!ceo&#125;相当于$name，因为!相当于$mage[root@server ~]# N1=N2[root@server ~]# N2=wangxiaochun[root@server ~]# eval NAME=\\$$N1[root@server ~]# echo $NAMEwangxiaochun[root@server ~]# NAME=$&#123;!N1&#125;[root@server ~]# echo $NAMEwangxiaochun 范例: 生成位置变量 12345678910[root@centos7 ~]#cat test.sh#!/bin/bashfor i in &#123;1..3&#125;;do echo $&#123;!i&#125; #eval echo \\$$idone[root@centos7 ~]#bash test.sh a b cabc 范例: 批量创建用户 123456789101112#!/bin/bashn=$#[ $n -eq 0 ] &amp;&amp; &#123; echo &quot;Usage: `basename $0` username...&quot; ; exit 2; &#125;for i in `eval echo &#123;1..$n&#125;`;do user=$&#123;!i&#125; id $user &amp;&gt; /dev/null &amp;&amp; echo $user is exist || &#123; useradd $user; echo $useris created; &#125;done[root@centos8 ~]#bash create_user.sh hehe xixi hahahehe is createdxixi is createdhaha is created","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"系统优化","slug":"Linux/system-optimization","date":"2025-08-20T08:52:50.000Z","updated":"2025-08-28T13:03:03.763Z","comments":true,"path":"Linux/system-optimization/","permalink":"https://aquapluto.github.io/Linux/system-optimization/","excerpt":"","text":"系统内核优文件描述符和进程系统正在经历着高并发访问，会涉及到打开很多文件，每个打开的文件都会对应一个文件描述符，而文件描述符是有上限的，达到上限将无法继续同时打开更多的文件，访问也就会受到限制，所以需要加大文件描述符与最大打开的进程数 硬限制（hard limit）一旦被设置以后就不能被非root用户修改 软限制（soft limit）可以增长达到硬限制（hard limit）。 硬限制（hard limit）一旦被设置以后就不能被非root用户修改，软限制（soft limit）可以增长达到硬限制 大型高并发项目可以设置为1000000，如果是一般中型项目几十万就可以了 1234567891011121314cat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF* soft nofile 102400* hard nofile 102400* soft nproc 102400* hard nproc 102400EOF&lt;domain&gt; &lt;type&gt; &lt;item&gt; value&gt;&lt;domain&gt; 表示要限制的用户&lt;type&gt; 设定类型&lt;item&gt; 表示可选的资源&lt;value&gt; 表示要限制的值/etc/security/limits.d/20-nproc.conf 优先级高于 /etc/security/limits.conf 调整Kernel pid max123456此文件的默认值32768将产生与早期内核相同的pid范围。在32位平台上，32768是pid最大值。在64位系统上，pid最大值可以设置为2^22等于4194304（pid最大值限制,大约400万）。[root@egon ~~]# cat /proc/sys/kernel/pid_max 131072 # 默认值echo &quot;kernel.pid_max= 4194303&quot; | tee -a /etc/sysctl.conf sysctl -p 其他内核优化12345678910111213141516171819202122[root@egon ~]# cat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOFnet.ipv4.tcp_fin_timeout = 2net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_syncookies = 1net.ipv4.tcp_keepalive_time = 600net.ipv4.ip_local_port_range = 4000 65000net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.tcp_max_tw_buckets = 36000net.ipv4.route.gc_timeout = 100net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_synack_retries = 1net.core.somaxconn = 16384net.core.netdev_max_backlog = 16384net.ipv4.tcp_max_orphans = 16384net.ipv4.ip_forward = 1EOF#生效[root@egon ~]# sysctl -psyncookies开启后用来防止syn洪水攻击，了解请看https://www.cnblogs.com/linhaifeng/articles/13959796.html OOM与内存相关优化buffer、cache、avalablefree -h 各部分含义 total：这行展示了系统的总内存。 used：这是已被进程使用但目前还没有释放的内存。这部分内存不包括 “buff&#x2F;cache” 这行所表示的内存。 free：这部分包括没有被任何形式的缓存使用的内存。 shared：这部分是tmpfs（Shmem）占用的内存。 buff&#x2F;cache：这个数值是 Buffer（像是文件系统元数据和跟踪的内存）和 Cache（被各种进程用来映射各种库、调用的内存）的总和。 available：这个是给应用程序实际可以分配的内存。 cache等于page cache缓存+slab缓存在 free -h 结果中，cache 是包括了 Page Cache 和 Slab 的总和。 Page Cache：称为页面缓存，用于文件的缓存，即以页为单位，为了加快文件的读写，内核中提供了page cache作为缓存。 另外，还有另一个名为 Slab 的内存对象缓存层，它包括了两个子系统 dentry cache（目录条目缓存）和 inode cache（索引节点缓存）。这两者以及其它的 slab 缓存也会被算入 free -h 结果中的 cache。 VSZ虚拟内存与RSS物理内存linux系统的内存是超配的，进程最先申请到的都是VSZ虚拟内存 只有真正用的时候才会真正的占用，真正占用的部分就是RSS物理内存，也称之为匿名内存，这部分内存大都是没有刷入磁盘的数据，所以也叫脏数据，因为没有落盘所以数据不安全容易丢 我们可以用ps aux看到VSZ与RSS。注意：ps 命令看到的VSZ与RSS的值单位是KB两个参数名，值可不一定是KB哦！ swap分区系统总是在物理内存不够时，才进行Swap交换。swap大小是有上限的，一旦swap使用完，操作系统会触发OOM-Killer机制，把消耗内存最多的进程kill掉以释放内存 所以swap分是物理内存不够用时的保命措施，一旦用了速度必然是慢了，但是能保命 swap分区工作原理：https://egonlin.com/?p=7605 内存不足时linux系统会如何处理？当 CentOS 7 系统的内存快用完的的时候，操作系统会按下述顺序运行（清空持续恶化则会按一个个阶段走下去） 阶段1：Buffers 和 Cache 清理：首先，当内存开始变得紧张时，系统会开始回收Buffers和Cache中的内存。这些缓存的内容如果需要，能很快被重新生成，因此它们是最先被系统考虑回收的部分。 阶段2：启动 Swapping：然后，如果确定缓存无法满足内存需求，即便在清理了Buffers和Cache后，内存仍然紧张，那么系统会开始 Swapping。这个阶段系统开始将一部分内存中的内容（通常是最近不活跃的进程）放入swap磁盘空间中，以腾出内存空间。这个阶段是有性能损失的，因为与读写内存相比，读写硬盘的速度要慢得多。 阶段3：启动 OOM Killer：最后，如果在启动了Swapping之后内存压力仍然很大，系统就会启动OOM Killer。OOM Killer会选择一些“牺牲品”，杀掉这些进程，以此释放内存。选择牺牲品的策略有很多，但通常来说，被杀掉的进程会是那些占用内存较多、优先级较低、启动时间较长的进程。 OOM相关知识详见：https://egonlin.com/?p=7401 强调一点：我们在&#x2F;var&#x2F;log&#x2F;messages日志里看到的oom事件会罗列进程的RSS，此处看到的单位时一个内存页，大小默认4K，这与你在ps aux里看到的RSS不是一个单位 调整swappiness在宿主机上，配置内核参数swappiness来控制全局 swapiness参数该参数可以决定系统将会有多频繁地使用交换分区。 12345[root@test04 ~]# cat /proc/sys/vm/swappiness 0设置 vm.swappiness=0 后并不代表禁用swap分区，只是告诉内核，能少用到swap分区就尽量少用到，设置 vm.swappiness=100的话，则表示尽量使用swap分区，默认的值是60 要注意，page cache与swap分区都是内存的优化方案， 1、page cache linux系统会把空闲的内存用作page cache以优化磁盘的读写，当物理内存不够用时，如果我们没有开启swap分区，那么linux系统就只能释放page cache来给rss用。 2、swap分区 对于物理内存rss里，大部分是没有对应磁盘文件的内存，比如用malloc申请到的内存，这种内存也称之为匿名内存，是不能被释放的。 如果打开了swap分区，在内存不足时，就可以考虑数据写入swap分区，而写入swap分区的都是来自rss的匿名内存。 那问题是，在物理内存不足时，是释放page cache还是使用swap分区呢？说白了，单独用谁都不合理，因为如果只释放page cache，有可能需要频繁读写一个文件，释放了page cache必然引起系统性能下降，如果只写把匿名内存写入swap分区，那一旦从rss释放到的匿名内存马上又需要使用，你又必须从swap分区里把刚刚写入的匿名内存数据重新读入内存，这同样会导致系统性能下降 所以，我们必须要找到一个page cache与swap分区的平衡点，这就需要用到swapiness swappiness 的取值范围是 0–100，缺省值为 60 该值代表的是一个权重，用来定义page cache与匿名内存的释放比例，这个比例是anon_prio:file_prio 如下swapiness相关代码，anno_prio就等于swapniess的值，代表的是匿名内存释放的比重，即使用swap分区的比重 1234swappiness 为 100 时，anonymous 和 file 具有相同的优先级。anon_prio = swappiness; file_prio = 200 - anon_prio; 1、如果anno_prio为100，那么匿名内存与page cache的释放比重为 100:100，即等比例释放 2、如果anno_prio为60，那么匿名内存与page cache的释放比重为 60:140，那page cache的释放权重要优先于匿名内存 3、如果anno_prio为0，那么匿名内存与page cache的释放比重为 0:200，那page cache的释放权重必然是优先于匿名内存，但也不代表完全不使用用swap分区了，只是说尽量不使用swap，在内存紧张时，依然会用swap来回收匿名内存 123[root@egon ~~]# cat /proc/sys/vm/swappiness 60[root@egon ~~]# echo &quot;vm.swappiness = 10&quot; | tee -a /etc/sysctl.conf","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"系统优化","slug":"系统优化","permalink":"https://aquapluto.github.io/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"}]},{"title":"文件共享服务","slug":"Linux/service-manage/file-share","date":"2025-08-20T08:52:20.000Z","updated":"2025-08-28T12:33:05.336Z","comments":true,"path":"Linux/service-manage/file-share/","permalink":"https://aquapluto.github.io/Linux/service-manage/file-share/","excerpt":"","text":"1 存储介绍IT 基础设施有三个主要组成，分别是 计算，存储，网络 存储类型分为三种 直连式存储：Direct-Attached Storage，简称 DAS（本地存储） 存储区域网络：Storage Area Network，简称 SAN（远程存储，块，共享空间给远程用户，用户独占，可以分区，创建文件系统，挂载） 网络附加存储：Network-Attached Storage，简称 NAS（远程存储，文件，共享目录文件） 1.1 三种存储比较SAN与NAS的主要区别体现在文件系统所在的位置 三种存储架构的应用场景 DAS虽然比较古老了，但是还是很适用于那些数据量不大，对磁盘访问速度要求较高的中小企业 NAS多适用于文件服务器，用来存储非结构化数据，虽然受限于以太网的速度，但是部署灵活，成本低 SAN则适用于大型应用或数据库系统，缺点是成本高、较为复杂 1.2 常见存储方式块存储：像硬盘，高性能，挂载后用。 文件存储：像U盘&#x2F;网盘，有目录，直接读写文件，可共享。 对象存储：像网盘（如OSS&#x2F;S3），通过URL操作，无目录层级，适合大文件。 分布式存储：底层整合多台机器，可统一提供以上三种服务。 类型 核心特点 访问方式 优点 缺点 典型应用 块存储 原始“磁盘”，需格式化 + 挂载 通过设备（如 /dev/sdb）访问 ⚡ 读写快、低延迟 ❌ 不易扩展、难共享 虚拟机磁盘、数据库 文件存储 层次化目录结构（如文件夹） 标准文件接口（open/read/write） ✅ 易共享、易管理、POSIX 兼容 🐢 速度较慢 NAS、共享文件夹、Web 静态资源 对象存储 扁平结构，唯一 ID 标识对象 RESTful API &#x2F; SDK（如 S3） ☁️ 海量扩展、高可用、支持元数据 🔒 不支持随机读写、只能全量操作 图片&#x2F;视频存储、备份归档、云存储 分布式存储 多节点协同，统一资源池 可提供块、文件、对象三种接口 🌐 高扩展、高性能、高可靠 ⚙️ 架构复杂 云平台、大数据、AI 训练 2 NFS 服务2.1 NFS工作原理 NFS：Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，NFS 是内核里的功能，基于RPC（Remote Procedure CallProtocol 远程过程调用）实现 RPC采用C&#x2F;S模式，客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行 注册中心：假设Aserver对外提供web服务，它的地址通过容器的方法实现，地址自动分配，不固定，用户想访问没办法直接访问，所以Aserver启动后，就会把地址向注册中心进行注册，用户就可以向注册中心寻找自己想要的服务查找IP地址 因为NFS的端口不固定，启动NFS服务时就会将端口号向RPC服务注册，RPC服务的端口号是固定的，111，用户想访问NFS服务就去访问111端口RPC服务，询问NFS的端口号，拿到NFS的端口号就可以去访问NFS了 NFS优势：节省本地存储空间，将常用的数据,如：&#x2F;home目录，存放在NFS服务器上且可以通过网络访问，本地终端将可减少自身存储空间的使用 简单例子 12A的/data/通过NFS共享出来B将A的/data/挂载到/tmp，在/tmp写数据实际上是写到了/data/，并且A也写数据到/data/，这样子B以后想访问/data/直接访问/tmp，不用到A机器去访问 2.2 NFS软件介绍软件包： 红帽系统: nfs-utils: 包括服务器和客户端相关工具，CentOS8 最小化安装时默认没有安装 Ubuntu: nfs-server（nfs-kernel-server） 服务器包名，nfs-common 客户端包名 相关软件包：rpcbind（必须），tcp_wrappers Kernel支持：nfs.ko 端口：2049(nfsd),，其它端口由portmap(111)分配 NFS服务主要进程： rpc.nfsd：最主要的NFS进程，管理客户端是否可登录 rpc.mountd：挂载和卸载NFS文件系统，包括权限管理 rpc.lockd：非必要，管理文件锁，避免同时写出错 rpc.statd：非必要，检查文件一致性，可修复文件 说明：CentOS 6 开始portmap进程由rpcbind代替 日志：&#x2F;var&#x2F;lib&#x2F;nfs&#x2F; 比较NFS和其他服务的端口 12345678tcp/iptcp/udpmysql 3306/tcpdns 53/tcp/udphttp 80/tcpftp 21, 20（主动）samba 445/tcp139/tcp 137,138/udpNFS 固定和不固定，这时候需要用到注册中心 NFS配置文件： 12/etc/exports #共享规则配置/etc/exports.d/*.exports #按业务创建规则，后缀必须为exports NFS 基于 C&#x2F;S 模式实现，所以有客户端软件和服务端软件 范例：红帽系统安装NFS软件包 1234567[root@centos8 ~]#yum -y install nfs-utils#查看支持的NFS版本,注意:只有服务启动才能看此文件[root@centos8 ~]#cat /proc/fs/nfsd/versions-2 +3 +4 +4.1 +4.2[root@centos8 ~]#systemctl enable --now nfs-server.service 范例：Ubuntu 安装NFS软件包 12345678910#服务器[root@ubuntu2004 ~]#apt update &amp;&amp; apt -y install nfs-kernel-server[root@ubuntu2004 ~]#systemctl status nfs-server#查看支持的NFS版本,注意:只有服务启动才能看此文件[root@ubuntu2004 ~]#cat /proc/fs/nfsd/versions-2 +3 +4 +4.1 +4.2#客户端[root@ubuntu2004 ~]#apt -y install nfs-common 服务端依赖包，注册中心，nfs 服务中有大量的组件，部份组件端口并不固定，需要依赖rpcbind发布端口 1234567891011121314151617181920212223242526272829303132333435363738[root@ubuntu ~]# dpkg -l rpcbindDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-==============-=============-============-=====================================================ii rpcbind 1.2.6-2build1 amd64 converts RPC program numbers into universal addresses#查看服务端端口[root@ubuntu ~]# ss -tunlp | grep rpcudp UNCONN 0 0 127.0.0.1:603 0.0.0.0:* users:((&quot;rpc.statd&quot;,pid=14843,fd=5))udp UNCONN 0 0 0.0.0.0:38632 0.0.0.0:* users:((&quot;rpc.statd&quot;,pid=14843,fd=8))udp UNCONN 0 0 0.0.0.0:58332 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15464,fd=4))udp UNCONN 0 0 0.0.0.0:54239 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15464,fd=12))udp UNCONN 0 0 0.0.0.0:48141 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15464,fd=8))udp UNCONN 0 0 0.0.0.0:111 0.0.0.0:* users:((&quot;rpcbind&quot;,pid=14257,fd=5),(&quot;systemd&quot;,pid=1,fd=138))....#重启服务[root@ubuntu ~]# systemctl restart nfs-server.service#再次查看端口，端口发生了变化[root@ubuntu ~]# ss -tunlp | grep rpcudp UNCONN 0 0 0.0.0.0:36333 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15507,fd=12))udp UNCONN 0 0 127.0.0.1:603 0.0.0.0:* users:((&quot;rpc.statd&quot;,pid=14843,fd=5))udp UNCONN 0 0 0.0.0.0:38632 0.0.0.0:* users:((&quot;rpc.statd&quot;,pid=14843,fd=8))udp UNCONN 0 0 0.0.0.0:111 0.0.0.0:* users:((&quot;rpcbind&quot;,pid=14257,fd=5),(&quot;systemd&quot;,pid=1,fd=138))udp UNCONN 0 0 0.0.0.0:48272 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15507,fd=4))udp UNCONN 0 0 0.0.0.0:38052 0.0.0.0:* users:((&quot;rpc.mountd&quot;,pid=15507,fd=8))#由于服务端监听的端口会发生变化，所以需要依赖rpcbind对客户端提供注册服务，rpcbind端口不会发生变化#查看服务端使用的端口[root@ubuntu ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper #rpcbind，早期叫portmapper .... 2.3 NFS共享配置文件格式1234567891011[root@ubuntu ~]# cat /etc/exports# /etc/exports: the access control list for filesystems which may be exported# to NFS clients. See exports(5).## Example for NFSv2 and NFSv3:# /srv/homes hostname1(rw,sync,no_subtree_check)hostname2(ro,sync,no_subtree_check)## Example for NFSv4:# /srv/nfs4 gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check)# /srv/nfs4/homes gss/krb5i(rw,sync,no_subtree_check)# 格式 12345/dir 主机1(opt1,opt2) 主机2(opt1,opt2)...#NFS服务器上要被共享的目录路径 #可以共享此目录的客户端主机1(配置项1...) #可以共享此目录的客户端主机2(配置项1...) 格式说明： 以#开始的行为注释 客户端主机格式： 12345678910anonymous # *表示不限制，即任何主机都能访问单个主机 #可以写具体的IPV4,IPV6，FQDN，主机名IP networks（网段） #两种掩码格式均支持172.18.0.0/255.255.0.0172.18.0.0/16wildcards #主机名通配，例如:*.wang.org，IP不可以netgroups #NIS域的主机组，@group_namegss/krb5i #这种写法来限制对使用rpcsec_gss安全性的客户端的访问 每个条目指定目录导出到的哪些主机，及相关的权限和选项 1234567891011121314151617181920默认选项：(ro,sync,root_squash,no_all_squash)ro,rw #只读和读写async #异步，数据变化后不立即写磁盘，先写入到缓冲区中，过一段时间再写入磁盘，性能高,安全性低sync #（1.0.0后为默认）同步，数据在请求时立即写入共享存储磁盘,性能低,安全性高root_squash #（默认）远程客户端主机上的root用户映射为nfsnobody,UID为65534的用户，CentOS8为nobody,CentOS7以前的版本为nfsnobodyno_root_squash #远程客户端主机root用户映射成NFS服务器的rootall_squash #所有远程客户端主机用户都映射成NFS主机上的UID=65534的用户，此项会覆盖no_root_squash，CentOS8为nobodyno_all_squash #（默认）保留共享文件的UID和GIDanonuid,anongid #指明匿名用户映射为特定用户UID和组GID，而非nobody,可配合all_squash使用,注意:目录需要给此用户权限,否则无法访问 insecure #允许非授权访问subtree_check #如果共享子目录，强制NFS 检查父目录权限no_subtree_check #不检查父目录权限wdelay #多个用户写时等待同时写no_wdelay #多个用户写时不等待，立即写，当使用 async 项时，无需此设置hide #不共享NFS 服务中的子目录，在 NFSv4中无效no_hide #共享NFS 服务器上的子目录，在 NFSv4中无效secure NFS #服务通过1024以下的安全TCP/IP端口通讯insecure NFS #服务通过1024以上的安全TCP/IP端口通讯 范例：NFS配置示例 12345678910111213[root@centos8 ~]#vim /etc/exports/myshare server.example.com/myshare *.example.com/myshare server?.example.com/myshare server[0-20].example.com/myshare 172.25.11.10/myshare 172.25.0.0/16/myshare 2000:472:18:b51:c32:a21/myshare 2000:472:18:b51::/64/myshare *.example.com 172.25.0.0/16/myshare desktop.example.com(ro)/myshare desktop.example.com(ro) server[0-20].example.com(rw)/myshare diskless.example.com(rw,no_root_squash) 范例：默认挂载 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#服务器[root@ubuntu ~]# mkdir /data/dir&#123;a,b&#125;[root@ubuntu ~]# cp /etc/fstab /data/dira/[root@ubuntu ~]# cat /etc/exports/data/dira *#读取配置，生效[root@ubuntu ~]# exportfs -r#查看[root@ubuntu ~]# exportfs -v/data/dira &lt;world&gt;(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash)[root@ubuntu ~]# mount10.0.0.208:/data/dira on /data/dir1 type nfs4(ro,relatime,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.0.0.206,local_lock=none,addr=10.0.0.208)#在客户端#查看NFS服务器上有什么共享文件夹[root@ubuntu ~]# showmount -e 10.0.0.208Export list for 10.0.0.208:/data/dira *[root@ubuntu ~]# mkdir -pv /data/dir&#123;1,2&#125;mkdir: created directory &#x27;/data&#x27;mkdir: created directory &#x27;/data/dir1&#x27;mkdir: created directory &#x27;/data/dir2&#x27;#将远程主机上的 /data/dira 目录挂载到本机的 /data/dir1 上[root@ubuntu ~]# mount 10.0.0.208:/data/dira /data/dir1#查看[root@ubuntu ~]# df -h /data/dir1/Filesystem Size Used Avail Use% Mounted on10.0.0.208:/data/dira 97G 7.4G 85G 9% /data/dir1[root@ubuntu ~]# ls -l /data/dir1total 4-rw-r--r-- 1 root root 657 Jul 9 09:58 fstab#可读[root@ubuntu ~]# cat /data/dir1/fstab# /etc/fstab: static file system information.#......#不可写[root@ubuntu ~]# echo &quot;123&quot; &gt;&gt; /data/dir1/fstab-bash: /data/dir1/fstab: Read-only file system[root@ubuntu ~]# touch /data/dir1/testtouch: cannot touch &#x27;/data/dir1/test&#x27;: Read-only file system 范例：指定客户端主机 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475[root@ubuntu ~]# cat /etc/exports#10.0.0.206 可读写， 10.0.0.150 默认选项/data/dira 10.0.0.206(rw) 10.0.0.150#生效[root@ubuntu ~]# exportfs -r[root@ubuntu ~]# exportfs -v/data/dira 10.0.0.206(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)/data/dira 10.0.0.150(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash)#206 主机上测试，还是可读不可写[root@ubuntu ~]# ls -l /data/dir1/total 4-rw-r--r-- 1 root root 657 Jul 9 09:58 fstab[root@ubuntu ~]# cat /data/dir1/fstab# /etc/fstab: static file system information.[root@ubuntu ~]# touch /data/dir1/test-206touch: cannot touch &#x27;/data/dir1/test-206&#x27;: Permission denied #权限不够#查看服务器上共享目录的权限[root@ubuntu ~]# ll /data/dira/total 4drwxr-xr-x 1 root root 657 Jul 9 09:58 /data/dira#虽然root上w权限，但是仅限于服务器的root，206虽然是以root用户远程连接，但是属于其他[root@ubuntu ~]#chmod 777 /data/dira#成功[root@ubuntu ~]# touch /data/dir1/test-206#客户端去服务器访问数据的时候，如果是以root身份，将映射成服务器的nobody用户，所以解释了为什么206虽然是以root用户远程连接，但是属于其他用户，之前无权限创建时因为没有给nobody用户授权[root@ubuntu ~]# ll /data/dir1/total 4-rw-r--r-- 1 root root 657 Jul 9 09:58 fstab-rw-r--r-- 1 nobody nogroup 0 Jul 9 10:02 test-206#所以解决权限问题有三种办法#第一种[root@ubuntu ~]#chown nobody /data/dira/#第二种[root@ubuntu ~]#setfacl -m u:nobody:rwx /data/dira/#第三种[root@ubuntu ~]# cat /etc/exports/data/dira 10.0.0.206(rw,no_root_squash) 10.0.0.150#150 主机上测试[root@rocky ~]# mkdir /data/dir&#123;1,2&#125;[root@rocky ~]# showmount -e 10.0.0.208Export list for 10.0.0.208:/data/dira 10.0.0.150,10.0.0.206#挂载[root@rocky ~]# mount 10.0.0.208:/data/dira /data/dir1#查看[root@rocky ~]# df /data/dir1/Filesystem 1K-blocks Used Available Use% Mounted on10.0.0.208:/data/dira 101590016 7749888 88633344 9% /data/dir1[root@rocky ~]# mount10.0.0.208:/data/dira on /data/dir1 type nfs4(rw,relatime,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.0.0.150,local_lock=none,addr=10.0.0.208)#查看，可读不可写[root@rocky ~]# ls -l /data/dir1total 4-rw-r--r-- 1 root root 657 Jul 9 09:58 fstab[root@rocky ~]# cat /data/dir1/fstab# /etc/fstab: static file system information.#[root@rocky ~]# touch /data/dir1/test-150touch: cannot touch &#x27;/data/dir1/test-150&#x27;: Read-only file system 范例：没有权限的主机无法挂载 12345678#10.0.0.210 主机[root@ubuntu ~]# showmount -e 10.0.0.208Export list for 10.0.0.208:/data/dira 10.0.0.150,10.0.0.206#当前主机不在NFS 服务器配置的客户端主机列表中，无法挂载[root@ubuntu ~]# mount 10.0.0.208:/data/dira /data/dir1mount.nfs: access denied by server while mounting 10.0.0.208:/data/dira 范例：网段写法 12[root@ubuntu ~]# cat /etc/exports/data/dira 10.0.0.0/24(rw) 范例：永久挂载 123#在客户端主机添加如下配置[root@ubuntu ~]# cat /etc/fstab10.0.0.208:/data/dira /var/www/html nfs defaults,_netdev 0 0 2.4 NFS工具2.4.1 rpcinforpcinfo 可以访问指定的 RPC 服务器，显示其响应信息，从而查询出在该服务器上注册的RPC服务，如果不指定主机，则默认是当前主机 查看注册在指定主机的RPC程序 1rpcinfo -p hostname 查看RPC注册程序 1rpcinfo -s hostname 范例 123456789101112131415#显示已注册到本机的所有RPC服务[root@ubuntu ~]# rpcinfo#显示已注册到本机的rpcbind V2 版本的 RPC 服务[root@ubuntu ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper #简短格式显示[root@ubuntu ~]# rpcinfo -s#查看远程主机[root@ubuntu ~]# rpcinfo -s 10.0.0.208 2.4.2 exportfsexportfs 命令用于管理本机 NFS 文件系统，默认配置文件是 &#x2F;etc&#x2F;exports 1234-v #查看本机所有NFS共享-r #重读配置文件，并共享目录-a #输出本机所有共享-au #停止本机所有共享 2.4.3 showmountshoumount 可以查看远程主机的共享设置 123456showmount [ -opt... ] [ host ]#常用选项-h|--help #显示帮助-a|--all #显示己连接的客户端-e|--exports #显示指定NFS服务器上的配置列表 常见用法： 12#查看远程主机的NFS共享showmount -e hostname 范例 123[root@centos7 ~]#showmount -e 10.0.0.8Export list for 10.0.0.8:/data/wordpress * 2.4.4 mount.nfs客户端 NFS 服务挂载命令，将远程NFS 服务器上共享出来的目录挂载到本机，可以直接写成 mount NFS相关的挂载选项：man 5 nfs 1234567891011121314151617#常用选项-r #只读挂载-v #显示详细信息-V #显示版本-w #读写挂载-n #不更新/etc/fstab 文件，默认项-o #指定挂载参数#常用挂载参数fg #（默认）前台挂载bg #后台挂载hard #（默认）持续请求，如果挂不上，一直重试soft #非持续请求intr #是否可以强制中断，配合hard 选项，如果挂不上，可以ctrl+c 中断rsize和wsize #指定一次读的最大字节数，值必须为1024的倍数，最大为1048576，最小为1024，如果小于1024会被替换成4096_netdev #无网络服务时不挂载NFS资源vers #指定版本，客户端centos8默认4.2 ，centos7默认4.1 centos6默认4.0，如果NFS 服务端不支持此版本，则无法挂载 提示：基于安全考虑，建议使用 nosuid , _netdev , noexec 挂载选项 范例：临时挂载NFS共享 1[root@ubuntu ~]# mount -o rw,fg,hard,intr 10.0.0.208:/testdir /mnt/nfs/ 范例: 12345678[root@centos7 ~]#mkdir /mnt/nfs[root@centos7 ~]#mount 10.0.0.8:/data/wordpress /mnt/nfs[root@centos7 ~]#ls /mnt/nfsindex.html[root@centos7 ~]#df -T /mnt/nfsFilesystem Type 1K-blocks Used Available Use% Mounted on10.0.0.8:/data/wordpress nfs4 52403200 398336 52004864 1% /mnt/nfs 范例：开机挂载 12#vim /etc/fstab 172.16.0.1:/public /mnt/nfs nfs defaults,_netdev 0 0 范例: 远程的 root 映射为NFS服务器的nobody用户 12345678910[root@centos6 ~]#grep nobody /etc/passwdnobody:x:99:99:Nobody:/:/sbin/nologinnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin[root@centos7 ~]#grep nobody /etc/passwdnobody:x:99:99:Nobody:/:/sbin/nologinnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin[root@centos8 ~]#grep nobody /etc/passwdnobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin 2.5 NFS 共享实现2.5.1 目标将NFS的共享目录，做为远程主机用户的家目录 2.5.2 环境准备 123456共三台主机一台主机 nfs serverIP:10.0.0.8另两台当 nfs clientIP:10.0.0.7IP:10.0.0.6 2.5.3 步骤2.5.3.1 在服务端配置共享1234567#NFS服务器创建用户和相应的家目录，将用户wang的家目录共享[root@centos8 ~]#yum -y install nfs-utils[root@centos8 ~]#systemctl enable --now nfs-server[root@centos8 ~]#mkdir -pv /data/home/wang[root@centos8 ~]#Vim /etc/exports.d/test.exports/data/home/wang *(rw)[root@centos8 ~]#exportfs -r 2.5.3.2 客户端配置123456789101112131415161718192021222324252627282930#在第一台NFS客户端主机10.0.0.7上实现[root@centos7 ~]#yum -y install nfs-utils[root@centos7 ~]#useradd -u 2000 wang[root@centos7 ~]#vim /etc/fstab10.0.0.8:/data/home/wang /home/wang nfs _netdev 0 0[root@centos7 ~]#mount -a[root@centos7 ~]#su - wangLast login: Fri Jul 3 16:33:34 CST 2020 on pts/0[wang@centos7 ~]$pwd/home/wang[wang@centos7 ~]$df /home/wang -TFilesystem Type 1K-blocks Used Available Use% Mounted on10.0.0.8:/data/home/wang nfs4 52403200 398464 52004736 1% /home/wang#在第二台NFS客户端主机10.0.0.6上实现[root@centos6 ~]#yum -y install nfs-utils[root@centos6 ~]#useradd -u 2000 wang[root@centos6 ~]#vim /etc/fstab10.0.0.8:/data/home/wang /home/wang nfs _netdev 0 0[root@centos6 ~]#su - wang[wang@centos6 ~]$pwd/home/wang[wang@centos6 ~]$df -T /home/wangFilesystem Type 1K-blocks Used Available Use% Mounted on10.0.0.8:/data/home/wang nfs 52403200 398464 52004736 1% /home/wang 2.5.3.3 用户映射12345678910111213141516171819202122232425262728293031323334353637383940414243#普通用户不映射#在客户机上以普通用户创建文件[wang@centos7 ~]$ touch /home/wang/wang.txt#客户机上显示属主属组是wang[wang@centos7 ~]$ ls -l /home/wang/wang.txt-rw-rw-r-- 1 wang wang 0 Jul 9 00:31 /home/wang/wang.txt#NFS 服务器上查看，找不到对应的用户，直接显示UID[root@centos8 ~]#ls -l /data/home/wang/wang.txt-rw-rw-r-- 1 2000 2000 0 Jul 9 00:31 /data/home/wang/wang.txt#NFS 服务器上以相同UID 创建用户,再查看[root@centos8 ~]#useradd -d /data/home/wang -u 2000 wang[root@centos8 ~]#ls -l /data/home/wang/wang.txt-rw-rw-r-- 1 wang wang 0 Jul 9 00:31 /data/home/wang/wang.txt#再次修改规则，all_squash 项会覆盖 no_root_squash[root@centos8 ~]#cat /etc/exports/data/www *(rw,no_root_squash,all_squash)#生效[root@centos8 ~]# exportfs -r[root@centos8 ~]# exportfs -v/data/www &lt;world&gt;(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,all_squash)#在客户端创建文件[root@centos7 ~]#touch /home/wang/wang1.txt[root@centos7 ~]#su - wang [wang@centos7 ~]$ touch /home/wang/wang2.txt[wang@centos7 ~]$ exitlogout#在客户端查看[root@centos7 ~]# ll /home/wang/wang&#123;1,2&#125;.txt-rw-r--r-- 1 nobody nogroup 0 Jul 9 08:51 /home/wang/wang2.txt-rw-rw-r-- 1 nobody nogroup 0 Jul 9 08:51 /home/wang/wang1.txt#在NFS服务端查看，普通用户和 root 都被映射[root@centos8 ~]# ll /data/home/wang/wang&#123;1,2&#125;.txt-rw-r--r-- 1 nobody nogroup 0 Jul 9 08:51 /data/home/wang/wang2.txt-rw-rw-r-- 1 nobody nogroup 0 Jul 9 08:51 /data/home/wang/wang1.txt 2.5.3.4 统一用户映射123456789101112131415161718192021222324#NFS 服务端配置[root@centos8 ~]# groupadd -g 12345 www[root@centos8 ~]# useradd -u 12345 -g 12345 -s /sbin/nologin www#指定映射用户，对 root 和普通用户都生效[root@centos7 ~]# cat /etc/exports/data/www *(rw,all_squash,anongid=12345,anonuid=12345)[root@ubuntu ~]# exportfs -r[root@ubuntu ~]# exportfs -v/data/www &lt;world&gt;(sync,wdelay,hide,no_subtree_check,anonuid=12345,anongid=12345 ,sec=sys,rw,secure,root_squash,all_squash)#客户端创建文件[root@centos7 ~]# touch /home/wang/wang3.txt[root@centos7 ~]# su - wang[wang@centos7 ~]$ touch /home/wang/wang4.txt[wang@centos7 ~]$ exitlogout#客户端查看[root@centos7 ~]# ll /home/wang/wang&#123;3,4&#125;.txt-rw-r--r-- 1 12345 12345 0 Jul 9 09:37 /home/wang/wang4.txt-rw-rw-r-- 1 12345 12345 0 Jul 9 09:37 /home/wang/wang3.txt 统一客户端主机用户和权限的方法 保证客户端主机使用相同的用户(相同的用户ID)对共享目录进行读写 在NFS 服务器上统一映射 新建服务器使用 LDAP（轻量级目录访问协议） 服务进行集中的帐号管理 3 数据的实时同步在生产环境，要将数据或文件进行实时同步，保证数据更新后其它节点能立即获得最新的数据，会需要两台主机的特定目录实现实时同步。比如，将NFS共享目录的数据文件，自动实时同步到备份服务器特定目录中 数据同步的两种方式 PULL：拉，使用定时任务的方式配合同步命令或脚本等，从指定服务器上将数据同步到本地，一般是周期性定时同步 PUSH：推，如果当前机器上的数据或文件发生更新了，立即推送到指定的节点上，可以做到实时同步 3.1 实时同步技术介绍实现实时同步的方法 inotify + rsync 方式实现数据同步,需自行编写脚本组合inotify和 rsync 实现 sersync ：前金山公司周洋（花椒直播）在 inotify+rsync 软件基础上进行开发的，功能更加强大 工作原理： 要利用监控服务（inotify），监控同步数据服务器目录中信息的变化 发现目录中数据产生变化，就利用rsync服务推送到备份服务器上 inotify： 异步的文件系统事件监控机制，利用事件驱动机制，而无须通过诸如cron等的轮询机制来获取事件，linux内核从2.6.13起支持 inotify，通过inotify可以监控文件系统中添加、删除，修改、移动等各种事件 1234[root@ubuntu2204 ~]#grep -i inotify /boot/config-5.15.0-52-genericCONFIG_INOTIFY_USER=y[root@centos8 ~]#grep -i inotify /boot/config-4.18.0-80.el8.x86_64CONFIG_INOTIFY_USER=y 实现inotify软件： inotify-tools sersync lrsyncd inotify+rsync使用方式 inotify 对同步数据目录信息的监控 rsync 完成对数据的同步 利用脚本进行结合 3.2 inotify + rsync 实现数据实时同步实现原理：利用内核中的 inotify 监控指定目录，当目录中的文件或数据发生变化时，立即调用 rsync 服务将数据推送到远程主机上。 3.2.1 实现 inotifyinotify 是一个内核，用于通知用户空间程序文件系统变化的机制，在监听到文件系统发生变化后，会向相应的应用程序发送事件，如文件增加，修改，删除等事件发生后可以立即让用户空间知道 项目地址 3.2.1.1 内核支持内核是否支持inotify Linux支持inotify的内核最小版本为 2.6.13，参看man 7 inotify 1234567891011121314151617181920212223242526#列出下面的文件，说明服务器内核支持inotify[root@centos8 ~]#ls -l /proc/sys/fs/inotify -rw-r--r-- 1 root root 0 Dec 7 10:10 max_queued_events-rw-r--r-- 1 root root 0 Dec 7 10:10 max_user_instances-rw-r--r-- 1 root root 0 Dec 6 05:54 max_user_watches#inotify事件队列最大长度，如值太小会出现Event Queue Overflow错误，默认16384, 生产环境建议调大,比如 27679[root@centos8 ~]#cat /proc/sys/fs/inotify/max_queued_events16384#每个用户创建inotify实例最大值，默认值128[root@centos8 ~]#cat /proc/sys/fs/inotify/max_user_instances128#每个inotify实例可以监视的文件的总数量（inotifywait 单进程），默认值：8192,建议调大[root@centos8 ~]#cat /proc/sys/fs/inotify/max_user_watches8192[root@ubuntu2204 ~]#cat /proc/sys/fs/inotify/max_queued_events16384[root@ubuntu2204 ~]#cat /proc/sys/fs/inotify/max_user_instances128[root@ubuntu2204 ~]#cat /proc/sys/fs/inotify/max_user_watches14281#一个用户可以最多开128个inotify实例，每个实例最多可以监控14165个文件 内核参数如果需要修改，可以配置文件 1234567891011121314[root@ubuntu ~]# cat /etc/sysctl.conffs.inotify.max_queued_events=66666fs.inotify.max_user_instances=256fs.inotify.max_user_watches=100000[root@ubuntu ~]# sysctl -pfs.inotify.max_queued_events = 66666fs.inotify.max_user_instances = 256fs.inotify.max_user_watches = 100000[root@centos8 ~]#cat /proc/sys/fs/inotify/*66666256100000 3.2.1.2 inotify-tools工具inotify 是内核中的功能模块，只能通过调用API接口的形式使用其功能，我们可以通过相关软件来对其进行操作，能实现内核中 inotify 调用的软件主要有：inotify-tools，sersync，lrsyncd inotify-tools参考文档 安装inotify-tools：基于epel源 12345678[root@data-centos8 ~]# yum -y install inotify-tools[root@data-ubuntu2004]#apt -y install inotify-tools#主要工具/usr/bin/fsnotifywait #fsnotify监控工具，fsnotify 是 inotify 的新版本/usr/bin/fsnotifywatch #fsnotify统计工具/usr/bin/inotifywait #实时监控指定目录的所有事件，在被监控的文件或目录上等待特定事件发生(open,close,write..)/usr/bin/inotifywatch #收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计 inotify-tools包主要工具： inotifywait： 在被监控的文件或目录上等待特定文件系统事件（open ，close，delete等）发生，常用于实时同步的目录监控 inotifywatch：收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计 inotifywait 命令 12345678910111213inotifywait [ options ] file1 [ file2 ] [ file3 ] [ ... ]-m, --monitor #始终保持事件监听-d, --daemon #以守护进程方式执行，和-m相似，配合-o使用-r, --recursive #递归监控目录数据信息变化-q, --quiet #输出少量事件信息--exclude &lt;pattern&gt; #指定排除文件或目录，使用扩展的正则表达式匹配的模式实现--excludei &lt;pattern&gt; #和exclude相似，不区分大小写-o, --outfile &lt;file&gt; #打印事件到文件中，相当于标准正确输出，注意：使用绝对路径-s, --syslogOutput #发送错误到syslog相当于标准错误输出--timefmt &lt;fmt&gt; #指定时间输出格式--format &lt;fmt&gt; #指定的输出格式；即实际监控输出内容-e #指定监听指定的事件，如果省略，表示所有事件都进行监听 inotifywait 的–timefmt 时间格式 参考 man 3 strftime 1234567%Y #年份信息，包含世纪信息%y #年份信息，不包括世纪信息%m #显示月份，范围 01-12%d #每月的第几天，范围是 01-31%H #小时信息，使用 24小时制，范围 00-23%M #分钟，范围 00-59%S #秒，范例 0-60 1--timefmt &quot;%Y-%m-%d %H:%M:%S&quot; inotifywait 的 –format 格式定义 12345%T #输出时间格式中定义的时间格式信息，通过 --timefmt option 语法格式指定时间信息%w #事件出现时，监控文件或目录的名称信息，相当于dirname%f #事件出现时，将显示监控目录下触发事件的文件或目录信息，否则为空，相当于basename%e #显示发生的事件信息，不同的事件默认用逗号分隔%Xe #显示发生的事件信息，不同的事件指定用X进行分隔 12--format &quot;%T %w%f event: %;e&quot;--format &#x27;%T %w %f&#x27; inotifywait -e 选项指定的事件类型 123456789101112131415create #文件或目录创建delete #文件或目录被删除modify #文件或目录内容被写入attrib #文件或目录属性改变close_write #文件或目录关闭，在写入模式打开之后关闭的close_nowrite #文件或目录关闭，在只读模式打开之后关闭的close #文件或目录关闭，不管读或是写模式open #文件或目录被打开lsdir #浏览目录内容moved_to #文件或目录被移动到监控的目录中moved_from #文件或目录从监控的目录中被移动move #文件或目录不管移动到或是移出监控目录都触发事件access #文件或目录内容被读取delete_self #文件或目录被删除，目录本身被删除unmount #取消挂载 范例： 1-e create,delete,moved_to,close_write,attrib，moved_from 范例：只监控一个事件 1234567891011121314151617181920[root@ubuntu ~]# tree /data//data/├── dir1└── dir22 directories, 0 files#开始监控[root@ubuntu ~]# inotifywait /data/Setting up watches.Watches established.#在另一个终端中执行[root@ubuntu ~]# ls /data/dir1 dir2#提示open事件并退出[root@ubuntu ~]# inotifywait /data/Setting up watches.Watches established./data/ OPEN,ISDIR 范例：持续监控 123456789101112131415161718192021222324252627282930313233[root@ubuntu ~]# inotifywait -m /data/Setting up watches.Watches established.#另一个终端操作[root@ubuntu ~]# ls /datadir1 dir2[root@ubuntu ~]# ls /data/dir1[root@ubuntu ~]# touch /data/test.txt#查看监控，一条命令可能有多个事件[root@ubuntu ~]# inotifywait -m /data/Setting up watches.Watches established./data/ OPEN,ISDIR/data/ ACCESS,ISDIR/data/ ACCESS,ISDIR/data/ CLOSE_NOWRITE,CLOSE,ISDIR/data/ OPEN,ISDIR dir1/data/ ACCESS,ISDIR dir1/data/ ACCESS,ISDIR dir1/data/ CLOSE_NOWRITE,CLOSE,ISDIR dir1/data/ CREATE test.txt/data/ OPEN test.txt/data/ ATTRIB test.txt #ATTRIB表示属性更改/data/ CLOSE_WRITE,CLOSE test.txt #CLOSE_WRITE表示有文件内容发生变化 #递归监控inotifywait -mrq /data/www --exclude=&quot;.*\\.swx|\\.swp&quot;/data/www/ OPEN f1.txt/data/www/ ACCESS f1.txt/data/www/ CLOSE_NOWRITE,CLOSE f1.txt 范例：持续后台监控，并指定输出格式 12345[root@ubuntu ~]# inotifywait -drq /data/ -o inotify.log --timefmt &quot;%Y-%m-%d %H:%M:%S&quot; --format &quot;%T %w%f event: %e&quot;[root@ubuntu ~]# cat inotify.log2023-07-11 14:45:53 /data/ event: OPEN,ISDIR2023-07-11 14:45:53 /data/ event: ACCESS,ISDIR2023-07-11 14:45:53 /data/ event: CLOSE_NOWRITE,CLOSE,ISDIR 范例：持续前台监控特定事件，指定输出格式 1234567891011121314[root@ubuntu ~]# ls /data/dir1 dir2 test.txt[root@ubuntu ~]# touch /data/test.log[root@ubuntu ~]# touch /data/test.log[root@ubuntu ~]# rm -f /data/test.log[root@ubuntu ~]# inotifywait -mrq /data/ --timefmt &quot;%F %H:%M:%S&quot; --format &quot;%T %w%f event:%;e&quot; -e create,delete,moved_to,close_write,attrib2023-07-11 14:58:03 /data/test.log event:CREATE2023-07-11 14:58:03 /data/test.log event:ATTRIB2023-07-11 14:58:03 /data/test.log event:CLOSE_WRITE;CLOSE2023-07-11 14:58:06 /data/test.log event:ATTRIB2023-07-11 14:58:06 /data/test.log event:CLOSE_WRITE;CLOSE2023-07-11 14:58:09 /data/test.log event:DELETE 范例：将结果输出到文件 123456789101112[root@ubuntu ~]# inotifywait -m -r /data/ -o inotify.txtSetting up watches. Beware: since -r was given, this may take a while!Watches established.[root@ubuntu ~]# ls /data/dir1 dir2 test.txt#查看结果文件[root@ubuntu ~]# cat inotify.txt/data/ OPEN,ISDIR/data/ ACCESS,ISDIR/data/ CLOSE_NOWRITE,CLOSE,ISDIR 范例：从文件中读取要监控的内容 123456[root@ubuntu ~]# cat a.txt/data/[root@ubuntu ~]# inotifywait -rm --fromfile a.txtSetting up watches. Beware: since -r was given, this may take a while!Watches established. 3.2.2 rsync 服务rsync 常用于做为 linux系统下的数据镜像备份工具，实现远程同步，支持本地复制，或者与其他SSH rsync主机同步数据，支持增量备份，配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时数据同步 官方网站 服务器软件包：rsync（Ubuntu20.04），rsync-daemon（CentOS 8） 服务文件：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rsyncd.service 配置文件：&#x2F;etc&#x2F;rsyncd.conf 端口：873&#x2F;tcp 123456789101112131415161718192021222324252627282930313233343536373839404142#Ubuntu默认提供了service文件[root@ubuntu2204 ~]#systemctl cat rsync.service# /lib/systemd/system/rsync.service[Unit]Description=fast remote file copy program daemonConditionPathExists=/etc/rsyncd.confAfter=network.targetDocumentation=man:rsync(1) man:rsyncd.conf(5)[Service]ExecStart=/usr/bin/rsync --daemon --no-detachRestartSec=1# Citing README.md:## [...] Using ssh is recommended for its security features.## Alternatively, rsync can run in `daemon&#x27; mode, listening on a socket.# This is generally used for public file distribution, [...]## So let&#x27;s assume some extra security is more than welcome here. We do full# system protection (which makes /usr, /boot, &amp; /etc read-only) and hide# devices. To override these defaults, it&#x27;s best to do so in the drop-in# directory, often done via `systemctl edit rsync.service`. The file needs# just the bare minimum of the right [heading] and override values.# See systemd.unit(5) and search for &quot;drop-in&quot; for full details.ProtectSystem=full#ProtectHome=on|off|read-onlyPrivateDevices=onNoNewPrivileges=on[Install]WantedBy=multi-user.target#红帽系统需要安装rsync-daemon包提供service文件[root@backup-centos8 ~]#dnf -y install rsync-daemon[root@backup-centos8 ~]#rpm -ql rsync-daemon/etc/rsyncd.conf/etc/sysconfig/rsyncd/usr/lib/systemd/system/rsyncd.service/usr/lib/systemd/system/rsyncd.socket/usr/lib/systemd/system/rsyncd@.service/usr/share/man/man5/rsyncd.conf.5.gz 3.2.2.1 rsync命令123456789101112#Local：代替cprsync [OPTION]... SRC [SRC]... DEST #本地文件同步#远程主机需要开启ssh协议rsync [OPTION]... [USER@]HOST:SRC [DEST] #PULL 拉，将远程主机上的文件拉到本地rsync [OPTION]... SRC [SRC]... [USER@]HOST:DEST #PUSH 推，将本地文件推送到远程主机上#远程主机需要开启rsync协议，需要搭建rsync服务器rsync [OPTION]... [USER@]HOST::SRC [DEST] #PULL 拉，将远程主机上的文件拉到本地rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] #PULL 拉，将远程主机上的文件拉到本地rsync [OPTION]... SRC [SRC]... [USER@]HOST::DEST #PUSH 推，将本地文件推送到远程主机上rsync [OPTION]... SRC [SRC]... rsync://[USER@]HOST[:PORT]/DEST #PUSH 推，将本地文件推送到远程主机上 rsync 有三种工作方式： 本地文件系统上实现同步。命令行语法格式为上述”Local”段的格式。 本地主机使用远程shell和远程主机通信。命令行语法格式为上述”Access via remote shell”段的格式。 本地主机通过网络套接字连接远程主机上的 rsync daemon。命令行语法格式为上述”Access via rsync daemon”段的格式。 前两者的本质是通过本地或远程shell，而第3种方式则是让远程主机上运行rsyncd服务，使其监听在一个端口上，等待客户端的连接 123456789101112131415161718192021222324252627282930-v #显示rsync过程中详细信息。可以使用&quot;-vvvv&quot;获取更详细信息。-P #显示文件传输的进度信息。(实际上&quot;-P&quot;=&quot;--partial --progress&quot;，其中的&quot;--progress&quot;才是显示进度信息的)。-n --dry-run #仅测试传输，而不实际传输。常和&quot;-vvvv&quot;配合使用来查看rsync是如何工作的。-a --archive #归档模式，表示递归传输并保持文件属性。等同于&quot;-rtopgDl&quot;。-r --recursive #递归到目录中去。-t --times #保持mtime属性。强烈建议任何时候都加上&quot;-t&quot;，否则目标文件mtime会设置为系统时间，导致下次更新检查出mtime不同从而导致增量传输无效。-o --owner #保持owner属性(属主)。-g --group #保持group属性(属组)。-p --perms #保持perms属性(权限，不包括特殊权限)。-D #是&quot;--device --specials&quot;选项的组合，即也拷贝设备文件和特殊文件。-l --links #如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象-z #传输时进行压缩提高效率-R --relative #使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性。用法见下文示例。--size-only #默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。-u --update #仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。-d --dirs #以不递归的方式拷贝目录本身。默认递归时，如果源为&quot;dir1/file1&quot;，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。--max-size #限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：&quot;--max-size=1.5m&quot;)--min-size #限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。--exclude #指定排除规则来排除不需要传输的文件。--delete #以SRC为主，对DEST进行同步。多则删之，少则补之。注意&quot;--delete&quot;是在接收端执行的，所以它是在exclude/include规则生效之后才执行的。-b --backup #对目标上已存在的文件做一个备份，备份的文件名后默认使用&quot;~&quot;做后缀。--backup-dir #指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。-e #指定所要使用的远程shell程序，默认为ssh。--port #连接daemon时使用的端口号，默认为873端口。--password-file #daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码。-W --whole-file #sync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。--existing #要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。--ignore-existing #要求只更新目标端不存在的文件。和&quot;--existing&quot;结合使用有特殊功能，见下文示例。--remove-source-files #要求删除源端已经成功传输的文件--bwlimit=RATE #指定限速,单位默为为MB/s 开启服务方式 1234rsync --daemon服务方式（守护进程）：持续运行，后台执行，一般都有对应的配置文件命令方式：一次性，前台执行，ls -l -a 范例：实现 rsync daemon 服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#在备份服务器启动 rsync 进程，启动失败，因为 /etc/rsyncd.conf 配置文件不存在[root@backup-centos8 ~]#rsync --daemonFailed to parse config file: /etc/rsyncd.conf#创建空配置文件[root@backup-centos8 ~]#touch /etc/rsyncd.conf[root@backup-centos8 ~]#rsync --daemon#监听 873 端口[root@backup-centos8 ~]#ss -ntlp|grep rsyncLISTEN 0 5 0.0.0.0:873 0.0.0.0:* users:((&quot;rsync&quot;,pid=2921,fd=4)) LISTEN 0 5 [::]:873 [::]:* users:((&quot;rsync&quot;,pid=2921,fd=5)) #修改服务端配置，指定共享目录[root@backup-centos8 ~]#cat /etc/rsyncd.conf[backup] #对外给用户看到的共享名path = /data/backup/ #定义一个文件夹实现共享，实际的共享名 read only = no #指定可读写,默认只读#Ubuntu要重启，centos不用，直接生效[root@ubuntu ~]# systemctl restart rsync.service#查看rsync服务器的模块名称[root@data-centos8 ~]#rsync rsync://10.0.0.18backup#两种写法都可以， :: 表示走rsync协议[root@data-centos8 ~]#rsync 10.0.0.18::backup##访问rsync服务器的共享目录，看到有文件[root@data-centos8 ~]#rsync rsync://10.0.0.18/backupdrwxr-xr-x 19 2023/12/11 17:23:49 .-rw-r--r-- 0 2023/12/11 17:23:49 a.txt#拉[root@data-centos8 ~]#rsync 10.0.0.18::backup/* .[root@data-centos8 ~]#rsync rsync://10.0.0.18/backup/* .[root@data-centos8 ~]#lsanaconda-ks.cfg a.txt #推#传输文件到远程失败，此处的 root 是指rsync服务的用户，当前服务端并没有配置此信息，默认会被映射成 nobody#注意：Ubuntu的nobody的组为nogroup，centos8nobody的组为nobody[root@data-centos8 ~]#rsync /etc/hosts 10.0.0.18::backup/hosts.txtrsync: mkstemp &quot;/.hosts.txt.84dX4G&quot; (in backup) failed: Permission denied (13)rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1189) [sender=3.1.3]#指定目录给nobody权限，默认用户以nobody访问此目录[root@backup-centos8 ~]#setfacl -m u:nobody:rwx /data/backup/#现在使用的是匿名连接[root@data-centos8 ~]#rsync /etc/networks root@10.0.0.18::backup #默认所有用户都映射为nobody用户[root@data-centos8 ~]#rsync /etc/issue wang@10.0.0.18::backup #wang用户在服务端并不存在[root@data-centos8 ~]#rsync /etc/passwd 10.0.0.18::backup[root@data-centos8 ~]#rsync /etc/shells rsync://root@10.0.0.18/backup#服务端查看，属主属组都是 nobody[root@backup-centos8 backup]#ll /data/backup/total 16-rw-r--r-- 1 root root 0 Dec 11 17:23 a.txt-rw-r--r-- 1 nobody nobody 23 Dec 11 17:53 issue-rw-r--r-- 1 nobody nobody 58 Dec 11 17:52 networks-rw-r--r-- 1 nobody nobody 1522 Dec 11 17:53 passwd-rw-r--r-- 1 nobody nobody 44 Dec 11 17:53 shells 3.2.2.2 以独立服务方式运行rsync并实现验证功能范例：以独立服务方式运行 rsync 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#创建rsync服务器的配置文件，指定映射账号，指定日志文件，指定远程连接用户名和密码，禁用匿名连接[root@centos8 ~]#vi /etc/rsyncd.confuid = root #指定以哪个用户身份访问共享目录，默认为nobody,注意:共享目录需要给此用户权限,否则无法访问gid = root #指定以哪个组身份访问共享目录，默认为nobody,Ubuntu中为nogroup#port = 874 #可指定非标准端口,默认873/tcp#use chroot = nomax connections = 0 #最大并发连接数，0表示不限制ignore errors #有错误可以跳过exclude = lost+found/ #排除lost+found目录，lost+found目录是在ext4文件系统才有，在/boot下，有些文件在使用的时候，因为文件系统出了问题等，使文件找不到自己所在的目录，那么就会放在lost+found目录里log file = /var/log/rsyncd.log #日志文件pid file = /var/run/rsyncd.pid #pid文件，存主进程编号lock file = /var/run/rsyncd.lock #锁文件，避免这个服务（多个进程）重复启动reverse lookup = no #反向解析 #hosts allow = 10.0.0.0/24[backup] #每个模块名对应一个不同的path目录，如果同名后面模块生效path = /data/backup/ comment = backup dir #描述read only = no #默认是yes,即只读auth users = rsyncuser #验证用户信息，必须以rsyncuser用户，并且以/etc/rsync.pas里存的密码成对验证才能访问， 默认anonymous可以访问rsync服务器secrets file = /etc/rsync.pas#配置文件内容[root@ubuntu2204 ~]#cat /etc/rsyncd.confuid = rootgid = rootmax connections = 0ignore errorsexclude = lost+found/log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.lockreverse lookup = no[backup]path = /data/backup/comment = backup dirread only = noauth users = rsyncusersecrets file = /etc/rsync.pas#服务器端准备目录[root@backup-centos8 ~]#mkdir -pv /data/backup#服务器端生成验证文件[root@backup-centos8 ~]#echo &quot;rsyncuser:123456&quot; &gt; /etc/rsync.pas[root@backup-centos8 ~]#chmod 600 /etc/rsync.pas#服务器端启动rsync服务[root@backup-centos8 ~]#rsync --daemon #可加入/etc/rc.d/rc.local实现开机启动[root@backup-centos8 ~]#systemctl start rsyncd #CentOS 7 以上版本[root@ubuntu ~]# systemctl restart rsync.service#客户端配置密码文件#也可将密码赋值给环境变量RSYNC_PASSWORD变量,但不安全#export RSYNC_PASSWORD=123456 [root@data-centos8 ~]#echo &quot;123456&quot; &gt; /etc/rsync.pas[root@data-centos8 ~]#chmod 600 /etc/rsync.pas #此为必要项,权限必须修改#查看远程rsync服务器的模块信息[root@data-server ~]#rsync rsync://rsync服务器IPbackup backup dir#交互式验证查看具体模块内的文件[root@data-server ~]#rsync rsync://rsyncuser@rsync服务器IP/backupPassword:#非交互式查看共享目录[root@data-server ~]#rsync --password-file=/etc/rsync.pas rsync://rsyncuser@rsync服务器IP/backup#客户端测试同步数据[root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas /data/www/ rsyncuser@rsync服务器IP::backup[root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas rsyncuser@rsync服务器IP::backup /data/www/ 3.3 inotify+rsync+shell 脚本实现实时数据同步 注意: 此脚本执行前先确保两主机初始数据处于同步状态,此脚本实现后续的数据同步 12345678910111213141516[root@data-centos8 ~]#vim inotify_rsync.sh#!/bin/bashSRC=&#x27;/data/www/&#x27; #注意最后的/DEST=&#x27;rsyncuser@rsync服务器IP::backup&#x27;#Ubuntu20.04不支持 --password-file=/etc/rsync.pas，可以使用下面的变量实现export RSYNC_PASSWORD=123456#rpm -q inotify-tools &amp;&gt; /dev/null ||yum -y install inotify-tools#rpm -q rsync &amp;&gt; /dev/null || yum -y install rsyncinotifywait -mrq --exclude=&quot;.*\\.swp&quot; --timefmt &#x27;%Y-%m-%d %H:%M:%S&#x27; --format &#x27;%T %w %f&#x27; -e create,delete,moved_from,moved_to,close_write,attrib $&#123;SRC&#125; | while read DATE TIME DIR FILE;do FILEPATH=$&#123;DIR&#125;$&#123;FILE&#125; rsync -az --delete $SRC $DEST &amp;&amp; echo &quot;At $&#123;TIME&#125; on $&#123;DATE&#125;, file $FILEPATH was backuped up via rsync&quot; &gt;&gt; /var/log/changelist.log #rsync -az --delete --password-file=/etc/rsync.pas $SRC $DEST &amp;&amp; echo &quot;At $&#123;TIME&#125; on $&#123;DATE&#125;, file $FILEPATH was backuped up via rsync&quot; &gt;&gt; /var/log/changelist.logdone#查看文件传输日志[root@data-centos8 ~]#tail -f /var/log/changelist.log 后台执行 121 开启screen窗口2 nohup bash inotify_rsync.sh &amp;&gt;/dev/dull &amp; 3.4 sersync 实现实时数据同步3.4.1 sersync 介绍sersync类似于inotify，同样用于监控，但它克服了inotify的缺点，功能更加强大 inotify最大的不足是会产生重复事件，或者同一个目录下多个文件的操作会产生多个事件，例如，当监控目录中有5个文件时，删除目录时会产生6个监控事件，从而导致重复调用rsync命令。另外比如：vim文件时，inotify会监控到临时文件的事件，但这些事件相对于rsync来说是不应该被监控的 sersync 优点： sersync是使用c++编写，而且对linux系统文件系统产生的临时文件和重复的文件操作进行过滤， 所以在结合rsync同步的时候，节省了运行时耗和网络资源。因此更快。 sersync配置很简单，其中提供了静态编译好的二进制文件和xml配置文件，直接使用即可 sersync使用多线程进行同步，尤其在同步较大文件时，能够保证多个服务器实时保持同步状态 sersync有出错处理机制，通过失败队列对出错的文件重新同步，如果仍旧失败，则按设定时长对同步失败的文件重新同步 sersync不仅可以实现实时同步，另外还自带crontab功能，只需在xml配置文件中开启，即也可以按要求隔一段时间整体同步一次，而无需再额外配置crontab功能 sersync使用场景 网站数据实时备份：自动同步网站服务器上的数据变更到备份服务器。 集群数据一致性维护：在多个服务器之间同步文件，保持数据的一致性。 文件共享：在不同的机器或位置之间实时共享文件数据。 sersync 配合 rsync 使用，可以实现较为高效和稳定的文件同步解冗，特别适用于对实时性要求较高的环境。sersync 可以二次开发 同步原理 在Master服务器上开启sersync服务，sersync负责监控配置路径中文件系统事件的变化； Master服务器上面的sersync服务调用rsync命令把更新的文件推送到目标服务器Slave上面； 在Master服务器上面安装sersync服务及要确保有rsync命令，在Slave服务器上面配置rsync server。 sersync项目地址 sersync下载地址 123456789101112131415#下载[root@ubuntu ~]# wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz#解压[root@ubuntu ~]# tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz[root@ubuntu ~]# lsGNU-Linux-x86 sersync2.5.4_64bit_binary_stable_final.tar.gz snap[root@ubuntu ~]# ls GNU-Linux-x86/confxml.xml sersync2#移动[root@ubuntu ~]# mv GNU-Linux-x86/ /usr/local/sersync[root@ubuntu ~]# ls /usr/local/sersync/confxml.xml sersync2 sersync2 命令用法和参数 123456789101112131415[root@ubuntu sersync]# ./sersync2 -hset the system paramexecute：echo 50000000 &gt; /proc/sys/fs/inotify/max_user_watchesexecute：echo 327679 &gt; /proc/sys/fs/inotify/max_queued_eventsparse the command param_______________________________________________________参数-d:启用守护进程模式参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍c参数-n: 指定开启守护线程的数量，默认为10个参数-o:指定配置文件，默认使用confxml.xml文件参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块参数-m:单独启用其他模块，使用 -m socket 开启socket模块参数-m:单独启用其他模块，使用 -m http 开启http模块不加-m参数，则默认执行同步程序________________________________________________________________ 3.4.2 基于rsync daemon 实现 sersync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#在数据服务器上下载sersync，并拷贝至相应的目录，设置PATH变量[root@data-centos8 ~]#wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz[root@data-centos8 ~]#tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz[root@data-centos8 ~]#cp -a GNU-Linux-x86 /usr/local/sersync[root@data-centos8 ~]#echo &#x27;PATH=/usr/local/sersync:$PATH&#x27; &gt;/etc/profile.d/sersync.sh[root@data-centos8 ~]#source /etc/profile.d/sersync.sh#sersync目录只有两个文件：一个是二进制程序文件，一个是xml格式的配置文件[root@data-centos8 ~]#ls /usr/local/sersync/confxml.xml sersync2#确认安装rsync客户端工具[root@data-centos8 ~]#rpm -q rsync &amp;&gt; /dev/null || dnf -y install rsync#备份sersync配置文件[root@data-centos8 ~]#cp /usr/local/sersync/confxml.xml&#123;,.bak&#125;#修改sersync配置文件[root@data-centos8 ~]#vim /usr/local/sersync/confxml.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;head version=&quot;2.5&quot;&gt; &lt;host hostip=&quot;localhost&quot; port=&quot;8008&quot;&gt;&lt;/host&gt; &lt;debug start=&quot;false&quot;/&gt; #是否开启调试模式 &lt;fileSystem xfs=&quot;false&quot;/&gt; &lt;filter start=&quot;false&quot;&gt; #不开启文件过滤功能，当为true时,以下类型的文件将不同步 &lt;exclude expression=&quot;(.*)\\.svn&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;(.*)\\.gz&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;^info/*&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;^static/*&quot;&gt;&lt;/exclude&gt; &lt;/filter&gt; &lt;inotify&gt; #监控事件，默认监控delete/close_write/moved_from/moved_to/create folder &lt;delete start=&quot;true&quot;/&gt; &lt;createFolder start=&quot;true&quot;/&gt; &lt;createFile start=&quot;false&quot;/&gt; &lt;closeWrite start=&quot;true&quot;/&gt; &lt;moveFrom start=&quot;true&quot;/&gt; &lt;moveTo start=&quot;true&quot;/&gt; &lt;attrib start=&quot;true&quot;/&gt; #修改此行为true，文件属性变化后也会同步 &lt;modify start=&quot;false&quot;/&gt; &lt;/inotify&gt; &lt;sersync&gt; #rsync命令的配置段 &lt;localpath watch=&quot;/data/www&quot;&gt; #修改此行,需要同步的源目录或文件，建议同步目录 &lt;remote ip=&quot;备份服务器IP&quot; name=&quot;backup&quot;/&gt; #修改此行,指定远程主机地址和目录，即备份服务器地址和rsyncdaemon的模块名，如果下面开启了ssh start，此时name为远程shell方式运行时的目标目录 &lt;!--&lt;remote ip=&quot;192.168.8.39&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;!--&lt;remote ip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params=&quot;-artuz&quot;/&gt; #指定rsync选项 &lt;auth start=&quot;true&quot; users=&quot;rsyncuser&quot; passwordfile=&quot;/etc/rsync.pas&quot;/&gt; #修改此行为true,指定备份服务器的rsync配置的用户和密码文件 &lt;userDefinedPort start=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt; #指定rsync的非标准端口号 &lt;timeout start=&quot;false&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt; &lt;ssh start=&quot;false&quot;/&gt; #默认使用rsync daemon运行rsync命令,true为使用远程shell模式 &lt;/rsync&gt; &lt;failLog path=&quot;/tmp/rsync_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--default every 60mins execute once--&gt; #错误重传及日志文件路径 &lt;crontab start=&quot;false&quot; schedule=&quot;600&quot;&gt;&lt;!--600mins--&gt; #不开启crontab功能 &lt;crontabfilter start=&quot;false&quot;&gt; #不开启crontab定时传输的筛选功能 &lt;exclude expression=&quot;*.php&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;info/*&quot;&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start=&quot;false&quot; name=&quot;command&quot;/&gt; &lt;/sersync&gt;#####################################以下行不需要修改#################################### &lt;plugin name=&quot;command&quot;&gt; &lt;param prefix=&quot;/bin/sh&quot; suffix=&quot;&quot; ignoreError=&quot;true&quot;/&gt; &lt;!--prefix /opt/tongbu/mmm.sh suffix--&gt; &lt;filter start=&quot;false&quot;&gt; &lt;include expression=&quot;(.*)\\.php&quot;/&gt; &lt;include expression=&quot;(.*)\\.sh&quot;/&gt; &lt;/filter&gt; &lt;/plugin&gt; &lt;plugin name=&quot;socket&quot;&gt; &lt;localpath watch=&quot;/opt/tongbu&quot;&gt; &lt;deshost ip=&quot;192.168.138.20&quot; port=&quot;8009&quot;/&gt; &lt;/localpath&gt; &lt;/plugin&gt; &lt;plugin name=&quot;refreshCDN&quot;&gt; &lt;localpath watch=&quot;/data0/htdocs/cms.xoyo.com/site/&quot;&gt; &lt;cdninfo domainname=&quot;ccms.chinacache.com&quot; port=&quot;80&quot; username=&quot;xxxx&quot;passwd=&quot;xxxx&quot;/&gt; &lt;sendurl base=&quot;http://pic.xoyo.com/cms&quot;/&gt; &lt;regexurl regex=&quot;false&quot; match=&quot;cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images&quot;/&gt; &lt;/localpath&gt; &lt;/plugin&gt;&lt;/head&gt;#创建连接rsynd服务器的用户密码文件,并必须修改权限[root@data-centos8 ~]#echo 123456 &gt; /etc/rsync.pas[root@data-centos8 ~]#chmod 600 /etc/rsync.pas#以后台方式执行同步[root@data-centos8 ~]#sersync2 -dro /usr/local/sersync/confxml.xmlset the system paramexecute：echo 50000000 &gt; /proc/sys/fs/inotify/max_user_watchesexecute：echo 327679 &gt; /proc/sys/fs/inotify/max_queued_eventsparse the command paramoption: -d run as a daemonoption: -r rsync all the local files to the remote servers before the sersyncworkoption: -o config xml name： /usr/local/sersync/confxml.xmldaemon thread num: 10parse xml config filehost ip : localhost host port: 8008daemon start，sersync run behind the consoleuse rsync password-file :user is rsyncuserpasswordfile is /etc/rsync.pasconfig xml parse successplease set /etc/rsyncd.conf max connections=0 Manuallysersync working thread 12 = 1(primary thread) + 1(fail retry thread) +10(daemon sub threads)Max threads numbers is: 22 = 12(Thread pool nums) + 10(Sub threads)please according your cpu ，use -n param to adjust the cpu rate------------------------------------------rsync the directory recursivly to the remote servers onceworking please wait...#如果同步失败,可以手动执行下面命令,观察过程[root@data-centos8 ~]# cd /data/www &amp;&amp; rsync -artuz -R --delete ./ rsyncuser@backup-server::backup --password-file=/etc/rsync.pas &gt;/dev/null 2&gt;&amp;1run the sersync:watch path is: /data/www________________________________________________________________ #sersync支持多实例，也即监控多个目录时，只需分别配置不同配置文件，然后使用sersync2指定对应配置文件运行[root@data-centos8 ~]#sersync2 -rd -o /etc/sersync.d/nginx.xml 3.4.3 基于远程shell 实现 sersync1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#不需要配置rsync daemon,只需要配置基于key验证的ssh即可[root@data-centos8 ~]#ssh-keygen[root@data-centos8 ~]#ssh-copy-id backup-server#下载sersync，并拷贝至相应的目录，设置PATH变量同5.5.2#修改sersync配置文件[root@data-centos8 ~]#cat /usr/local/sersync/confxml.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;head version=&quot;2.5&quot;&gt; &lt;host hostip=&quot;localhost&quot; port=&quot;8008&quot;&gt;&lt;/host&gt; &lt;debug start=&quot;false&quot;/&gt; &lt;fileSystem xfs=&quot;false&quot;/&gt; &lt;filter start=&quot;false&quot;&gt; &lt;exclude expression=&quot;(.*)\\.svn&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;(.*)\\.gz&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;^info/*&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;^static/*&quot;&gt;&lt;/exclude&gt; &lt;/filter&gt; &lt;inotify&gt; &lt;delete start=&quot;true&quot;/&gt; &lt;createFolder start=&quot;true&quot;/&gt; &lt;createFile start=&quot;false&quot;/&gt; &lt;closeWrite start=&quot;true&quot;/&gt; &lt;moveFrom start=&quot;true&quot;/&gt; &lt;moveTo start=&quot;true&quot;/&gt; &lt;attrib start=&quot;true&quot;/&gt; #修改此行为true &lt;modify start=&quot;false&quot;/&gt; &lt;/inotify&gt; &lt;sersync&gt; &lt;localpath watch=&quot;/data/www&quot;&gt; #修改此行,指定源数据目录 &lt;remote ip=&quot;备份服务器IP&quot; name=&quot;/data/backup&quot;/&gt; #修改此行指定备份服务器地址和备份目标目录 &lt;!--&lt;remote ip=&quot;192.168.8.39&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;!--&lt;remote ip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params=&quot;-artuz&quot;/&gt; &lt;auth start=&quot;false&quot; users=&quot;root&quot; passwordfile=&quot;/etc/rsync.pas&quot;/&gt; #必须修改此行,不启用认证start=false &lt;userDefinedPort start=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt; &lt;timeout start=&quot;false&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt; &lt;ssh start=&quot;true&quot;/&gt; #修改此行为true,使用远程shell方式的rsync连接方式，无需在目标主机上配置启动rsync daemon服务 #####################################以下行不需要修改#################################### &lt;/rsync&gt; &lt;failLog path=&quot;/tmp/rsync_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--default every 60mins execute once--&gt; &lt;crontab start=&quot;false&quot; schedule=&quot;600&quot;&gt;&lt;!--600mins--&gt; &lt;crontabfilter start=&quot;false&quot;&gt; &lt;exclude expression=&quot;*.php&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;info/*&quot;&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start=&quot;false&quot; name=&quot;command&quot;/&gt; &lt;/sersync&gt;#将中间的行可以删除&lt;/head&gt;[root@data-centos8 ~]#sersync2 -dro /usr/local/sersync/confxml.xmlset the system paramexecute：echo 50000000 &gt; /proc/sys/fs/inotify/max_user_watchesexecute：echo 327679 &gt; /proc/sys/fs/inotify/max_queued_eventsparse the command paramoption: -d run as a daemonoption: -r rsync all the local files to the remote servers before the sersyncworkoption: -o config xml name： /apps/sersync/confxml.xmldaemon thread num: 10parse xml config filehost ip : localhost host port: 8008daemon start，sersync run behind the consoleconfig xml parse successplease set /etc/rsyncd.conf max connections=0 Manuallysersync working thread 12 = 1(primary thread) + 1(fail retry thread) +10(daemon sub threads)Max threads numbers is: 22 = 12(Thread pool nums) + 10(Sub threads)please according your cpu ，use -n param to adjust the cpu rate------------------------------------------rsync the directory recursivly to the remote servers onceworking please wait...execute command: cd /data/www &amp;&amp; rsync -auz -R --delete ./ -e ssh10.0.0.18:/data/backup &gt;/dev/null 2&gt;&amp;1run the sersync:watch path is: /data/www 4 实战案例：实现基于分布式的LAMP架构，并将NFS实时同步到备份服务器 配置 说明 10.0.0.176（centos） DNS 10.0.0.177 MySQL 10.0.0.179（rocky） Web 10.0.0.180 Web 10.0.0.182（Ubuntu） NFS 10.0.0.183 NFS BACKUP 配置DNS 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@DNS ~]#yum -y install bind bind-utils[root@DNS ~]#systemctl enable --now named[root@DNS ~]#vim /etc/named.rfc1912.zoneszone &quot;wu.org&quot; IN &#123; type master; file &quot;wu.org.zone&quot;;&#125;;[root@DNS ~]#vim /etc/named.conf // listen-on port 53 &#123; 127.0.0.1; &#125;;// allow-query &#123; localhost; &#125;;[root@DNS ~]#vim /var/named/wu.org.zone$TTL 1D@ IN SOA wu.org. admin.wu.com. (1 3H 1M 1D 1W) NS master master A 10.0.0.176www A 10.0.0.179www A 10.0.0.180[root@DNS ~]#chmod 640 /var/named/wu.org.zone [root@DNS ~]#chgrp named /var/named/wu.org.zone[root@DNS ~]#named-checkconf[root@DNS ~]#named-checkzone wu.org /var/named/wu.org.zone[root@DNS ~]#rndc reload#测试[root@DNS ~]#host www.wu.org 127.0.0.1Using domain server:Name: 127.0.0.1Address: 127.0.0.1#53Aliases: www.wu.org has address 10.0.0.179www.wu.org has address 10.0.0.180C:\\Users\\Administrator&gt;nslookup&gt; server 10.0.0.176默认服务器: [10.0.0.176]Address: 10.0.0.176&gt; www.wu.org服务器: [10.0.0.176]Address: 10.0.0.176名称: www.wu.orgAddresses: 10.0.0.180 10.0.0.179 #Switchhosts软件10.0.0.179 www.wu.orgC:\\Users\\Administrator&gt;ping www.wu.org正在 Ping www.wu.org [10.0.0.179] 具有 32 字节的数据:来自 10.0.0.179 的回复: 字节=32 时间&lt;1ms TTL=64来自 10.0.0.179 的回复: 字节=32 时间&lt;1ms TTL=64 配置Web1和MySQL 123456789101112131415161718192021222324252627[root@Web1 ~]#yum -y install httpd php php-mysqlnd php-json nfs-utils[root@Web1 ~]#systemctl enable --now httpd[root@Web1 ~]#wget https://cn.wordpress.org/latest-zh_CN.zip[root@Web1 ~]#unzip latest-zh_CN.zip[root@Web1 ~]#mv wordpress/* /var/www/html/[root@Web1 ~]#chown apache.apache /var/www/html/ -R[root@MySQL ~]#yum install -y mysql-server[root@MySQL ~]#systemctl enable --now mysqld#Ubuntu默认开启mysql，但是要改端口指向地址vim /etc/mysql/mysql.conf.d/mysqld.cnf#bind...#mysql...systemctl restart mysqlmysql&gt; create database wordpress;mysql&gt; create user wordpress@&#x27;10.0.0.%&#x27; identified by &#x27;123456&#x27;;mysql&gt; grant all on wordpress.* to wordpress@&#x27;10.0.0.%&#x27;;Windows访问：www.wu.org[root@Web1 ~]#cd /var/www/html/wp-content/[root@Web1 wp-content]#lsindex.php languages plugins themes uploads#说明themes:主题uploads：图片 配置NFS 12345678910111213141516171819202122232425262728293031323334353637383940[root@NFS ~]#apt update &amp;&amp; apt install -y nfs-server[root@NFS ~]#mkdir -p /data/www[root@NFS ~]#mkdir /etc/exports.d[root@NFS ~]#vim /etc/exports.d/wordpress.exports/data/www 10.0.0.0/24(rw)[root@NFS ~]#exportfs -r[root@NFS ~]#groupadd -g 48 apache[root@NFS ~]#useradd -u 48 -g 48 apache[root@NFS ~]#chown -R apache.apache /data/www/#说明如果web服务器为Ubuntu，就只需执行chown -R www-data.www-data /data/www/，因为Ubuntu共有www-data账号[root@Web1 ~]#rsync -av /var/www/html/ 10.0.0.182:/data/www/[root@NFS ~]#ll /data/www/total 244drwxr-xr-x 5 apache apache 4096 Dec 13 06:23 ./drwxr-xr-x 3 root root 4096 Dec 13 06:50 ../-rw-r--r-- 1 apache apache 228 Dec 13 06:23 .htaccess-rw-r--r-- 1 apache apache 405 Feb 6 2020 index.php-rw-r--r-- 1 apache apache 19915 Dec 6 18:09 license.txt-rw-r--r-- 1 apache apache 7399 Dec 6 18:09 readme.html-rw-r--r-- 1 apache apache 7211 May 12 2023 wp-activate.phpdrwxr-xr-x 9 apache apache 4096 Dec 6 18:00 wp-admin/-rw-r--r-- 1 apache apache 351 Feb 6 2020 wp-blog-header.php-rw-r--r-- 1 apache apache 2323 Jun 14 14:11 wp-comments-post.php-rw-rw-rw- 1 apache apache 3293 Dec 13 06:09 wp-config.php-rw-r--r-- 1 apache apache 3013 Dec 6 18:09 wp-config-sample.phpdrwxr-xr-x 6 apache apache 4096 Dec 13 06:28 wp-content/-rw-r--r-- 1 apache apache 5638 May 30 2023 wp-cron.phpdrwxr-xr-x 27 apache apache 12288 Dec 6 18:09 wp-includes/-rw-r--r-- 1 apache apache 2502 Nov 26 2022 wp-links-opml.php-rw-r--r-- 1 apache apache 3927 Jul 16 12:16 wp-load.php-rw-r--r-- 1 apache apache 50924 Sep 29 22:01 wp-login.php-rw-r--r-- 1 apache apache 8525 Sep 16 06:50 wp-mail.php-rw-r--r-- 1 apache apache 26409 Oct 10 14:05 wp-settings.php-rw-r--r-- 1 apache apache 34385 Jun 19 18:27 wp-signup.php-rw-r--r-- 1 apache apache 4885 Jun 22 14:36 wp-trackback.php-rw-r--r-- 1 apache apache 3154 Sep 30 07:39 xmlrpc.php 测试 123456789101112131415161718192021222324252627[root@Web1 ~]#showmount -e 10.0.0.182Export list for 10.0.0.182:/data/www 10.0.0.0/24[root@Web1 ~]#mv /var/www/html/* /opt/[root@Web1 ~]#vim /etc/fstab 10.0.0.182:/data/www /var/www/html nfs _netdev 0 0 [root@Web1 ~]#mount -a[root@Web1 ~]#dfFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 894016 0 894016 0% /devtmpfs 914116 0 914116 0% /dev/shmtmpfs 914116 8936 905180 1% /runtmpfs 914116 0 914116 0% /sys/fs/cgroup/dev/mapper/rl-root 17811456 2600584 15210872 15% //dev/sda1 1038336 217304 821032 21% /boottmpfs 182820 0 182820 0% /run/user/010.0.0.182:/data/www 10219008 3314688 6363648 35% /var/www/html[root@Web1 ~]#ls /var/www/html/index.php wp-admin wp-config-sample.php wp-links-opml.php wp-settings.phplicense.txt wp-blog-header.php wp-content wp-load.php wp-signup.phpreadme.html wp-comments-post.php wp-cron.php wp-login.php wp-trackback.phpwp-activate.php wp-config.php wp-includes wp-mail.php xmlrpc.php#Windows访问正常 配置Web2 12345678910111213141516171819202122232425[root@Web2 ~]#yum -y install httpd php php-mysqlnd php-json nfs-utils[root@Web2 ~]#systemctl enable --now httpd[root@Web2 ~]#vim /etc/fstab 10.0.0.182:/data/www /var/www/html nfs _netdev 0 0 [root@Web2 ~]#mount -a[root@Web2 ~]#dfFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 894016 0 894016 0% /devtmpfs 914116 0 914116 0% /dev/shmtmpfs 914116 8916 905200 1% /runtmpfs 914116 0 914116 0% /sys/fs/cgroup/dev/mapper/rl-root 17811456 2431172 15380284 14% //dev/sda1 1038336 217304 821032 21% /boottmpfs 182820 0 182820 0% /run/user/010.0.0.182:/data/www 10219008 3314688 6363648 35% /var/www/html[root@Web2 ~]#ls /var/www/html/index.php wp-admin wp-config-sample.php wp-links-opml.php wp-settings.phplicense.txt wp-blog-header.php wp-content wp-load.php wp-signup.phpreadme.html wp-comments-post.php wp-cron.php wp-login.php wp-trackback.phpwp-activate.php wp-config.php wp-includes wp-mail.php xmlrpc.php#Switchhosts软件10.0.0.180 www.wu.org 配置backup 1234567891011121314151617181920212223242526272829303132333435363738394041[root@BACKUP ~]#vim /etc/rsyncd.confuid = rootgid = rootmax connections = 0ignore errorsexclude = lost+found/log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.lockreverse lookup = no[backup]path = /data/backup/comment = backup dirread only = noauth users = rsyncusersecrets file = /etc/rsync.pas[root@BACKUP ~]#mkdir -pv /data/backup[root@BACKUP ~]#echo &quot;rsyncuser:123456&quot; &gt; /etc/rsync.pas[root@BACKUP ~]#chmod 600 /etc/rsync.pas[root@BACKUP ~]#systemctl restart rsync.service[root@NFS ~]#tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz -C /usr/local/[root@NFS ~]#cd /usr/local/[root@NFS local]#lsbin etc games GNU-Linux-x86 include lib man sbin share src[root@NFS local]#ln -s GNU-Linux-x86/ sersync[root@NFS local]#ln -s /usr/local/sersync/sersync2 /usr/local/bin/[root@NFS local]#cd sersync[root@NFS sersync]#rm -rf confxml.xml [root@NFS sersync]#rz[root@NFS sersync]#lsconfxml.xml sersync2[root@NFS sersync]#vim confxml.xml&lt;remote ip=&quot;10.0.0.183&quot; name=&quot;backup&quot;/&gt;[root@NFS sersync]#echo 123456 &gt; /etc/rsync.pas[root@NFS sersync]#chmod 600 /etc/rsync.pas 测试 1234567891011121314151617181920212223[root@NFS ~]#sersync2 -dro /usr/local/sersync/confxml.xml后台执行：nohup sersync2 -dro /usr/local/sersync/confxml.xml &amp;&gt; /dev/null &amp;[root@BACKUP ~]#ls /data/backup/index.php wp-admin wp-config-sample.php wp-links-opml.php wp-settings.phplicense.txt wp-blog-header.php wp-content wp-load.php wp-signup.phpreadme.html wp-comments-post.php wp-cron.php wp-login.php wp-trackback.phpwp-activate.php wp-config.php wp-includes wp-mail.php xmlrpc.php[root@BACKUP ~]#tree /data/backup/wp-content/uploads//data/backup/wp-content/uploads/└── 2023 └── 12 └── image.png1#Windows发表新的文章[root@BACKUP ~]#tree /data/backup/wp-content/uploads//data/backup/wp-content/uploads/└── 2023 └── 12 └── image.png1 └── image.png2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"日志服务","slug":"Linux/service-manage/log","date":"2025-08-20T08:52:09.000Z","updated":"2025-08-28T12:33:05.349Z","comments":true,"path":"Linux/service-manage/log/","permalink":"https://aquapluto.github.io/Linux/service-manage/log/","excerpt":"","text":"1 系统日志管理1.1 系统日志介绍在现实生活中，记录日志非常重要﹐比如:银行转账时会有转账记录﹔飞机飞行过程中的黑盒子（飞行数据记录器）记录着飞机的飞行过程. 那么将系统和应用发生的事件记录至日志中，也很意义,常可以助于排错和分析使用 日志记录的内容包括： 历史事件：时间，地点，人物，事件 日志级别：事件的关键性程度，Loglevel 1.1.1 sysklogd 系统日志服务CentOS 5 之前版本采用的日志管理系统服务 klogd: linux kernel 记录内核日志 syslogd: system application 记录应用日志 事件记录格式： 日期时间 主机 进程[pid]: 事件内容 C&#x2F;S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主机的日志实现集中管理 1.1.2 rsyslog 系统日志服务rsyslog是CentOS 6 以后版本的系统管理服务.它提供了高性能，出色的安全性和模块化设计。 尽管rsyslog最初是常规的syslogd，但已发展成为一种瑞士军刀式的记录工具，能够接受来自各种来源的输入，并将其转换，然后输出到不同的目的地。 当应用有限的处理时，RSYSLOG每秒可以将超过一百万的消息传递到本地目的地。 即使在远程的目的地和更精细的处理中，性能通常也被认为是“惊人的”。 官方网站:https://www.rsyslog.com/ rsyslog 特性 多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式 适用于企业级中继链 rsyslog 会默认安装 1234567891011[root@rocky ~]# rpm -q rsyslogrsyslog-8.2102.0-7.el8.x86_64[root@ubuntu ~]# dpkg -l rsyslogDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-==============-===================-============-=========================================ii rsyslog 8.2112.0-2ubuntu2.2 amd64 reliable system and kernel logging daemon 1.1.3 ELKELK：由Elasticsearch, Logstash, Kibana三个软件组成 非关系型分布式数据库 基于Apache软件基金会jakarta项目组的项目lucene Elasticsearch是个开源分布式搜索引擎，可以处理大规模日志数据，比如：Nginx、Tomcat、系统日志等功能 Logstash对日志进行收集、分析，过滤，并将其存储供以后使用 Kibana 可以提供的日志分析友好的 Web 界面 rsyslog 日志服务与 ELK 日志服务的区别： rsyslog 主要用于单机日志管理 ELK 主要用于分布式集群环境中的日志管理。 1.2 Rsyslog 管理1.2.1 系统日志术语facility：设施，从功能或程序上对日志进行归类 在一台主机上会同时运行多个服务和软件，每个服务或软件都有可能会产生大量的日志，如果每个服务或软件产生的日志都独立存放管理，那文件数量就太多了，如果都放到一个文件中，似乎也不是很合适，所以 syslog 将日志进行了分类，相同类型的日志放一个文件，这样便于管理 123456789101112131415161718#syslog 内置分类LOG_AUTH #auth 安全和认证相关的日志LOG_AUTHPRIV #authpriv 安全和认证相关的日志，私有LOG_CRON #cron 系统定时任务 crontab 与 at 产生的相关日志LOG_DAEMON #daemon 各守护进程产生的日志LOG_FTP #ftp ftp守护进程产生的日志LOG_KERN #kern 内核产生的日志LOG_LOCAL0 -- LOG_LOCAL7 #local0-local7 自定义分类LOG_LPR #lpr 打印服务日志LOG_MAIL #mail 邮件服务日志LOG_NEWS #news 网络新闻服务产生的日志LOG_SYSLOG #syslog syslogd 服务自己的日志LOG_USER #user 用户等级LOG_UUCP #uucp uucp子系统的日志信息* #通配符，代表所有分类#自定义的分类local0-local7 #保留给本机用户使用的一些登录文件讯息，终端信息等 Priority 优先级别 rsyslog 在记录日志的时候，将各种产生日志的事件和行为进行了优先级的排序，使用者可以根据不同环境(测试&#x2F;生产)和需求，设置不同的级别来记录日志，这样可以保证，记录下来的内容都是是我们想要的 123456789101112#syslog 内置优先级分类，从高到低，如果在记录日志时，设置了优先级，则只会记录设定的优先级和高于设定优先级的日志LOG_EMERG #emerg/panic 紧急，致命错误LOG_ALERT #alert 告警，当前状态必须立即进行纠正LOG_CRIT #crit 关键状态的警告，例如 硬件故障LOG_ERR #err/error 其它错误LOG_WARNING #warning/warn 警告级别的信息LOG_NOTICE #notice 通知级别的信息，LOG_INFO #info 通告级别的信息LOG_DEBUG #debug 调试程序时的信息* #所有级别的日志none #不需要任何日志 #panic,error,warn在新版中被弃，不建议使用 参看帮助： man 3 syslog，man logger 12[root@centos8 ~]#yum -y install man-pages[root@centos8 ~]#man 3 syslog 1.2.2 rsyslog 相关文件 程序包：rsyslog 主程序：&#x2F;usr&#x2F;sbin&#x2F;rsyslogd Ubuntu: &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rsyslog.service CentOS 6：&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;rsyslog {start|stop|restart|status} CentOS 7,8：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rsyslog.service 配置文件：&#x2F;etc&#x2F;rsyslog.conf，&#x2F;etc&#x2F;rsyslog.d&#x2F;.conf 库文件： &#x2F;lib64&#x2F;rsyslog&#x2F;*.so 1.2.3 rsyslog配置文件&#x2F;etc&#x2F;rsyslog.conf 配置文件格式：由三部分组成 MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置，ubuntu 系统中，默认 rule 规则是单独放在一个文件中的 Ubuntu的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@ubuntu ~]# cat /etc/rsyslog.conf# Default logging rules can be found in /etc/rsyslog.d/50-default.conf##################### MODULES ##################### #rsyslog 在安装是有很多支持模块，但默认不是所有模块都开启，如果有需要，写在MODULES范围即可module(load=&quot;imuxsock&quot;) # provides support for local system logging#module(load=&quot;immark&quot;) # provides --MARK-- message capability# provides UDP syslog reception #UDP模块，默认没有启用#module(load=&quot;imudp&quot;)#input(type=&quot;imudp&quot; port=&quot;514&quot;)# provides TCP syslog reception #TCP 模块，默认没有启用#module(load=&quot;imtcp&quot;)#input(type=&quot;imtcp&quot; port=&quot;514&quot;)# provides kernel logging support and enable non-kernel klog messagesmodule(load=&quot;imklog&quot; permitnonkernelfacility=&quot;on&quot;) #内核日志需要的模块############################### GLOBAL DIRECTIVES ################################# Use traditional timestamp format.# To enable high precision timestamps, comment out the following line.#$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat #默认日志模板# Filter duplicated messages$RepeatedMsgReduction on #默认开启重复过滤## Set the default permissions for all log files.##创建日志文件的默认权限和属主属组$FileOwner syslog $FileGroup adm$FileCreateMode 0640$DirCreateMode 0755$Umask 0022$PrivDropToUser syslog$PrivDropToGroup syslog## Where to place spool and state files#$WorkDirectory /var/spool/rsyslog #工作目录，默认目录为空## Include all config files in /etc/rsyslog.d/#$IncludeConfig /etc/rsyslog.d/*.conf #独立配置文件引用目录[root@ubuntu2004 ~]#ll /var/log/syslog-rw-r----- 1 syslog adm 43342 Dec 8 14:22 /var/log/syslog[root@ubuntu2004 ~]#ls /etc/rsyslog.d/*.conf/etc/rsyslog.d/20-ufw.conf /etc/rsyslog.d/21-cloudinit.conf /etc/rsyslog.d/50-default.conf RULES配置格式： 每一行 rule 由两列组成，分别是选择器和处理动作，选择器将过滤后的日志交由处理动作处理；选择器可以同时有多个，用分号分隔，处理动作也可以同时有多个，用 &amp; 分隔，处理动作中可以指定模板，不同的模板会生成不同的日志内容，模板可以自定义。 选择器有以下几种定义方式： 用分类和优先级来过滤，同一条 rule 中，分类和优先级都可以有多个，用逗号分隔 基于日志内容中的指定字段来过滤 基于表达式构建脚本来过滤 处理动作有以下几种： 输出到日志文件或某个特定设备 保存到数据库 发送给指定用户，该用户必须己登录，可以同时指定多个用户，用逗号分隔 传送到远程主机 通过管道传送给其它命令 丢弃日志，不处理 1facility.priority; facility.priority… target facility格式： 12* #所有的facility facility1,facility2,facility3,... #指定的facility列表 priority格式： 12345* #所有级别none #没有级别，即不记录PRIORITY #指定级别（含）以上的所有级别=PRIORITY #仅记录指定级别的日志信息!priority #排除指定的 priority，这种写法不能单独使用 target格式： 12345678910111213141516171819202122232425输出到日志文件或设备# /path/file 将日志内容写到指定文件，通常在/var/log/# -/path/file 将日志内容写到指定文件，-表示异步写入，异步表示把数据收到后，会先写入内存（缓冲区）中，过一会再写入/path/file# /dev/null 将日志内容输出到指定设备保存到数据库，保存到数据库要开启相应模块module (load=&quot;ommysql&quot;)*.* action(type=&quot;ommysql&quot; server=&quot;10.0.0.210&quot; db=&quot;rsyslog&quot; uid=&quot;rsysloger&quot; pwd=&quot;123456&quot;)发送给指定用户# root 将日志内容发送给用户 root# root,tom 将日志内容发送给用户 root 和 tom# * 将日志内容发送给所有己登录用户发送到远程主机，即日志服务器 # @host 把日志送往至指定的远程UDP日志服务器，@@host 将日志发送到远程TCP日志服务器# @192.168.2.123 使用 UDP 协议发送到远程主机，默认端口514# @@log.magedu.com:256 使用 TCP 协议发送到远程主机 256 端口，默认端口514# @(z6)[fe80::20c:29ff:fe7e:ce82] 使用 UPD 协议发送到远程主机(IPV6地址)，启用zlib压缩，压缩级别为9通过管道传送给其它命令，管道必须有名管道，要事先创建，此功能在 rsyslog8 版本后才支持 # | COMMAND，转发给其它命令处理不处理# stop 不处理，丢弃 Ubuntu 系统中默认 rule 配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@ubuntu2004 ~]#cat /etc/rsyslog.d/50-default.conf # Default rules for rsyslog.## For more information see rsyslog.conf(5) and /etc/rsyslog.conf## First some standard log files. Log by facility.#auth,authpriv.* /var/log/auth.log #登录验证相关的日志记录在auth.log中,要经常看，黑客登陆失败或成功会有记录*.*;auth,authpriv.none -/var/log/syslog #除了登录校验之外的日志，都记录在syslog中，异步写，建议将优先级改成info#cron.* /var/log/cron.log #计划任务#daemon.* -/var/log/daemon.logkern.* -/var/log/kern.log #内核所有日志都记录在kern.log 中，异步写#lpr.* -/var/log/lpr.logmail.* -/var/log/mail.log #邮件相关日志记录在 mail.log中，异步写#user.* -/var/log/user.log #用户账号## Logging for the mail system. Split it up so that# it is easy to write scripts to parse these files.##mail.info -/var/log/mail.info#mail.warn -/var/log/mail.warnmail.err /var/log/mail.err #邮件服务 err 及以上的日志记录在 mail.err 中## Some &quot;catch-all&quot; log files.##*.=debug;\\# auth,authpriv.none;\\# news.none;mail.none -/var/log/debug#*.=info;*.=notice;*.=warn;\\# auth,authpriv.none;\\# cron,daemon.none;\\# mail,news.none -/var/log/messages## Emergencies are sent to everybody logged in.#*.emerg :omusrmsg:* #所有致命错误信息，调用omusrmsg 模块发给所有登录用户## I like to have messages displayed on the console, but only on a virtual# console I usually leave idle.##daemon,mail.*;\\# news.=crit;news.=err;news.=notice;\\# *.=debug;*.=info;\\# *.=notice;*.=warn /dev/tty8 1.2.4 在本机自定义服务日志范例：将ssh服务的日志记录至自定义的local的日志设备 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#sshd服务日志默认是归属于 AUTH 分类，默认级别是 INFO[root@ubuntu2004 ~]#vim /etc/ssh/sshd_config# Logging#SyslogFacility AUTH#LogLevel INFO#根据配置，此日志记录在 /var/log/auth.log 中[root@ubuntu ~]# cat /etc/rsyslog.d/50-default.conf | grep &quot;^auth&quot;auth,authpriv.* /var/log/auth.log#查看日志，能看到相关内容[root@ubuntu ~]# tail -n 3 /var/log/auth.logJun 28 20:00:35 ubuntu2204 sshd[920]: Received signal 15; terminating.Jun 28 20:00:35 ubuntu2204 sshd[3431]: Server listening on 0.0.0.0 port 22.Jun 28 20:00:35 ubuntu2204 sshd[3431]: Server listening on :: port 22.#修改 sshd 服务日志的配置项，分类改到 LOCAL6，级别不改[root@ubuntu2004 ~]#vim /etc/ssh/sshd_config# Logging#SyslogFacility AUTH#LogLevel INFOSyslogFacility LOCAL6#可以新增配置文件sshd.log，也可以在原来文件中将local6分类的日志写入[root@ubuntu2004 ~]#vim /etc/rsyslog.d/sshd.conf[root@ubuntu2004 ~]#vim /etc/rsyslog.d/50-default.conf local6.info /var/log/sshd.log[root@ubuntu2004 ~]#systemctl restart rsyslog[root@ubuntu2004 ~]#systemctl restart sshd#生成/var/log/sshd.log[root@ubuntu2004 ~]#ll /var/log/sshd.log -rw-r----- 1 syslog adm 149 Dec 8 15:53 /var/log/sshd.log[root@ubuntu2004 ~]#tail -f /var/log/sshd.logDec 8 15:53:48 ubuntu2004 sshd[19015]: Server listening on 0.0.0.0 port 22.Dec 8 15:53:48 ubuntu2004 sshd[19015]: Server listening on :: port 22.#测试[root@ubuntu2004 ~]#ssh 127.0.0.1[root@ubuntu2004 ~]#tail -f /var/log/sshd.log....Dec 8 15:55:54 ubuntu2004 sshd[19080]: Accepted password for root from 10.0.0.1 port 64271 ssh2Dec 8 15:56:09 ubuntu2004 sshd[19225]: Accepted password for root from 127.0.0.1 port 33988 ssh2Dec 8 15:56:18 ubuntu2004 sshd[19225]: Received disconnect from 127.0.0.1 port 33988:11: disconnected by userDec 8 15:56:18 ubuntu2004 sshd[19225]: Disconnected from user root 127.0.0.1 port 33988[root@ubuntu2004 ~]#logger -p local6.info &quot;hello sshd&quot;[root@ubuntu2004 ~]#tail -f /var/log/sshd.log....Dec 8 15:56:59 ubuntu2004 root: hello sshd 1.2.5 rsyslog 日志内容和模板通常的日志文件的格式： 日志文件有很多，如： &#x2F;var&#x2F;log&#x2F;messages,cron,secure等，基本格式都是类似的。格式如下 1事件产生的日期时间（默认精确到秒） 主机 应用程序程序名[进程](pid)：事件内容 centos日志文件格式 123456789[root@centos8 ~]#tail /var/log/messagesNov 12 08:34:18 centos8 dnf[14114]: Metadata cache created.Nov 12 08:34:18 centos8 systemd[1]: Started dnf makecache.....[root@centos8 ~]#tail /var/log/secureNov 11 18:27:12 centos8 groupadd[11940]: group added to /etc/group: name=dhcpd,GID=177Nov 11 18:27:12 centos8 groupadd[11940]: group added to /etc/gshadow: name=dhcpd... Ubuntu 中日志内容 123456789[root@ubuntu ~]# tail /var/log/syslogMay 2 03:56:07 ubuntu systemd[1]: systemd-rfkill.service: Deactivatedsuccessfully.May 2 05:37:36 ubuntu systemd-resolved[87114]: Clock change detected. Flushingcaches.......[root@ubuntu ~]# tail /var/log/auth.logMay 2 03:54:07 ubuntu sshd[903]: Received signal 15; terminating.May 2 03:54:08 ubuntu sshd[87070]: Server listening on 0.0.0.0 port 22....... 日志内容由 template 决定，如果没有显式指定，默认使用 RSYSLOG_TraditionalFileFormat，其具体内容如下 12template(name=&quot;RSYSLOG_TraditionalFileFormat&quot; type=&quot;string&quot;string=&quot;%TIMESTAMP% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\\n&quot;) rsyslog 中有13个内置的模板，我们可以在配置文件中直接使用，其名称如下，具体定义的内容需要查询相关文档 https://www.rsyslog.com/doc/v8-stable/configuration/templates.html 12345678910111213RSYSLOG_TraditionalFileFormatRSYSLOG_FileFormatRSYSLOG_TraditionalForwardFormatRSYSLOG_SysklogdFileFormatRSYSLOG_ForwardFormatRSYSLOG_SyslogProtocol23FormatRSYSLOG_DebugFormatRSYSLOG_WallFmtRSYSLOG_StdUsrMsgFmtRSYSLOG_StdDBFmtRSYSLOG_StdPgSQLFmtRSYSLOG_spoofadrRSYSLOG_StdJSONFmt 除了使用内置模板外，我们还可以自定义模板。 自定义模板可以直接写在配置文件中 生成的日志内容模板决定，而模板是由 rsyslog 中的相关属性组成，这些属性在生成日志内容时会被替换成具体内容。所谓属性是指rsyslog 中的一些特殊关键字，在模板语法中，使用 %属性名% 来表示一个字段 范例：启用高精度时间 12345678910111213141516171819202122232425#默认日志时间精确到秒，可以修改配置实现[root@ubuntu2204 ~]#head /var/log/syslogOct 29 02:27:39 ubuntu2204 systemd-modules-load[521]: Inserted module &#x27;msr&#x27;Oct 29 02:27:39 ubuntu2204 systemd-modules-load[521]: Inserted module&#x27;ipmi_devintf&#x27;Oct 29 02:27:39 ubuntu2204 lvm[506]: 1 logical volume(s) in volume group&quot;ubuntu-vg&quot; monitoredOct 29 02:27:39 ubuntu2204 systemd[1]: Mounted FUSE Control File System.Oct 29 02:27:39 ubuntu2204 systemd[1]: Mounted Kernel Configuration File System......[root@ubuntu2204 ~]#vi /etc/rsyslog.conf############################### GLOBAL DIRECTIVES ################################将下面行注释#$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat[root@ubuntu2204 ~]#systemctl restart rsyslog#验证结果[root@ubuntu2204 ~]#tail /var/log/syslog2022-12-09T19:21:21.717291+08:00 ubuntu2204 systemd[1]: Stopping System Logging Service...2022-12-09T19:21:21.721852+08:00 ubuntu2204 rsyslogd: [originsoftware=&quot;rsyslogd&quot; swVersion=&quot;8.2112.0&quot; x-pid=&quot;818&quot; x-info=&quot;https://www.rsyslog.com&quot;] exiting on signal 15.2022-12-09T19:21:21.729966+08:00 ubuntu2204 systemd[1]: rsyslog.service:Deactivated successfully.2022-12-09T19:21:21.730558+08:00 ubuntu2204 systemd[1]: Stopped System Logging Service.2022-12-09T19:21:21.732955+08:00 ubuntu2204 systemd[1]: Starting System Logging Service... 1.2.6 日志相关工具dmesg 命令 dmesg 命令用来查看主机硬件相关日志 logger 命令 logger 命令可以手动生成相关日志 12345678910logger [options] [&lt;message&gt;]#常用选项-p|--priority #指定优先级-f|--file #从文件中读取日志内容-t|--tag #指定日志tag-n|--server #指定远程主机IP或主机名-P|--port #指定远程主机端口-T|--tcp #指定使用TCP协议传输-d|--udp #指定使用UDP协议传输 范例 12345678910111213#无选项[root@ubuntu ~]# logger &quot;this is test msg&quot;root@ubuntu2204:~# tail -n 1 /var/log/syslogMay 3 07:07:08 ubuntu2204 root: this is test msg[root@ubuntu ~]# cat test.txtthis msg from test.txt#从文件中读取，指定tag，指定优先级[root@ubuntu ~]# logger -t test -f test.txt -p error[root@ubuntu ~]# tail -n 1 /var/log/syslogMay 4 14:09:53 ubuntu test: this msg from test.txt 1.2.7 案例：启用网络日志服务启用网络日志服务功能，可以使用 rsyslog 服务中的远程转发功能，通过 TCP 或 UDP 协议将多个远程主机的日志，发送到集中的日志服务器，进行集中存储，方便统一管理 配置 rsyslog 主机，开启 TCP, UDP 相关功能 123456789101112131415161718#启用相关模块, 去掉 UDP,TCP 模块的注释[root@rsyslog ~]#vim /etc/rsyslog.conf# provides UDP syslog receptionmodule(load=&quot;imudp&quot;)input(type=&quot;imudp&quot; port=&quot;514&quot;)# provides TCP syslog receptionmodule(load=&quot;imtcp&quot;)input(type=&quot;imtcp&quot; port=&quot;514&quot;)#重启服务[root@rsyslog ~]#systemctl restart rsyslog.service#查看端口[root@ubuntu ~]# ss -tunlp | grep 514udp UNCONN 0 0 0.0.0.0:514 0.0.0.0:* users:((&quot;rsyslogd&quot;,pid=3995,fd=5))udp UNCONN 0 0 [::]:514 [::]:* users:((&quot;rsyslogd&quot;,pid=3995,fd=6))tcp LISTEN 0 25 0.0.0.0:514 0.0.0.0:* users:((&quot;rsyslogd&quot;,pid=3995,fd=7))tcp LISTEN 0 25 [::]:514 [::]:* users:((&quot;rsyslogd&quot;,pid=3995,fd=8)) 配置 client-1 主机日志远程转发 123456789[root@ubuntu2004 ~]#hostnamectl set-hostname client-1#配置远程转发，转发到 10.0.0.180 的tcp和udp协议514端口,默认514可以省略[root@client-1 ~]#vim /etc/rsyslog.d/50-default.conf*.info @@10.0.0.180:514 #TCP*.info @10.0.0.180:514 #UDP#重启服务[root@client-1 ~]# systemctl restart rsyslog 根据 rsyslog 主机中的配置，转发过来的日志会被写到 &#x2F;var&#x2F;log&#x2F;messages 文件中 12345678910111213[root@rsyslog ~]#vim /etc/rsyslog.conf*.info;mail.none;authpriv.none;cron.none /var/log/messages#测试-在client-1主机上写入日志[root@client-1 ~]# logger &quot;this msg from client-1&quot;#client-1 主机上也有该日志[root@client-1 ~]#tail -f /var/log/syslogMar 20 07:08:40 client-1 root: this msg from client-1#在 rsyslog 上查看[root@rsyslog ~]#tail -f /var/log/messagesMar 20 07:10:01 client-1 root: this msg from client-1 配置 client-2 主机日志远程转发 123456789101112131415161718#配置远程转发，转发到10.0.0.18的tcp和udp协议514端口,默认514可以省略[root@client-2 ~]# vim /etc/rsyslog.conf*.info @@10.0.0.18:514 #TCP*.info @10.0.0.18:514 #UDP#重启服务[root@client-2 ~]# systemctl restart rsyslog.service#测试[root@client-2 ~]# logger &quot;this msg from client-2&quot;#本机查看[root@client-1 ~]#tail -f /var/log/syslogMar 20 07:08:40 client-1 root: this msg from client-2#log-server 查看[root@rsyslog ~]#tail -f /var/log/messagesMar 20 07:10:01 client-1 root: this msg from client-2 范例：CentOS 7 和 6 启用网络日志功能 123456789vim /etc/rsyslog.conf####MODULES##### Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514# Provides TCP syslog reception$ModLoad imtcp$InputTCPServerRun 514 1.2.8 常见日志文件Rocky 中常见日志说明 12345678[root@rocky ~]# cat /etc/rsyslog.conf | grep -Ev &quot;^#|^$&quot;*.info;mail.none;authpriv.none;cron.none /var/log/messages #除了mail,authpriv,cron 之外都记录authpriv.* /var/log/secure #安全认证相关日志mail.* -/var/log/maillog #邮件服务相关日志cron.* /var/log/cron #定时任务相关日志*.emerg :omusrmsg:* #所有致命错误信息，调用omusrmsg发给所有登录用户uucp,news.crit /var/log/spooler #uucp,新闻相关日志local7.* /var/log/boot.log #操作系统启动流程日志 ubuntu 中常见日志说明 12345678910[root@ubuntu ~]# cat /etc/rsyslog.d/*conf | grep -Ev &quot;^#|^$&quot;:msg,contains,&quot;[UFW &quot; /var/log/ufw.log #ufw 服务日志:syslogtag, isequal, &quot;[CLOUDINIT]&quot; /var/log/cloud-init.log #cloud-init服务日志&amp; stop #其它不处理auth,authpriv.* /var/log/auth.log #auth,authpriv的日志*.*;auth,authpriv.none -/var/log/syslog #除了auth,authpriv之外的日志kern.* -/var/log/kern.log #内核产生的日志mail.* -/var/log/mail.log #邮件服务日志mail.err /var/log/mail.err #邮件服务err(含)以上日志*.emerg :omusrmsg:* #所有致命错误信息，调用omusrmsg发给所有登录用户 除了在 rsyslog 中定义的日志之外，系统中默认还有 btmp, lastlog, wtmp 三个日志文件，这三个文件都是非文本格式，无法直接打开，这三个文件需要经常看，巡检黑客攻击 &#x2F;var&#x2F;log&#x2F;secure，&#x2F;var&#x2F;log&#x2F;auth.log：系统安全日志，文本格式，应周期性分析 &#x2F;var&#x2F;log&#x2F;btmp：当前系统上，用户的失败尝试登录相关的日志信息，二进制格式，lastb命令进行查看 &#x2F;var&#x2F;log&#x2F;wtmp：当前系统上，用户正常登录系统的相关日志信息，二进制格式，last命令可以查看 12#显示系统关机项和运行级别更改last -x, --system &#x2F;var&#x2F;log&#x2F;lastlog：每一个用户最近一次的登录信息，二进制格式，lastlog命令可以查看 &#x2F;var&#x2F;log&#x2F;dmesg：CentOS7 之前版本系统引导过程中的日志信息，文本格式，开机后的硬件变化将不再记录，也可以通过专用命dmesg查看，可持续记录硬件变化的情况 &#x2F;var&#x2F;log&#x2F;boot.log 系统服务启动的相关信息，文本格式，Ubuntu无此文件 &#x2F;var&#x2F;log&#x2F;messages(红帽系统)，&#x2F;var&#x2F;log&#x2F;syslog (Ubuntu) ：系统中大部分的信息 &#x2F;var&#x2F;log&#x2F;anaconda : anaconda的日志，Ubuntu无此文件 范例 1234[root@rocky8 ~]#file /var/log/&#123;btmp,lastlog,wtmp&#125;/var/log/btmp: data/var/log/lastlog: dBase III DBT, version number 0, next free block index 1653273886/var/log/wtmp: firmware 0 v0 (revision 0) V2, 0 bytes or less, UNKNOWN2 0x2e322e78, at 0x0 0 bytes , at 0x0 0 bytes 范例：找到失败登录的IP 123456[root@centos8 ~]#awk &#x27;/Failed password/&#123;print $(NF-3)&#125;&#x27; /var/log/secure192.168.39.7192.168.39.18192.168.39.18[root@ubuntu2004 ~]#awk &#x27;/authentication failure/&#123;print $(NF-3)&#125;&#x27; /var/log/auth.log 范例：找出失败登录次数最多的前10个IP 1234567891011121314151617181920212223[root@centos8 ~]#lastb -f btmp-test1 | awk &#x27;&#123;print $3&#125;&#x27;|sort | uniq -c|sort -nr|head8374 112.64.33.387041 221.125.235.46502 183.247.184.2205970 203.190.163.1255297 202.89.0.273062 119.163.122.322961 124.126.248.62921 92.222.1.402896 112.65.170.1861955 118.97.213.118 [root@centos8 ~]#lastb -f btmp-test2 | awk &#x27;&#123;ip[$3]++&#125;END&#123;for(i in ip)&#123;print ip[i],i&#125;&#125;&#x27;|sort -nr|head86294 58.218.92.3743148 58.218.92.2618036 112.85.42.20110501 111.26.195.10110501 111.231.235.4910501 111.204.186.20710501 111.11.29.19910499 118.26.23.2256288 42.7.26.1424236 58.218.92.30 1.3 日志管理工具 journalctl在 systemd 为 1号进程的系统版本中，systemd 提供了一个集中的方式来处理所有来自进程，应用程序等的操作系统日志，所有这些日志事件都由 systemd 的 journald 守护进程来处理。journald 守护进程收集所有来自 Linux 操作系统的各种日志，并将其作为二进制数据存储在文件中。 以二进制数据集中记录事件、系统问题的好处有很多。例如，由于系统日志是以二进制而不是文本形式存储的，你可以以文本、JSON 对象等多种方式进行转译，以满足各种需求。另外，由于日志是按顺序存储的，通过对日志的日期&#x2F;时间操作，超级容易追踪到单个事件 CentOS 7 以后版，利用Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用 journalctl一个命令，查看所有日志（内核日志和应用日志）。 日志的配置文件： 1/etc/systemd/journald.conf journalctl命令格式 1journalctl [OPTIONS...] [MATCHES...] 选项说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216--no-full, --full, -l 如果字段内容超长则以省略号(...)截断以适应列宽。 默认显示完整的字段内容(超长的部分换行显示或者被分页工具截断)。 老旧的 -l/--full 选项 仅用于撤销已有的 --no-full 选项，除此之外没有其他用处。 -a, --all 完整显示所有字段内容， 即使其中包含不可打印字符或者字段内容超长。 -f, --follow 只显示最新的日志项，并且不断显示新生成的日志项。 此选项隐含了 -n 选项。 -e, --pager-end 在分页工具内立即跳转到日志的尾部。 此选项隐含了 -n1000 以确保分页工具不必缓存太多的日志行。 不过这个隐含的行数可以被明确设置的 -n 选项覆盖。 注意，此选项仅可用于 less(1) 分页器。 -n, --lines= 限制显示最新的日志行数。 --pager-end 与 --follow 隐含了此选项。 此选项的参数：若为正整数则表示最大行数； 若为 &quot;all&quot; 则表示不限制行数； 若不设参数则表示默认值10行。 --no-tail 显示所有日志行， 也就是用于撤销已有的 --lines= 选项(即使与 -f 连用)。 -r, --reverse 反转日志行的输出顺序， 也就是最先显示最新的日志。 -o, --output= 控制日志的输出格式。 可以使用如下选项： short 这是默认值， 其输出格式与传统的 syslog[1] 文件的格式相似， 每条日志一行。 short-iso 与 short 类似，只是将时间戳字段以 ISO 8601 格式显示。 short-precise 与 short 类似，只是将时间戳字段的秒数精确到微秒级别。 short-monotonic 与 short 类似，只是将时间戳字段的零值从内核启动时开始计算。 short-unix 与 short 类似，只是将时间戳字段显示为从&quot;UNIX时间原点&quot;(1970-1-1 00:00:00UTC)以来的秒数。 精确到微秒级别。 verbose 以结构化的格式显示每条日志的所有字段。 export 将日志序列化为二进制字节流(大部分依然是文本) 以适用于备份与网络传输(详见Journal Export Format[2] 文档)。 json 将日志项按照JSON数据结构格式化， 每条日志一行(详见 Journal JSON Format[3]文档)。 json-pretty 将日志项按照JSON数据结构格式化， 但是每个字段一行， 以便于人类阅读。 json-sse 将日志项按照JSON数据结构格式化，每条日志一行，但是用大括号包围， 以适应Server-Sent Events[4] 的要求。 cat 仅显示日志的实际内容， 而不显示与此日志相关的任何元数据(包括时间戳)。 --utc 以世界统一时间(UTC)表示时间 --no-hostname 不显示来源于本机的日志消息的主机名字段。 此选项仅对 short 系列输出格式(见上文)有效。 -x, --catalog 在日志的输出中增加一些解释性的短文本， 以帮助进一步说明日志的含义、 问题的解决方案、支持论坛、 开发文档、以及其他任何内容。 并非所有日志都有这些额外的帮助文本， 详见 Message Catalog Developer Documentation[5] 文档。 注意，如果要将日志输出用于bug报告， 请不要使用此选项。 -q, --quiet 当以普通用户身份运行时， 不显示任何警告信息与提示信息。 例如：&quot;-- Logs begin at...&quot;, &quot;-- Reboot --&quot; -m, --merge 混合显示包括远程日志在内的所有可见日志。 -b [ID][±offset], --boot=[ID][±offset] 显示特定于某次启动的日志， 这相当于添加了一个 &quot;_BOOT_ID=&quot; 匹配条件。 如果参数为空(也就是 ID 与 ±offset 都未指定)， 则表示仅显示本次启动的日志。 如果省略了 ID ， 那么当 ±offset 是正数的时候， 将从日志头开始正向查找， 否则(也就是为负数或零)将从日志尾开始反响查找。 举例来说， &quot;-b 1&quot;表示按时间顺序排列最早的那次启动， &quot;-b 2&quot;则表示在时间上第二早的那次启动； &quot;-b -0&quot;表示最后一次启动， &quot;-b -1&quot;表示在时间上第二近的那次启动， 以此类推。 如果 ±offset 也省略了， 那么相当于&quot;-b -0&quot;， 除非本次启动不是最后一次启动(例如用--directory 指定了另外一台主机上的日志目录)。 如果指定了32字符的 ID ， 那么表示以此 ID 所代表的那次启动为基准 计算偏移量(±offset)， 计算方法同上。 换句话说， 省略 ID 表示以本次启动为基准计算偏移量(±offset)。 --list-boots 列出每次启动的 序号(也就是相对于本次启动的偏移量)、32字符的ID、 第一条日志的时间戳、最后一条日志的时间戳。 -k, --dmesg 仅显示内核日志。隐含了 -b 选项以及 &quot;_TRANSPORT=kernel&quot; 匹配项。 -t, --identifier=SYSLOG_IDENTIFIER 仅显示 syslog[1] 识别符为 SYSLOG_IDENTIFIER 的日志项。 可以多次使用该选项以指定多个识别符。 -u, --unit=UNIT|PATTERN 仅显示属于特定单元的日志。 也就是单元名称正好等于 UNIT 或者符合 PATTERN 模式的单元。 这相当于添加了一个 &quot;_SYSTEMD_UNIT=UNIT&quot; 匹配项(对于 UNIT 来说)，或一组匹配项(对于 PATTERN 来说)。 可以多次使用此选项以添加多个并列的匹配条件(相当于用&quot;OR&quot;逻辑连接)。 --user-unit= 仅显示属于特定用户会话单元的日志。 相当于同时添加了 &quot;_SYSTEMD_USER_UNIT=&quot; 与&quot;_UID=&quot; 两个匹配条件。 可以多次使用此选项以添加多个并列的匹配条件(相当于用&quot;OR&quot;逻辑连接)。 -p, --priority= 根据日志等级(包括等级范围)过滤输出结果。 日志等级数字与其名称之间的对应关系如下 (参见 syslog(3))： &quot;emerg&quot; (0), &quot;alert&quot; (1), &quot;crit&quot; (2), &quot;err&quot; (3),&quot;warning&quot; (4), &quot;notice&quot; (5), &quot;info&quot; (6), &quot;debug&quot; (7) 。 若设为一个单独的数字或日志等级名称， 则表示仅显示小于或等于此等级的日志(也就是重要程度等于或高于此等级的日志)。 若使用 FROM..TO.. 设置一个范围， 则表示仅显示指定的等级范围内(含两端)的日志。 此选项相当于添加了 &quot;PRIORITY=&quot; 匹配条件。 -c, --cursor= 从指定的游标(cursor)开始显示日志。 [提示]每条日志都有一个&quot;__CURSOR&quot;字段，类似于该条日志的指纹。 --after-cursor= 从指定的游标(cursor)之后开始显示日志。 如果使用了 --show-cursor 选项，则也会显示游标本身。 --show-cursor 在最后一条日志之后显示游标， 类似下面这样，以&quot;--&quot;开头：-- cursor: s=0639... 游标的具体格式是私有的(也就是没有公开的规范)， 并且会变化。 -S, --since=, -U, --until= 显示晚于指定时间(--since=)的日志、显示早于指定时间(--until=)的日志。 参数的格式类似 &quot;2012-10-30 18:17:16&quot; 这样。 如果省略了&quot;时:分:秒&quot;部分，则相当于设为 &quot;00:00:00&quot; 。 如果仅省略了&quot;秒&quot;的部分则相当于设为 &quot;:00&quot; 。 如果省略了&quot;年-月-日&quot;部分， 则相当于设为当前日期。 除了&quot;年-月-日 时:分:秒&quot;格式，参数还可以进行如下设置： (1)设为 &quot;yesterday&quot;, &quot;today&quot;, &quot;tomorrow&quot;以表示那一天的零点(00:00:00)。 (2)设为 &quot;now&quot; 以表示当前时间。 (3)可以在&quot;年-月-日 时:分:秒&quot;前加上 &quot;-&quot;(前移) 或 &quot;+&quot;(后移) 前缀以表示相对于当前时间的偏移。 关于时间与日期的详细规范， 参见systemd.time(7) -F, --field= 显示所有日志中某个字段的所有可能值。 [译者注]类似于SQL语句：&quot;SELECT DISTINCT 某字段 FROM 全部日志&quot; -N, --fields 输出所有日志字段的名称 --system, --user 仅显示系统服务与内核的日志(--system)、 仅显示当前用户的日志(--user)。 如果两个选项都未指定，则显示当前用户的所有可见日志。 -M, --machine= 显示来自于正在运行的、特定名称的本地容器的日志。 参数必须是一个本地容器的名称。 -D DIR, --directory=DIR 仅显示来自于特定目录中的日志， 而不是默认的运行时和系统日志目录中的日志。 --file=GLOB GLOB 是一个可以包含&quot;?&quot;与&quot;*&quot;的文件路径匹配模式。 表示仅显示来自与指定的 GLOB模式匹配的文件中的日志， 而不是默认的运行时和系统日志目录中的日志。 可以多次使用此选项以指定多个匹配模式(多个模式之间用&quot;OR&quot;逻辑连接)。 --root=ROOT 在对日志进行操作时， 将 ROOT 视为系统的根目录。 例如 --update-catalog 将会创ROOT/var/lib/systemd/catalog/database --new-id128 此选项并不用于显示日志内容， 而是用于重新生成一个标识日志分类的 128-bit ID 。 此选项的目的在于 帮助开发者生成易于辨别的日志消息， 以方便调试。 --header 此选项并不用于显示日志内容， 而是用于显示日志文件内部的头信息(类似于元数据)。 --disk-usage 此选项并不用于显示日志内容，而是用于显示所有日志文件(归档文件与活动文件)的磁盘占用总量。 --vacuum-size=, --vacuum-time=, --vacuum-files= 这些选项并不用于显示日志内容，而是用于清理日志归档文件(并不清理活动的日志文件)， 以释放磁盘空间。 --vacuum-size= 可用于限制归档文件的最大磁盘使用量 (可以使用 &quot;K&quot;, &quot;M&quot;, &quot;G&quot;, &quot;T&quot;后缀)； --vacuum-time= 可用于清除指定时间之前的归档 (可以使用 &quot;s&quot;, &quot;m&quot;, &quot;h&quot;,&quot;days&quot;, &quot;weeks&quot;, &quot;months&quot;, &quot;years&quot; 后缀)； --vacuum-files=可用于限制日志归档文件的最大数量。 注意，--vacuum-size= 对 --disk-usage的输出仅有间接效果， 因为 --disk-usage 输出的是归档日志与活动日志的总量。同样，--vacuum-files= 也未必一定会减少日志文件的总数，因为它同样仅作用于归档文件而不会删除活动的日志文件。此三个选项可以同时使用，以同时从三个维度去限制归档文件。若将某选项设为零，则表示取消此选项的限制。 --list-catalog [128-bit-ID...] 简要列出日志分类信息， 其中包括对分类信息的简要描述。 如果明确指定了分类ID(128-bit-ID)， 那么仅显示指定的分类。 --dump-catalog [128-bit-ID...] 详细列出日志分类信息 (格式与 .catalog 文件相同)。 如果明确指定了分类ID(128-bit-ID)， 那么仅显示指定的分类。 --update-catalog 更新日志分类索引二进制文件。 每当安装、删除、更新了分类文件，都需要执行一次此动作。 --setup-keys 此选项并不用于显示日志内容， 而是用于生成一个新的FSS(Forward Secure Sealing)密钥对。 此密钥对包含一个&quot;sealing key&quot;与一个&quot;verification key&quot;。 &quot;sealing key&quot;保存在本地日志目录中， 而&quot;verification key&quot;则必须保存在其他地方。 详见 journald.conf(5) 中的 Seal= 选项。 --force 与 --setup-keys 连用， 表示即使已经配置了FSS(Forward Secure Sealing)密钥对，也要强制重新生成。 --interval= 与 --setup-keys 连用，指定&quot;sealing key&quot;的变化间隔。 较短的时间间隔会导致占用更多的CPU资源， 但是能够减少未检测的日志变化时间。 默认值是 15min --verify 检查日志文件的内在一致性。 如果日志文件在生成时开启了FSS特性， 并且使用 --verify-key= 指定了FSS的&quot;verification key&quot;，那么，同时还将验证日志文件的真实性。 --verify-key= 与 --verify 选项连用， 指定FSS的&quot;verification key&quot; --sync 要求日志守护进程将所有未写入磁盘的日志数据刷写到磁盘上，并且一直阻塞到刷写操作实际完成之后才返回。 因此该命令可以保证当它返回的时候，所有在调用此命令的时间点之前的日志， 已经全部安全的刷写到了磁盘中。 --flush 要求日志守护进程 将 /run/log/journal 中的日志数据 刷写到 /var/log/journal 中(如果持久存储设备当前可用的话)。 此操作会一直阻塞到操作完成之后才会返回，因此可以确保在该命令返回时， 数据转移确实已经完成。 注意，此命令仅执行一个单独的、一次性的转移动作， 若没有数据需要转移，则此命令什么也不做， 并且也会返回一个表示操作已正确完成的返回值。 --rotate 要求日志守护进程滚动日志文件。 此命令会一直阻塞到滚动完成之后才会返回。 -h, --help 显示简短的帮助信息并退出。 --version 显示简短的版本信息并退出。 --no-pager 不将程序的输出内容管道(pipe)给分页程序 范例：journalctl用法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#查看所有日志（默认情况下 ，只保存本次启动的日志）journalctl#查看内核日志（不显示应用日志）journalctl -k#查看系统本次启动的日志journalctl -bjournalctl -b -0#查看上一次启动的日志（需更改设置）journalctl -b -1#查看指定时间的日志journalctl --since=&quot;2017-10-30 18:10:30&quot;journalctl --since &quot;20 min ago&quot;journalctl --since yesterdayjournalctl --since &quot;2017-01-10&quot; --until &quot;2017-01-11 03:00&quot;journalctl --since 09:00 --until &quot;1 hour ago&quot;#显示尾部的最新10行日志journalctl -n#显示尾部指定行数的日志journalctl -n 20#实时滚动显示最新日志journalctl -f#查看指定服务的日志journalctl /usr/lib/systemd/systemd#查看指定进程的日志journalctl _PID=1#查看某个路径的脚本的日志journalctl /usr/bin/bash#查看指定用户的日志journalctl _UID=33 --since today#查看某个 Unit 的日志journalctl -u nginx.servicejournalctl -u nginx.service --since today#实时滚动显示某个 Unit 的最新日志journalctl -u nginx.service -f#合并显示多个 Unit 的日志journalctl -u nginx.service -u php-fpm.service --since today#查看指定优先级（及其以上级别）的日志，共有8级0: emerg1: alert2: crit3: err4: warning5: notice6: info7: debugjournalctl -p err -b#日志默认分页输出，--no-pager 改为正常的标准输出journalctl --no-pager#日志管理journalctl#以 JSON 格式（单行）输出journalctl -b -u nginx.service -o json#以 JSON 格式（多行）输出，可读性更好journalctl -b -u nginx.service -o json-pretty#显示日志占据的硬盘空间journalctl --disk-usage#指定日志文件占据的最大空间journalctl --vacuum-size=1G#指定日志文件保存多久journalctl --vacuum-time=1years 2 实战案例：利用 MySQL 存储日志信息 1210.0.0.180：rocky10.0.0.179：Ubuntu 2.1 目标在网络转发的基础上，，利用rsyslog日志服务，将收集的日志记录于MySQL中 2.2 环境准备123两台主机一台：rsyslog日志服务器，IP：10.0.0.180一台：mysql数据库服务器，IP：10.0.0.179 2.3 实现步骤2.3.1 在rsyslog服务器上安装连接mysql模块相关的程序包12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[root@rsyslog ~]#yum -y install rsyslog-mysql[root@rsyslog ~]#yum install -y mysql#补充：Ubuntu[root@ubuntu2004 ~]#apt -y install rsyslog-mysql#模块配置文件，到时创建数据库和账号要按照这个来[root@rsyslog ~]#vim /etc/rsyslog.d/mysql.conf### Configuration file for rsyslog-mysql### Changes are preservedmodule (load=&quot;ommysql&quot;)*.* action(type=&quot;ommysql&quot; server=&quot;localhost&quot; db=&quot;Syslog&quot; uid=&quot;rsyslog&quot; pwd=&quot;&quot;)#查看包文件[root@rsyslog ~]#rpm -ql rsyslog-mysql /usr/lib/.build-id/usr/lib/.build-id/7e/usr/lib/.build-id/7e/30458f368f71ec11b45c0445303b98fbc47a9c/usr/lib64/rsyslog/ommysql.so #库文件/usr/share/doc/rsyslog/mysql-createDB.sql #mysql 数据表脚本文件#补充Ubuntu[root@ubuntu2004 ~]# dpkg -L rsyslog-mysql....../usr/lib/x86_64-linux-gnu/rsyslog/ommysql.so #库文件/usr/share/dbconfig-common/data/rsyslog-mysql/install/mysql #mysql 数据表脚本文件/usr/share/rsyslog-mysql/rsyslog-mysql.conf.template #rsyslog 配置文件模板#查看sql脚本文件内容[root@rsyslog ~]#cat /usr/share/doc/rsyslog/mysql-createDB.sqlCREATE DATABASE Syslog;USE Syslog;CREATE TABLE SystemEvents( ID int unsigned not null auto_increment primary key, CustomerID bigint, ReceivedAt datetime NULL, DeviceReportedTime datetime NULL, Facility smallint NULL, Priority smallint NULL, FromHost varchar(60) NULL, Message text, NTSeverity int NULL, Importance int NULL, EventSource varchar(60), EventUser varchar(60) NULL, EventCategory int NULL, EventID int NULL, EventBinaryData text NULL, MaxAvailable int NULL, CurrUsage int NULL, MinUsage int NULL, MaxUsage int NULL, InfoUnitID int NULL , SysLogTag varchar(60), EventLogType varchar(60), GenericFileName VarChar(60), SystemID int NULL);CREATE TABLE SystemEventsProperties( ID int unsigned not null auto_increment primary key, SystemEventID int NULL , ParamName varchar(255) NULL , ParamValue text NULL);#补充Ubuntu[root@centos8 ~]#cat /usr/share/dbconfig-common/data/rsyslog-mysql/install/mysqlCREATE DATABASE Syslog; #Ubuntu22.04和20.04没有这两行，需要手动创建数据库USE Syslog; 2.3.2 准备 MySQL12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#Ubuntu默认开启mysql服务[root@mysql ~]#apt update &amp;&amp; apt install -y mysql-server#但是只监听本机，无法远程连接[root@ubuntu2004 ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 151 127.0.0.1:3306 0.0.0.0:* #修改文件，将两行注释[root@mysql ~]#vim /etc/mysql/mysql.conf.d/mysqld.cnf #bind-address = 127.0.0.1#mysqlx-bind-address = 127.0.0.1[root@mysql ~]#systemctl restart mysql[root@mysql ~]#ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 151 *:3306 *:* #因为Ubuntu的数据库脚本中没有创建数据库的命令，需要手动创建mysql&gt; create database Syslog;Query OK, 1 row affected (0.01 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| Syslog || information_schema || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)#根据模块文件的要求创建账号和授权mysql&gt; create user rsyslog@&#x27;10.0.0.%&#x27; identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.01 sec)mysql&gt; grant all on Syslog.* to rsyslog@&#x27;10.0.0.%&#x27;;Query OK, 0 rows affected (0.01 sec)#测试能否在rsyslog服务器上远程连接mysql服务器[root@rsyslog ~]#mysql -ursyslog -p123456 -h10.0.0.179mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || performance_schema |+--------------------+3 rows in set (0.00 sec)#方法1：在rsyslog服务器上导入数据库mysql&gt; source /usr/share/doc/rsyslog/mysql-createDB.sql;[root@rsyslog ~]#mysql -ursyslog -p123456 -h10.0.0.179 &lt; /usr/share/doc/rsyslog/mysql-createDB.sql[root@rsyslog ~]#mysql -ursyslog -p123456 -h10.0.0.179 -e &quot;source /usr/share/doc/rsyslog/mysql-createDB.sql&quot;#补充Ubuntu[root@ubuntu2204 ~]#mysql -ursyslog -p123456 -h10.0.0.179 Syslog &lt; /usr/share/dbconfig-common/data/rsyslog-ysql/install/mysql[root@ubuntu2204 ~]#mysql -ursyslog -p123456 -h10.0.0.179 Syslog -e &quot;source /usr/share/dbconfig-common/data/rsyslog-ysql/install/mysql&quot;#方法2：在mysql服务器上导入数据库#将sql脚本复制到数据库服库上[root@rsyslog ~]#scp /usr/share/doc/rsyslog/mysql-createDB.sql 10.0.0.179:mysql&gt; show tables;+------------------------+| Tables_in_Syslog |+------------------------+| SystemEvents || SystemEventsProperties |+------------------------+2 rows in set (0.01 sec)#两张表都为空mysql&gt; select count(*) from SystemEvents;+----------+| count(*) |+----------+| 0 |+----------+1 row in set (0.02 sec)mysql&gt; select count(*) from SystemEventsProperties;+----------+| count(*) |+----------+| 0 |+----------+1 row in set (0.01 sec) 2.3.3 配置日志服务器将日志发送至指定数据库1234567891011121314151617181920212223#配置rsyslog将日志保存到mysql中[root@rsyslog ~]#vim /etc/rsyslog.conf#####MODULES#####在 MODULES 语言下面，如果是 Ubuntu22.04,20.04和CentOS8 加下面行module(load=&quot;ommysql&quot;)#在 MODULES 语言下面，如果是 CentOS 7，6 加下面行$ModLoad ommysql#在RULES语句块加下面行的格式#facility.priority :ommysql:DBHOST,DBNAME,DBUSER, PASSWORD*.info :ommysql:10.0.0.179,Syslog,rsyslog,123456[root@rsyslog ~]#systemctl restart rsyslog.service#Ubuntu 自动生成以下配置文件，只需要按环境修改#由于原模块文件中没有设置密码，要加上去，把级别改了，把server改了，指向mysql服务器[root@ubuntu2004 ~]#vim /etc/rsyslog.d/mysql.confmodule (load=&quot;ommysql&quot;)*.info action(type=&quot;ommysql&quot; server=&quot;10.0.0.179&quot; db=&quot;Syslog&quot; uid=&quot;rsyslog&quot; pwd=&quot;123456&quot;)[root@ubuntu2004 ~]#systemctl restart rsyslog 2.3.4 测试123456789101112#测试将client1，client2的日志发送数据库[root@client-1 ~]#logger &quot;this msg from client-1&quot;[root@client-2 ~]#logger &quot;this msg from client-2&quot;mysql&gt; select FromHost,Message from SystemEvents order by id desc limit 3;+------------+---------------------------+| FromHost | Message |+------------+---------------------------+| client-2 | this msg from client-2 || client-1 | this msg from client-1 |+------------+---------------------------+3 rows in set (0.00 sec) 在此基础上，我们可以再实现一个 Web 服务，将 Mysql 中的日志数据在页面上显示出来 12#推荐的开源程序https://loganalyzer.adiscon.com/ 3 Logrotate 日志转储3.1 Logrotate 介绍日志是重要的系统文件，记录和保存了系统中所有的重要事件。但是日志文件也需要进行定期的维护，因为日志文件是不断增长的，如果完全不进行日志维护，而任由其随意递增，那么用不了多久，我们的硬盘就会被写满。 日志维护的最主要的工作就是把旧的日志文件删除，从而腾出空间保存新的日志文件。这项工作如果靠管理员手工来完成，那其实是非常烦琐的，而且也容易忘记。那么 Linux 系统是否可以自动完成日志的轮替工作呢？ logrotate 就是用来进行日志轮替（也叫日志转储）的，也就是把旧的日志文件移动并改名，同时创建一个新的空日志文件用来记录新日志，当旧日志文件超出保存的范围时就删除。 在 Linux 系统中，能够帮助使用者定位问题的有效手段之一就是查日志。 如果一个服务或一个程序的日志，一直只写一个文件，则会导致该日志文件越来越大，无论是查看还是搜索内容，备份等，都会特别不方便，而且如果服务器数量较多，日志文件大小增长较快，也会很容易触发告警。 为了解决这种情况，我们可以使用日志转储服务，对服务日志进行分割，按照一定的规则将日志保存在不同的文件中，这样更便于管理和归档，可以节省磁盘空间 当前服务器上的日志转储 12345678910[root@log-server ~]# ll /var/log/dmesg*-rw-r----- 1 root adm 132571 Jul 4 08:49 /var/log/dmesg-rw-r----- 1 root adm 132565 Jul 3 20:12 /var/log/dmesg.0-rw-r----- 1 root adm 26381 Jun 30 08:18 /var/log/dmesg.1.gz-rw-r----- 1 root adm 26443 Jun 28 22:01 /var/log/dmesg.2.gz[root@log-server ~]# ll /var/log/alternatives.log*-rw-r--r-- 1 root root 416 Jul 4 08:49 /var/log/alternatives.log-rw-r--r-- 1 root root 9415 Jun 30 08:31 /var/log/alternatives.log.1-rw-r--r-- 1 root root 3160 May 9 11:58 /var/log/alternatives.log.2.gz logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 工作原理：系统计划任务每天执行一次脚本文件，在脚本中再执行 &#x2F;usr&#x2F;sbin&#x2F;logrotate&#x2F;etc&#x2F;logrotate.conf ，即调用 logrotate 程序再配合定义好的转储规则对日志文件进行转储 日志文件的命名规则 日志轮替最主要的作用就是把旧的日志文件移动并改名，同时建立新的空日志文件，当旧日志文件超出保存的范围时就删除。那么，旧的日志文件改名之后，如何命名呢？主要依靠 &#x2F;etc&#x2F;logrotate.conf 配置文件中的“dateext”参数。 如果配置文件中有“dateext”参数，那么日志会用日期来作为日志文件的后缀，如“secure-20130605”。这样日志文件名不会重叠，也就不需要对日志文件进行改名，只需要保存指定的日志个数，删除多余的日志文件即可。 如果配置文件中没有“dateext”参数，那么日志文件就需要进行改名了。当第一次进行日志轮替时，当前的“secure”日志会自动改名为“secure.1”，然后新建“secure”日志，用来保存新的日志；当第二次进行日志轮替时，“secure.1”会自动改名为“secure.2”，当前的“secure”日志会自动改名为“secure.1”，然后也会新建“secure”日志，用来保存新的日志；以此类推。 3.2 Logrotate 配置软件包：logrotate 相关文件 计划任务：&#x2F;etc&#x2F;cron.daily&#x2F;logrotate，&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;logrotate.service，&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;logrotate.timer 程序文件：&#x2F;usr&#x2F;sbin&#x2F;logrotate 配置文件： &#x2F;etc&#x2F;logrotate.conf 日志文件：&#x2F;var&#x2F;lib&#x2F;logrotate&#x2F;logrotate.status 12345/etc/cron.daily/logrotate #定时任务脚本，放在 cron.daily 目录中，默认系统会每天执行一次/etc/logrotate.conf #主配置文件，定义日志转储策略/etc/logrotate.d/ #配置文件目录，定义日志转储策略/usr/sbin/logrotate #主程序/var/lib/logrotate/status #logrotate服务的日志文件 在配置文件中定义转储规则，配置文件中的主要配置项 1234567891011121314151617181920212223242526[root@log-server ~]# cat /etc/logrotate.conf# see &quot;man logrotate&quot; for details# global options do not affect preceding include directives# rotate log files weeklyweekly #默认每周一次转储# use the adm group by default, since this is the owning group# of /var/log/syslog.su root adm #默认使用adm组# keep 4 weeks worth of backlogsrotate 4 #默认保留最近4周的文件(4个文件)# create new (empty) log files after rotating old onescreate #转储完成后生成新的空文件存储新的日志# use date as a suffix of the rotated file#dateext #默认不使用日志后缀# uncomment this if you want your log files compressed#compress #默认不启用文件压缩# packages drop log rotation information into this directoryinclude /etc/logrotate.d #包含的子目录# system-specific logs may also be configured here. 配置文件主要参数如下： 配置参数 说明 compress 通过gzip压缩转储以后的日志 nocompress 不压缩 copytruncate 用于还在打开中的日志文件，把当前日志备份并截断 nocopytruncate 备份日志文件但是不截断 create mode owner group 转储文件，使用指定的权限，所有者，所属组创建新的日志文件 nocreate 不建立新的日志文件 delaycompress 和 compress 一起使用时，转储的日志文件到下一次转储时才压缩 nodelaycompress 覆盖 delaycompress 选项，转储同时压缩 errors address 专储时的错误信息发送到指定的Email 地址 ifempty 即使是空文件也转储，此为默认选项 notifempty 如果是空文件的话，不转储 mail address 把转储的日志文件发送到指定的E-mail 地址 nomail 转储时不发送日志文件 olddir directory 转储后的日志文件放入指定目录，必须和当前日志文件在同一个文件系统 noolddir 转储后的日志文件和当前日志文件放在同一个目录下 prerotate&#x2F;endscript 在转储以前需要执行的命令，这两个关键字必须单独成行 postrotate&#x2F;endscript 在转储以后需要执行的命令，这两个关键字必须单独成行 daily 指定转储周期为每天 weekly 指定转储周期为每周 monthly 指定转储周期为每月 rotate count 指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份 tabooext [+] list 让logrotate不转储指定扩展名的文件，缺省的扩展名是：.rpm-orig，.rpmsave，v，和 ~ size size 当日志文件到达指定的大小时才转储，bytes(缺省)及KB或MB sharedscripts 默认，对每个转储日志运行prerotate和postrotate脚本，日志文件的绝对路径作为第一个参数传递给脚本。 这意味着单个脚本可以针对与多个文件匹配的日志文件条目多次运行（例如&#x2F;var&#x2F;log&#x2F;example&#x2F;*.log）。 如果指定此项sharedscripts，则无论有多少个日志与通配符模式匹配，脚本都只会运行一次 nosharedscripts 针对每一个转储的日志文件，都执行一次prerotate 和 postrotate脚本，此为默认值 missingok 如果日志不存在，不提示错误，继续处理下一个 nomissingok 如果日志不存在，提示错误，此为默认值 每个服务单独的配置文件，如果在单独配置文件中没有定义的配置项，则使用主配置文件中的配置项或默认配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849root@log-server ~]# ls /etc/logrotate.d/alternatives apport apt bootlog btmp dbconfig-common dpkg nginx php8.1-fpm rsyslog ubuntu-advantage-tools ufw unattended-upgrades wtmp[root@log-server ~]# cat /etc/logrotate.d/rsyslog/var/log/syslog/var/log/mail.info/var/log/mail.warn/var/log/mail.err/var/log/mail.log/var/log/daemon.log/var/log/kern.log/var/log/auth.log/var/log/user.log/var/log/lpr.log/var/log/cron.log/var/log/debug/var/log/messages&#123; #上述所有日志文件都适用于此转储规则 rotate 4 #保留最近4个文件，加上当前使用的，一个5个 weekly #每周转储 missingok #如果要转储的日志文件不存在，不提示错误，继续下一个 notifempty #如果是空文件，不转储 compress #启用gzip压缩转储后的日志文件 delaycompress #和 compress 一起使用时，转储的日志文件到下一次转储时才压缩 sharedscripts #运行脚本，分别是转储前和转储后脚本 postrotate #转储后脚本 /usr/lib/rsyslog/rsyslog-rotate endscript&#125;[root@log-server ~]# cat /etc/logrotate.d/nginx/var/log/nginx/*.log &#123; daily missingok rotate 14 compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate &gt;/dev/null 2&gt;&amp;1 #让nginx重新锚定新生成的日志文件 endscript&#125; 3.3 Logrotate 自定义规则实现123456789101112logrotate [OPTION...] &lt;configfile&gt;#常用选项-?|--help #显示帮助信息-d|--debug #不执行任何操作，仅显示错误信息，类似于测试-f|--force #强制执行-m|--mail=command #指定执行邮件发送的命令，默认 /usr/bin/mail-s|--state=statefile #指定服务日志文件，默认 /var/lib/logrotate/status-v|--verbose #显示详细信息-l|--log=logfile #指定详细信息日志，加上此选项，会将详细信息写到指定文件--version #显示版本信息--skip-state-lock #不给 statefile 文件加锁 范例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#创建测试日志文件[root@log-server ~]# dd if=/dev/zero of=/var/log/test1.log bs=2M count=1[root@log-server ~]# dd if=/dev/zero of=/var/log/test2.log bs=2M count=1[root@log-server ~]# ll -h /var/log/test*-rw-r--r-- 1 root root 2.0M Jul 4 17:51 /var/log/test1.log-rw-r--r-- 1 root root 2.0M Jul 4 17:52 /var/log/test2.log#定义转储规则[root@log-server ~]# cat /etc/logrotate.d/test&#123;1,2&#125;/var/log/test1.log &#123; daily rotate 5 su root root compress delaycompress missingok size 1M notifempty create 0640 syslog adm postrotate echo `date +%F_%T` &gt;&gt; /tmp/test1.log endscript&#125;/var/log/test2.log &#123; daily rotate 5 su root root dateext compress delaycompress missingok size 1M notifempty create 644 root root postrotate echo `date +%F_%T` &gt;&gt; /tmp/test2.log endscript&#125;#手动执行转储[root@log-server ~]# logrotate /etc/logrotate.d/test1#查看日志，生成新的空文件，权限，属主属组都符合预设[root@log-server ~]# ls -lh /var/log/test1*-rw-r----- 1 syslog adm 0 Jul 5 22:58 /var/log/test1.log-rw-r--r-- 1 root root 2.0M Jul 5 21:05 /var/log/test1.log.1#再次转储，先保证日志达到转储条件[root@log-server ~]# dd if=/dev/zero of=/var/log/test1.log bs=3M count=1[root@log-server ~]# logrotate /etc/logrotate.d/test1[root@log-server ~]# ls -lh /var/log/test1*-rw-r----- 1 syslog adm 0 Jul 5 23:16 /var/log/test1.log-rw-r----- 1 syslog adm 3.0M Jul 5 23:03 /var/log/test1.log.1 #最新的转储-rw-r--r-- 1 root root 2.1K Jul 5 21:05 /var/log/test1.log.2.gz #前一个被转储的日志被压缩#查看日志文件，转储成功后命令被执行[root@log-server ~]# cat /tmp/test1.log2023-07-05_22:58:112023-07-05_23:16:12#调用主配置文件进行转储，主配置文件中包含了 test1 test2 配置，所以都会被转储[root@log-server ~]# logrotate /etc/logrotate.conf#test1 没有达到转储条件[root@log-server ~]# ls -lh /var/log/test1*-rw-r----- 1 syslog adm 0 Jul 5 23:16 /var/log/test1.log-rw-r----- 1 syslog adm 3.0M Jul 5 23:03 /var/log/test1.log.1-rw-r--r-- 1 root root 2.1K Jul 5 21:05 /var/log/test1.log.2.gz#test2 达到条件，且有日期后缀[root@log-server ~]# ls -lh /var/log/test2*-rw-r--r-- 1 root root 0 Jul 5 23:26 /var/log/test2.log-rw-r--r-- 1 root root 2.0M Jul 4 17:52 /var/log/test2.log-20230705 3.4 Logrotate 配置范例范例：Ubuntu22.04 包文件内容 12345678910111213141516171819202122232425262728293031323334353637[root@ubuntu2204 ~]#dpkg -L logrotate/lib/systemd/system/logrotate.service...[root@ubuntu2204 ~]#cat /lib/systemd/system/logrotate.service[Unit]Description=Rotate log filesDocumentation=man:logrotate(8) man:logrotate.conf(5)RequiresMountsFor=/var/logConditionACPower=true[Service]Type=oneshotExecStart=/usr/sbin/logrotate /etc/logrotate.conf# performance optionsNice=19IOSchedulingClass=best-effortIOSchedulingPriority=7# hardening options# details: https://www.freedesktop.org/software/systemd/man/systemd.exec.html# no ProtectHome for userdir logs# no PrivateNetwork for mail deliviery# no NoNewPrivileges for third party rotate scripts# no RestrictSUIDSGID for creating setgid directoriesLockPersonality=trueMemoryDenyWriteExecute=truePrivateDevices=truePrivateTmp=trueProtectClock=trueProtectControlGroups=trueProtectHostname=trueProtectKernelLogs=trueProtectKernelModules=trueProtectKernelTunables=trueProtectSystem=fullRestrictNamespaces=trueRestrictRealtime=true 范例：Rocky8包文件内容 123456789101112[root@rocky8 ~]#rpm -ql logrotate/etc/cron.daily/logrotate.....[root@rocky8 ~]#cat /etc/cron.daily/logrotate#!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;fiexit $EXITVALUE 范例： 定制设置nginx的日志转储 12345678910111213141516171819202122232425262728293031323334353637383940414243444546cat /etc/logrotate.d/nginx/var/log/nginx/*.log &#123; daily rotate 100 missingok compress delaycompress notifempty create 644 ngnix nginx postrotate if [ -f /app/nginx/logs/nginx.pid ]; then kill -USR1 `cat /app/nginx/logs/nginx.pid` fi endscript&#125;#说明#终端1[root@rocky8 ~]#touch a.log[root@rocky8 ~]#tail -f a.log#终端2#查看进程和fd描述符[root@rocky8 ~]#lsof a.logCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEtail 6337 root 3r REG 253,0 0 33575489 a.log#/root/a.log的fd为3[root@rocky8 ~]#ll /proc/6337/fdtotal 0lrwx------ 1 root root 64 Dec 9 14:38 0 -&gt; /dev/pts/1lrwx------ 1 root root 64 Dec 9 14:38 1 -&gt; /dev/pts/1lrwx------ 1 root root 64 Dec 9 14:38 2 -&gt; /dev/pts/1lr-x------ 1 root root 64 Dec 9 14:38 3 -&gt; /root/a.log[root@rocky8 ~]#mv a.log b.log[root@rocky8 ~]#ll /proc/6337/fdtotal 0....lr-x------ 1 root root 64 Dec 9 14:38 3 -&gt; /root/b.log#终端1，虽然改名了，但是没有报错[root@rocky8 ~]#tail -f a.log所以这说明了tail -f 跟踪的不是文件名，而是文件描述符，所以USR1信号的作用就是重新加载日志文件，把新的日志文件写到新生成的文件中，在转储中，nginx旧的日志转储到了access.2023-12-09，随后生成新的文件access去存储新的日志文件，但是转储完后并没有去跟踪fd，还是原来的，即access.2023-12-09，那么新的日志就会写到这里面去，不会写到新的文件access，所以需要USR1信号，去指向新的fd，把新的日志文件写到新生成的文件中 范例： nginx安装内置转储规则 123456789101112131415161718192021222324252627282930313233[root@ubuntu2204 ~]#cat /etc/logrotate.d/nginx/var/log/nginx/*.log &#123; daily missingok rotate 14 compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate &gt;/dev/null 2&gt;&amp;1 endscript&#125;[root@rocky8 ~]#cat /etc/logrotate.d/nginx/var/log/nginx/*log &#123; create 0664 nginx root daily rotate 10 missingok notifempty compress sharedscripts postrotate /bin/kill -USR1 `cat /run/nginx.pid 2&gt;/dev/null` 2&gt;/dev/null || true endscript&#125; 范例：Ubuntu22.04 日志转储 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970[root@ubuntu2204 ~]#mkdir -p /var/log/test /data[root@ubuntu2204 ~]#dd if=/dev/zero of=/var/log/test/test1.log bs=1M count=2[root@ubuntu2204 ~]#ll /var/log/test/*-rw-r--r-- 1 root root 2097152 11月 18 12:21 /var/log/test/test1.log[root@ubuntu2204 ~]#cat /etc/logrotate.d/test1/var/log/test/test1.log &#123; #daily和size 1M要同时满足才会转储 daily rotate 5 compress delaycompress missingok size 1M notifempty create 0640 bin daemon sharedscripts postrotate echo `date +%F_%T` &gt;&gt; /data/test1.log endscript&#125;#手动转储，不等它满足条件才转储[root@ubuntu2204 ~]#logrotate /etc/logrotate.d/test1#查看结果[root@ubuntu2204 ~]#ll /var/log/test/总用量 2056drwxr-xr-x 2 600 root 4096 11月 18 12:22 ./drwxrwxr-x 12 root syslog 4096 11月 18 12:14 ../-rw-r----- 1 bin daemon 0 11月 18 12:22 test1.log #新生成文件准备转储新的日志-rw-r--r-- 1 root root 2097152 11月 18 12:21 test1.log.1 #旧的日志内容在这#添加日志[root@ubuntu2204 ~]#dd if=/dev/zero of=/var/log/test/test1.log bs=1M count=2#手动转储[root@ubuntu2204 ~]#logrotate /etc/logrotate.d/test1#观察结果，发现延迟压缩[root@ubuntu2204 ~]#ll /var/log/test/总用量 2060drwxr-xr-x 2 600 root 4096 11月 18 12:23 ./drwxrwxr-x 12 root syslog 4096 11月 18 12:14 ../-rw-r----- 1 bin daemon 0 11月 18 12:23 test1.log-rw-r----- 1 bin daemon 2097152 11月 18 12:23 test1.log.1 -rw-r--r-- 1 root root 2067 11月 18 12:21 test1.log.2.gz #之前旧的test1.log.1压缩[root@ubuntu2204 ~]#cat /data/test1.log2022-11-18_12:22:402022-11-18_12:23:07#修改全局配置[root@ubuntu2204 ~]#vim /etc/logrotate.conf#取消注释dateext#生成新日志[root@ubuntu2204 ~]#dd if=/dev/zero of=/var/log/test/test1.log bs=1k count=1025#使用全局配置[root@ubuntu2204 ~]#logrotate /etc/logrotate.conf#查看生成日志文件格式为时间后缀[root@ubuntu2204 ~]#ll /var/log/test/总计 2084drwxr-xr-x 2 root root 4096 5月 8 17:13 ./drwxrwxr-x 11 root syslog 4096 5月 8 17:00 ../-rw-r----- 1 bin daemon 1049600 5月 8 17:13 test1.log-rw-r----- 1 bin daemon 1049600 5月 8 17:10 test1.log.1-rw-r----- 1 bin daemon 1052 5月 8 17:12 test1.log-20230508.gz 范例：对指定日志手动执行日志转储 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#生成测试日志[root@centos8 ~]#dd if=/dev/zero of=/var/log/test1.log bs=2M count=11+0 records in1+0 records out2097152 bytes (2.1 MB, 2.0 MiB) copied, 0.00291879 s, 719 MB/s[root@centos8 ~]#dd if=/dev/zero of=/var/log/test2.log bs=2M count=11+0 records in1+0 records out2097152 bytes (2.1 MB, 2.0 MiB) copied, 0.00200561 s, 1.0 GB/s#针对不同的日志创建转储配置文件#Ubuntu需加下面两行su bin syslogsharedscripts [root@centos8 ~]#cat /etc/logrotate.d/test1/var/log/test1.log &#123; daily rotate 5 compress delaycompress missingok size 1M notifempty create 640 bin daemon postrotate echo `date +%F_%T` &gt;&gt; /data/test1.log endscript&#125;[root@centos8 ~]#cat /etc/logrotate.d/test2/var/log/test2.log &#123; daily rotate 5 compress delaycompress missingok size 1M notifempty create 644 root root postrotate echo `date +%F_%T` &gt;&gt; /data/test2.log endscript &#125; #针对一个测试日志，手动执行日志转储[root@centos8 ~]#logrotate /etc/logrotate.d/test1 [root@centos8 ~]#ll /var/log/test*-rw-r----- 1 bin daemon 0 Dec 14 16:38 /var/log/test1.log-rw-r--r-- 1 root root 2097152 Dec 14 16:35 /var/log/test1.log.1-rw-r--r-- 1 root root 2097152 Dec 14 16:36 /var/log/test2.log[root@centos8 ~]#ls /datatest1.log[root@centos8 ~]#cat /data/test1.log2019-11-12_14:00:14#对所有日志进行手动转储[root@centos8 ~]#logrotate /etc/logrotate.conf[root@centos8 ~]#ll /var/log/test*-rw-r--r-- 1 bin daemon 0 Nov 12 14:00 /var/log/test1.log-rw-r--r-- 1 root root 2097152 Nov 12 13:59 /var/log/test1.log.1-rw-r--r-- 1 root root 0 Nov 12 14:01 /var/log/test2.log-rw-r--r-- 1 root root 2097152 Nov 12 13:59 /var/log/test2.log-20191112[root@centos8 ~]#ls /datatest1.log test2.log[root@centos8 ~]#cat /data/test1.log2019-11-12_14:01:51","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"计划任务","slug":"Linux/service-manage/plan-tasks","date":"2025-08-20T08:52:03.000Z","updated":"2025-08-28T12:33:05.352Z","comments":true,"path":"Linux/service-manage/plan-tasks/","permalink":"https://aquapluto.github.io/Linux/service-manage/plan-tasks/","excerpt":"","text":"一次性任务at 工具 由包 at 提供 依赖与atd服务,需要启动才能实现at任务 at队列存放在&#x2F;var&#x2F;spool&#x2F;at目录中,ubuntu存放在&#x2F;var&#x2F;spool&#x2F;cron&#x2F;atjobs目录下 执行任务时PATH变量的值和当前定义任务的用户身份一致 作业执行命令的结果中的标准输出和错误以执行任务的用户身份发邮件通知给 root 默认CentOS 8 最小化安装没有安装邮件服务,需要自行安装 at 命令： 123456789at [option] TIME-V 显示版本信息-t time 时间格式 [[CC]YY]MMDDhhmm[.ss]-l 列出指定队列中等待运行的作业；相当于atq-d N 删除指定的N号作业；相当于atrm-c N 查看具体作业N号任务-f file 指定的文件中读取任务-m 当任务被完成之后，将给用户发送邮件，即使没有标准输出 TIME：定义出什么时候进行 at 这项任务的时间 123456HH:MM [YYYY-mm-dd]noon：正午，中午12点midnight：午夜，晚上12点teatime：下午茶时间，下午4点tomorrow：明天now+#&#123;minutes,hours,days, OR weeks&#125; at 时间格式 12345678910111213#HH:MM 在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务02:00 #HH:MM YYYY-MM-DD 规定在某年某月的某一天的特殊时刻进行该项任务02:00 2016-09-20 #HH:MM[am|pm] [Month] [Date]06pm March 1717:20 tomorrow#HH:MM[am|pm] + number [minutes|hours|days|weeks]， 在某个时间点再加几个时间后才进行该项任务now + 5 min02pm + 3 days at 任务执行方式 交互式 输入重定向 at -f file &#x2F;etc&#x2F;at.{allow,deny} 控制用户是否能执行at任务 白名单：&#x2F;etc&#x2F;at.allow 默认不存在，只有该文件中的用户才能执行at命令 黑名单：&#x2F;etc&#x2F;at.deny 默认存在，拒绝该文件中用户执行at命令，而没有在at.deny 文件中的使用者则可执行 如果两个文件都不存在，只有 root 可以执行 at 命令 权限控制是allow的优先级更高，如果用户在allow 和 deny 中都存在，则是有权限执行的 范例 12345678910111213141516171819202122#在某个时间执行多个任务[root@centos ~]#systemctl start atd#添加今天16:03的定时任务[root@centos ~]#at 16:03at&gt; touch /root/at.txtat&gt; echo hello wprldat&gt; &lt;EOT&gt; #Ctrl+d结束job 7 at Sun Sep 17 16:03:00 2023[root@centos ~]#lsanaconda-ks.cfg apps at.log at.txt data dir motd_peiqi passwd pwd[root@centos ~]#cat at.txt You have new mail in /var/spool/mail/wu#五分钟之后执行[root@centos ~]#at now+5min#列出任务[root@centos ~]# at -l1 Sat May 20 00:05:00 2023 a root#查看任务具体内容[root@centos ~]# at -c 1 范例: ubuntu at任务存放路径 1234567891011121314151617#任务保存在这个目录中[root@ubuntu ~]# ls -l /var/spool/cron/atjobs/total 4-rwx------ 1 root daemon 2947 May 19 22:47 a0000201ac6709#查看文件，就是上面输入的内容[root@ubuntu ~]# cat /var/spool/at/a0000201ac6709#到时间查看执行结果[root@ubuntu ~]# ll /tmp/at-00-05#输出内容在邮件里面[root@ubuntu ~]# mail#原来生成的任务文件己经被删除了[root@ubuntu ~]# ls -l /var/spool/cron/atjobs/total 0 输入输出重定向 12345678910111213#创建[root@ubuntu ~]# echo reboot | at now+5minwarning: commands will be executed using /bin/shjob 11 at Sat May 20 00:13:00 2023#查看[root@ubuntu ~]# at -l11 Sat May 20 00:13:00 2023 a root#删除[root@ubuntu ~]# at -d 11[root@ubuntu ~]# at -l[root@ubuntu ~]# 定时任务一般都是要在将来的某个时间去执行，然后标准输出以及错误输出都不会写输出到终端，这是因为，在任务执行的时候，当前终端没有连接上来，或者不是创建任务的用户 周期性任务计划 croncron 守护进程每分钟都会自动检查 &#x2F;etc&#x2F;crontab 文件、etc&#x2F;cron.d&#x2F; 等目录中的改变。如果发现了改变，它们就会被载入内存。所以你如果修改了计划任务导致其crontab文件改变后，并不需要重启守护进程。 crontab的用户手册中推荐每一个命令使用绝对路径，例如调用rm命令时写作：&#x2F;bin&#x2F;rm，这是为了防止由于每一个用户的PATH环境变量不同而导致命令无法找到的错误。 编写定时任务时，先在命令行上面执行一次，查看是否可以执行成功。 把定时任务执行的结果定向到空&amp;&gt;&#x2F;dev&#x2F;null，如果不定向到空的话，邮件服务postfix开启时，系统会一直发送邮件信息日积月累会白白耗费磁盘空间 周期性任务计划cron相关的程序包 cronie：主程序包，提供crond守护进程及相关辅助工具 crontabs：包含CentOS提供系统维护任务 cronie-anacron：cronie的补充程序，用于监控cronie任务执行状况，如:cronie中的任务在过去该运行的时间点未能正常运行，则anacron会随后启动一次此任务 cron 依赖于crond服务，确保crond守护处于运行状态 12345#CentOS 7 以后版本:systemctl status crond#CentOS 6:service crond status cron任务分为 系统cron任务：系统维护作业，/etc/crontab 主配置文件， /etc/cron.d/ 子配置文件 用户cron任务：红帽系统保存在 /var/spool/cron/USERNAME，Ubuntu 系统存放在/var/spool/cron/crontabs/USERNAME，利用 crontab 命令管理 cron 程序计划任务日志 1234[root@rocky86 ~]# ll /var/log/cron-rw------- 1 root root 21454 Aug 25 17:01 /var/log/cron#ubuntu 中的crontab任务日志放在/var/log/syslog 中 系统cron计划任务计划任务不会在屏幕上打印，只会发邮件，所以可以利用重定向 &#x2F;etc&#x2F;crontab 格式说明 12345678910111213[root@centos8 ~]#cat /etc/crontabSHELL=/bin/bash #默认的SHELL类型PATH=/sbin:/bin:/usr/sbin:/usr/bin #默认的PATH变量值,可修改为其它路径MAILTO=root #默认标准输出和错误发邮件给root,可以指向其它用户# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 计划任务时间表示法 123456789101112131415161718192021(1)* 表示该位置上所有可以出现的值* * * * * #每分钟执行一次1 2 * * * #每天2时1分执行一次(2)N,N,... 表示该位置上多个值，离散取值1,3,5 2,4,6 * * * #表示第2，4，6 这三个小时中每个小时的第1,3,5 分的时候执行一次(3)N-N 表示范围取值1-5 2-6 * * * #表示第2到第6小时，每小时的第1到第5分每分钟执行一次(4)/N 表示频率，步长*/5 */6 * * * #表示每6小时，在该小时内，每5分钟执行一次(5)特定关健字@yearly #每年1月1日执行一次，相当于 0 0 1 1 *@annually #每年1月1日执行一次，相当于 0 0 1 1 *@monthly #每月1日执行一次，相当于 0 0 1 * *@weekly #每周日执行一次，相当于 0 0 * * 0@daily #每天0时执行一次，相当于 0 0 * * *@hourly #每小时0分执行一次，相当于 0 * * * *@reboot #重启后执行一次 范例 123456789101112131415161718192021222324#晚上9点10分运行echo命令,输出信息仍会发送到root 邮箱10 21 * * * wang /bin/echo &quot;Howdy!&quot;#半夜2点半执行脚本30 2 * * * /data/backup.sh#每3小时echo和wall命令0 */3 * * * wang /bin/echo “howdy”; wall “welcome to Magedu!”#每周2和每周4的第1时，第3时，第5到8时，每5分钟执行一次*/5 1,3,5-8 * * 2,4#每月的1到10日，或每周1到周五的2时1分执行一次 1 2 1-10 * 1-5#每小时1-30分内，每5分钟执行一次1-30/5 * * * *#每周1,3,5执行* * * * 1,3,5#每个月的1号，10号，20号的半夜2点或者周六和周日的半夜2点每10分钟执行（因为1,10,20不一定是周六周日，会有冲突，所以是或者的关系）#要是想1,10,20号和周六周日是并且的关系，可以把0,6换成*，然后在脚本里面判断是否是周六周日*/10 2 1,10,20 * 0,6 crond任务相关文件 123456/etc/crontab 配置文件/etc/cron.d/ 配置文件/etc/cron.hourly/ 脚本/etc/cron.daily/ 脚本/etc/cron.weekly/ 脚本/etc/cron.monthly/ 脚本 用户计划任务crontab命令: 每个用户都有专用的cron任务文件：/var/spool/cron/USERNAME 如果想添加系统级的cron任务，写在此文件中/etc/crontab 默认标准输出和错误会被发邮件给对应的用户,如：wang创建的任务就发送至wang的邮箱 root能够修改其它用户的作业 用户的cron 中默认 PATH=/usr/bin:/bin，所以使用命令的时候要查看是否在其路径下，不在的话要指明命令的路径，或者如果在任务文件的第一行加PATH=/path或者加入到计划任务执行的脚本中 第六个字段指定要运行的命令。 该行的整个命令部分，直至换行符或“％”字符，指定的shell执行.除非使用反斜杠（\\）进行转义，否则该命令中的“％”字符将变为换行符，并且第一个％之后的所有数据将作为标准输入发送到该命令。 运行结果的标准输出和错误以邮件通知给相关用户 cron任务中不建议使用%，它有特殊用途，它表示换行的特殊意义，且第一个%后的所有字符串会被将成当作命令的标准输入,如果在命令中要使用%，则需要用 \\ 转义 1234567crontab [-u user] [-l | -r | -e] [-i]-l 列出所有任务-e 编辑任务-r 移除所有任务-i 同-r一同使用，以交互式模式移除指定任务-u user 指定用户管理cron任务,仅root可运行 控制用户执行计划任务：&#x2F;etc&#x2F;cron.{allow,deny}，ubuntu中无此文件 范例：修改默认的cron的文本编辑工具 1234567891011121314151617#Ubuntu默认的cron文本编辑器是nano可以修改为vimroot@ubuntu1804:~# crontab -eno crontab for root - using an empty oneSelect an editor. To change later, run &#x27;select-editor&#x27;. 1. /bin/nano &lt;---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/ed Choose 1-4 [1]:#如果没有在此处选择，可以写配置文件修改编辑工具[root@ubuntu ~]# echo &quot;export EDITOR=vim&quot; &gt;&gt; /etc/profile.d/env.sh[root@ubuntu ~]# . /etc/profile.d/env.sh[root@ubuntu ~]# cat /etc/profile.d/env.shexport EDITOR=vim 范例：PATH变量 在cron里面的PATH变量的路径很少，这就导致在计划任务里面，有其他路径的命令会报错，为了解决这一问题，有以下方法解决 12345678910111213#方法1,在计划任务配置中指定PATH[root@centos8 ~]#crontab -lPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin* * * * * useradd hehe;echo $PATH#方法2,在脚本中指定PATH变量[root@centos8 ~]#crontab -l* * * * * /data/test.sh[root@centos8 ~]#cat /data/test.sh#!/bin/bashPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binuseradd heheecho $PATH 范例：磁盘检测 123456789[root@centos8 ~]#cat /usr/bin/disk_check.sh#!/bin/bashPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binWARNING=10df | sed -En &#x27;/^\\/dev\\/sd/s@^([^ ]+).* ([0-9]+)%.*@\\1 \\2@p&#x27;| while read DEVICE USE;do [ $USE -gt $WARNING ] &amp;&amp; echo &quot;$DEVICE will be full,USE:$USE&quot; | mail -s diskfull rootdone[root@centos8 ~]#crontab -l*/10 * * * * check_disk.sh 范例：磁盘检测 1234567[root@centos8 ~]#cat check_disk.sh#!/bin/bashPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bindf | awk -F &#x27; +|%&#x27; &#x27;/^\\/dev\\/sd/&#123;if($5 &gt; 10)&#123;system(&quot;echo &quot;$1&quot; will be full,use:&quot; $5 &quot;| mail -s warning root@wangxiaochun.com&quot;)&#125; &#125;&#x27;[root@centos8 ~]#crontab -l*/10 * * * * /root/check_disk.sh 范例：磁盘检测 123456789101112131415[root@centos8 ~]#cat check_disk2.sh#!/bin/bashPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binWARNING=2df | awk -F &#x27; +|%&#x27; &#x27;/^\\/dev\\/sd/&#123;print $1,$5&#125;&#x27;|while read DISK USE;doif [ $USE -gt $WARNING ];then echo &quot;$DISK will be full,use:$USE&quot; | mail -s diskwarning root@wangxiaochun.comfidone[root@centos ~]#crontab -e*/10 * * * * /root/check_disk2.sh[root@centos8 ~]#crontab -l*/10 * * * * /root/check_disk2.sh 范例：查看用户文件和执行日志 123456789101112131415[root@centos ~]#crontab -e* * * * * echo $PATH &gt;&gt; /root/path.log[root@centos ~]#cat /var/spool/cron/root * * * * * echo $PATH &gt;&gt; /root/path.log #每分钟执行一次[root@centos ~]#tail -f /var/log/cron #查看是否有执行Sep 17 16:55:01 centos CROND[12590]: (root) CMD (echo $PATH &gt;&gt; /root/path.log)Sep 17 16:56:01 centos CROND[12609]: (root) CMD (echo $PATH &gt;&gt; /root/path.log)[root@centos ~]#lsanaconda-ks.cfg apps at2.txt at.log at.txt data dir motd_peiqi passwd path.log pwd[root@centos ~]#cat path.log /usr/bin:/bin 注意：运行结果的标准输出和错误以邮件通知给相关用户，如果不想有邮件，则可以在定时任务中加上重定向 12(1) COMMAND &gt; /dev/null(2) COMMAND &amp;&gt; /dev/null cron任务中不建议使用%，它有特殊用途，它表示换行的特殊意义，且第一个%后的所有字符串会被将成当作命令的标准输入，如果在命令中要使用%，则需要用 \\转义 注意：将%放置于单引号中是不支持的 范例： 在crontab中%的用法 1230 2 * * * /bin/cp -a /etc/ /data/etc`date +\\%F_\\%T`30 2 * * * /bin/cp -a /etc/ /data/etc`date +‘%F_%T’` 有问题 交互式删除 123456789[root@ubuntu ~]# crontab -l* * * * * echo &quot;this is test cron from root&quot;* * * * * echo &quot;this is test cron222 from root&quot; &amp;&gt;/dev/null[root@ubuntu ~]# crontab -ircrontab: really delete root&#x27;s crontab? (y/n) y[root@ubuntu ~]# crontab -lno crontab for root 重定向创建 1234567[root@ubuntu ~]# crontab -lno crontab for root[root@ubuntu ~]# echo @reboot echo &quot;this is test msg&quot; | crontab[root@ubuntu ~]# crontab -l@reboot echo this is test msg 秒级别运行任务 123456789101112131415for min in 0 1 2; do echo &quot;hi&quot;; sleep 20; done#用cron 执行脚本，在脚本中写循环来实现[root@ubuntu ~]# crontab -l5 1 * * * /root/cron-test.sh[root@ubuntu ~]# cat cron-test.sh#!/bin/bashPATH=/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binfor i in &#123;1..60&#125;;do if [ $[$i%5] -eq 0 ];then echo `date` &gt;&gt; /tmp/cron-sh-test.log fi sleep 1done 定时任务示例12345678910111213141516171819202122232425262728293031323334353637* * * * * #每分钟执行一次*/1 * * * * #每分钟都执行一次 */3 * * * * #每隔3钟执行一次*/10 02 * * * #每天凌晨2点，每隔10分钟执行一次 00 02 * * * #每天的凌晨2点整执行一次 00 02 1 * * #每月的1日的凌晨2点整执行一次 00 02 14 2 * #每年的2月14日凌晨2点执行一次 00 02 * * 7 #每周天的凌晨2点整执行一次 00 02 * 6 5 #每年的6月份整个月中、每到周五凌晨2点就会执行一次 &quot;日期穿刺&quot;问题：当日期字段和星期字段都被特定的值所指定时，那么满足其中任意一个字段的条件，任务就会被执行00 02 14 * 7 #每月14日或每周日的凌晨2点都执行00 02 14 2 7 #每年的2月14日或每年2月的周天的凌晨2点执行 00 00 14 2 * #每年2月14日的凌晨00:00执行一次 00 02 * 1,5,8 * #每年的1月、5月、8月的每天凌晨2点都会执行一次 00 02 1-8 * * #每月1号到8号凌晨2点都会执行一次 00 21 * * * #每天晚上21:00执行一次 45 4 1,10,22 * * #每月1、10、22日的4:45执行一次 45 4 1-10 * * #每月1到10日的4:45执行一次 3,15 8-11 */2 * * #每隔两天的上午8点到11点的第3和第15分钟执行 0 23-7/2 * * * #晚上11点到早上7点之间，每隔两小时执行 15 21 * * 1-5 #周一到周五每天晚上21:15执行 白名单和黑名单当 /etc/cron.allow 和 /etc/cron.deny 两个文件同时存在时，系统首先检查 /etc/cron.allow 文件。 如果你的用户名在 /etc/cron.allow 文件中，你就可以使用cron配置定时任务。 如果你的用户名不在 /etc/cron.allow 文件中，系统将不会再检查 /etc/cron.deny 文件，因此你将无法使用cron。 总的来说，/etc/cron.allow 文件具有优先级，且只要你的用户名在该文件中，无论 /etc/cron.deny 的内容如何，你都将获得访问cron的权限。如果你没有在 /etc/cron.allow 文件中找到你的用户名，即使你的用户名也没有在 /etc/cron.deny 文件中，你也将不能够访问cron。 所以，在这两个文件同时存在的情况下，想要授权某个用户使用cron，你应在 /etc/cron.allow 文件中添加该用户的用户名。 相反，如果你想阻止某个用户访问cron, 你应确保该用户的用户名既不在 /etc/cron.allow 文件中，也在 /etc/cron.deny 文件中。 crontab不执行的问题1234567891011121314151617181920212223242526272829第一，脚本代码有问题，解决：先手动调试跑通 第二，执行环境问题：手动执行成功而crontab不能执行的时候，很可能就是执行环境的问题，例如相关路径的设置问题，可以在代码最前面执行 source /home/user/.bash_profile 第三，系统时间不正确。这种问题最好理解，也是比较常见和隐蔽的问题，解决方案：date -s ******** 第四，就是我们的脚本是否有可执行权限。必须保证执行脚本的用户有执行改文件的权限。 第五，crontab 守护进程死掉了。这种情况是极少发生的，但也不排除，当我们实在是找不到其他原因的时候可以用。解决方案：重启该进程。 第六，crontab不执行的问题困扰了好长时间，脚本写的都正确，但是就是不执行，最终解决方法如下：crontab -u root /var/spool/cron/root这样root用户的crontab就生效了[root@localhost ~]# systemctl restart crond重启下服务就好了 第七，crond没有启动 第八，脚本编码问题，脚本在window下编写，传到linux下后报“锘?!/bin/bash”，用vi编辑器新建新shell脚本，输入内容后保存。 第九：特殊符号无法识别，需要添加转义 * * * * * tar czf /tmp/`date &#x27;+%Y&#x27;` /etc 该计划任务中命令的执行流程是crond-&gt;tar命令，而crond在执行tar命令时，无法识别通配符%的意思（shell能识别），所以该命令无法正常执行 解决方案一：添加转义符号* * * * * tar czf /tmp/`date &#x27;+\\%Y&#x27;` /etc 解决方案二：直接将命令扔到脚本里通常都会把要执行的操作放到文件中，然后/bin/bash a.sh去执行，* * * * * /bin/bash a.sh ，这样的执行流程就变成了crond-&gt;bash shell-&gt;a.sh,这样a.sh内即便是写%号，也能被识别出来 注意问题使用脚本执行定时任务（只有一条简单命令的可以直接使用命令执行） 运行脚本一定要用绝对路径执行，并且最好统一脚本位置 定时任务中date命令的百分号需转义才能使用 命令或脚本结果(正确及错误)定向到空(&amp;&gt;&#x2F;dev&#x2F;null)或追加到文件中 &amp;&gt;&gt;&#x2F;tmp&#x2F;run.log 避免不必要的程序及命令输出,如打包命令，tar -v的显示过程的选项 打包压缩使用相对路径（切到目标目录的上一级打包目标，否则可能会带着一层目录） tar czf a.tar.gz /test1 cd /test1，tar czf ../b.tar.gz ./* 定时任务脚本中的程序文件，尽量用绝对路径（iptables命令在计划任务中必须写绝对路） 系统与命令位置有关的环境变量问题,建议脚本中重新定义环境变量PATH","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"时间同步服务","slug":"Linux/service-manage/time-synchronization","date":"2025-08-20T08:51:55.000Z","updated":"2025-08-28T12:33:05.355Z","comments":true,"path":"Linux/service-manage/time-synchronization/","permalink":"https://aquapluto.github.io/Linux/service-manage/time-synchronization/","excerpt":"","text":"前言加密和安全当前都离不开时间的同步，否则各种网络服务可能不能正常运行 多主机协作工作时，各个主机的时间同步很重要，时间不一致会造成很多重要应用的故障，如：加密协议，日志，集群等， 利用NTP（Network Time Protocol） 协议使网络中的各个计算机时间达到同步。目前NTP协议属于运维基础架构中必备的基本服务之一 时间同步软件实现： ntp：使用渐进性同步机制，如果本地时间与标准时间相差较大，则需要一定的时间才能同步完成 chrony 一次性同步时间范例： ntpdate 一次性同步时间（centos7） 12345678910[root@centos7 ~]#date -s &#x27;-1 year&#x27; #修改时间Sat May 25 16:26:13 CST 2019[root@centos7 ~]#dateSat May 25 16:26:14 CST 2019[root@centos7 ~]#ntpdate ntp.aliyun.com #网上搜时间同步服务器网站25 May 16:26:30 ntpdate[24545]: step time server 203.107.6.88 offset31622399.992886 sec[root@centos7 ~]#dateMon May 25 16:26:34 CST 2020 范例： rdate 一次性同步时间 123456[root@centos7 ~]#yum -y install rdate[root@centos7 ~]#date -s &#x27;1 year&#x27;Tue Jan 18 21:33:13 CST 2022[root@centos7 ~]#rdate -s -u time.nist.gov[root@centos7 ~]#dateMon Jan 18 21:33:22 CST 2021 chrony实现NTP协议的的自由软件。 可使系统时钟与NTP服务器，参考时钟（例如GPS接收器）以及使用手表和键盘的手动输入进行同步。 还可以作为NTPv4（RFC 5905）服务器和对等体运行，为网络中的计算机提供时间服务。 设计用于在各种条件下良好运行，包括间歇性和高度拥挤的网络连接，温度变化（计算机时钟对温度敏感），以及不能连续运行或在虚拟机上运行的系统。 chrony 的优势： 更快的同步只需要数分钟而非数小时时间，从而最大程度减少了时间和频率误差，对于并非全天24 小时运行的虚拟计算机而言非常有用 能够更好地响应时钟频率的快速变化，对于具备不稳定时钟的虚拟机或导致时钟频率发生变化的节能技术而言非常有用 在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响 在应对临时非对称延迟时（例如，在大规模下载造成链接饱和时）提供了更好的稳定性 无需对服务器进行定期轮询，因此具备间歇性网络连接的系统仍然可以快速同步时钟 官方网站：https://chrony.tuxfamily.org/ 官方文档：https://chrony.tuxfamily.org/documentation.html chrony 文件组成包：chrony 两个主要程序：chronyd和chronyc chronyd：后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算机增减时间的比率，并对此进行补偿 chronyc：命令行用户工具，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可在一台不同的远程计算机上工作 服务unit 文件： 123456789/usr/lib/systemd/system/chronyd.service[root@ubuntu ~]# systemctl status chronyd.service● chrony.service - chrony, an NTP client/server Loaded: loaded (/lib/systemd/system/chrony.service; enabled; vendor preset:enabled) Active: active (running) since Tue 2023-05-30 08:15:46 CST; 3min 56s ago Docs: man:chronyd(8) man:chronyc(1) man:chrony.conf(5) 监听端口： 12服务端: 123/udp #其它机器通过此端口连接本机，将本机当作ntp服务器客户端: 323/udp #本机通过此端口同步时间 配置文件： 1/etc/chrony.conf 配置文件chrony.conf官方文档：https://chrony.tuxfamily.org/doc/3.5/chrony.conf.html 常用字段说明 12345678910111213server #可用于时钟服务器，iburst选项表示当服务器可达时，发送一个八个数据包而不是通常的一个数据包，包间隔通常为2秒,作用是加速与时间服务器的同步过程pool #该指令的语法与server 指令的语法相似，不同之处在于它用于指定NTP服务器池而不是单个NTP服务器。池名称应解析为随时间可能会变化的多个地址driftfile #根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中，会在重启后为系统时钟作出补偿rtcsync #启用内核模式，系统时间每11分钟会拷贝到实时时钟（RTC）allow / deny #指定一台主机、子网，或者网络以允许/拒绝访问本服务器cmdallow / cmddeny #指定哪台主机可以/不可以通过chronyd使用控制命令bindcmdaddress #允许chronyd监听哪个接口来接收由chronyc执行的命令makestep #通常chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在调整期大于某个阀值时调整系统时钟local stratum 10 #即使server指令中时间服务器不可用，也允许将本地时间作为标准时间授时给其它客户端 NTP 客户端工具chronyc 可以运行在交互式和非交互式两种方式，支持以下子命令 12345678910help #命令可以查看更多chronyc的交互命令accheck #检查是否对特定主机可访问当前服务器activity #显示有多少NTP源在线/离线sources [-v] #显示当前时间源的同步信息sourcestats [-v] #显示当前时间源的同步统计信息add server #手动添加一台新的NTP服务器clients #报告已访问本服务器的客户端列表delete #手动移除NTP服务器或对等服务器settime #手动设置守护进程时间tracking #显示系统时间信息 范例: Centos6 ntp客户端同步检查 123[root@centos6 ~]#ntpq -p#可以查看 delay (延迟)、offset(偏移)和jitter(抖动)等值来判断同步的质量 范例：启动服务 1[root@rocky86 ~]# systemctl start chronyd.service 范例 12345678910111213141516[root@ubuntu ~]# chronycchronyc&gt; trackingReference ID : CA701FC5 (dns2.synet.edu.cn) #当前同步的NTP服务器ID和IP地址Stratum : 2 #层次，跳数Ref time (UTC) : Tue May 30 01:00:39 2023 #源最后一次获取到的UTC时间System time : 0.000000001 seconds fast of NTP time #当前系统时间与NTP服务时间的偏移量Last offset : +0.000733123 seconds #最后偏移上次时钟更新时本地偏移量RMS offset : 0.000733123 seconds #偏移量平均值Frequency : 12.340 ppm fast #系统时钟偏差值的速率，单位为百万分之一Residual freq : +588.341 ppm #当前源的剩余频率Skew : 9.803 ppm #估计误差范围，单位为百万分之一Root delay : 0.022467736 seconds #到根设备的网络延迟总和Root dispersion : 0.003619912 seconds #到根设备的网络延迟平均值Update interval : 0.0 seconds #最近两次时钟更新之间的间隔Leap status : Normal #跳跃状态 范例：列出配置中所有ntp服务源的状态 123456789101112131415161718192021chronyc&gt; sourcestatsName/IP Address NP NR Span Frequency Freq Skew Offset Std Dev==============================================================================prod-ntp-4.ntp4.ps5.cano&gt; 8 4 520 +4.121 108.727 -32ms 8633usalphyn.canonical.com 10 7 527 +1.811 20.994 +1955us 2343usprod-ntp-5.ntp1.ps5.cano&gt; 10 5 463 -5.653 24.302 -36ms 2702uspugot.canonical.com 11 6 527 +2.124 7.392 -30ms 1047usntp1.flashdance.cx 10 6 526 +0.550 31.722 +1606us 3371usntp.wdc2.us.leaseweb.net 11 5 529 -3.635 17.252 -3281us 2297usdns2.synet.edu.cn 12 7 525 -0.105 12.072 -2299ns 1467ustick.ntp.infomaniak.ch 12 9 527 +8.028 28.147 +3958us 3535us#字段说明Name/IP Address #NTP服务器IP地址或主机名，或者参考时钟的refid值NP #当前服务器可用的采样点，用这些点执行线性回归方法来估算偏移值NR #最后一次回归计算后具有相同符号的偏差值的运行次数Span #最旧样本和最新样本之间的间隔，默认单位秒Frequency #NTP服务器的估算偏差值的速率，单位为百万分之一Freq Skew #Freq的估计误差范围，单位为百万分之一Offset #NTP源服务器的偏移量Std Dev #估算的样本标准偏差 范例：检查同步情况 123456789101112131415[root@centos7 ~]#chronyc sources -vMS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* dns2.synet.edu.cn 1 6 377 58 +1648us[+2216us] +/- 13ms^- tick.ntp.infomaniak.ch 1 6 377 56 +111us[ +111us] +/- 82ms#字段说明M #NTP源 ^表示服务器, = 表示二级时钟, # 表示本地时钟S #NTP源状态，*此源己同步, +可接收的源, -合并算法排除的可接受源, ?没连上的源, x认为该源有错, ~不确定的源Name/IP address #NTP服务器主机名或IP地址或refid值Stratum #层次，跳数，1 表示本地时钟，2 表示通过第一层级的服务器实现同步，以此类推Poll #NTP源的轮询频率，以秒为单位，值为基数2的对数，6表示64秒进行一次同步，chronyd会自动调整此值Reach #8进制数，表示源的可达性，每次对钟收发8个数据包，337表示最后一次同步8个数据包都收到，377二进制就是8个1LastRx #多久前从源收到最后一次数据，默认单位是秒Last sample #上次同步时NTP服务器与本地时间的偏移值 调整后偏移量[实际偏移量]实际测量中的误差范围,+表示正偏移，本地快 修改配置文件 1234567[root@ubuntu ~]# vim /etc/chrony/chrony.conf#注释pool行#添加下列行server ntp.aliyun.com iburst#重启服务[root@ubuntu ~]# systemctl restart chronyd.service 修改时间，并查看同步过程 1234567891011121314151617181920212223242526272829#先重启一下服务，才可以很快的观察到过程，不然要等很久，因为其实质是渐进性同步[root@ubuntu ~]# systemctl restart chrony.service[root@ubuntu ~]# date +%F-%T2023-05-30-10:43:23[root@ubuntu ~]# date -s &quot;-1 day&quot;Mon May 29 10:43:29 AM CST 2023[root@ubuntu ~]# date +%F-%T2023-05-29-10:43:30#查看同步过程[root@ubuntu ~]# chronyc sourcesMS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? 203.107.6.88 0 6 17 - +0ns[ +0ns] +/- 0ns#己经测得差了1天MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? 203.107.6.88 2 6 37 25 -86400s[-86400s] +/- 24ms#此次同步完成MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 203.107.6.88 2 6 377 43 +139us[+1222us] +/- 24ms[root@ubuntu ~]# date &quot;+%F %T&quot;2023-05-30 10:50:02 chrony 是渐进式同步，如果差距过大，想立即同步完成，则可以重启服务 1234567[root@ubuntu ~]# date +%F-%T2023-05-29 10:50:02[root@ubuntu ~]# systemctl restart chronyd.service[root@ubuntu ~]# date +%F-%T2023-05-30 10:50:02 公共NTP服务 阿里云公共NTP服务器Unix&#x2F;linux类：ntp.aliyun.com，ntp1-7.aliyun.comwindows类： time.pool.aliyun.com 腾讯公共NTPtime1-5.cloud.tencent.com 大学ntp服务s1a.time.edu.cn 北京邮电大学s1b.time.edu.cn 清华大学s1c.time.edu.cn 北京大学 国家授时中心服务器：210.72.145.44 美国标准技术院: time.nist.gov 时间工具timedatectl 时间和时区管理 12345678910111213141516timedatectl [OPTIONS...] COMMAND ...#常用选项-h|--help #显示帮助信息--version #显示版本信息-a|--all #显示所有属性--value #查询时仅显示值，不显示字段标题#常用子命令status #显示当前时间设置，默认项show #以友好格式显示，具体同容同 statusset-time TIME #修改时间set-timezone ZONE #修改时区list-timezones #列出当前可用时区set-local-rtc BOOL #RPC时间是否关联本地时区set-ntp BOOL #是否开启ntp 服务 范例 123456789101112131415161718#查看日期时间、时区及NTP状态：timedatectl#查看时区列表：timedatectl list-timezones#修改时区：timedatectl set-timezone Asia/Shanghai#修改时区root@ubuntu2004:~# rm -f /etc/localtimeroot@ubuntu2004:~# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#修改日期时间：timedatectl set-time &quot;2017-01-23 10:30:00&quot;#开启NTP：timedatectl set-ntp true/false 范例 123456789101112[root@ubuntu ~]# timedatectl Local time: Tue 2023-05-30 10:54:31 CST #本机时间, CST表示北京时间 Universal time: Tue 2023-05-30 02:54:31 UTC #世界标准时间，UTC表示世界标准时间 RTC time: Tue 2023-05-30 02:54:32 #RTC时间，硬件时间 Time zone: Asia/Shanghai (CST, +0800) #本机时区System clock synchronized: yes #系统时间是否己同步完成 NTP service: active #NTP时间同步服务是否启用 RTC in local TZ: no #RTC时间是否关联本机时区 #RTC Real-Time Clock 硬件时间，来自于时钟芯片#UTC Coordinated Universal Time 世界协调时间，又称世界标准时间#GMT Greenwich Mean Time 格林尼治(天文台)标准时间 范例：开启RTC时间与本地时区绑定 12345678910[root@ubuntu ~]# timedatectl set-local-rtc 1 #开启RTC时间与本地时区一致[root@ubuntu ~]# timedatectl Local time: Tue 2023-05-30 11:06:33 CST Universal time: Tue 2023-05-30 03:06:33 UTC RTC time: Tue 2023-05-30 11:06:32 #与本地时间一致 Time zone: Asia/Shanghai (CST, +0800)System clock synchronized: yes NTP service: active RTC in local TZ: yes 范例：查看 12345678[root@ubuntu ~]# timedatectl show -aTimezone=Asia/ShanghaiLocalRTC=noCanNTP=yesNTP=yesNTPSynchronized=noTimeUSec=Wed 2042-10-15 00:00:18 CSTRTCTimeUSec=Wed 2042-10-15 00:00:18 CST 范例：开启ntp时间同步服务 12345678910111213141516[root@ubuntu ~]# systemctl is-active chronyd.serviceinactive[root@ubuntu ~]# timedatectl set-ntp 1[root@ubuntu ~]# systemctl is-active chronyd.serviceactive#NTP服务开启，时间被同步回来[root@ubuntu ~]# timedatectl Local time: Tue 2023-05-30 11:25:52 CST Universal time: Tue 2023-05-30 03:25:52 UTC RTC time: Tue 2023-05-30 03:25:52 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yes NTP service: active RTC in local TZ: no 实战案例: 实现私有的时间服务器 在同一个网络内，如果有多个需要进行时间同步的服务器，则我们可以在内网自建NTP Server，这样可以节约访问外网的网络资源；另一方面，如果外网不可用，则至少可以保证，内网的NTP服务还是可用的。 原理：有两台服务器作为客户端，去同步国内的NTP服务器，同时作为时间同步服务器，为企业其他服务器提供时间同步服务 范例：假设10.0.0.183作为企业内部的时间同步服务器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[root@centos7 ~]#yum -y install chrony[root@centos7 ~]#vim /etc/chrony.confserver 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst#查询到该ip地址是国外的，不靠谱，要用中国的[root@centos7 ~]#ping 0.centos.pool.ntp.orgPING 0.centos.pool.ntp.org (193.182.111.14) 56(84) bytes of data. #修改为国内的时间同步服务器[root@centos7 ~]#vim /etc/chrony.conf server ntp.aliyun.com iburstserver time1-5.cloud.tencent.com iburstserver s1b.time.edu.cn iburst[root@centos7 ~]#systemctl restart chronyd[root@centos7 ~]#ps aux | grep chronychrony 40167 0.0 0.0 117808 1644 ? S 22:05 0:00 /usr/sbin/chronydroot 40181 0.0 0.0 112812 980 pts/0 S+ 22:06 0:00 grep --color=auto chrony#多了323端口，就是作为客户端，与阿里云那些服务器同步，但是不能作为服务器给别的客户端连[root@centos7 ~]#ss -ntlu Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port udp UNCONN 0 0 127.0.0.1:323 *:* #只能自己跟别的服务器连 udp UNCONN 0 0 [::1]:323 [::]:* tcp LISTEN 0 128 *:22 *:* tcp LISTEN 0 100 127.0.0.1:25 *:* tcp LISTEN 0 128 [::]:22 [::]:* tcp LISTEN 0 100 [::1]:25 [::]:* [root@centos7 ~]#chronyc sources -v^* 203.107.6.88 2 6 377 48 -950us[-1642us] +/- 32ms #代表已同步^? 202.112.1.34 0 8 0 - +0ns[ +0ns] +/- 0ns #不可到达#设置作为服务器，允许哪些客户端可以和它同步[root@centos7 ~]#vim /etc/chrony.conf # Allow NTP client access from local network.allow 0.0.0.0/0 #允许任何网段进行同步[root@centos7 ~]#systemctl restart chronyd#服务启动后会打开端口123/udp[root@centos7 ~]#ss -ntlu Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port udp UNCONN 0 0 *:123 *:* #可以让别人连接自己[root@centos7 ~]#date -s &#x27;2 year&#x27; #假装时间错误Sun Oct 12 22:32:19 CST 2025[root@centos7 ~]#dateSun Oct 12 22:32:53 CST 2025#客户端配置[root@Rocky8 ~]#vim /etc/chrony.conf #现在将10.0.0.183作为该服务器的时间同步服务器server 10.0.0.183 iburst[root@Rocky8 ~]#systemctl restart chronyd #跟随10.0.0.183的时间[root@Rocky8 ~]#date 2025年 10月 12日 星期日 22:35:44 CST[root@centos7 ~]#systemctl restart chronyd [root@centos7 ~]#chronyc sources -v#恢复原来时间[root@centos7 ~]#date Thu Oct 12 22:36:35 CST 2023[root@Rocky8 ~]#systemctl restart chronyd [root@Rocky8 ~]#chronyc sources -v[root@Rocky8 ~]#date2023年 10月 12日 星期四 22:38:42 CST#假如10.0.0.183和互联网断开了，就会影响内部服务器的同步时间，所以需要修改文件[root@centos7 ~]#vim /etc/chrony.conf #删除此行注释,当互联网无法连接,仍然可以为客户端提供时间同步服务local stratum 10","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"域名DNS解析服务","slug":"Linux/service-manage/DNS","date":"2025-08-20T08:51:47.000Z","updated":"2025-08-28T12:33:05.299Z","comments":true,"path":"Linux/service-manage/DNS/","permalink":"https://aquapluto.github.io/Linux/service-manage/DNS/","excerpt":"","text":"一、DNS服务相关概念和技术linux上的DNS文件&#x2F;etc&#x2F;hostshosts文件：直接定义域名与IP地址的对应关系，当主机访问某个域名时，会先从hosts文件中寻找与该域名对应的IP地址，如果找到则直接请求该IP地址，如果找不到才会将该域名提交DNS服务请求解析该域名对应的IP地址 远程登录linux主机过慢问题：有时客户端想远程登录一台linux主机，但每次登录输入密码后都会等很长一段时间才会进入，这是因为linux主机在返回信息时需要解析ip，如果在linux主机的hosts文件事先加入客户端的ip地址，这时再从客户端远程登录linux就会变很快。当然！这里所说的远程登录不仅仅是ssh登录，还可以是mysql远程登录，或是文件共享的查询等。 Windows系统中的hosts文件 1234%windir%\\System32\\drivers\\etc\\hosts# %windir% 是windows 系统中的环境变量写法，表示 Windows 安装目录，上述路径一般是C:\\Windows\\System32\\drivers\\etc Linux系统中的hosts文件 12345/etc/hosts #只适合机器少的场景，机器多就不适合用#格式122.10.117.2 www.magedu.org. [www]93.46.8.89 www.google.com. [google] 范例：实现域名解析 12345678[root@Rocky8 ~]#vim /etc/chrony.conf server ntp.wujl.org iburst[root@Rocky8 ~]#vim /etc/hosts10.0.0.183 ntp.wujl.org[root@Rocky8 ~]#ping ntp.wujl.orgPING ntp.wujl.org (10.0.0.183) 56(84) bytes of data. &#x2F;etc&#x2F;resolv.confresolv.conf文件：DNS客户机配置文件，用于设置DNS服务器的IP地址及DNS域名，还包含了主机的域名搜索顺序。该文件是由域名解析器（resolver，一个根据主机名解析IP地址的库）使用的配置文件。 作用 可以提供DNS服务器域名和IP地址，帮助解析 search选项可以补全短域名 假如resolv.conf没有任何配置并且网络没有配置DNS，你可能是这样的状态： 1234[root@nick ~]# ping www.baidu.comping: unknown host www.baidu.com连不通外网！！！ 我们可以往里面加一个域名服务器 1nameserver 114.114.114.114 DNS解析的步骤： 查找&#x2F;etc&#x2F;hosts 根据nameserver查找域名 如果在nameserver查找不到域名就进行search补全，重新走1~2步 1Client --&gt;hosts文件 --&gt; Client DNS Service Local Cache（缓存） --&gt; DNS Server (recursion递归) --&gt; DNS Server Cache --&gt; DNS iteration(迭代) --&gt; 根 --&gt; 顶级域名DNS --&gt;二级域名DNS… &#x2F;etc&#x2F;nsswitch.conf配置解析顺序，是先解析hosts文件，还是先解析DNS服务器 nsswitch.conf与系统获取解析的顺序有关。 123[root@f5ha.com ~]# vi /etc/nsswitch.conf #找到hosts关键字#hosts: db files nisplus nis dnshosts: files dns #此为默认配置 从配置文件就可以看出系统是先files（&#x2F;etc&#x2F;hosts）解析，再从dns（&#x2F;etc&#x2F;resolv.conf）解析。 &#x2F;etc&#x2F;hosts和DNS的优先级 123456789vim /etc/hosts10.0.0.8 www.baidu.comvim /etc/sysconfig/nerwork-scripts/ifcfg-eth0....DOMAIN=magedu.com....由于hosts比DNS优先级高，所以在/etc/hosts将www.baidu.com指向的IP地址为10.0.0.8后，去ping www.baidu.com得出的IP地址是10.0.0.8，就不是原先百度的地址 Ubuntu中的 systemd-resolved 服务在 ubuntu 系统中，虽然在网卡中配置了 DNS 服务器的IP地址，但在使用相关命令进行 DNS 解析时，默认的 DNS 服务器使用的是 127.0.0.53，而并不是我们在网卡上配置的DNS 服务器地址。 systemd-resolved 服务为本地应用程序提供了网络名字解析服务, 系统通过它对外进行 dns 请求 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@ubuntu ~]# cat /etc/resolv.conf......nameserver 127.0.0.53 #默认DNS 配置在此处options edns0 trust-adsearch magedu.com magedu.org#直接修改上述文件[root@ubuntu ~]# vim /etc/resolv.conf......#nameserver 127.0.0.53nameserver 223.6.6.6#测试[root@ubuntu ~]# nslookup www.magedu.comServer: 223.6.6.6Address: 223.6.6.6#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192#但是只要再次重启网络相关，该内容会被还原[root@ubuntu ~]# netplan apply[root@ubuntu ~]# cat /etc/resolv.conf | grep nameservernameserver 127.0.0.53#修改软链接文件指向,保证永久生效[root@ubuntu ~]# ll /etc/resolv.conflrwxrwxrwx 1 root root 39 Apr 21 2022 /etc/resolv.conf -&gt;../run/systemd/resolve/stub-resolv.conf[root@ubuntu ~]# rm -f /etc/resolv.conf[root@ubuntu ~]# ln -sv /run/systemd/resolve/resolv.conf /etc/resolv.conf&#x27;/etc/resolv.conf&#x27; -&gt; &#x27;/run/systemd/resolve/resolv.conf&#x27;[root@ubuntu ~]# ll /etc/resolv.conflrwxrwxrwx 1 root root 32 Jun 1 11:26 /etc/resolv.conf -&gt;/run/systemd/resolve/resolv.conf[root@ubuntu ~]# nslookup www.magedu.comServer: 223.6.6.6Address: 223.6.6.6#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192 设置全局DNS 1234567891011121314151617181920[root@ubuntu ~]# vim /etc/systemd/resolved.conf......DNS=223.5.5.5 223.6.6.6#重启服务[root@ubuntu ~]# systemctl restart systemd-resolved.service#查看[root@ubuntu ~]# cat /etc/resolv.conf......nameserver 223.5.5.5nameserver 223.6.6.6#测试[root@ubuntu ~]# nslookup www.magedu.comServer: 223.5.5.5Address: 223.5.5.5#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192 DNS服务器的分类 根DNS服务器：有13个，根域名服务器并不直接对域名进行解析，而是返回域名所属顶级域名的顶级域名服务器的IP地址 顶级域名DNS服务器：负责管理二级域名，即知道哪个域名服务器管理着二级域名 主&#x2F;权限&#x2F;授权DNS服务器：负责管理某个区的域名。他里面存的解析记录并不是从别人那里缓存到本地的，而是实打实配置存到自己机器上的，从这里拿到的记录具有权威性 从DNS服务器：又称之为辅助dns，这是一个备份服务器，从这里拿到的记录也具有权威性 缓存DNS服务器：不负责本地解析，采用递归方式转发客户机查询请求，并返回结果给客户机的DNS服务器，同时缓存查询回来的结果 转发器：这台DNS发现非本机负责的请求后，不再向根发起请求，而是直接转发给指定的一台或多台服务器，自身并不保存查询结果 DNS解析答案 肯定答案：存在对应的查询结果 否定答案：请求的条目不存在等原因导致无法返回结果 权威答案：直接由存有此查询结果的DNS服务器（权威服务器）返回的答案 非权威答案：由其它非权威服务器返回的查询答案 DNS解析的优先级 用浏览器访问：Chrome DNS 缓存 &gt; HOSTS文件 &gt; 系统DNS缓存 &gt; DNS服务器 不用浏览器访问：HOSTS文件 &gt; 系统DNS缓存 &gt; DNS服务器 DNS资源记录具体解析规则 /etc/bind/db.* 该文件定义域名的具体解析规则，该文件有多条资源记录组成，每一行都是一条资源记录，在RFC文档中，DNS解析记录被称为Resource Recode（资源记录），缩写为 RR 资源记录定义1NAME TTL CLASS TYPE VALUE NAME：资源记录名称，根据TYPE不一样，写法会有不同 TTL：缓存有效期，默认单位是秒 其他单位M(分)，H(时)， D(天)，W(周) 开头写，全局继承：$TTL 1D CLASS：资源记录类别，最常用IN（第一条写IN后，后面的可以省略，默认继承上一条） TYPE：解析记录类型 VALUE：值是由TYPE（类型）决定的 注意： TTL可从全局继承 使用 “@” 符号可用于引用当前区域的域名 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询方式响应 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值进行定义；此仅表示通过多个不同的名字可以找到同一个主机 解析记录类型SOA记录起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录，用于于设置当前DNS服务器的某些规则，规定主服务器，即在众多NS记录里哪一台才是主要的服务器 SOA 记录表示此DNS是该域名的权威解析服务器，当在查询的过程中，各级缓存都没有要查询的内容时，最后会通过递归查询的方式到达此DNS服务器，并请求此域名的SOA记录 1234567891011121314151617magedu.org. 86400 IN SOA ns.magedu.org. nsadmin.magedu.org. ( 2015042201 ; 2H ; 10M ; 1W ; 1D ; )#也可以这么写magedu.org. 86400 IN SOA ns.magedu.org. nsadmin.magedu.org. (2015042201 2H 10M 1W 1D)ns.magedu.org. #DNS服务器名称nsadmin.magedu.org. #服务器管理员邮箱2015042201 #版本号2H #从服务器更新间隔10M #失败重试间隔1W #从服务器数据失效时长1D #无效记录缓存时长 VALUE 字段中从左到右具体内容如下 字段 说明 DNS服务器名称 描述性字段，表示当前DNS服务器名称，注意最后要加 “.” 服务器管理员邮箱 邮箱中的@要写成 . 当前数据库的版本号 主从服务器要同步数据，此字段就是数据更新的标识，判断数据库有无发生变化，记住改数据库文件后也要改这个版本号，不然主服务器不会推新的数据给从服务器 从服务器拉取数据的时间间隔 从服务器在主服务器拉数据的周期 从服务器同步失败后重试时间间隔 上次同步失败后，间隔多久重试，假如从服务器在主服务器拉数据时恰好网断了，可以重试 从服务器同步失败超过多长时间从服务器失败 同步失败时长超过此值，则认为从服务器数据无效，假如网断了，从服务器迟迟和主服务器连接不上，这时主服务器已经数据更新，从服务器还是老旧的数据，避免这种情况，设置过期时间，超了这个时间，从服务器还是不能与主服务器同步，就不能对外提供服务 不存在的记录缓存时长 当查询一个不存在的解析记录时，该记录在指定时间内直接返回不存在，假如有用户查询不存在的东西，那么将这个不存在的东西缓存下来，让用户在一段时间内，如果他查的是不存在的记录，直接结果就是不存在，就不需要去查询，消耗服务器的资源 注意： 当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字，只是注释功能，可以不需要配置对应的NS记录和A记录 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般用 . 替换，例如：admin.magedu.org 主从服务区域传输相关定义以及否定的答案的统一的TTL NS记录NS记录和SOA记录是任何一个DNS区域都不可或缺的两条记录，NS记录也叫名称服务器记录，用于说明这个区域有哪些DNS服务器负责解析，即说明了在这个区域里，有多少个服务器来承担解析的任务 一般来说，为了服务的安全可靠，一个域名，至少应该有两条NS记录，保证服务的冗余，防止出现单点失败，即规定从服务器 注意： 相邻的两个资源记录的name相同时，后续的可省略 对NS记录而言，任何一个NS记录后面的服务器名字，都应该在后续有一个A记录 一个区域可以有多个NS记录 多个从服务器就多条NS记录 从服务器的名字可以随便，但是最后都要解析成A记录 123456# 比如你想查找www.linux-magedu.com，然后linux-magedu.com这个域的解析工作是由dns1.linux-magedu.com和dns2.linux-magedu.com负责的，这时你就知道去dns1.linux-magedu.com服务器或者dns2.linux-magedu.com服务器上去继续查询www.linux-magedu.com，然后这个域名的服务器会向你返回www.linux-magedu.comlinux-magedu.com. 86400 IN NS dns1.linux-magedu.com.linux-magedu.com. 86400 IN NS dns2.linux-magedu.com.dns1.linux-magedu.com. 86400 IN A 10.0.0.206dns2.linux-magedu.com. 86400 IN A 10.0.0.208 A记录把域名解析为IP，例:www.egonlin.com IN A 1.1.1.1 避免用户写错名称时给错误答案，可通过泛域名解析进行解析至某特定地址 1234567891011121314www.magedu.org. IN A 1.1.1.1www.magedu.org. IN A 2.2.2.2 # 如果有多条A记录，且有A记录的IP与DNS机器IP相同，则优先返回mx1.magedu.org. IN A 3.3.3.3mx2.magedu.org. IN A 4.4.4.4$GENERATE 1-254 HOST$ IN A 1.2.3.$*.magedu.org. IN A 5.5.5.5 # 泛解析，匹配所有以magedu.org结束的域名或主机名magedu.org. IN A 6.6.6.6linux-magedu.com. 86400 IN A 10.0.0.167@ 86400 IN A 10.0.0.167 # @代表域名，此条记录含义同上 范例：阿里云 AAAA记录将域名转为IPv6地址 CNAME记录把一个域名解析为另外一个域名 1www.magedu.org. IN CNAME websrv.magedu.org. PTR记录反向DNS解析，即将IPv4或IPv6地址映射回域名 注意：网络地址及后缀可省略；主机地址依然需要反着写 1234567#A记录www.magedu.org. IN A 1.2.3.4#与其对应的PTR记录4.3.2.1.in-addr.arpa. IN PTR www.magedu.org.#如1.2.3为网络地址，可简写成：4 IN PTR www.magedu.org. MX记录用于邮件交换，指定邮件服务器，将一个域的电子邮件定向到托管该域用户帐号的服务器(SMTP服务器) 比如 A 用户向 B 用户发送一封邮件，那么他需要向DNS查询 B 的MX记录，DNS在定位到了 B 的MX记录后反馈给A 用户，然后 A 用户把邮件投递到B用户的MX记录服务器里 一个域可以定义多条MX记录，但每条MX记录的优先级不同，如果邮件通过最高优先级记录无法递送，则采用第二优先级，以此类推。 注意： 一个区域内，MX记录可有多个；但每个记录的value之前应该有一个数字(0-99)，表示此服务器的优先级；数字越小优先级越高 对MX记录而言，任何一个MX记录后面的服务器名字，都应该在后续有一个A记录 1234magedu.org. IN MX 10 mx1.magedu.org. IN MX 20 mx2.magedu.org.mx1 A 10.0.0.100mx2 A 10.0.0.200 TXT记录对域名进行标识和说明的一种方式，一般做验证记录时会使用此项 1_dnsauth.linux-magedu.com. 86400 IN TXT 2024dtetmvzwclwf6wsl0y6jcpvwga2wkibgyb1a103yd7re2 互联网域名域名注册 代理商：万网, 新网, godaddy 注册完成以后，想自己用专用服务来解析 管理后台：把NS记录指向的服务器名称，和A记录指向的服务器地址 范例：阿里云DNS管理后台界面 HttpDNSHttpDNS是使用HTTP协议向DNS服务器的80端口进行请求，代替传统的DNS协议向DNS服务器的53端口进行请求。也就是使用Http协议去进行DNS解析请求，DNS服务器返回的解析结果（域名对应的服务器IP），直接向该IP发起对应的API服务请求，代替使用域名。 HttpDNS的原理非常简单，主要有两步： 客户端直接访问HttpDNS接口，获取业务在域名配置管理系统上配置的访问延迟最优的IP。（基于容灾考虑，还是保留次选使用运营商LocalDNS解析域名的方式） 客户端向获取到的IP后就向直接往此IP发送业务协议请求。以Http请求为例，通过在header中指定host字段，向HttpDNS返回的IP发送标准的Http请求即可。 bind 是一款实现DNS服务的开放源码软件，能够提供双向解析，转发，子域授权，view 等功能，使用广泛，目前Internet上半数以上的DNS服务器都是由Bind来实现的 二、DNS软件bind能实现DNS功能的软件有很多，像 bind，powerdns，dnsmasq，unbound，coredns等 bind 是一款实现DNS服务的开放源码软件，能够提供双向解析，转发，子域授权，view 等功能，使用广泛，目前Internet上半数以上的DNS服务器都是由Bind来实现的 CentosBIND相关程序包 bind：服务器 bind-utils: 客户端 bind-libs：相关库,依赖关系自动安装 bind-chroot: 安全包，将dns相关文件放至 &#x2F;var&#x2F;named&#x2F;chroot&#x2F; 安装bind软件 1[root@centos8 ~]#dnf -y install bind bind-utils 启动服务 named会开启TCP和UDP的53端口， 953端口是给管理工具使用的 1[root@centos ~]# systemctl enable --now named 将其它机器的DNS指向本机 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113[root@rocky8 ~]#hostname -I10.0.0.179[root@centos8 ~]#vim /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.176PREFIX=24GATEWAY=10.0.0.2DNS1=10.0.0.179ONBOOT=yes[root@centos8 ~]#nmcli con reload [root@centos8 ~]#nmcli con up eth0 [root@centos8 ~]#cat /etc/resolv.conf # Generated by NetworkManagernameserver 10.0.0.179#失败了，显示不可达[root@centos8 ~]#dig www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; www.baidu.com;; global options: +cmd;; connection timed out; no servers could be reached#原因是rocky上udp/53指向的是127.0.0.1，而centos的DNS指向的是10.0.0.179[root@rocky8 ~]#ss -ntluNetid State Recv-Q Send-Q Local Address:Port Peer Address:Port Process udp UNCONN 0 0 127.0.0.1:53 0.0.0.0:* #解决方法就是将rocky的udp/53指向所有[root@rocky8 ~]#vim /etc/named.confoptions &#123; listen-on port 53 &#123; 127.0.0.1;10.0.0.179; &#125;; #第一种，注意要加“;”，但不推荐，万一本机的IP地址变了就不适用了 options &#123; listen-on port 53 &#123; localhost; &#125;; #第二种，localhost代表了本机所有的IPoptions &#123;// listen-on port 53 &#123; 127.0.0.1; &#125;; #第三种，加注释，由于是C语言风格，所以加//#重启[root@rocky8 ~]#rndc reloadserver reload successful[root@rocky8 ~]#ss -ntluNetid State Recv-Q Send-Q Local Address:Port Peer Address:Port Process udp UNCONN 0 0 10.0.0.179:53 0.0.0.0:* #失败，显示拒绝[root@centos8 ~]#dig www.baidu.com.....;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: REFUSED, id: 4293 #显示拒绝......;; SERVER: 10.0.0.179#53(10.0.0.179) #但是能连上10.0.0.179.....#原因如下[root@rocky8 ~]#vim /etc/named.confoptions &#123; ..... allow-query &#123; localhost; &#125;; #只允许本机IP查询#修改options &#123; ..... allow-query &#123; localhost;10.0.0.0/24; &#125;; #第一种，允许本机和10网段查询，不推荐 options &#123; ..... allow-query &#123; localhost;any; &#125;; #第二种，允许本机和其他所有机器查询 options &#123; .....// allow-query &#123; localhost; &#125;; #第三种，默认允许所有 [root@rocky8 ~]#rndc reloadserver reload successful#成功[root@centos8 ~]#dig www.baidu.com......;; ANSWER SECTION:www.baidu.com. 1200 IN CNAME www.a.shifen.com.www.a.shifen.com. 120 IN A 183.2.172.42www.a.shifen.com. 120 IN A 183.2.172.185......#如果将53/udp禁掉[root@rocky8 ~]#iptables -A INPUT -p udp --dport 53 -j REJECT#这个时候就失败了[root@centos8 ~]#dig www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; www.baidu.com;; global options: +cmd;; connection timed out; no servers could be reached#如果将53/tcp禁掉[root@rocky8 ~]#iptables -R INPUT 1 -p tcp --dport 53 -j REJECT#不影响，这说明了udp53端口做解析用的[root@centos8 ~]#dig www.baidu.com......;; ANSWER SECTION:www.baidu.com. 1200 IN CNAME www.a.shifen.com.www.a.shifen.com. 120 IN A 183.2.172.42www.a.shifen.com. 120 IN A 183.2.172.185......#如果将953端口禁掉[root@rocky8 ~]#iptables -R INPUT 1 -p tcp --dport 953 -j REJECT#管理工具会使用失败[root@rocky8 ~]#rndc reloadrndc: connect failed: 127.0.0.1#953: connection refused 自己就是DNS服务器，将DNS指向自己 1234567891011121314151617181920212223242526272829#现在指向的是10.0.0.2和100.76.76.76[root@rocky8 ~]#cat /etc/resolv.conf# Generated by NetworkManagernameserver 10.0.0.2nameserver 100.76.76.76#修改[root@rocky8 ~]#vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0NAME=eth0BOOTPROTO=noneIPADDR=10.0.0.179PREFIX=24GATEWAY=10.0.0.2DNS1=127.0.0.1ONBOOT=yes[root@rocky8 ~]#nmcli con reload[root@rocky8 ~]#nmcli con up eth0[root@rocky8 ~]#cat /etc/resolv.conf# Generated by NetworkManagernameserver 127.0.0.1#能ping成功，理论上只要安装了DNS服务，就能有解析服务[root@rocky8 ~]#ping www.baidu.comPING www.a.shifen.com (183.2.172.185) 56(84) bytes of data.64 bytes from 183.2.172.185 (183.2.172.185): icmp_seq=1 ttl=128 time=8.33 ms64 bytes from 183.2.172.185 (183.2.172.185): icmp_seq=2 ttl=128 time=7.95 ms bind己经内置了13个根域名服务器地址 12[root@centos ~]# cat /var/named/named.ca[root@ubuntu ~]# cat /usr/share/dns/root.hints 范例: DNS客户端相关库 12345678910111213[root@centos8 ~]#ping www.baidu.comPING www.a.shifen.com (110.242.68.4) 56(84) bytes of data.64 bytes from 110.242.68.4 (110.242.68.4): icmp_seq=1 ttl=128 time=10.9 ms64 bytes from 110.242.68.4 (110.242.68.4): icmp_seq=2 ttl=128 time=10.5 ms^C--- www.a.shifen.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 3msrtt min/avg/max/mdev = 10.539/10.698/10.857/0.159 ms[root@centos8 ~]#ldd `which ping` | grep libresolv.so libresolv.so.2 =&gt; /lib64/libresolv.so.2 (0x00007f230739b000) [root@centos8 ~]#ldd `which curl` |grep libresolv.so libresolv.so.2 =&gt; /lib64/libresolv.so.2 (0x00007fe95048a000) BIND包相关文件 BIND主程序：/usr/sbin/named 服务脚本和Unit名称：/etc/rc.d/init.d/named，/usr/lib/systemd/system/named.service 主配置文件：/etc/named.conf, /etc/named.rfc1912.zones, /etc/rndc.key 管理工具：/usr/sbin/rndc，remote name domain controller，默认与bind安装在同一主机，且只能通过127.0.0.1连接named进程，提供辅助性的管理功能；953&#x2F;tcp 解析库文件：/var/named/ZONE_NAME.ZONE 注意 一台物理服务器可同时为多个区域提供解析 必须要有根区域文件；named.ca 应该有两个（如果包括ipv6的，应该更多）实现localhost和本地回环地址的解析库 主配置文件 &#x2F;etc&#x2F;named.conf1234567891011121314[root@rocky8 ~]#vim /etc/named.conf options &#123; .... directory &quot;/var/named&quot;; #域名数据库文件存放路径 dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; ....&#125;;........include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;; 配置 配置字段 说明 全局配置 options{}; 全局配置选项 日志子系统配置 logging{}; 运行日志 区域定义 zone “ZONE_NAME” IN {}; 定义了要解析的域名与具体解析规则之间的对应关系，本机能够为哪些zone进行解析，就要定义哪些zone 注意： 任何服务程序如果期望其能够通过网络被其它主机访问，至少应该监听在一个能与外部主机通信的 IP地址上缓存名称服务器的配置：监听外部地址即可 dnssec: 建议关闭dnssec，设为no 常用全局配置选项 12345678910111213141516options &#123; #此配置表示DNS服务只监听了本机127.0.0.1的53端口，如果对外提供DNS服务，可以将此行注释或值改成any listen-on port 53 &#123; 127.0.0.1; &#125;; #监听IPV6的53端口，配置方法同上 listen-on-v6 port 53 &#123; ::1; &#125;; #监听本机所有IPV6地址，不想监听IPV6地址，可以将 any 改成 none listen-on-v6 &#123; any; &#125;; #此配置表示仅本机可以使用DNS服务的解析查询功能，如果对外提供DNS服务，可以将此行注释或值改成any allow-query &#123; localhost; &#125;; #是否启用加密验证，在使用转发的时候，将此项改为 no dnssec-validation auto; #转发服务器 forwarders &#123; 10.0.0.207; &#125;; #转发策略,具体见后续章节 forward first;&#125;; 中间配置文件 &#x2F;etc&#x2F;named.rfc1912.zones 定义了要解析的域名与具体解析规则之间的对应关系，本机能够为哪些zone进行解析，就要定义哪些zone 将自己要配置的域名和域名数据库之间的关联关系都放在这个文件当中，最好不要放在 &#x2F;etc&#x2F;named.conf，这样子不好管理 12345678[root@rocky8 ~]#vim /etc/named.rfc1912.zones ......zone &quot;localhost&quot; IN &#123; #IN 可以省略不写 type master; #类型 master,slave 用于表示DNS主服务器或者从服务器,forward表示转发 file &quot;named.localhost&quot;; #具体解析规则文件路径（也就是域名数据库文件） allow-update &#123; none; &#125;;&#125;;...... 具体解析规则 &#x2F;var&#x2F;etc&#x2F;*该文件定义域名的具体解析规则，该文件有多条资源记录组成，每一行都是一条资源记录，在RFC文档中，DNS解析记录被称为Resource Recode（资源记录），缩写为 RR UbuntuBIND相关程序包 bind9：服务器 bind9-utils: 客户端 bind9-libs：相关库,依赖关系自动安装 bind9-chroot: 安全包，将dns相关文件放至 &#x2F;var&#x2F;named&#x2F;chroot&#x2F; 安装bind软件 1[root@ubuntu2004 ~]#apt -y install bind9 bind9-utils 启动服务 named会开启TCP和UDP的53端口， 953端口是给管理工具使用的 1[root@ubuntu ~]# systemctl enable --now named.service BIND包相关文件1234567891011121314[root@ubuntu bind]# dpkg -L bind9....../etc/bind/etc/bind/bind.keys/etc/bind/db.0 #db.* 名具体解析规则文件/etc/bind/db.127/etc/bind/db.255/etc/bind/db.empty/etc/bind/db.local/etc/bind/named.conf #主配置文件/etc/bind/named.conf.default-zones #中间配置文件，该文件中定义了域名和具体解析规则文件的对应关系/etc/bind/named.conf.local #中间配置文件，引用/etc/bind/zones.rfc1918，被注释/etc/bind/named.conf.options #bind配置项/etc/bind/zones.rfc1918 #中间配置文件，该文件中定义了域名和具体解析规则文件的对应关系 主配置文件 &#x2F;etc&#x2F;bind&#x2F;named.conf12345[root@ubuntu bind]# cat /etc/bind/named.conf......include &quot;/etc/bind/named.conf.options&quot;;include &quot;/etc/bind/named.conf.local&quot;;include &quot;/etc/bind/named.conf.default-zones&quot;; 选项配置文件 &#x2F;etc&#x2F;bind&#x2F;named.conf.options该文件主要包括以下几部份内容，默认只有全局配置部份 配置 配置字段 备注 全局配置 options{}; 全局配置选项 日志子系统配置 logging{}; 运行日志 网络自定义集合 acl 将某个网段或某个具体IP地址定义在一个集合里面 视图 view 配合acl将不同的请求来源用不同的解析规则返回，实现智能DNS 常用全局配置选项 12345678910111213141516options &#123; #此配置表示DNS服务只监听了本机127.0.0.1的53端口，如果对外提供DNS服务，可以将此行注释或值改成any listen-on port 53 &#123; 127.0.0.1; &#125;; #监听IPV6的53端口，配置方法同上 listen-on-v6 port 53 &#123; ::1; &#125;; #监听本机所有IPV6地址，不想监听IPV6地址，可以将 any 改成 none listen-on-v6 &#123; any; &#125;; #此配置表示仅本机可以使用DNS服务的解析查询功能，如果对外提供DNS服务，可以将此行注释或值改成any allow-query &#123; localhost; &#125;; #是否启用加密验证，在使用转发的时候，将此项改为 no dnssec-validation auto; #转发服务器 forwarders &#123; 10.0.0.207; &#125;; #转发策略,具体见后续章节 forward first;&#125;; 中间配置文件 &#x2F;etc&#x2F;bind&#x2F;named.conf.default-zones该文件中定义了要解析的域名与具体解析规则之间的对应关系 1234zone &quot;ZONE_NAME&quot; IN &#123; #IN 可以省略不写 type &#123;master|slave|hint|forward&#125;; #类型 master,slave 用于DNS主从,forward表示转发 file &quot;file_path&quot;; #具体解析规则文件路径&#125;; 具体解析规则 &#x2F;etc&#x2F;bind&#x2F;db.*该文件定义域名的具体解析规则，该文件有多条资源记录组成，每一行都是一条资源记录，在RFC文档中，DNS解析记录被称为Resource Recode（资源记录），缩写为 RR allow 访问控制指令在named配置中有四个allow开头的字段，主要用来实现访问控制 配置 说明 allow-query{}; 允许查询本DNS的主机，白名单，注释就代表所有主机都可使用本机当DNS allow-transfer{}; 允许区域传送的主机，白名单，注释代表所有，一般用在主从DNS配置时指定从节点 allow-recursion{}; 允许递归的主机,建议全局使用 allow-update{}; 允许可以远程更新解析规则的主机 三、DNS测试和管理工具dig 命令dig只用于测试dns系统，不会查询本地 hosts文件中定义的域名和IP对应关系 1[root@ubuntu ~]# apt install bind9 123456789101112131415161718192021222324252627282930313233343536373839dig [@global-server] [domain] [q-type] [q-class] &#123;q-opt&#125; &#123;global-d-opt&#125; host [@local-server] &#123;local-d-opt&#125; [ host [@local-server] &#123;local-d-opt&#125; [...]] dig [-t type] name [@SERVER] [query options]#参数说明@global-server #指定DNS服务器domain #要查询的域名q-type #要查询的记录类型(a,any,mx,ns,soa,hinfo,axfr,txt,...)，默认aq-class #要查询的解析类型(in|hs|ch)，默认 ind-opt #查询选项 +[no]trace #是否追踪查询过程 +[no]cmd #是否在查询结果中显示头信息 +[no]recurse #是否进行递归解析查询 +[no]all #是否显示所有信息，如果否，要指明具体显示内容 +[no]answer #是否显示answer部份 +[no]question #是否显示question部份 +[no]authority #是否显示authority部份 +[no]comment #是否显示comment部份 +[no]stat #是否显示status部份 +[no]short #是否只显示关键信息q-opt #选项 -h #显示帮助 -v #显示版本号 -4 #仅查询IPV4的DNS服务器 -6 #仅查询IPV6的DNS服务器 -b address[#port] #使用指定客户端IP去查询DNS -f filename #从文件中获取要查询的域名 -p port #指定DNS服务查询端口 -t type #指定要查询的资源记录类型A|NS|AAA|PTR|... -u #以微秒显示打印时间 -x dot-notation #反向解析 #常用组合dig domaindig @dns-erver domain | dig domain @dns-serverdig -t q-type domain | dig domain q-typegit -x IP | dig -t ptr reverseIP.in-addr.arpa #reverseIP 表示将要查询的IP倒序输出 范例：查询DNS解析，使用默认DNS服务器 1234567891011121314151617181920212223242526272829303132333435363738394041[root@ubuntu ~]# dig www.jose-404.com; &lt;&lt;&gt;&gt; DiG 9.18.12-0ubuntu0.22.04.1-Ubuntu &lt;&lt;&gt;&gt; www.jose-404.com #dig命令版本和参数，查询参数为www.jose-404.com;; global options: +cmd #默认选项，此项表示显示头部软件版本和参数信息#查询结果;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 2948 #QUERY 表示是执行查询操作，NOERROR 表示解析成功，id: 12947 此次查询的ID，在dns协议中，通过ID编号匹配查询请求和返回结果;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1#flags: qr rd ra 标志位#qr(query，查询标志，代表查询操作)#rd(recursion desired, 表示客户端希望进行递归查询)#ra(recursive available, 表示DNS服务器支持递归查询)#aa(Authoritative Answer, 权威回复，如果查询结果由管理域名的域名服务器而不是缓存服务器提供的，则称为权威回复)#QUERY: 1 查询数，表示1个查询，对应下面 QUESTION SECTION中的记录数#ANSWER: 13 查询结果，表示有13个查询结果，对应下面 ANSWER SECTION 中的记录数#AUTHORITY: 0 权威域名服务器记录数量，此处表示有0个权威域名服务器#ADDITIONAL: 1 额外记录数量，此处表示有1个额外记录，此处缺失该部份内容#选项;; OPT PSEUDOSECTION:#EDNS: Extended DNS 扩展用户数据报文协议#version:0 协议版本为 0#flag:; 标记位为空#udp:65494 数据包大小; EDNS: version: 0, flags:; udp: 65494#查询域名，此处表示查www.jose-404.com;; QUESTION SECTION:;www.jose-404.com. IN A#具体查询结果;; ANSWER SECTION:www.jose-404.com. 1 IN A 47.94.245.255#第一列是要要询的域名#第二列是TTL(time to live),表示该记录的缓存时间，单位是秒#第三列是要查询的信息类型，IN代表类别为IP协议，即Internet#第四列是要查询的记录类型，NS表示name server，即域名服务器#第五列表示查询得到的值;; Query time: 15 msec #本次查询消耗时长;; SERVER: 127.0.0.53#53(127.0.0.53) (UDP) #DNS服务器为10.0.0.2 端口是53;; WHEN: Tue May 30 16:46:53 CST 2023 #查询时间;; MSG SIZE rcvd: 61 #返回内容长度为61字节 范例：指定DNS服务器，指定本机请求DNS服务的IP 1[root@ubuntu ~]# dig www.jose-404.com @114.114.114.114 -b 10.0.0.206 范例：反向解析 123#两种方法[root@rocky86 ~]# dig -x 47.94.245.255 +nocmd[root@ubuntu ~]# dig -t ptr 255.245.94.47.in-addr.arpa +nocmd 范例：短格式 12[root@ubuntu ~]# dig www.jose-404.com +short47.94.245.255 范例：从文件中获取要查询的域名 123456789101112[root@ubuntu ~]# cat domain.txtwww.baidu.comwww.jd.com[root@ubuntu ~]# dig -f domain.txt +shortwww.a.shifen.com.124.237.176.4124.237.176.3www.jd.com.gslb.qianxun.com.www.jd.com.s.galileo.jcloud-cdn.com.wwwv6.jcloudimg.com.111.225.218.3 范例：只查询别名解析 12345[root@ubuntu ~]# dig -t cname www.jd.com......[root@ubuntu ~]# dig www.jd.com in cname..... 范例：模拟区域传送 12345dig -t axfr ZONE_NAME @SERVERdig -t axfr magedu.org @10.10.10.11dig –t axfr 100.1.10.in-addr.arpa @172.16.1.1dig -t NS . @114.114.114.114dig -t NS . @a.root-servers.net host命令host 命令可以根据域名查询得到对应的服务器IP地址，不会查询本地 hosts文件中定义的域名和IP对应关系 1234567891011121314151617host [option] hostname [server]a #显示所有信息-c #指定查询类型 HS|CH|IN-C #查询SOA-d #同 -v-p #指定端口-r #不递归查询-t #指定查询类型 CNAME|NS|SOA|TXT|DNSKEY|AXFR|...-T #使用TCP进行DNS查询-U #使用UDP进行DNS查询-v #显示执行过程-V #显示命令版本-w #如果没有查询结果，则阻塞，一直等待-W N #等待N秒后超时-4 #仅查询IPV4的DNS server-6 #仅查询IPV4的DNS server 范例 1234567[root@ubuntu ~]# host www.magedu.comwww.magedu.com has address 10.0.0.206[root@ubuntu ~]# host www.baidu.comwww.baidu.com is an alias for www.a.shifen.com.www.a.shifen.com has address 124.237.176.3www.a.shifen.com has address 124.237.176.4 范例：指定DNS服务器 123456[root@ubuntu ~]# host www.magedu.com 114.114.114.114Using domain server:Name: 114.114.114.114Address: 114.114.114.114#53Aliases:www.magedu.com has address 140.143.156.192 范例 12345host -t NS magedu.org 172.16.0.1host -t soa magedu.orghost -t mx magedu.orghost -t axfr magedu.orghost 1.2.3.4 nslookup命令nslookup：主要用来查询DNS记录，查看域名解析是否正常，也可用来诊断网络问题 支持交互式和非交互式两种执行方式，在Windows系统中和Linux系统中都可以使用 不会查询本地 hosts文件中定义的域名和IP对应关系，也不能查询dns的递归或者迭代 123nslookup [-option] [name | -] [server]-type #指定查询类型 A|AAAA|CNAME|... 范例：交互式模式 1234nslookup&gt;server IP: 指明使用哪个DNS server进行查询set q=RR_TYPE: 指明查询的资源记录类型NAME: 要查询的名称 范例：非交互式查询 1234567[root@ubuntu ~]# nslookup www.magedu.comServer: 127.0.0.53Address: 127.0.0.53#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192 范例：交换式查询 12345678[root@ubuntu ~]# nslookup&gt; www.magedu.comServer: 127.0.0.53Address: 127.0.0.53#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192 范例：指定DNS服务器 1234567891011121314151617181920212223#非交互式[root@ubuntu ~]# nslookup www.magedu.com 114.114.114.114Server: 114.114.114.114Address: 114.114.114.114#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192#交互式[root@ubuntu ~]# nslookup&gt; server 223.5.5.5Default server: 223.5.5.5Address: 223.5.5.5#53&gt; www.magedu.com;; communications error to 223.5.5.5#53: timed outServer: 223.5.5.5Address: 223.5.5.5#53Non-authoritative answer:Name: www.magedu.comAddress: 140.143.156.192 范例：指定查询类型 1[root@ubuntu ~]# nslookup -type=cname www.baidu.com 范例：查看默认信息 12[root@ubuntu ~]# nslookup&gt; set all 范例：Windows系统中使用 1234567891011C:\\Users\\44301&gt;nslookup默认服务器: xd-cache-1.bjtelecom.netAddress: 219.141.136.10&gt; www.magedu.com服务器: xd-cache-1.bjtelecom.netAddress: 219.141.136.10非权威应答:名称: www.magedu.comAddress: 140.143.156.192 rndc 命令rndc 是 bind 程序的客户端工具，默认使用 TCP的 953 端口连接 bind 服务器，进行管理DNS 12345678910111213rndc COMMANDCOMMAND: status: 查看状态 reload: 重载主配置文件和区域解析库文件 reload zonename: 重载区域解析库文件 retransfer zonename: 手动启动区域传送，而不管序列号是否增加 notify zonename: 重新对区域传送发通知 reconfig: 重载主配置文件 querylog: 开启或关闭查询日志文件/var/log/message trace: 递增debug一个级别 trace LEVEL: 指定使用的级别 notrace：将调试级别设置为 0 flush：清空DNS服务器的所有缓存记录 重启主配置文件和区域解析库文件 12#相当于systemctl restart named，使用前提是named服务已经开启[root@centos ~]#rndc reload whois 命令whois 命令可以查询域名注册信息 范例: whois 查询域名信息 12[root@centos7 ~]#yum -y install whois[root@centos7 ~]#whois magedu.com 可以从网站查询信息,查询链接 1https://www.toolnb.com/domaininfo/wangxiaochun.com.html 四、在公有云上配置DNS解析要在互联网上运行一个可以被访问的项目，我们至少需要一个域名，一个服务器，一个固定IP地址。 目前国内主流的公有云平台包括阿里云，腾迅云，华为云，亚马逊云(AWS) 等。 这些平台都提供云主机，域名注册与解析等服务，过程也大相径庭。 我们以阿里云平台为例，描述一下在公有云平台上配置域名解析的过程 打开阿里云官网 https://account.aliyun.com/ 当我们己经购买了域名和主机后，就可以开始配置域名解析工作了 在左侧控制台中，选择 云解析DNS，进入 域名解析 页面 在列表中选择要进行解析的域名，点击操作列中的 解析设置 点击 添加记录 参数说明 参数 说明 值 记录类型 解析类型，默认选A，将域名解析到服务器IP A 解析请求来源 指定只响应符合来源的解析请求 默认值 记录值 填写主机域名对应的服务器的IP地址 47.92.245.255 TTL 解析结果在本地DNS缓存中的生命周期时长 10分钟 测试解析状态 123456[root@ubuntu ~]# ping www.jose-404.com -c1PING www.jose-404.com (47.94.245.255) 56(84) bytes of data.64 bytes from 47.94.245.255 (47.94.245.255): icmp_seq=1 ttl=128 time=10.2 ms--- www.jose-404.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 10.248/10.248/10.248/0.000 ms","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"}]},{"title":"shell脚本介绍","slug":"Linux/shell/introduce","date":"2025-08-20T08:50:45.000Z","updated":"2025-08-28T12:33:05.358Z","comments":true,"path":"Linux/shell/introduce/","permalink":"https://aquapluto.github.io/Linux/shell/introduce/","excerpt":"","text":"脚本基本结构格式要求：首行shebang机制 12345#!/bin/bash#!/usr/bin/python#!/usr/bin/perl#!/usr/bin/ruby#!/usr/bin/lua 脚本创建过程第一步：使用文本编辑器来创建文本文件 第一行必须包括shell声明序列：#! 添加注释,注释以#开头 第二步：加执行权限 给予执行权限，在命令行上指定脚本的绝对或相对路径 第三步：运行脚本 直接运行解释器，将脚本作为解释器程序的参数运行 脚本注释规范1、第一行一般为调用使用的语言 2、程序名，避免更改文件名为无法找到正确的文件 3、版本号 4、更改后的时间 5、作者相关信息 6、该程序的作用，及注意事项 7、最后是各版本的更新简要说明 范例：初始化操作 123456789101112131415161718192021222324[root@centos7 ~]#vim .vimrc #个人[root@centos7 ~]#vim /etc/.vimrc #全局set ts=4set expandtabset ignorecaseset shiftwidth=4autocmd BufNewFile *.sh exec &quot;:call SetTitle()&quot;func SetTitle() if expand(&quot;%:e&quot;) == &#x27;sh&#x27; call setline(1,&quot;#!/bin/bash&quot;) call setline(2,&quot;#&quot;) call setline(3,&quot;#*******************************************#&quot;) call setline(4,&quot;#Author: wangxiaochun&quot;) call setline(5,&quot;#QQ 999999999999&quot;) call setline(6,&quot;#Date: &quot;.strftime(&quot;%Y-%m-%d&quot;)) call setline(7,&quot;#FileName: &quot;.expand(&quot;%&quot;)) call setline(8,&quot;#URL: http://www.baidu.com&quot;) call setline(9,&quot;Description: The test script&quot;) call setline(10,&quot;Copyright (C): &quot;.strftime(&quot;%Y&quot;).&quot; All rights reserved&quot;) call setline(11,&quot;#******************************************#&quot;) call setline(12,&quot;&quot;) endifendfuncautocmd BufNewFile * normal G 执行脚本的方式直接执行 1bash hello.sh 重定向执行 12cat /data/hello.sh | bashbash &lt; /data/hello.sh 添加权限后以路径执行 1234chmod +x /data/hello.sh绝对路径：/data/scripts hello.sh相对路径：./hello.sh 软链接执行 123echo $PATH #查看PATH下的目录路径ln -s /data/scripts/hello.sh /user/local/bin/ #创建软链接hello.sh #直接执行 共享网站上执行远程主机的脚本 1curl (-s) http://www.wangxiaochun.com/testdir/hello.sh | bash 在远程主机运行本地shell脚本 1ssh 10.0.0.18 /bin/bash &lt; test.sh 脚本错误语法错误，会导致后续的命令不继续执行，可以用bash -n 检查错误，提示的出错行数不一定是准确的 123456789#!bin/bashecho startingifecho continue#cmd1是错误命令，不可以执行后续命令[root@centos scripts]#bash text.sh startingtext.sh: line 7: syntax error: unexpected end of file 命令错误，默认后续的命令还会继续执行，用bash -n 无法检查出来 ，可以使用 bash -x 进行观察 12345678910#!bin/bashecho startingcmd1echo continue#虽然cmd1是错误命令，但还是可以执行后续命令[root@centos scripts]#bash text.sh startingtext.sh: line 5: cmd1: command not foundcontinue 逻辑错误：例如单词写错了，shell不会认为错误，你输什么执行什么，只能使用 bash -x 进行观察 有一些错误是因为不可见字符导致的，可以set line 查看并删掉 Windows和Linux换行符的错误：Windows 行尾符（CR+LF），这在 Unix&#x2F;Linux 环境中会导致语法错误 12345dos2unix database-bakup.shsed &#x27;s/\\r$//&#x27; database-bakup.sh &gt; database-bakup.sh.fixedmv database-bakup.sh.fixed database-bakup.shtr -d &#x27;\\r&#x27; &lt; database-bakup.sh &gt; database-bakup.sh.fixedmv database-bakup.sh.fixed database-bakup.sh bash shell的配置文件生效范围分类全局配置：针对所有用户皆有效 123/etc/profile/etc/profile.d/*.sh/etc/bashrc 个人配置：只针对特定用户有效 12~/.bash_profile~/.bashrc 功能分类profile类为交互式登录的shell提供配置 用于定义环境变量 运行命令或脚本 bashrc类：为非交互式和交互式登录的shell提供配置 定义命令别名和函数 定义本地变量 配置文件生效修改profile和bashrc文件后需生效两种方法: 重新启动shell进程 source| . 配置文件 注意：source 会在当前shell中执行脚本,所有一般只用于执行置文件，或在脚本中调用另一个脚本的场景 1. ~/.bashrc bash退出任务保存在 ~/.bash_logout 文件中（用户），在退出登录shell时运行 功能： 创建自动备份 清除临时文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"正则表达式","slug":"Linux/linux-basics/regular-expression","date":"2025-08-19T06:03:03.000Z","updated":"2025-08-28T12:33:05.260Z","comments":true,"path":"Linux/linux-basics/regular-expression/","permalink":"https://aquapluto.github.io/Linux/linux-basics/regular-expression/","excerpt":"","text":"1 基本正则表达式正则表达式匹配的是文本中的字符串，与文件通配符不一样 正则表达式要用双引号或者单引号引起来 1.1 字符匹配123456789101112131415161718192021. #匹配任意单个字符(除了\\n)，可以是一个汉字或其它国家的文字，如果要表示圆点字符本身，需要用反斜刚“\\”转义，或者在中括号的内部，也表示圆点.这个字符本身[] #匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z]；一些字符在[]中表示本身，就不用\\转义[^] #匹配指定范围外的任意单个字符,示例：[^wang][:alnum:] #字母和数字[:alpha:] #代表任何英文大小写字符，亦即 A-Z, a-z[:lower:] #小写字母,示例:[[:lower:]],相当于[a-z][:upper:] #大写字母[:blank:] #空白字符（空格和制表符）[:space:] #包括空格、制表符(水平和垂直)、换行符、回车符等各种类型的空白,比[:blank:]包含的范围广[:cntrl:] #不可打印的控制字符（退格、删除、警铃...）[:digit:] #十进制数字[:xdigit:]#十六进制数字[:graph:] #可打印的非空白字符[:print:] #可打印字符[:punct:] #标点符号-----------------\\s #匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [\\f\\r\\t\\v]。注意 Unicode正则表达式会匹配全角空格符\\S #匹配任何非空白字符。等价于 [^\\f\\r\\t\\v]\\w #匹配一个字母,数字,下划线,汉字,其它国家文字的字符，等价于[_[:alnum:]字]\\W #匹配一个非字母,数字,下划线,汉字,其它国家文字的字符，等价于[^_[:alnum:]字]\\d #匹配数字 范例 123456789101112131415161718192021[root@centos8 ~]#ls /etc/ | grep &#x27;rc[.0-6]&#x27;[root@centos8 ~]#ls /etc/ | grep &#x27;rc[.0-6].&#x27;rc0.drc1.drc2.drc3.drc4.drc5.drc6.drc.drc.local[root@centos8 ~]#ls /etc/ | grep &#x27;rc[0-6]&#x27;[root@centos8 ~]#ls /etc/ | grep &#x27;rc[.0-6]\\.&#x27;rc0.drc1.drc2.drc3.drc4.drc5.drc6.d 范例 12^ab.[0-9]$ -- 表示ab开头，中间任意1个字符后面是0-9任意一个数字^[a-z].&#123;3&#125;$ -- 表示a-z中任意一个小写字母，后面跟三个任意字符 范例：[] 方括号表示某些字符允许在一个字符串中某一个特定位置出现 12345^[ab]$ 表示一个字符串中有一个a 或 b &lt;===&gt; ^a|b$^[a-d]$ 表示一个字符串包含小写 abcd 中的一个 &lt;==&gt;^[abcd]$&lt;==&gt;^a|b|c|d$^[0-9]a$ 表示0-9中任意一个数字后面跟一个小写字母a^[a-z]&#123;2&#125;$ 表示a-z中任意的字符串总共出现2个^[A-Z]+$ 表示A-Z中任意一个大写字母至少出现1次 范例：方括号[]中使用 ^ ，表示不希望出现字符，简称过滤字符，而且 ^ 必须用在[]中的第一位 1^a[^0-9]%$ # 表示a和 % 中间不能出现数字 1.2 匹配次数用在要指定次数的字符后面，用于指定前面的字符要出现的次数 1234567891011121314* #匹配前面的字符任意次，包括0次，贪婪模式：尽可能长的匹配.* #任意长度的任意字符，具有贪婪的性质，匹配到不能匹配为止，根据后面的正则表达式，会进行回溯.*? #表示匹配任意字符到下一个符合条件的字符\\? #匹配其前面的字符出现0次或1次,即:可有可无\\+ #匹配其前面的字符出现最少1次,即:肯定有且 &gt;=1 次\\&#123;n\\&#125; #匹配前面的字符n次\\&#123;m,n\\&#125; #匹配前面的字符至少m次，至多n次\\&#123;,n\\&#125; #匹配前面的字符至多n次,&lt;=n\\&#123;n,\\&#125; #匹配前面的字符至少n次注意：.* 具有贪婪的性质，匹配到不能匹配为止，根据后面的正则表达式，会进行回溯。.*? 则相反，一个匹配以后，就往下进行，所以不会进行回溯，具有最小匹配的性质。正则表达式a.*?xxx 可以匹配 abxxx axxxxx abbbbbxxx 贪婪匹配 当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。 特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 懒惰匹配 当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。 特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“？” 12345*? #重复任意次，但尽可能少重复+? #重复1次或更多次，但尽可能少重复?? #重复0次或1次，但尽可能少重复&#123;n,m&#125;? #重复n到m次，但尽可能少重复&#123;n,&#125;? #重复n次以上，但尽可能少重复 范例 12345678910111213[15:34:46 root@10 data[]#cat f1.txt goooooooooglegooglegoglegooooglegooogle[15:34:52 root@10 data[]#grep &#x27;gooo*gle&#x27; f1.txt #前两个o一定有，第三个o包括0次，任意次goooooooooglegooglegooooglegooogle 范例 123456789101112131415[15:41:26 root@10 data[]#cat f1.txtgoooooooooglegooglegoglegooooglegoooglegdnsadgle[15:41:33 root@10 data[]#grep &#x27;g.*gle&#x27; f1.txt goooooooooglegooglegoglegooooglegoooglegdnsadgle 范例 12345[15:41:44 root@10 data[]#echo /etc/sysconfig/ | grep &#x27;/etc/sysconfig/\\?&#x27;/etc/sysconfig/[15:51:35 root@10 data[]#echo /etc/sysconfig | grep &#x27;/etc/sysconfig/\\?&#x27;/etc/sysconfig 范例 123456789^abc*$ #表示 c 可能出现0次或者至少1次, ab必须出现1次^bcd+$ #表示 d 至少出现1次，bc必须出现1次^cba?$ #表示 a 可能出现0次或者1次，cb必须出现1次^(abc)+$ #表示 abc 这个整体至少出现1次^[abc]+$ #表示 abc 中任意一个字符，至少出现1次^ab+c$ #表示 a 必须出现1次 ,b至少出现1次 ，c必须出现1次^ab&#123;0,2&#125;$ #a出现1次，b至少0次，最多2次^ab&#123;3&#125;$ #a出现1次，b出现3次 ^ab&#123;3&#125;$ &lt;====&gt; ^abbb$^ab&#123;2,&#125;$ #a出现1次，b出现至少2次 范例：匹配正负数 12345678[root@centos8 ~]#echo -1 -2 123 -123 234 |grep &#x27;\\-\\?[0-9]\\+&#x27;-1 -2 123 -123 234[root@centos8 ~]#echo -1 -2 123 -123 234 |grep -E &#x27;\\-?[0-9]+&#x27;-1 -2 123 -123 234[root@centos8 ~]#echo -1 -2 123 -123 234 |grep -E -- &#x27;-?[0-9]+&#x27;-1 -2 123 -123 234[root@centos8 ~]#echo -1 -2 123 -123 234 |grep -E &#x27;(-)?[0-9]+&#x27;-1 -2 123 -123 234 范例: 取IP地址 12345[root@centos8 ~]#ifconfig eth0|grep netmask |grep -o &#x27;[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;&#x27;|head -n110.0.0.8[root@centos8 ~]#ifconfig eth0|grep -o &#x27;[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;&#x27;|head -n110.0.0.8 1.3 位置锚定位置锚定可以用于定位出现的位置 12345678910^ #行首锚定, 用于模式的最左侧$ #行尾锚定，用于模式的最右侧^PATTERN$ #用于模式匹配整行，^tom$：表示以tom开头，并以tom结束的字符串^$ #空行^[[:space:]]*$ #空白行\\&lt; 或 \\b #词首锚定，用于单词模式的左侧\\&gt; 或 \\b #词尾锚定，用于单词模式的右侧\\&lt;PATTERN\\&gt; #匹配整个单词#注意: 单词是由字母,数字,下划线组成 范例：取#开头的行 1[16:10:09 root@10 ~[]#echo /etc/fstab | grep &#x27;^#&#x27; /etc/fstab 范例：取bash结尾的行 1[16:13:27 root@10 ~[]#grep &#x27;bash$&#x27; /etc/passwd 范例：排除掉空行的行 1[16:15:03 root@10 ~[]#grep -v &#x27;^$&#x27; /etc/fstab 范例：排除掉空行和#开头的行 1234[root@centos8 ~]#grep -v &#x27;^$&#x27; /etc/profile | grep -v &#x27;^#&#x27;[root@centos8 ~]#grep &#x27;^[^#]&#x27; /etc/profile[root@centos8 ~]#grep -v &#x27;^$\\|#&#x27; /etc/profile[root@ubuntu2204 ~]# grep -v &#x27;^\\(#\\|$\\)&#x27; /etc/apache2/apache2.conf 范例 1234567[16:15:32 root@10 ~[]#echo wujunlin | grep &#x27;\\bwu&#x27;wujunlin[16:17:26 root@10 ~[]#echo junlin-wu | grep &#x27;\\bwu&#x27;junlin-wu[16:17:37 root@10 ~[]#echo junlinwu | grep &#x27;wu\\b&#x27;junlinwu 1.4 分组其他1.4.1 分组分组：() 将多个字符捆绑在一起，当作一个整体处理，如：(root)+ 后向引用：分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为: \\1, \\2, \\3, … \\1 表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符 注意: \\0 表示正则表达式匹配的所有字符 注意：后向引用引用前面的分组括号中的模式所匹配字符，而非模式本身 123\\(string1\\(string2\\)\\)\\1 ：string1\\(string2\\)\\2 ：string2 范例 12345678910111213141516171819#abc作为一个整体出现3次[root@ubuntu2204 ~]# echo abcabcabc | grep &quot;\\(abc\\)\\&#123;3\\&#125;&quot;abcabcabc#后向引用[root@ubuntu2204 ~]# echo abcabcabc | grep &quot;\\(abc\\)\\1&quot;abcabcabc[root@ubuntu2204 ~]# echo abcabcabc | grep &quot;\\(abc\\)\\1\\1&quot;abcabcabc#\\1表示引用第一个分组的内容，即 abc[root@ubuntu2204 ~]# echo &quot;abcdefabc&quot; | grep &quot;\\(abc\\)def\\1&quot;abcdefabc#\\1表示引用第一个分组的内容，即abc,\\&#123;3\\&#125;表示引用内容出现3次[root@ubuntu2204 ~]# echo abc-def-abcabcabc | grep &quot;^\\(abc\\)-\\(def\\)-\\1\\&#123;3\\&#125;&quot;abc-def-abcabcabc[root@ubuntu2204 ~]# echo abc-def-abcabcabc-def-abc-defdef | grep &quot;^\\(abc\\)-\\(def\\)-\\1\\&#123;3\\&#125;-\\2-\\1-\\2\\&#123;2\\&#125;&quot;abc-def-abcabcabc-def-abc-defdef 1.4.2 或者或者：\\ | 123a\\|b #a或b C\\|cat #C或cat \\(C\\|c\\)at #Cat或cat 范例：排除空行和#开头的行 1234[root@centos6 ~]#grep -v &#x27;^#&#x27; /etc/httpd/conf/httpd.conf |grep -v ^$[root@centos6 ~]#grep -v &#x27;^#\\|^$&#x27; /etc/httpd/conf/httpd.conf[root@centos6 ~]#grep -v &#x27;^\\(#\\|$\\)&#x27; /etc/httpd/conf/httpd.conf[root@centos6 ~]#grep &quot;^[^#]&quot; /etc/httpd/conf/httpd.conf 2 扩展正则表达式2.1 字符匹配123456789101112131415. 任意单个字符[wang] 指定范围的字符[^wang] 不在指定范围的字符[:alnum:] 字母和数字[:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z[:lower:] 小写字母,示例:[[:lower:]],相当于[a-z][:upper:] 大写字母[:blank:] 空白字符（空格和制表符）[:space:] 水平和垂直的空白字符（比[:blank:]包含的范围广）[:cntrl:] 不可打印的控制字符（退格、删除、警铃...）[:digit:] 十进制数字[:xdigit:]十六进制数字[:graph:] 可打印的非空白字符[:print:] 可打印字符[:punct:] 标点符号 2.2 匹配次数12345* 匹配前面字符任意次? 0或1次+ 1次或多次&#123;n&#125; 匹配n次&#123;m,n&#125; 至少m，至多n次 2.3 位置锚定1234^ 行首$ 行尾\\&lt;, \\b 语首\\&gt;, \\b 语尾 2.4 分组其他123456() 分组后向引用：\\1, \\2, ... 注意: \\0 表示正则表达式匹配的所有字符| 或者a|b #a或bC|cat #C或cat(C|c)at #Cat或cat 范例 12[root@centos8 ~]#ifconfig | grep -Ewo &quot;(([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([1-9]?[0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])&quot;|head -n110.0.0.8 3 正则表达式的误区与常见错误1. 过于复杂的正则 有时，我们会尝试创建一个完美、一劳永逸的正则表达式，但这往往会导致正则变得难以阅读和维护。建议： 分解复杂的正则，使其更具可读性，并加入必要的注释。 2. 对**.**的误解 . 在正则表达式中匹配任何字符，但很多人忘记了它不匹配换行符（除非使用了re.DOTALL标志）。 3. 忘记转义特殊字符 有些字符，如 ., *, + 在正则中有特殊含义。如果你想匹配这些字符本身，记得使用 \\ 进行转义。 4. 不考虑边界情况 例如，\\d&#123;1,2&#125; 可以匹配1到99之间的数字，但它也会匹配100中的10。使用\\b来匹配单词边界，避免这类问题。 5. 使用**.\\***而不加思索 .* 会尝试匹配尽可能多的字符，这可能不是你想要的。考虑使用非贪婪匹配.*?或更具体的匹配模式。 6. 忽视大小写 除非使用了re.IGNORECASE标志，否则正则表达式匹配是区分大小写的。 7. 仅测试正常情况 当编写正则表达式时，确保你不仅仅测试预期的匹配，还要测试不应该匹配的内容。 8. 不利用测试工具 在线工具，如 regex101，可以为你提供匹配的实时反馈和解释，帮助你更好地理解和调试正则表达式。 9. 使用正则表达式解析复杂结构 虽然技术上可以使用正则表达式来解析HTML或XML，但这并不是一个好主意。使用专门为此设计的解析器更为可靠和高效。 4 常用的正则表达式校验数字的表达式 12345678910111213141、数字：^[0-9]*$2、n位的数字：^\\d&#123;n&#125;$3、至少n位的数字：^\\d&#123;n,&#125;$4、m-n位的数字：^\\d&#123;m,n&#125;$5、零和非零开头的数字：^(0|[1-9][0-9]*)$6、非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(\\.[0-9]&#123;1,2&#125;)?$7、带1-2位小数的正数或负数：^(\\-)?\\d+(\\.\\d&#123;1,2&#125;)$8、正数、负数、和小数：^(\\-|\\+)?\\d+(\\.\\d+)?$9、有两位小数的正实数：^[0-9]+(\\.[0-9]&#123;2&#125;)?$10、有1~3位小数的正实数：^[0-9]+(\\.[0-9]&#123;1,3&#125;)?$11、非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\\+?[1-9][0-9]*$12、非零的负整数：^\\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\\d*$13、非负整数：^\\d+$ 或 ^[1-9]\\d*|0$14、非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$ 校验字符的表达式 1234567891011121、汉字：^[\\u4e00-\\u9fa5]&#123;0,&#125;$2、英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$3、长度为3-20的所有字符：^.&#123;3,20&#125;$4、由26个英文字母组成的字符串：^[A-Za-z]+$5、由26个大写英文字母组成的字符串：^[A-Z]+$6、由26个小写英文字母组成的字符串：^[a-z]+$7、由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$8、由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w&#123;3,20&#125;$9、中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$10、中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]&#123;2,20&#125;$11、可以输入含有^%&amp;&#x27;,;=?$\\&quot;等字符：[^%&amp;&#x27;,;=?$\\x22]+12、禁止输入含有~的字符：[^~\\x22]+ 特殊需求表达式 1234567891011121314151617181920212223242526272829303132333435363738391、Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$2、域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(\\.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+\\.?3、InternetURL：[a-zA-z]+://[^\\s]* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&amp;=]*)?$4、手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|4|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d&#123;8&#125;$5、电话号码(&quot;XXX-XXXXXXX&quot;、&quot;XXXX-XXXXXXXX&quot;、&quot;XXX-XXXXXXX&quot;、&quot;XXX-XXXXXXXX&quot;、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\\(\\d&#123;3,4&#125;-)|\\d&#123;3.4&#125;-)?\\d&#123;7,8&#125;$6、国内电话号码(0511-4405222、021-87888822)：\\d&#123;3&#125;-\\d&#123;8&#125;|\\d&#123;4&#125;-\\d&#123;7&#125;7、电话号码正则表达式（支持手机号码，3-4位区号，7-8位直播号码，1－4位分机号）: ((\\d&#123;11&#125;)|^((\\d&#123;7,8&#125;)|(\\d&#123;4&#125;|\\d&#123;3&#125;)-(\\d&#123;7,8&#125;)|(\\d&#123;4&#125;|\\d&#123;3&#125;)-(\\d&#123;7,8&#125;)-(\\d&#123;4&#125;|\\d&#123;3&#125;|\\d&#123;2&#125;|\\d&#123;1&#125;)|(\\d&#123;7,8&#125;)-(\\d&#123;4&#125;|\\d&#123;3&#125;|\\d&#123;2&#125;|\\d&#123;1&#125;))$)8、身份证号(15位、18位数字)，最后一位是校验位，可能为数字或字符X：(^\\d&#123;15&#125;$)|(^\\d&#123;18&#125;$)|(^\\d&#123;17&#125;(\\d|X|x)$)9、帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$10、密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w&#123;5,17&#125;$11、强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在 8-10 之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z])[a-zA-Z0-9]&#123;8,10&#125;$12、强密码(必须包含大小写字母和数字的组合，可以使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$13、日期格式：^\\d&#123;4&#125;-\\d&#123;1,2&#125;-\\d&#123;1,2&#125;14、一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$15、一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$16、xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$17、腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)18、中国邮政编码：[1-9]\\d&#123;5&#125;(?!\\d) (中国邮政编码为6位数字)19、IPv4地址：((2(5[0-5]|[0-4]\\d))|[0-1]?\\d&#123;1,2&#125;)(\\.((2(5[0-5]|[0-4]\\d))|[0-1]?\\d&#123;1,2&#125;))&#123;3&#125;20、空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"用户和权限管理","slug":"Linux/linux-basics/user-permission","date":"2025-08-19T06:02:56.000Z","updated":"2025-08-28T12:33:05.261Z","comments":true,"path":"Linux/linux-basics/user-permission/","permalink":"https://aquapluto.github.io/Linux/linux-basics/user-permission/","excerpt":"","text":"1 Linux权限模型资源分派： Authentication：认证，验证用户身份 Authorization：授权，不同的用户设置不同权限 Accouting|Audition：审计 当用户登录成功时，系统会自动分配令牌 token，包括：用户标识和组成员等信息 3A认证：又称AAA认证，是一套针对网络设备的网络访问控制策略安全模型 1.1 用户Linux系统是多用户系统，可以同时存在多个用户，每个用户之间都是互相隔离的 Linux中每个用户是通过 User Id （UID）来唯一标识的 管理员：root, 0 普通用户：1-60000 自动分配 系统用户：1-499 （CentOS 6以前）, 1-999 （CentOS 7以后）对守护进程获取资源进行权限分配 登录用户：500+ （CentOS6以前）, 1000+（CentOS7以后）给用户进行交互式登录使用 1.2 用户组Linux中可以将一个或多个用户加入用户组中，组就是包含0个或多个用户的集合，用户组是通过Group ID（GID） 来唯一标识的 管理员组：root, 0 普通组： 系统组：1-499（CentOS 6以前）, 1-999（CentOS7以后）, 对守护进程获取资源进行权限分配 普通组：500+（CentOS 6以前）, 1000+（CentOS7以后）, 给用户使用 1.3 用户和组的关系 一个用户至少有一个组，也可以有多个组； 一个组至少有0个用户，也可以有多个用户； 用户的主要组(primary group)：又称私有组，一个用户必须属于且只有一个主组，创建用户时，默认会创建与其同名的组作为主组； 用户的附加组(supplementary group)：又称辅助组，一个用户可以属于0个或多个附加组； 使用组，可以对用户进行批量管理，比如对一个组授权，则该组下所有的用户能能继承这个组的权限； 1.4 安全上下文Linux安全上下文Context 运行中的程序，即进程 (process)，以进程发起者的身份运行，进程所能够访问资源的权限取决于进程的运行者的身份 程序，进程，用户之间的关系是怎样的 只有可以被执行的文件，才能叫作程序； 对于同一个程序，也不是所有用户都可以运行的，这要取决于当前用户对该程序有没有可执行权限； 用户张三，运行了某个程序，那么，张三就发起了一个进程，该进程的发起者，就是张三，该进程是以张三的身份在运行； 比如：分别以 root 和 wang 的身份运行 /bin/cat /etc/shadow ，得到的结果是不同的，资源能否能被访问，是由运行者的身份决定，非程序本身 进程的访问资源 一个进程能不能访问某些资源，是由进程发起者决定的（跟进程本身的程序文件无关），比如某进程要读写某个文件，则要看该进程发起者有没有权限读取该文件； 123456789[wang@centos8 ~]$cat /etc/shadowcat: /etc/shadow: Permission denied[root@centos8 ~]#cat /etc/shadowroot:$6$zsrWEC56PrKifAEz$hylCuGySe.H6l6O2MRvbtqy/VZgnZbau.y57dE85.YHq03MTJVV4UvQVIDcYA1IJzbgpWE0vTU.BtPHLbNBNn0:18246:0:99999:7:::bin:*:18027:0:99999:7:::daemon:*:18027:0:99999:7:::adm:*:18027:0:99999:7:::lp:*:18027:0:99999:7::: 进程来用文件的时候，如何匹配权限的呢？ 进程启动（必须赋予某种身份） 默认为当前登录用户 在配置文件里修改指定进程启动的身份 拿着进程的用户身份，去匹配目标文件的权限 进程的用户身份会依次配文件的ugo的rwx 2 用户管理2.1 用户创建1234567891011121314151617181920useradd [options] LOGIN-u UID #指明UID-g GID #指明用户所属主组，可为组名，也可以GID-s SHELL #指明用户的默认shell程序，可用列表在/etc/shells文件中-d HOME_DIR #以指定的路径(不存在)为家目录-m #创建家目录，用于系统用户-M #不创建家目录，用于非系统用户-o #配合-u 选项，不检查UID的唯一性，即允许使用重复的 UID 创建用户-G GROUP1[,GROUP2,...] #为用户指明附加组，组须事先存在-N #不创建私用（同名）组做主组，使用users组做主组-r #创建系统用户，不会创建邮箱-p #指定加密的密码-c &quot;COMMENT“ #用户的注释信息-D #显示或更改默认的 useradd 配置，默认配置文件是/etc/default/useradd-e #指定账户的过期日期 YYYY-MM-DD 格式-f #密码过期之后，账户被彻底禁用之前的天数，0 表示密码过期立即禁用，-1表示不使用此功能-k #指定家目录模板，创建家目录，会生成一些默认文件，如果指定，就从该目录复制文件，默认是/etc/skel/，要配合-m-K #不使用 /etc/login.defs 中的默认值，自己指定，比如-K UID_MIN=100-l|--no-log-init #不将用户添加到最近登录和登录失败记录，前面讲到的3a认证审计，就在此处lastlog|lastb|cat /var/log/secure 当创建一个用户时，如果没有指定用户的主组，将会创建一个同名的组作为用户的主组 useradd创建用户时，对于未指定的选项（-u、-g等等），会以/etc/login.defs、/etc/default/useradd两个配置文件中的配置作为参照物 配置文件/etc/login.defs详解 123456789101112131415161718[root@egon ~]# grep -Ev &quot;^#|^$&quot; /etc/login.defsMAIL_DIR /var/spool/mailPASS_MAX_DAYS 99999 #密码最大有效期PASS_MIN_DAYS 0 #两次修改密码的最小间隔时间PASS_MIN_LEN 5 #密码最小长度，对于root无效PASS_WARN_AGE 7 #密码过期前多少天开始提示UID_MIN 1000 #用户ID的最小值UID_MAX 60000 #用户ID的最大值SYS_UID_MIN 201 #系统用户ID的最小值SYS_UID_MAX 999 #系统用户ID的最大值GID_MIN 1000 #组ID的最小值GID_MAX 60000 #组ID的最大值SYS_GID_MIN 201 #系统用户组ID的最小值SYS_GID_MAX 999 #系统用户组ID的最大值CREATE_HOME yes #使用useradd的时候是可以创建用户家目录UMASK 077 #创建家目录时umask的默认控制权限USERGROUPS_ENAB yes #删除用户的时候是否同时删除用户组ENCRYPT_METHOD SHA512 #密码加密规则 配置文件/etc/default/useradd详解 12345678[root@egon ~]# cat /etc/default/useraddGROUP=100 #依赖于/etc/login.defs的USERGRUUPS_ENAB参数，如果为no，则在此处控制HOME=/home #把用户的家目录建在/home中。INACTIVE=-1 #是否启用账号过期停权,-1表示不启用。EXPIRE= #账号终止日期,不设置表示不启用。SHELL=/bin/bash #新用户默认所有的shell类型。SKEL=/etc/skel #配置新用户家目录的默认文件存放路径。CREATE_MAIL_SPOOL=yes #创建mail文件。 范例 12useradd -u 123 -g mysql -s /sbin/nologin -d /data/mysql -M mysqlID-u，组名-g，默认程序-s，家目录-d【不想创建-M，想创建-m】，用户名 显示或更改默认设置 1234useradd -Duseradd –D -s SHELLuseradd –D –b BASE_DIRuseradd –D –g GROUP 新建用户的相关文件：当使用useradd创建用户时，创建的用户家目录下会存在.bash_* 环境变量相关的文件，这些环境变量文件默认从/etc/skel目录中拷贝。这个默认拷贝环境变量位置是由/etc/default/useradd配置文件中定义的。 123/etc/default/useradd #cat /etc/default/useradd 可以查看新建账号的属性/etc/skel/* #新建的文件的家目录的默认文件是在/etc/skel里的，/etc/skel包含一个新用户在创建后所拥有的默认文件和目录，在创建新用户时，系统会将/etc/skel目录下的文件和目录复制到新用户的家目录中/etc/login.defs 批量创建用户 1newusers passwd 格式文件 批量修改用户口令 1echo username:passwd | chpasswd 范例：误删除了用户git的家目录，请重建并恢复该用户家目录及相应的权限属性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@centos8 data]# useradd git[root@centos8 data]# ll -d /home/gitdrwx------. 3 git git 78 Nov 20 21:51 /home/git[root@centos8 data]# ll -a /home/gittotal 12drwx------. 3 git git 78 Nov 20 21:51 .drwxr-xr-x. 10 root root 113 Nov 20 21:51 ..-rw-r--r--. 1 git git 18 Nov 9 2019 .bash_logout-rw-r--r--. 1 git git 141 Nov 9 2019 .bash_profile-rw-r--r--. 1 git git 312 Nov 9 2019 .bashrcdrwxr-xr-x. 4 git git 39 Nov 20 13:27 .mozilla[root@centos8 data]# rm -rf /home/git[root@centos8 data]# ll /hometotal 0drwx------. 3 docker docker 99 Nov 20 21:14 dockerdrwx------. 3 hf hf 120 Nov 20 16:49 hfdrwx------. 3 mongodb mongodb 112 Nov 20 21:31 mongodbdrwx------. 3 neteagle neteagle 99 Nov 20 15:59 neteagledrwx------. 3 redis redis 99 Nov 20 21:33 redisdrwx------. 3 tomcat tomcat 78 Nov 20 21:41 tomcatdrwx------. 3 zabbix zabbix 99 Nov 20 21:40 zabbix[root@centos8 data]# ll -a /etc/skel/total 24drwxr-xr-x. 3 root root 78 Nov 20 13:28 .drwxr-xr-x. 135 root root 8192 Nov 20 21:51 ..-rw-r--r--. 1 root root 18 Nov 9 2019 .bash_logout-rw-r--r--. 1 root root 141 Nov 9 2019 .bash_profile-rw-r--r--. 1 root root 312 Nov 9 2019 .bashrcdrwxr-xr-x. 4 root root 39 Nov 20 13:27 .mozilla[root@centos8 data]# cp -a /etc/skel/ /home/git[root@centos8 data]# ll -a /home/gittotal 12drwxr-xr-x. 3 root root 78 Nov 20 13:28 .drwxr-xr-x. 10 root root 113 Nov 20 21:59 ..-rw-r--r--. 1 root root 18 Nov 9 2019 .bash_logout-rw-r--r--. 1 root root 141 Nov 9 2019 .bash_profile-rw-r--r--. 1 root root 312 Nov 9 2019 .bashrcdrwxr-xr-x. 4 root root 39 Nov 20 13:27 .mozilla[root@centos8 data]# ll -d /home/gitdrwxr-xr-x. 3 root root 78 Nov 20 13:28 /home/git[root@centos8 data]# chown git.git /home/git[root@centos8 data]# ll -d /home/gitdrwxr-xr-x. 3 git git 78 Nov 20 13:28 /home/git[root@centos8 data]# chmod 700 /home/git[root@centos8 data]# ll -d /home/gitdrwx------. 3 git git 78 Nov 20 13:28 /home/git#简化[root@centos7 ~]# cp -r /etc/skel/. /home/git[root@centos7 ~]# chmod 700 /home/git[root@centos7 ~]# chown -R git.git /home/git 2.2 用户属性修改12345678910111213usermod [OPTION] login-u UID: 新UID-g GID: 新主组-G GROUP1[,GROUP2,...[,GROUPN]]]：新附加组，原来的附加组将会被覆盖；若保留原有，则要同时使用-a选项-s SHELL：新的默认SHELL-c &#x27;COMMENT&#x27;：新的注释信息-d HOME: 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项-l login_name: 新的名字-L: lock指定用户,在/etc/shadow 密码栏的增加 !-U: unlock指定用户,将 /etc/shadow 密码栏的 ! 拿掉-e YYYY-MM-DD: 指明用户账号过期日期-f INACTIVE: 设定非活动期限，即宽限期 2.3 删除用户1234userdel [OPTION]... Login-f, --force 强制-r, --remove 删除用户家目录和邮箱 范例: 强制删除用户和数据 12345678910111213141516171819[root@centos8 ~]#useradd test[root@centos8 ~]#id testuid=1001(test) gid=1001(test) groups=1001(test)#在另一终端用test登录[root@centos8 ~]#su - test[test@centos8 ~]$#删除正在登录的用户失败[root@centos8 ~]#userdel -r testuserdel: user test is currently used by process 29909[root@centos8 ~]#id testuid=1001(test) gid=1001(test) groups=1001(test)#强制删除用户[root@centos8 ~]#userdel -rf testuserdel: user test is currently used by process 29909[root@centos8 ~]#id testid: ‘test’: no such user 2.4 查看用户相关的ID信息123456id [OPTION]... [USER]-u: 显示UID-g: 显示GID-G: 显示用户所属的组的ID-n: 显示名称，需配合ugG使用 2.5 设置密码2.5.1 openssl passwd在Linux系统中我们要向手动生成一个密码可以采用opensll passwd来生成一个密码作为用户账号的密码。Linux系统中的密码存放在&#x2F;etc&#x2F;shadow文件中，并且是以加密的方式存放的，根据加密方式的不同，所产生的加密后的密码的位数也不同 openssl passwd的作用是用来计算密码hash的，目的是为了防止密码以明文的形式出现 123456789101112语法格式： openssl passwd [option] passwdopenssl passwd常用的选项如下：-1：表示采用的是MD5加密算法。-salt：指定salt值，不使用随机产生的salt。在使用加密算法进行加密时，即使密码一样，salt不一样，所计算出来的hash值也不一样，除非密码一样，salt值也一样，计算出来的hash值才一样。salt为8字节的字符串。 示例：[tom@localhost ~]$ openssl passwd -1 -salt &#x27;i have a dream&#x27; ##注意&#x27;i have a dream&#x27; 不是密码而是密码的盐,注意密码的盐里不要有中文Password: ##这里输入的是密码$1$12345678$1qWiC4czIc07B4J8bPjfC0 ##这是生成的密文密码##将生成的密码串，手动添加到/etc/shadow中就可用作用户的登陆密码了。 2.5.2 passwd用于更新用户的身份验证令牌（口令&#x2F;密码） 123456789101112passwd [OPTIONS] UserName-d：删除指定用户密码-l：锁定指定用户-u：解锁指定用户-e：强制用户下次登录修改密码-f：强制操作-n mindays：指定最短使用期限-x maxdays：最大使用期限-w warndays：提前多少天开始警告-i inactivedays：非活动期限--stdin：从标准输入接收用户密码,Ubuntu无此选项 范例：非交互式修改用户密码 12345#此方式更通用，适用于各种Linux版本，如:ubuntu[root@centos8 ~]#echo -e &#x27;123456\\n123456&#x27; | passwd mage #因为交互式中需要输入两次密码#适用于Rocky和Centos，不适用于Ubuntu[root@centos8 ~]#echo &#x27;123456&#x27; | passwd --stdin mage 范例：设置用户下次必须更改密码 12345678910111213141516171819202122232425262728293031[root@centos8 ~]#useradd wang[root@centos8 ~]#echo 123456 | passwd --stdin wangChanging password for user wang.passwd: all authentication tokens updated successfully.[root@centos8 ~]#getent shadow wangwang:$6$4f78ko7hJ4fcMvIH$lpbOkFfziDBLT.8XBCi8c/N7wysDAejN5H9Fgxkt99HRDLTEosO43CKYi2XSSVHxAK568Olj3C5bwfNExlves/:18348:0:99999:7:::[root@centos8 ~]#passwd -e wang[root@centos8 ~]#su - mageLast login: Fri Mar 27 09:55:27 CST 2020 on pts/0[mage@centos8 ~]$su - wangPassword:You are required to change your password immediately (administrator enforced)Current password:New password:Retype new password:Last login: Fri Mar 27 10:01:20 CST 2020 on pts/0Last failed login: Fri Mar 27 10:02:37 CST 2020 on pts/0There was 1 failed login attempt since the last successful login.[wang@centos8 ~]$exitlogout[mage@centos8 ~]$exitlogout[root@centos8 ~]#getent shadow wangwang:$6$TX0iLjF52ByHh1zH$g.WI4LNfauuwgnxpRhd7ePqFKHZ85YU3r6Lh2S0PWRXWGjGlDVtomLWqpdiWrT.vwqD/Wzok.kzQhUHc8UCs91:18348:0:99999:7::: 2.5.3 chpassed用于批量更新密码。注意：命令内没有用户名和密码，回车后以”用户名:密码”的格式输入（密码一般为明文），chpasswd根据选项加密 123456chapasswd [选项] -c #使用指定的方法加密。加密方法有DES，MD5，NONE，SHA256，SHA512-e #提供的密码已经加密-h #帮助-m #md5算法 范例：非交互式修改密码 123456789echo &quot;user003:123456&quot; | chpasswd[root@rocky8 ~]#cat &gt; passwd.txtnginx:123456k8s:123456^C#注意要写绝对路径[root@rocky8 ~]#chpasswd &lt; /root/passwd.txt 默认普通用户是没有chpasswd的权限，但是可以通过修改命令文件权限来修改 1chmod 4755 /usr/sbin/chpasswd 2.6 修改用户密码策略123456789chage [OPTION]... LOGIN-d LAST_DAY #更改密码的时间-m --mindays MIN_DAYS #两次修改密码之间相距的最小天数-M --maxdays MAX_DAYS #密码保持有效的最大天数-W --warndays WARN_DAYS #密码过期前，提前收到警告信息的天数-I --inactive INACTIVE #密码过期INACTIVE天数后，设定密码为失效状态-E --expiredate EXPIRE_DATE #用户的有效期，0表示马上过期，-1表示永不过期-l #显示密码策略 密码过期：设置的密码经过一段的时间后，系统会认为该密码不安全，于是将密码设置为过期状态，用户登录的时候，系统会提示用户进行密码修改 密码失效：经过一段时间，如果用户没有进行密码修改，则系统会将该密码设置为失效状态（此时用户不可通过该密码进行登录 范例：下一次登录强制重设密码 1[root@centos8 ~]#chage -d 0 wang 范例 1234567891011121314151617#test用户将在2019年4月29日失效（不可登陆）[root@centos8 ~]#chage -E 2019-04-29 test#设置test用户最后一次修改密码的日期为2019年6月30日[root@centos8 ~]#chage -d 2019-06-30 test#从最近修改密码的日期开始的5天内，用户test不能再次修改密码[root@centos8 ~]#chage -m 5 test#test用户自修改密码的日期开始，修改后的密码将在8天后过期[root@centos8 ~]#chage -M 8 test#用户test从密码过期开始算起，3天不修改密码则密码失效[root@centos8 ~]#chage -I 3 test#用户test的密码快要过期的的8天内，系统会持续对用户进行警告[root@centos8 ~]#chage -W 8 test 范例 12345678[root@centos7 ~]#chage -l wuLast password change : never #最近一次密码修改时间Password expires : never #密码过期时间Password inactive : never #密码失效时间Account expires : never #帐户过期时间Minimum number of days between password change : 0 #两次改变密码之间相距的最小天数 Maximum number of days between password change : 99999 #两次改变密码之间相距的最大天数Number of days of warning before password expires : 7 #在密码过期之前警告的天数 范例 1234567891011[root@centos7 ~]#cat /etc/shadowtest:!!:18077:5:8:8:3:18012:第一个字段为：用户名;第二个字段为：加密的密码第三个字段为：密码最后一次修改的时间 （chage -d）第四个字段为：密码最小修改间隔时间 （chage -m）第五个字段为：密码的有效期 （chage -M）第六个字段为：密码需要变更前的警告天数 （ chage -W）第七个字段为：密码过期后的宽限天数 （chage -I）第八个字段为：账号失效时间 （chage -E）第九个字段为：保留 2.7 用户文件2.7.1 &#x2F;etc&#x2F;passwd 1root:x:0:0:root:/root:/bin/bash 第一字段：用户名（也被称为登录名)； 第二字段：口令；在例子中我们看到的是一个x，其实密码已被映射到&#x2F;etc&#x2F;shadow 文件中； 第三字段：UID ；请参看本文的UID的解说； 第四字段：GID；请参看本文的GID的解说； 第五字段：描述信息，可选 第六字段：用户的家目录所在位置； 第七字段：用户所用SHELL的类型 2.7.2 &#x2F;etc&#x2F;shadow 12small_egon:$1$VE.Mq2Xf$2c9Qi7EQ9JP8GKF8gH7PB1:13072:0:99999:7:::big_egon:$1$IPDvUhXP$8R6J/VtPXvLyXxhLWPrnt/:13072:0:99999:7::13108: 第一字段：用户名（也被称为登录名)，在&#x2F;etc&#x2F;shadow中，用户名和&#x2F;etc&#x2F;passwd 是相同的，这样就把passwd 和shadow中用的用户记录联系在一起；这个字段是非空的； 第二字段：密码（已被加密)，如果是有些用户在这段是x，表示这个用户不能登录到系统；这个字段是非空的； 第三字段：上次修改口令的时间；这个时间是从1970年01月01日算起到最近一次修改口令的时间间隔（天数)，您可以通过passwd 来修改用户的密码，然后查看&#x2F;etc&#x2F;shadow中此字段的变化； 第四字段：两次修改口令间隔最少的天数；如果设置为0,则禁用此功能；也就是说用户必须经过多少天才能修改其口令；此项功能用处不是太大；默认值是通过&#x2F;etc&#x2F;login.defs文件定义中获取，PASS_MIN_DAYS 中有定义； 第五字段：两次修改口令间隔最多的天数；这个能增强管理员管理用户口令的时效性，应该说在增强了系统的安全性；如果是系统默认值，是在添加用户时由&#x2F;etc&#x2F;login.defs文件定义中获取，在PASS_MAX_DAYS 中定义； 第六字段：提前多少天警告用户口令将过期；当用户登录系统后，系统登录程序提醒用户口令将要作废；如果是系统默认值，是在添加用户时由&#x2F;etc&#x2F;login.defs文件定义中获取，在PASS_WARN_AGE 中定义； 第七字段：在口令过期之后多少天禁用此用户；此字段表示用户口令作废多少天后，系统会禁用此用户，也就是说系统会不能再让此用户登录，也不会提示用户过期，是完全禁用； 第八字段：用户过期日期；此字段指定了用户作废的天数（从1970年的1月1日开始的天数)，如果这个字段的值为空，帐号永久可用； www.hackdig.com 第九字段：保留字段，目前为空，以备将来Linux发展之用； 2.7.3 其他文件/etc/skel/：用户老家的模板 /home/xxx：用户家目录 /var/spool/mail/xxx：用户邮箱文件 3 组管理3.1 创建组1234groupadd [OPTION]... group_name-g GID 指明GID号；[GID_MIN, GID_MAX]-r 创建系统组名，CentOS 6之前: ID&lt;500，CentOS 7以后: ID&lt;1000 范例 1groupadd -g 48 -r apache 3.2 修改组1234groupmod [OPTION]... group-n group_name: 新名字-g GID: 新的GID 范例 1groupmod -n new_group_name old_group_name #重命名一个用户组 3.3 删除组如果一个组是一个用户的主组，那么该组不能被删除，删掉用户会默认一起删掉他的主组 123groupdel [options] GROUP-f, --force 强制删除，即使是用户的主组也强制删除组,但会导致无主组的用户不可用无法登录 3.4 添加、更改和查看组成员对于用户来说，组是分类的 一类是基本组或称主组，用户只能有一个基本组，创建时可通过-g指定，如未指定则创建一个默认的组(与用户同名) 附加组，基本组不能满足授权要求，创建附加组，将用户加入该组，用户可以属于多个附加组，加入一个组后就拥有了该组的权限 groupmems 12345678#更改组成员groupmems [options] [action]-g, --group groupname #更改为指定组 (只有root)-a, --add username #指定用户加入组-d, --delete username #从组中删除用户-p, --purge #从组中清除所有成员-l, --list #显示组成员列表 groups 12#查看用户所属组列表groups [OPTION].[USERNAME]... 范例 12345678910111213141516[root@centos8 ~]#groupmems -l -g admins[root@centos8 ~]#groupmems -a mage -g admins[root@centos8 ~]#id mageuid=1001(mage) gid=1001(mage) groups=1001(mage),1002(admins)[root@centos8 ~]#groupmems -l -g adminsmage[root@centos8 ~]#groupmems -a wang -g admins[root@centos8 ~]#groupmems -l -g adminsmage wang[root@centos8 ~]#groupmems -d wang -g admins[root@centos8 ~]#groups wangwang : wang[root@centos8 ~]#groupmems -l -g adminsmage[root@centos8 ~]#groupmems -p -g admins[root@centos8 ~]#groupmems -l -g admins 范例 123456789#创建组 groupadd g1 groupadd g2 groupadd g3#加入组 usermod -G g1,g2,g3 wu groupmems -a wu -g g1(g2,g3)#查看组成员 groupmems -l -g g1(g2,g3) **gpasswd：**将用户添加到组或从组中删除，只针对已存在的用户 12345gpasswd [OPTION] GROUP-a user 将user添加至指定组中-d user 从指定附加组中移除用户user-A user1,user2,... 设置有管理权限的用户列表 范例 1234567891011121314151617181920212223242526272829#增加组成员[root@centos8 ~]#groupadd admins[root@centos8 ~]#id wanguid=1000(wang) gid=1000(wang) groups=1000(wang)[root@centos8 ~]#gpasswd -a wang adminsAdding user wang to group admins[root@centos8 ~]#id wanguid=1000(wang) gid=1000(wang) groups=1000(wang),1002(admins)[root@centos8 ~]#groups wangwang : wang admins[root@centos8 ~]#getent group adminsadmins:x:1002:wang#删除组成员[root@centos8 ~]#gpasswd -d wang adminsRemoving user wang from group admins[root@centos8 ~]#groups wangwang : wang[root@centos8 ~]#id wanguid=1000(wang) gid=1000(wang) groups=1000(wang)[root@centos8 ~]#getent group adminsadmins:x:1002: 我们可以为组设置密码，然后让一些非组成员的用户通过命令”newgrp”临时切换到组内并输入密码的方式获取用户组的权限和特性 123456789101112131415161718192021222324[root@localhost ~]# groupadd group1[root@localhost ~]# gpasswd group1正在修改 group1 组的密码新密码：请重新输入新密码：[root@localhost ~]# touch /tmp/a.txt[root@localhost ~]# ll /tmp/a.txt -rw-r--r-- 1 root root 0 8月 10 21:01 /tmp/a.txt[root@localhost ~]# chown .group1 /tmp/a.txt [root@localhost ~]# !llll /tmp/a.txt -rw-r--r-- 1 root group1 0 8月 10 21:01 /tmp/a.txt[root@localhost ~]# chmod g+w /tmp/a.txt [root@localhost ~]# gpasswd group1[root@localhost ~]# su - egon上一次登录：一 8月 10 21:01:46 CST 2020pts/0 上[egon@localhost ~]$ echo 123 &gt;&gt; /tmp/a.txt # 此时没有权限-bash: /tmp/a.txt: 权限不够[egon@localhost ~]$ newgrp group1 # 临时切换到组group1下，拥有其权限密码：[egon@localhost ~]$ echo 123 &gt;&gt; /tmp/a.txt [egon@localhost ~]$ cat /tmp/a.txt 123 3.5 组文件3.5.1 &#x2F;etc&#x2F;group 3.5.2 &#x2F;etc&#x2F;gshadow 4 权限管理4.1 修改文件所有者和所属组4.1.1 修改文件所有者12345678chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE...OWNER #只修改所有者OWNER:GROUP #同时修改所有者和属组:GROUP #只修改属组，冒号也可用 . 替换--reference=RFILE #参考指定的的属性，来修改 -R #递归，此选项慎用，非常危险！ 范例 123456789101112131415161718192021[root@centos8 data]#chown wang f1.txt[root@centos8 data]#lltotal 4-rw-r--r-- 1 wang root 709 Dec 18 10:13 f1.txt[root@centos8 data]#chown :admins f1.txt[root@centos8 data]#ll f1.txt-rw-r--r-- 1 wang admins 709 Dec 18 10:13 f1.txt[root@centos8 data]#chown root.bin f1.txt[root@centos8 data]#lltotal 4-rw-r--r-- 1 root bin 709 Dec 18 10:13 f1.txt[root@centos8 data]#lltotal 8-rw-r--r-- 1 wang admins 709 Dec 18 10:13 f1.txt-rw-r--r-- 1 root root 23 Dec 18 10:15 f2.txt[root@centos8 data]#chown --reference=f1.txt f2.txt[root@centos8 data]#lltotal 8-rw-r--r-- 1 wang admins 709 Dec 18 10:13 f1.txt-rw-r--r-- 1 wang admins 23 Dec 18 10:15 f2.txt 范例：把data下的所有文件的所有者和所属组都改了（很危险） 1[root@centos8 ~]#chown -R wang.admins /data/ 4.1.2 修改文件所属组1234chgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE...-R #递归，此选项慎用，非常危险！ 范例 12345[root@centos8 data]#ll f1.txt-rw-r--r-- 1 wang root 709 Dec 18 10:13 f1.txt[root@centos8 data]#chgrp admins f1.txt[root@centos8 data]#ll f1.txt-rw-r--r-- 1 wang admins 709 Dec 18 10:13 f1.txt 4.2 文件权限4.2.1 文件权限说明文件的权限主要针对三类对象进行定义 123owner 属主, ugroup 属组, gother 其他, o 注意 用户的最终权限，是从左向右进行顺序匹配，即，所有者，所属组，其他人，一旦匹配权限立即生效，不再向右查看其权限 r 和 w 权限对root用户无效，对没有读写权限的文件，root用户也可读可写 只要所有者,所属组或other三者之一有x权限,root就可以执行 每个文件针对每类访问者都定义了三种权限 123r Readable 4w Writable 2x eXcutable 1 对文件的权限 123456r 可使用文件查看类工具，比如：cat，可以获取其内容w 可修改其内容,文件的是否被删除和文件的权限无关x 可以把此文件提请内核启动为一个进程，即可以执行（运行）此文件（此文件的内容必须是可执行）二进制的命令：/usr/bin/ls #只需要拥有对它的x权限就可以执行脚本文件(内容是一对普通文本) #需要对它拥有r+x权限 对目录的权限 123456789r 可以使用ls查看此目录中文件名列表,但无法看到文件的属性meta信息,包括inode号,不能查看文件的内容w 可在此目录中创建文件，也可删除此目录中的文件，而和此被删除的文件的权限无关x 可以cd进入此目录，可以使用ls -l file或stat file 查看此目录中指定文件的元数据，当预先知道文件名称时,也可以查看文件的内容,属于目录的可访问的最小权限X 分配给目录或有部分x权限的文件的x权限，对无任意x权限的文件则不会分配x权限#目录权限常见组合- 不能访问目录r-x 只读目录rwx 可读也可写目录 &#x3D;&#x3D;！！！注意 ！！！&#x3D;&#x3D; vim修改的原理是将源文件删掉，然后再将内容的内容覆盖写入了新文件，新文件名重命名为原文件名 当前用户对沿途所有文件夹都有x权限 并且当前用户对目标文件夹有w权限 但是当前用户对目标文件没有w权限 此时当前用可以vim编辑文件内容，并且可以wq!强制保存（输入y确认）退出完成文件修改，其实是将源文件删掉了，可以通过查看前后操作的文件inode号来确定 &#x3D;&#x3D;！！！注意 ！！！&#x3D;&#x3D; 软链接是没有权限的，改它的权限实际是改的是它所指向的文件，也就是原始文件 去看一个文件是否有权限，不仅要知道这个文件的权限，还要考虑到是否允许进入到它所在的这个目录的权限 如果没有执行权限，root也无法执行 即使对一个文件有所有权限，但是在它所在的目录下没有w权限，也无法修改其内容；相反，如果对一个文件什么权限也没有，但是在其目录下有所有权限，也可以修改其内容 文件的执行是危险的，但是目录的执行权限是常规的 4.2.2 修改文件权限1234chmod [OPTION]... MODE[,MODE]... FILE...chmod [OPTION]... OCTAL-MODE FILE...#参考RFILE文件的权限，将FILE的修改为同RFILE，就是复制该文件的权限信息给指定文件chmod [OPTION]... --reference=RFILE FILE... 模式法 12345678chmod who opt per filewho:u(属主)，g(属组)，o(其他)，a(所有)opt(操作):+(增加)，-(删除)，=(赋予)per(权限):r(读)，w(修改)，x(执行)chmod o+w a.txtug=rx #属主属组权限改为读和执行o= #other用户无任何权限 a=rwx #所有用户都有读写执行权限 数字法 12345678910111213#有权限1无权限0--- 000 0--x 001 1-w- 010 2-wx 011 3r-- 100 4r-x 101 5rw- 110 6rwx 111 7rwxrw---- a.txt （二：111 110 000 十：7 6 0）chmod 760 a.txtchmod ugo+rwx directory1 4.2.3 新建文件和目录的默认权限umask值可以控制创建文件、文件夹时的默认权限 新建文件的默认权限: 666-umask值，如果所得结果某位存在执行（奇数）权限，则将其权限+1,偶数不变 基于安全考虑，默认新建的文件没有执行权限，这就是为什么奇数加1的原因 新建目录的默认权限: 777-umask值 root用户的umask默认值为022 文件的权限：644 文件夹的权限：755 其他用户的umask默认值为002 文件的权限：664 文件夹的权限：775 umask设置越小，权限越大，慎用！ 查看umask 12345umask#模式方式显示umask –S#输出可被调用umask –p 范例 123456[root@centos8 ~]#umask0022 #0表示八进制。022影响新建文件的权限[root@centos8 ~]#umask -Su=rwx,g=rx,o=rx[root@centos8 ~]#umask -pumask 0022 修改umask 12umask 002umask u=rw,g=r,o= 持久保存umask 全局设置： &#x2F;etc&#x2F;bashrc 用户设置：~&#x2F;.bashrc 范例：只实现临时文件权限为000 123456#第一种touch a.txt ;chmod 000 a.txt#第二种umask 777 ;touch a.txt ;umask 022#第三种(umask 777;touch a.txt) 4.2.4 特殊权限4.2.4.1 SUIDSUID 作用于二进制可执行文件上，用户将继承此程序所有者的权限 给命令文件加的权限 chmod u+s /usr/bin/passwd 加了suid权限的命令在启动时的用户身份会用自己的命令文件的属主身份 数字代号：4 前提：进程有属主和属组；文件有属主和属组 任何一个可执行程序文件能不能启动为进程,取决发起者对程序文件是否拥有执行权限 启动为进程之后，其进程的属主为发起者,进程的属组为发起者所属的组 进程访问文件时的权限，取决于进程的发起者 二进制的可执行文件上SUID权限功能： 任何一个可执行程序文件能不能启动为进程：取决发起者对程序文件是否拥有执行权限 启动为进程之后，其进程的属主为原程序文件的属主 SUID只对二进制可执行程序有效 SUID设置在目录上无意义 SUID权限设定 123chmod u+s FILE...chmod 4xxx FILEchmod u-s FILE... 范例 12[root@centos8 ~]#ls -l /usr/bin/passwd-rwsr-xr-x. 1 root root 34928 May 11 2019 /usr/bin/passwd 4.2.4.2 SGID作于于目录上, 此目录中新建的文件的所属组将自动从此目录继承 可以给文件夹加 chmod g+s /aaa 后续在&#x2F;aaa 文件夹下创建的文件、文件夹的属组都会继承自&#x2F;aaa文件夹的属组 数字代号：2 二进制的可执行文件上SGID权限功能： 任何一个可执行程序文件能不能启动为进程：取决发起者对程序文件是否拥有执行权限 启动为进程之后，其进程的属组为原程序文件的属组 SGID权限设定 123chmod g+s FILE...chmod 2xxx FILEchmod g-s FILE... 目录上的SGID权限功能：默认情况下，用户创建文件时，其属组为此用户所属的主组，一旦某目录被设定了SGID，则对此目录有写权限的用户在此目录中创建的文件所属的组为此目录的属组，通常用于创建一个协作目录 4.2.4.3 StickySTICKY 作用于目录上，此目录中的文件只能由所有者或者root来删除，sticky 设置在文件上无意义 chmod o+t /share 在&#x2F;share文件下的文件只能被root用户及属主自己操作 数字代号：1 Sticky权限设定 123chmod o+t DIR...chmod 1xxx DIRchmod o-t DIR... 4.3 特殊属性设置文件的特殊属性，可以访问 root 用户误操作删除或修改文件，限制root的权限 不能删除，改名，更改：chattr +i file 只能追加内容，不能删除，改名：chattr +a file 显示特定属性：lsattr 范例 1234567891011121314[root@centos7 ~]#chattr +i a.txt [root@centos7 ~]#lsattr a.txt----i----------- a.txt[root@centos7 ~]#rm -rf a.txtrm: cannot remove ‘a.txt’: Operation not permitted[root@centos7 ~]#echo aaa &gt;&gt; a.txt-bash: a.txt: Permission denied[root@centos7 ~]#mv a.txt p.txtmv: cannot move ‘a.txt’ to ‘p.txt’: Operation not permitted[root@centos7 ~]#cat a.txtBEGIN&#123;print strftime(&quot;%Y-%m-%dT%H:%M&quot;,systime()-3600)&#125;[root@centos7 ~]#chattr -i a.txt [root@centos7 ~]#lsattr a.txt---------------- a.txt 范例 1234567chattr +a file1 #只允许以追加方式读写文件chattr +c file1 #允许这个文件能被内核自动压缩/解压chattr +d file1 #在进行文件系统备份时，dump程序将忽略这个文件chattr +i file1 #设置成不可变的文件，不能被删除、修改、重命名或者链接chattr +s file1 #允许一个文件被安全地删除chattr +S file1 #一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘chattr +u file1 #若文件被删除，系统会允许你在以后恢复这个被删除的文件 4.4 访问控制列表 ACL4.4.1 ACL权限功能ACL：实现灵活的权限管理 除了文件的所有者，所属组和其它人，可以对更多的用户设置权限，比如对单个用户设置权限 CentOS7 默认创建的xfs和ext4文件系统具有ACL功能 CentOS7 之前版本，默认手工创建的ext4文件系统无ACL功能,需手动增加 12tune2fs –o acl /dev/sdb1mount –o acl /dev/sdb1 /mnt/test ACL生效顺序：所有者，自定义用户，所属组|自定义组，其他人 4.4.2 ACL相关命令setfacl 可设置ACL权限 12345678910111213141516setfacl [-bkndRLPvh] [&#123;-m|-x&#125; acl_spec] [&#123;-M|-X&#125; acl_file] file ...-m #修改acl权限-M #从文件读取规则-x #删除文件acl 权限-Xe #从文件读取规则-b #删除文件所有acl权限-k #删除默认acl规则-n #不重新计算mask值-d #在目录上设置默认acl-R #递归执行-L #将acl 应用在软链接指向的目标文件上，与-R一起使用-P #将acl 不应用在软链接指向的目标文件上，与-R一起使用--set #用新规则替换旧规则，会删除原有ACL项，用新的替代，一定要包含UGO的设置，不能象 -m一样只有 ACL--set-file #从文件读取新规则--mask #重新计算mask值 范例 1234567891011121314151617181920#对单个用户设置权限setfacl -m u:username:rwx|0(-) file #u表示用户，rwx表示赋予什么权限，不赋予权限表示0(-)##清除所有ACL权限setfacl -b file1#复制file1的acl权限给file2getfacl file1 | setfacl --set-file=- file2 #设置 tom 无任何权限[root@ubuntu2204 tmp]# setfacl -m u:tom:- f1[root@ubuntu2204 tmp]# getfacl f1# file: f1# owner: root# group: rootuser::rw-user:tom:---group::r--mask::r--other::r-- 范例：给组加ACL 123456789101112[root@ubuntu2204 tmp]# setfacl -m g:tom:rwx f1[root@ubuntu2204 tmp]# getfacl f1# file: f1# owner: root# group: rootuser::rw-user:mage:---user:jerry:rw-group::r--group:tom:rwxmask::rwxother::r-- 范例：–set替换 123456789101112131415161718192021222324252627[root@ubuntu2204 tmp]# ll f2-rw-rwxr--+ 1 root root 3 Jun 26 20:17 f2[root@ubuntu2204 tmp]# getfacl f2# file: f2# owner: root# group: rootuser::rw-user:mage:---user:jerry:rw-group::r--group:tom:rwxmask::rwxother::r--[root@ubuntu2204 tmp]# setfacl --set u::rw,u:jerry:-,g::-,o::- f2[root@ubuntu2204 tmp]# ll f2-rw-------+ 1 root root 3 Jun 26 20:17 f2[root@ubuntu2204 tmp]# getfacl f2# file: f2# owner: root# group: rootuser::rw-user:jerry:---group::---mask::---other::--- 范例：设置wu用户不能访问data目录下的a2.txt文件 123456789101112131415161718[root@centos7 data]#ll a2.txt -rw-r--r--. 1 root root 12 Aug 16 16:59 a2.txt[root@centos7 data]#su wu[wu@centos7 data]$cat a2.txt aefdgh[wu@centos7 data]$exitexit[root@centos7 data]#setfacl -m u:wu:0 a2.txt [root@centos7 data]#ll a2.txt -rw-r--r--+ 1 root root 12 Aug 16 16:59 a2.txt[root@centos7 data]#su wu[wu@centos7 data]$cat a2.txt cat: a2.txt: Permission denied getfacl 可查看设置的ACL权限 123456789[root@centos7 data]#getfacl a2.txt# file: a2.txt# owner: root# group: rootuser::rw-user:wu:---group::r--mask::r--other::r-- mask 权限 mask只影响除所有者和other的之外的人和组的最大权限 mask需要与用户的权限进行逻辑与运算后，才能变成有限的权限(Effective Permission) 用户或组的设置必须存在于mask权限设定范围内才会生效 范例 1setfacl -m mask::rx file 对于脚本程序来讲，必须先要有读权限，才能执行 4.5 切换用户或以其他用户身份执行命令如果在当前登录终端中，要执行某条命令，但当前登录用户又没有可执行权限或没有某些资源权限；则在此种情况下，我们可以： 让有权限的用户登录终端，再执行相应的操作； 在当前终端终，临时切换，以有权限的用户的身份去执行命令； 4.5.1 su切换用户su: 即 switch user，命令可以切换用户身份，并且以指定用户的身份执行命令 1234567su [options...] [-] [user [args...]]-c&lt;指令&gt;或--command=&lt;指令&gt; #不切换用户，而是临时使用该用户权限和环境执行命令-f或--fast #适用于csh与tsch，使shell不用去读取启动文件。-l或--login #完全切换，改变身份时，也同时变更工作目录，以及HOME,SHELL,USER,LOGNAME。此外，也会变更PATH变量 -m,-p或--preserve-environment #变更身份时，不要变更环境变量。-s&lt;shell&gt;或--shell=&lt;shell&gt; #指定要执行的shell（bash csh tcsh 等），预设值为 /etc/passwd 内的该使用者（USER） shell 按照进入shell环境方式的不同，分为两种 登录shell：登录账号密码，su - egon 会读取目标用户的配置文件，切换至自已的家目录 非登录shell：在shell环境中直接输入命令进入的shell环境，su egon 不会读取目标用户的配置文件，不改变当前工作目录 切换新用户后，使用 exit 退回旧的用户身份，而不要再用 su 切换至旧用户，否则会生成很多的bash子进程，环境可能会混乱 二者的区别的就是加载的配置文件不同 登录shell 12345/etc/profile/etc/profile.d/脚本/etc/bashrc # rocky9才加载的~/.bash_profile~/.bashrc 非登录shell 123~/.bashrc/etc/bashrc/etc/profile.d/脚本 注意: 如果全局配置和个人配置产生冲突，以个人配置为准。 直接以另一个用户执行命令，而不切换用户 1su [-] UserName -c &#x27;COMMAND&#x27; 范例 12345678[root@centos8 ~]#su - wang -c &#x27;touch wang.txt&#x27;[root@centos8 ~]#ll ~wang/total 0-rw-rw-r-- 1 wang wang 0 Mar 27 09:31 wang1.txt-rw-rw-r-- 1 wang wang 0 Mar 27 09:32 wang2.txt[root@centos8 ~]#su -s /bin/bash -c &#x27;whoami&#x27; binbin 范例 1234[root@centos8 ~]#su -s /bin/bash binbash-4.4$ whoamibinbash-4.4$ 完全切换和不完全切换的区别 1234567891011121314151617181920jose@ubuntu2204:~$ pwd/home/josejose@ubuntu2204:~$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin#不完全切换jose@ubuntu2204:~$ su rootPassword:[root@ubuntu2204 jose]# pwd/home/jose[root@ubuntu2204 jose]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin#完全切换jose@ubuntu2204:~$ su - rootPassword:[root@ubuntu2204 ~]# pwd/root[root@ubuntu2204 ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/root/bin 4.5.2 sudo让普通用户只用自己的账号密码进行认证，操作时可以临时获取管理的某种权限 修改sudo配置文件的两种方式 visudo 专门编辑文件&#x2F;etc&#x2F;sudoers visudo -c # 检查文件语法 vi /etc/sudoers 详细看 《加密与安全》 4.5.3 超级用户说明1、在生产环境中，一般会禁止root帐号通过SSH远程连接服务器（保护好皇帝），当然了，也会更改默认的SSH端口（保护好皇宫），以加强系统安全。 2、企业工作中：没有特殊需求，应该尽量不要登录root用户进行操作，应该在普通用户下操作任务，然后用sudo管理普通用户的权限，可以细到每个命令权限分配。 3、在linux系统中，uid为0的用户就是超级用户。但是通常不这么做，如果确实有必要在某一操作上用到管理的权限的话，那就用sudo单独授权，也不要直接用uid为0的用户。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"文件结构和IO重定向","slug":"Linux/linux-basics/file-structure-and-IO-redirects","date":"2025-08-19T05:52:56.000Z","updated":"2025-08-28T12:33:05.246Z","comments":true,"path":"Linux/linux-basics/file-structure-and-IO-redirects/","permalink":"https://aquapluto.github.io/Linux/linux-basics/file-structure-and-IO-redirects/","excerpt":"","text":"1 文件系统目录结构 文件和目录被组织成一个单根倒置树结构 文件系统从根目录下开始，用“&#x2F;”表示 根文件系统(rootfs)：root filesystem 标准Linux文件系统（如：ext4），文件名称大小写敏感，例如：MAIL, Mail, mail, mAiL以 . 开头的文件为隐藏文件 路径分隔的 &#x2F; 文件名最长255个字节 包括路径在内文件名称最长4095个字节 蓝色–&gt;目录 绿色–&gt;可执行文件 红色–&gt;压缩文件 浅蓝色–&gt;链接文件 灰色–&gt;其他文件 除了斜杠和NUL,所有字符都有效.但使用特殊字符的目录名和文件不推荐使用，有些字符需要用引号来引用 每个文件都有两类相关数据：元数据：metadata，即属性， 数据：data，即文件内容 Linux的文件系统分层结构：FHS Filesystem Hierarchy Standard 参考文档： http://www.pathname.com/fhs/ 1.1 各个目录功能12345678910111213141516171819202122232425262728293031323334353637383940414243444546#命令相关目录● /usr/bin：普通用户使用命令● /usr/sbin：root用户使用命令#启动目录● /boot：存放的启动相关文件，例如kernel，grub（引导装载程序）#系统文件目录● /usr/lib或/usr/lib64：库文件Glibc#用户家目录● /home：普通用户● /root：root用户#配置文件目录● /etc/sysconfig/network-script/：网络配置文件目录，rocky9有变动为/etc/NetworkManger/system-connections● /etc/hostname：系统主机名配置文件● /etc/resolv.conf：dns客户端配置文件● /etc/hosts：本地域名解析配置文件● /etc/fstab：系统挂载目录，开机自启动挂载列表● /etc/passwd：系统用户文件#设备目录文件● /dev/cdrom和/dev/sr0：系统光盘镜像设备● /dev/null：黑洞设备，只进不出，类似于垃圾回收站● /dev/random：生成随机数的设备● /dev/zero：能源源不断的产生数据● /dev/pts/0：虚拟的Bash Shell终端，提供给远程客户用，0代表第一个终端● /dev/stderr：错误输出● /dev/stdin：标准输入● /dev/stdout：标准输出#可变目录，存放一些变化文件，比如数据库，日志，邮件等● mysql：/var/lib/mysql● vsftpd：/var/ftp● mail：/var/spool/mail● cron：/var/spool/cron● log：/var/log/messages系统日志；/var/log/secure系统登陆日志● tmp：/var/tmp程序产生的临时文件#虚拟文件系统，反应出来的是内核，进程信息或实时状态，类似于汽车的仪表盘● /proc/meminfo：内存信息● /proc/cpuinfo：cpu信息#存储设备挂载目录● /media：移动设备默认挂载点● /mnt：手工挂载设备挂载点● /opt：早期第三方厂商的软件存放目录● /tmp：临时存放文件目录#centos7特有目录● /lost+found：使用ext2/ext3才有，存储发生意外后丢失的文件，只有root用户可以打开● /lost+found/run：存放程序运行后产生的pid文件● /lost+found/srv：物理设备产生的文件● /lost+found/sys：硬件设备的驱动程序信息 1.2 Linux下的文件类型1234567- 普通文件d 目录文件directoryl 符号链接文件linkb 块设备blockc 字符设备characterp 管道文件pipes 套接字文件socket linux 系统中的文件类型颜色标识 linux 系统中，每种颜色，都有对应的含义，可以根据文件在终端中显示的颜色，来判断是什么类型的文件 颜色与文件类型对应关系，由配置文件定义，可更改（此处的文件类型，可以理解为文件格式） 123456789101112vim /etc/DIR_COLORS普通文件 #白色 目录文件 #蓝色 符号链接文件 #浅蓝色 块设备 #黄色 字符设备 #黄色管道文件 #青黄套接字文件 #粉红图片文件 #粉红压缩文件或文件包 #红色其他文件 #灰色 管道文件 所谓管道，是指用于连接一个读进程和一个写进程，以实现它们之间通信的共享文件，又称 pipe 文件。 套接字文件 Socket本身有“插座”的意思，在Unix&#x2F;Linux环境下，用于表示进程间网络通信的特殊文件类型。本质为内核借助缓冲区形成的伪文件。 2 文件系统和inode表 在Linux系统中，一切皆文件，每个文件，又分为文件元数据和具体内容两部份，一个文件元数据和其具体内容数据，在磁盘分区上，是分开存放的。 这种存储文件元数据的区域就叫 inode，中文译作 “索引节点”，每个文件都有一个inode和n(n&gt;&#x3D;1)个block 数据块，inode 存储文件元数据，数据块存储文件具体内容数据 磁盘在格式化时，系统会自动将磁盘分为两个区域，一个是 inode 区（inode table），用来存放文件的 inode，另一个是数据区，分成很多个block(块)，用来存放文件的具体内容数据 2.1 文件系统文件系统：操作系统内核中用来控制硬盘的一种程序 每个硬盘分区都要有一个文件系统 硬盘分区—-》打隔断，分割出一个个小空间 硬盘的最小存取单位-》扇区（512字节，相当于0.5KB） 文件系统—-》对一个个小空间做装修，负责把空间的数据组织好 操作系统的最小存取单位-》block块（4KB，8个扇区） 操作系统读取硬盘的时候，不会一个扇区一个扇区地读取，这样效率太低，于是操作系统中的文件系统负责将磁盘的多扇区组织成一个个的block块，这样操作系统就可以一次性读取一个”块”（block），即一次性连续读取多个扇区，所以文件系统组织好了之后带来的方便之处 使用者—–》block块（文件系统）—–》n个扇区（硬盘的读写单位） 一个文件系统包含的三大类块 inode block块：存放文件的元数据 ls -l 的结果如权限、属主、数组 对一个文件来说，inode block就1个 data block块：存放文件的内容数据 cat看到的结果，真正的内容 对一个文件来说，如果过大，data block可能有多个 superblock超级块：记录此filesystem的整体信息，包括inode&#x2F;block的总量、使用量、剩余量，以及文件系统的格式与相关信息等； superblock一个文件系统整体就一个 硬盘满了，分两种情况 inode号耗尽 磁盘空间耗尽 如上图，每一个inode表记录对应的保存了以下信息： inode number 节点号 文件类型 权限 UID GID 链接数（指向这个文件名路径名称个数） 该文件的大小和不同的时间戳 指向磁盘上文件的数据块指针 有关文件的其他数据 总结 磁盘在格式化时，系统会自动将磁盘分为两个区域，一个是 inode 区（inode table），用来存放文件的 inode，另一个是数据区，分成很多个block(块)，用来存放文件的具体内容数据 一个磁盘分区上有多少个inode和多少个block，由系统自行决定，跟文件系统，磁盘分区大小，数据块大小有关 一个磁盘分区，能存放多少个文件，由文件大小，磁盘分区大小，inode数量决定 2.2 查找文件内容的底层流程打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名 文件夹也是文件： 元数据：权限、属主、属组——》inode block块 内容数据：存的该文件夹包含的——–》data block块 子文件名—–》inode块的编号 子文件夹名—–》inode块的编号 普通文件： 元数据：权限、属主、属组——–》inode block块 内容数据：你写的文件中的数据——–》data block块 如图，比如查看&#x2F;etc&#x2F;passwd：/ ---&gt; etc ---&gt; passwd 2.3 创建、修改、删除文件对于inode号的影响创建和复制文件，会占用inode号 移动文件，目标和源在相同的文件系统，不影响inode号码；在不同的文件系统，相当于cp和rm 重命名文件，只是改变文件名，不影响inode号 删除文件，释放的inode号可以被重用，数据实际上不会马上被删除，当另一个文件使用数据块时将被覆盖 当每次修改完服务器配置文件后，为什么都需要重新加载一下配置文件呢？因为vim每次修改完后，Inode号都会变，系统还是读取的原来inode号的配置文件，每次修改完服务器的配置文件，都要重启服务，重新读一下配置文件 123456#分区越大，可用的节点编号就越多，当前分区有多少个节点编号，就是说能在当前分区上创建多少个文件#如果当前分区上的节点编号用光，则无法再创建新文件，系统会提示 “No space left on device”#如果当前分区上的空间用光，同样无法创建新文件，系统同样提示 “No space left on device”磁盘分区还有空间，但提示没有足够空间创建文件，这就是因为 inode 编号耗尽的原因inode 编号资源还有，但磁盘数据空间被耗尽，同样无法创建文件 3 硬链接和软链接3.1 硬链接硬链接：指向文件系统中某个文件的实际物理位置的直接链接。在Linux中，文件实际上是存储在磁盘上的数据块（或inode）的引用。硬链接就是这些数据块的另一个名称或引用。创建硬链接相当于给文件增加了一个新的名字 目标文件与源文件指向同一个inode号 改动一个文件元数据或内容，另外一个也跟着变 删除源文件，仅仅只是解除了源文件名与inode号的关联关系，所以不会影响目标文件 硬链接无法跨分区 不能对目录做硬链接 使用场景 备份**：硬链接常用于备份，因为它们不占用额外**的磁盘空间（不需要额外存储数据和inode结构，但是需要存储目录项）。 文件重命名或移动**：**在重命名或移动文件时，硬链接可以保持文件的一致性。 多人共享**：**当多人需要对同一个文件进行操作的时候，如果每次都是直接操作原始文件，一旦有一个人执行了误删除，则该文件将立即永久消失。但如果每个人都在私人目录中创建一个该文件的硬链接，即使有一个人误删了他自己的文件，也不会导致原始文件被删除，大幅降低文件意外丢失的概率 1234ln filename [linkname ]# 给a.txt起了aa.txt的别名ln a.txt aa.txt 3.2 软链接软连接：类似于 Windows 中的快捷方式，包含的是另一个文件路径名的文本指针。当访问软链接时，系统会读取软链接文件中存储的路径信息，然后根据这个路径找到并访问目标文件。如果目标文件被移动或删除，软链接将失效，因为它存储的路径不再指向一个有效的文件 目标文件指向的是源文件的文件名，包含的不是文件的实际数据，具有不同的inode号 改动一个文件内容，另外一个也跟着变，但改元数据的话，彼此之间不会互相影响 删除源文件，目标文件不可用 软连接可以跨分区，跨文件系统，因为是指向文件名 可以对目录做软链接 注意问题 软链接路径：使用相对路径时，源文件路径（第一个参数）是相对于软链接文件所在目录的，软链接路径（第二个参数）是相对于当前工作目录的，即它们都相对于同一个当前目录，不可以是不同的目录 权限问题：软链接的权限总是lrwxrwxrwx，但实际访问权限取决于源文件。 备份和恢复**：**在备份和恢复时，软链接可能需要特别处理，以保持其指向正确的位置。 123456ln -s 源文件路径 软链接路径[root@ubuntu2204 ~]#ln -s /etc/issue /boot/issue.link /boot/issue.link这个符号链接指向/etc/issue文件访问/boot/issue.link相当于访问/etc/issue 范例：删除软链接文件 1234rm -rf /boot/issue.link # 只删除软链接本身（链接文件），不会删除源目录内容rm -rf /boot/issue.link/ # 删除源目录内容（链接指向的目录），但不会删除链接文件。此方法非常危险# 注意: 删除此软链接务必不要加-r选项 4 IO重定向和管道4.1 文件描述符文件描述符的概念：进程但凡打开一个文件，操作性系统都会为打开的文件分配一个编号（&gt;&#x3D;0的证书），这个编号就称之为文件描述符（也称之为文件句柄） Linux给程序提供三种 I&#x2F;O 设备 标准输入（STDIN） 0文件描述符：代表标准输入 标准输出（STDOUT） 1文件描述符：代表标准正确输出 标准错误（STDERR） 2文件描述符：代表标准错误输出 在Linux系统中，一切皆文件，所以，这三个设备也是以文件的形式存在于系统中；程序从标准输入文件中获取数据，再将运行结果和错误信息输出到标准输出设备和标准错误输出设备 一个进程运行起来之后，我们要用它的时候无非就是与之交互，交互&#x3D;输入+输出 整体的关系：进程(打开文件)———–》文件描述符——-》操作系统内核——–》硬盘 输入输出背后对应的机制是什么？在linux系统中很简单，一切皆文件，所以对于进程来讲 输入操作—-》某个打开的文件—》某个文件描述符 输出操作—-》某个打开的文件—》某个文件描述符 $$：当前运行的 shell 进程的进程 ID（PID） 123456[root@centos7 ~]#ll /proc/$$/fdtotal 0lrwx------ 1 root root 64 Oct 23 16:21 0 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 23 16:21 1 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 23 16:21 2 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 23 16:23 255 -&gt; /dev/pts/2 范例：假设我们打开了另外一个窗口，用 tail -f 命令打开了一个文件（还处于打开状态），如果我们想看到这个文件描述符，就去之前的窗口输入ll /proc/pidof tail/fd，数字是随机分的，但是012是固定的 123456789101112[root@centos7 ~]#tail -f anaconda-ks.cfg [root@centos7 ~]#ll /proc/`pidof tail`/fd #文件处于打开状态total 0lrwx------ 1 root root 64 Oct 23 16:28 0 -&gt; /dev/pts/3lrwx------ 1 root root 64 Oct 23 16:28 1 -&gt; /dev/pts/3lrwx------ 1 root root 64 Oct 23 16:28 2 -&gt; /dev/pts/3lr-x------ 1 root root 64 Oct 23 16:28 3 -&gt; /root/anaconda-ks.cfglr-x------ 1 root root 64 Oct 23 16:28 4 -&gt; anon_inode:inotify[root@centos7 ~]#ll /proc/`pidof tail`/fd #文件关闭ls: cannot access /proc//fd: No such file or directory 4.2 I&#x2F;O重定向 redirect4.2.1 标准输出和错误重定向12命令 操作符号 文件名-：表示标准输出或者标准输入 支持的操作符号 123451&gt; 或 &gt; #把STDOUT重定向到文件2&gt; #把STDERR重定向到文件&amp;&gt; #把标准输出和错误都重定向&gt;&amp; #和上面功能一样，建议使用上面方式注意：以上如果文件已存在，文件内容会被覆盖 追加 12&gt;&gt; #追加标准输出重定向至文件2&gt;&gt; #追加标准错误重定向至文件 标准输出和错误输出各自定向至不同位置 1COMMAND &gt; /path/to/file.out 2&gt; /path/to/error.out 合并标准输出和错误输出为同一个数据流进行重定向 12345&amp;&gt; 覆盖重定向&amp;&gt;&gt; 追加重定向COMMAND &gt; /path/to/file.out 2&gt;&amp;1 （顺序很重要）COMMAND &gt;&gt; /path/to/file.out 2&gt;&amp;1 范例：标准输出至其它终端 1234567[root@centos7 ~]#tty/dev/pts/2[root@centos7 ~]#ls &gt; /dev/pts/3[root@centos7 ~]#tty/dev/pts/3[root@centos7 ~]#anaconda-ks.cfg 范例：命令输出重定向 12345678910111213[root@centos7 ~]#hostname &gt; /root/data/data.txt[root@centos7 ~]#cat /root/data/data.txtcentos7[root@centos7 ~]#uname -r &gt; /root/data/data.txt #会覆盖之前的内容[root@centos7 ~]#cat /root/data/data.txt 3.10.0-1160.el7.x86_64[root@centos7 ~]#hostname &gt; /root/data/data.txt[root@centos7 ~]#uname -r &gt;&gt; /root/data/data.txt #追加不会覆盖[root@centos7 ~]#cat /root/data/data.txtcentos73.10.0-1160.el7.x86_64 范例：合并多个命令的结果至一个文件中 123456789[root@centos7 ~]#&#123; hostname;uname -r;&#125; &gt; /root/data/data.log[root@centos7 ~]#cat /root/data/data.logcentos73.10.0-1160.el7.x86_64[root@centos7 ~]#( hostname -I;uname -r ) &gt; /root/data/data.log[root@centos7 ~]#cat /root/data/data.log10.0.0.183 3.10.0-1160.el7.x86_64 范例：标准输出和标准错误分别放到一个文件里 1234567[root@centos7 ~]#ls data/ /xxx &gt; stdout.log 2&gt; stderr.log[root@centos7 ~]#cat stdout.log data/:scripts[root@centos7 ~]#cat stderr.log ls: cannot access /xxx: No such file or directory 范例：标准输出和标准错误都放到一个文件里 123456789101112131415161718192021222324#第一种[root@centos7 ~]#ls anaconda-ks.cfg xxx &amp;&gt;g.txt[root@centos7 ~]#cat g.txt ls: cannot access xxx: No such file or directoryanaconda-ks.cfg#第二种[root@centos7 ~]#ls anaconda-ks.cfg xxx &gt;f.txt 2&gt;&amp;1[root@centos7 ~]#cat f.txt ls: cannot access xxx: No such file or directoryanaconda-ks.cfg#第三种[root@centos7 ~]#ls anaconda-ks.cfg xxx 2&gt;t.txt 1&gt;&amp;2[root@centos7 ~]#cat t.txt ls: cannot access xxx: No such file or directoryanaconda-ks.cfg#错误写法#标准错误输出重定向至标准输出之前，要先定义好标准输出的文件[root@ubuntu2204 ~]# ls fstab null 2&gt;&amp;1 &gt; out.log#标准输出重定向至标准错误输出之前，要先定义好标准错误输出的文件[root@ubuntu2204 ~]# ls fstab null 1&gt;&amp;2 2&gt;out.log 范例: 实现标准输出和错误的互换 1234567#子进程中借用中间文件描述符3，将标准输出和标准错误输出作了对换[root@centos8 ~]#( cat /etc/centos-release /etc/xxx 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 ) &gt; f1.txt 2&gt; f2.txt[root@centos8 ~]#cat f1.txtcat: /etc/xxx: No such file or directory[root@centos8 ~]#cat f2.txtCentOS Linux release 8.2.2004 (Core) 4.2.2 标准输入重定向从文件中导入STDIN，代替当前终端的输入设备，使用 &lt; 来重定向标准输入 某些命令能够接受从文件中导入的STDIN 标准输入重定向是使用文件来代替键盘的输入，从文件中读取数据，代替当前终端的输入设备输入的数据 怎么判断命令能使用标准输入重定向？不跟任何选项参数，直接回车，看是否等待标准输入，如果是，则该命令可以使用标准输入重定向。 实现标准输入重定向的符号 COMMAND &lt; FILE bc 命令：可以避免在键盘屏幕上输入内容做计算 123456789[root@centos7 ~]#echo 2*3 &gt; data.txt # data.txt存放echo 2*3的标准输出[root@centos7 ~]#bc &lt; data.txt # data.txt作为bc的标准输入6[root@centos7 ~]#seq -s+ 10 &gt; seq.log # seq.log存放seq -s+ 10的标准输出[root@centos7 ~]#bc &lt; seq.log # seq.log作为bc的标准输入55注意：data.txt和seq.log只是临时文件，要是不想是临时文件，需要和管道符应用 cat命令 一行一行重定向 cat &gt; file 123456789[root@centos7 ~]#cat &gt; a.logabc^C[root@centos7 ~]#cat a.log abc 多行重定向 使用 “&lt;&lt;终止词” 命令从键盘把多行重导向给STDIN，直到终止词位置之前的所有文本都发送给STDIN 终止词可以是任何一个或多个符号，比如：!，@，$，EOF（End Of File），magedu等，其中EOF比较常用 cat &gt; file &lt;&lt;终止词 123456789[root@centos7 ~]#cat &gt; b.log &lt;&lt;EOF&gt; a&gt; b&gt; c&gt; EOF[root@centos7 ~]#cat b.log abc 4.2.3 高级重定向写法格式1 123456cmd &lt;&lt;&lt;&quot;string&quot; #cmd要支持标准输入，字符串把传给cmd，作为这个命令的标准输入[root@centos7 ~]#bc &lt;&lt;&lt; &quot;2+2&quot;4[root@rocky8 ~]#tr &#x27;a-z&#x27; &#x27;A-Z&#x27; &lt;&lt;&lt;&quot;I am wang&quot;I AM WANG 格式2 123456789cmd1 &lt; &lt;(cmd2) #把cmd2的输出写到一个临时文件里，然后把这个文件的内容传给cmd1，作为cmd1的标准输入&lt;(cmd2) 表示把cmd2的输出写入一个临时文件，注意：&lt;和（之间无空格cmd1 &lt; 标准输入重定向把两个合起来，就是把cmd2的输出stdout传递给cmd1作为输入stdin, 中间通过临时文件做传递[root@rocky8 ~]#tr &#x27;a-z&#x27; &#x27;A-Z&#x27; &lt; &lt;(echo I am wang)I AM WANG[root@rocky8 ~]#ll &lt;(echo I am wang)lr-x------ 1 root root 64 Nov 26 17:20 /dev/fd/63 -&gt; &#x27;pipe:[30384]&#x27; 4.3 管道符管道（使用符号“|”表示）用来连接多个命令，将前一个命令的输出作为后一个命令的输入 使用管道，要求前一个命令必须支持标准输出，后一个命令必须支持标准输入 格式：命令1 | 命令2 | 命令3 | … 功能说明： 将命令1的STDOUT发送给命令2的STDIN，命令2的STDOUT发送到命令3的STDIN 所有命令会在当前shell进程的子shell进程中执行 组合多种工具的功能 STDERR默认不能通过管道转发，可利用2&gt;&amp;1 或 |&amp; 实现，格式如下 12命令1 2&gt;&amp;1 | 命令2命令1 |&amp; 命令2 范例 1[root@centos8 ~]#df | tr -s &#x27; &#x27; 范例 1234567891011121314151617181920[root@centos8 ~]#ls /data /xxx | tr &#x27;a-z&#x27; &#x27;A-Z&#x27;ls: cannot access &#x27;/xxx&#x27;: No such file or directory/DATA:ALL.LOGF1.TXTPASSWD.LOG[root@centos8 ~]#ls /data /xxx 2&gt;&amp;1 | tr &#x27;a-z&#x27; &#x27;A-Z&#x27;LS: CANNOT ACCESS &#x27;/XXX&#x27;: NO SUCH FILE OR DIRECTORY/DATA:ALL.LOGF1.TXTPASSWD.LOG[root@centos8 ~]#ls /data /xxx |&amp; tr &#x27;a-z&#x27; &#x27;A-Z&#x27;LS: CANNOT ACCESS &#x27;/XXX&#x27;: NO SUCH FILE OR DIRECTORY/DATA:ALL.LOGF1.TXTPASSWD.LOG 范例 123456#转换为大写字母ls | tr ‘a-z’ ‘A-Z’#less实现分页地查看输入ls -l /etc | less#算术运算echo &quot;2^3&quot; |bc 范例：实现邮件服务 12345678910[root@rocky86 ~]# vim /etc/mail.rcset from=1701785325@qq.comset smtp=smtp.qq.comset smtp-auth-user=1701785325@qq.comset smtp-auth-password=meenopnxjawzbfccset smtp-auth=loginset ssl-verify=ignore#mail通过电子邮件发送输入echo &quot;test email&quot; | mail -s &quot;test&quot; wang@example.com 范例：用户密码修改 123456789101112131415161718192021[root@rocky86 ~]# passwd --stdin joseChanging password for user jose.magedupasswd: all authentication tokens updated successfully.[root@centos8 ~]# cat pass.txtcentos[root@rocky86 ~]# passwd --stdin jose &lt; pass.txtChanging password for user jose.passwd: all authentication tokens updated successfully.[root@rocky86 ~]# cat pass.txt | passwd --stdin joseChanging password for user jose.passwd: all authentication tokens updated successfully.[root@rocky86 ~]# echo magedu | passwd --stdin joseChanging password for user jose.passwd: all authentication tokens updated successfully.[root@rocky86 ~]# echo magedu | passwd --stdin jose &amp;&gt; /dev/null","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]},{"title":"linux基础","slug":"Linux/linux-basics/introduce","date":"2025-08-18T08:20:18.000Z","updated":"2025-08-28T12:33:05.256Z","comments":true,"path":"Linux/linux-basics/introduce/","permalink":"https://aquapluto.github.io/Linux/linux-basics/introduce/","excerpt":"","text":"1 系统构成与shell核心初始shell之系统命令基础 操作系统启动流程 系统安装 VM和Xshell 1.1 linux系统构成从功能维度去划分： 系统调用接口：负责跟上层的应用程序打交道 内核：负责跟下层的硬件打交道 应用程序本身是无法操作硬件的，但凡想操作硬件都要给系统发请求 从文件维度进行划分 操作系统源自iso镜像文件，镜像文件本质就是一个压缩包，压缩里放着一系列的系统的文件 这些文件分为两大类：bootfs+rootfs bootfs(系统启动前)：包含启动文件（bootloader程序，不是以文件的形式存在，是直接写入硬盘的第一个扇区/mbr）、内核文件(/boot/vm...) rootfs(系统启动后)：本质就是一堆文件夹&#x2F;文件 1.2 linux系统的启动linux系统启动顺序 加电，先启动bios bios负责找到启动盘 bios读取启动盘第一块扇区mbr主引导记录（放着的是bootloder程序）放入内存，让cpu来执行，bootloader成功启动 bootloader启动之后，负责从硬盘中找到内核文件读入内存，并启动，此时操作系统就启动起来 操作系统启动起来负责管理一系列进程，这些进程可以分为两大类 内核先启动一个老祖宗程序，pid为0 0号进程负责运行两个顶级程序，产生两个顶级的进程 运行init程序，pid号为1：是所有用户态进程的祖宗 它是系统的第一个进程，负责产生其他所有用户进程 init 以守护进程方式存在，是所有其他进程的祖先 具有启动守护进程，收养孤儿，定期发起wait或waitpid的功能去回收成为僵尸的儿子，将操作系统信号转发给子进程的功能 运行kthreadd程序，pid2：是所有内核态进程的祖宗 在内核完成了系统的各种初始化之后，这个程序需要执行的第一个用户态程就是 init 进程，PID号为1，该进程是系统中所有其他进程的祖宗，在centos6中该祖宗进程称之为init，在centos7之后该祖宗进程名为systemd。即操作系统启动时是先执行内核态代码，然后在内核里调用1号进程的代码，从内核态切换到用户态 linux系统启动级别 init 0 # 关机 init 6 # 重启 init 3 # multi-user.target，进入字符终端（进入bash环境） init 5 # 进入图形界面（前提需要安装图形桌面 yum -y group install &quot;Server with GUI&quot;） 设置启动级别 systemctl set-default graphical.target &#x2F;&#x2F; 图形界面 systemctl set-default multi-user.target &#x2F;&#x2F; 字符终端 1systemctl get-default 1.3 shell解释器介绍在默认启动级别为3的情况下，linux系统启动之后默认会启动一个命令解释器铺满全屏幕给你去（称之为字符终端），只能在里面敲命令 linux系统中的命令解释器称之为shell，翻译为壳，表达了对系统接口封装的思想 具体来说shell解释器分为很多种类，默认用的bash这种 1.4 shell命令的种类与优先级带着路径用命令 绝对路径：从根开始的路径 相对路径: 不是从根开始的路径，相对于你当前所在的文件夹作为起始点往后查找 不带着路径前缀去使用命令 别名：用来alias命令制作的命令（alias xxx=&quot;ls /etc/sysconfig/network-scripts;echo 123&quot;） Compound Commands复合命令：for((i=0;i&lt;3;i++));do echo 66666; done function定义命令的函数：function f()&#123; echo 123; &#125; built_in内置命令（内置在shell解释器中，解释器内部集成）：type ls hash缓存机制：优化机制，把敲得命令缓存内存中，下次直接会省去查找与加载的开销，直接使用即可 环境变量PATH（与命令查找有关系、负责兜底）：查找命令的机制，在系统任意位置都能访问到，是全局有效的变量，PATH变量的值存的是冒号分隔开的的一堆存放命令的文件夹 想要不加任何前缀去调用mmm命令的方法有两种 把该脚本移动到PATH的某个文件夹下面 把该脚本所在的文件夹添加到PATH里 优先级 1234567891011bash shell查找命令顺序：==&gt;以路径（绝对路径，相对路径）开始命令，例如：/bin/ls 或 cd /bin; ./ls ==&gt; alias ==&gt; Compound Commands复合命令 ==&gt; function ==&gt; build_in，如cd，kill，pwd、alias、echo等，可以用&quot;type -a 命令&quot;查看 ==&gt; hash：命令的本质是文件，将命令缓存到内存中，下次直接从内存取 ==&gt; $PATH，环境变量，查看环境变量echo $PATH，例如/bin/ls ==&gt; error: command not found # ps：查看命令的位置：which 命令 1.4.1 命令执行方式多个命令一起执行 1cmd1;cmd2;cmd3;echo -e &quot;\\a&quot; 单个命令换行敲 123[root@ubuntu2004 ~]#host\\&gt; nameubuntu2004 1.4.2 合并多个命令1(CMD1;CMD2......)` 或者`&#123; CMD1;CMD2;....; &#125; ( list ) 会开启子shell，并且list中变量赋值及内部命令是临时性的，执行后将不再影响后续的环境 &#123; list; &#125; 不会开启子shell, 在当前shell中运行,会影响当前shell环境 连接多个命令组成一条大命令 分号：左边命令运行完毕，无论成功与否，都会执行右边的命令 &amp;&amp; ：左边命令运行成功之后，才能执行右边的命令 1.5 linux系统安装VMware中的网络模式 连接模式 特点 NAT 虚拟机通过Vmnet8这个HUB互相连接，再通过物理机上的Vmnet8网卡连接物理机，能访问外网，物理机充当路由器 桥接 虚拟机和物理机连接同一网络，两者之间是并列关系，通过Vmnet0 这个HUB连接，跟所处环境有关，可通过Windows的以太网网卡（物理网卡）的ip地址确定 仅主机 虚拟机通过Vmnet1这个HUB互相连接，再通过物理机上的Vmnet1网卡连接物理机，不能访问外网 桥接模式：虚拟机和真机的地位一样，都是直接连接到路由器转发数据包。不过从物理层面来说，虚拟机的数据包还是会通过物理机的网卡转发到路由器，再由路由器转发出去 在物理机的网络连接中可以看到两张虚拟网卡VMnet1和VMnet8, 这两种网卡分别作用于仅主机模式与NAT模式。如果将这两块不小心卸载, 可以在vmware的 “编辑” 下的 “虚拟网络编辑器” 中点击 “还原默认设置”。 1.6 centos的平替方案centos停更的风险 安全：安全漏洞攻击，补丁与更新 兼容性：新软件可能不再支持旧版本的centos Ubuntu&#x2F;Debian 一直稳定开源，长期坚持稳定性优先策略，默认禁用root直接登录，LTS版本5年维护周期(更新较慢但是稳定) Rocky&#x2F;Alma 完全兼容RHEL生态，完全免费开源 两者区别 包管理器：前者使用dpkg和apt，后者使用rpm和dnf 安全：前者默认不启用SELinux安全模块，后者默认启用 2 linux基础命令2.1 系统信息2.1.1 查看 cpu12345678910111213141516171819202122232425262728#查看CPU信息[root@ubuntu2004 ~]#lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianAddress sizes: 45 bits physical, 48 bits virtualCPU(s): 4On-line CPU(s) list: 0-3Thread(s) per core: 1 #每个内核有几个线程Core(s) per socket: 2 #每个槽位有2个内核Socket(s): 2 #服务器面板上有2个cpu 槽位NUMA node(s): 1 #nodes的数量Vendor ID: GenuineIntelCPU family: 6Model: 154Model name: 12th Gen Intel(R) Core(TM) i7-12650HStepping: 3CPU MHz: 2688.003BogoMIPS: 5376.00Hypervisor vendor: VMwareVirtualization type: fullL1d cache: 192 KiBL1i cache: 128 KiBL2 cache: 5 MiBL3 cache: 48 MiBNUMA node0 CPU(s): 0-3 #对应的core[root@centos8 ~]# cat /proc/cpuinfo 2.1.2 查看系统架构12[root@ubuntu2204 ~]# archx86_64 2.1.3 查看内核版本12[root@ubuntu1804 ~]#uname -r4.15.0-29-generic 2.2 关机和重启12345678910111213# 关机haltpoweroffinit 0shutdown -h now# 重启reboot-f: 强制，不调用shutdown-p: 切断电源init 6shutdown -r nowctrl+alt+delete 三个键 2.3 文件传输123yum(apt) -y install lrzszsz ss.log # 将Linux创建的文件传输到Windowsrz # 将在Windows的文件传输的Linux 2.4 用户登录信息查看命令1234567891011121314151617181920212223242526272829303132333435# 显示当前用户的用户名whoami# 显示当前用户的用户名 终端 登录时间 来源IPwho am iwho [选项]... [ 文件 | 参数1 参数2 ] # 显示当前已登录的用户信息。who # 列出在当前主机上所有登录用户who -u | --users # 列出当前主机上所有用户的空闲时间 . 表示最近一分钟还是活跃状态 old 表示用户己经空闲超过24小时who -s | --short # 列出在当前主机上所有登录用户，等同于whowho -q | --count # 登录用户统计who -b | --boot # 上次系统启动时间who -a | --all # 多选项组合who -m # who am iw [options] # 显示当前所有登录用户的具体信息[root@ubuntu2004 ~]#w 12:28:22 up 16:28, 3 users, load average: 0.00, 0.02, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot tty1 - 19Nov23 89days 0.01s 0.00s -bashroot pts/0 10.0.0.1 Wed07 2days 0.05s 0.05s -bashroot pts/1 10.0.0.1 11:59 0.00s 0.02s 0.00s w参数说明：USER:登录名 TTY:终端 FROM:来源IP LOGIN@:登录时间 IDLE:空闲时间 JCPU:当前终端中所有进程使用cpu的时间,不包括后台作业占用的时间 PCPU:当前进程使用的cpu的时间WHAT:当前进程load average 表示平均负载，最近一分钟，最近五分钟，最近15分钟# 查看特定用户w root 2.5 主机名123456# 查看当前主机名 hostname# 修改主机名，只能数字，横线，字母组成，下划线不行，点后面不能是数字，可以是字母hostnamectl set-hostname xxx（永久生效） # 支持CentOS7和Ubuntu18.04以上版本hostname xxx（临时生效） 范例：错误的主机名可能会导致某些服务无法启动 1234[root@centos8 ~]#hostnamectl set-hostname centos8.3[root@centos8 ~]#systemctl restart postfixJob for postfix.service failed because the control process exited with error code.See &quot;systemctl status postfix.service&quot; and &quot;journalctl -xe&quot; for details. 2.6 登陆提示2.6.1 登陆前提示在命令行模式下本地终端(tty1~tty6)登录界面，会有几行提示文字， 这些文字都保存在&#x2F;etc&#x2F;issue文件中，可以自行修改。 1234567891011vi /etc/issue，输入你想要提示的内容issue 支持转义字符，全部可用的转义字符可以通过 man agetty 查看，这里列出常用的\\d #显示当前系统日期\\S #显示操作系统名称\\m #显示硬件体系结构，如i386、i686等\\n #显示主机名\\o #显示域名\\r #显示内核版本\\t #显示当前系统时间\\u #显示当前登录用户的序列号 如果是远程终端ssh 登录，则其登录前信息，可以放在&#x2F;etc&#x2F;issue.net 中，但是该文件中的内容不支持转义 如果要使用远程终端ssh 登录前的提示信息，还需要修改sshd的相关配置文件 1234567vim /etc/ssh/sshd_config#Banner none 将此处的banner 指向对应的文件即可Banner /etc/issue.net#重启sshd 服务service sshd restart 2.6.2 登陆后提示当用户从终端登录时，此文件的内容将会显示在终端上，如果shell工具支持中文，也可显示。 内容由使用者定制，经常用于通告信息，欢迎提示等。 但是，此文件只适用于命令行界面，如果是图形界面登录，将不显示此文件内容。 123456789vim /etc/motd,输入你想要提示的内容有文件可以拖进去，然后cp xxx(文件名) /etc/motd#ubuntu2204中没有该文件，可自行创建[root@ubuntu2204 ~]# ls /etc/motdls: cannot access &#x27;/etc/motd&#x27;: No such file or directory#登录后的提示来自于此目录下不同文件，如果不需要默认提示，可以将该目录清空[root@ubuntu2204 ~]# ls /etc/update-motd.d/ 2.7 命令提示符登录Linux后，默认的系统命令提示符毫无没有个性，无法明显辨别生产和测试环境，而导致误操作。可以通过修改PS1变量实现个性的提示符格式，避免这种低级错误 1234567891011#Ubunturoot@ubuntu2023：~##Rocky/Centos[root@10 wu ~]#root：用户名ubuntu2023|10 wu：主机名~：表示在哪个文件夹（目录）$：表示普通用户身份#：表示管理员身份 显示提示符格式 12345678910111213echo $PS1[\\u@\\h \\W]\\$\\e 控制符 \\u 用户名 \\h 主机名监测 \\H 主机名 \\w 当前所在目录 \\W 当前目录基名 \\t 24小时时间格式 \\T 12小时时间格式 ! 命令历史数# 开机后命令历史数 修改提示符 12345678910PS1=&quot;\\[\\e[1;5;41;33m\\][\\u@\\h \\W]\\\\$\\[\\e[0m\\]&quot;PS1=&quot;\\[\\e[1;32m\\][\\t \\[\\e[1;33m\\]\\u\\[\\e[35m\\]@\\h\\[\\e[1;31m\\] \\W[\\e[1;32m\\]]\\[\\e[0m\\]\\\\$&quot;PS1=&quot;\\[\\e]0;\\u@\\h: \\w\\a\\]$&#123;debian_chroot:+($debian_chroot)&#125;\\u@\\h:\\w\\$&quot;1：加强亮度5：闪烁41-47：命令符的底色31-37：命令符字体的颜色0m：表示颜色的结束 永久生效的办法 12345678910#Rocky/Centosvim /etc/profile(bashrc),进入之后将命令复制粘贴到文件的最后面，并保存#Ubuntu第一种：vim.bashrc，进入之后将命令复制粘贴到文件的最后面，并保存第二种：vim.bashrcforce_color_prompt=yes 2.8 命令别名123456789101112#修改并保存vim .bashrcalias NAME=&#x27;VALUE&#x27; #定义别名NAME，其相当于执行命令VALUE#显示当前shell进程所有可用的命令别名alias#删除别名unalias nameunalias -a #取消所有别名当别名和内外部命令重名时，优先运行别名命令 注意：在命令行中定义的别名，仅对当前shell进程有效 如果想永久有效，要定义在配置文件中 仅对当前用户：~&#x2F;.bashrc 对所有用户有效：&#x2F;etc&#x2F;bashrc 编辑配置给出的新配置不会立即生效，bash进程重新读取配置文件 12source /path/to/config_file. /path/to/config_file 如果别名同原命令同名，如果要执行原命令，可使用 12345\\ALIASNAME“ALIASNAME”‘ALIASNAME’command ALIASNAME/path/commmand #只适用于外部命令 2.9 获取帮助2.9.1 whatis &amp; whereiswhatis 使用数据库来显示命令的简短描述，以及对应的man手册的章节 whereis 可以列出命令或系统文件路径 1whatis|whereis cmd 2.9.2 查看命令类型区别指定的命令是内部或外部命令 1type cmd 范例: 查看是否存在对应内部和外部命令 123[root@centos8 ~]#type -a echoecho is a shell builtinecho is /usr/bin/echo 内部命令：由shell自带的，而且通过某命令形式提供, ,用户登录后自动加载并常驻内存中 1234567#查询内部命令的用法help cmd#管理内部命令enable cmd 启用内部命令enable –n cmd 禁用内部命令enable –n 查看所有禁用的内部命令 外部命令：在文件系统路径下有对应的可执行程序文件,当执行命令时才从磁盘加载至内存中,执行完毕后从内存中删除 12#查询外部命令的用法cmd --help 或 cmd -h 查看外部命令路径： 12which -a |--skip-aliaswhereis 2.9.3 man帮助123456789101112#提供命令帮助的文件man cmd #查看章节man1 man1p man2...（1,1p，2表示各个命令的章节的意思）man 1 passwd #查看passwd第一章的帮助man 5 passwd #查看passwd第五章的帮助#搜素关键字当文件太多时，想要找到自己想要的帮助时，可以/关键字/second按键n可以往下划，N往上划 2.9.4 info 命令info 是自由软件基金会的GNU项目，是GNU的超文本帮助系统，整个结构类似于一个网站，有导航，支持链接跳转不带参数，默认进入的是首页 1234567891011121314#info [OPTION]... [MENU-ITEM...]info #进入整个info文档info ls #在info 中查看ls的信息#常用快捷键向上方向键 #上移一行向下方向键 #下移一行PgUp #向上一屏PgDn #向下一屏Tab #在链接间滚动Enter #进入链接查看具体内容s|/ #搜索n/p/u/l #进入下/前/上一层/最后一个链接q #退出 2.10 Hash缓存表系统初始hash表为空，当外部命令执行时，默认会从PATH路径下寻找该命令，找到后会将这条命令的路径记录到hash表中，当再次使用该命令时，shell解释器首先会查看hash表，存在将执行之，如果不存在，将会去PATH路径下寻找，利用hash缓存表可大大提高命令的调用速率 123456hash #显示hash缓存hash -l #显示hash缓存，可作为输入使用hash -p path name #将命令全路径path起别名为namehash -t name #打印缓存中name的路径hash -d name #清除name缓存hash -r #清除缓存 2.11 会话管理命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称”窗口”），在里面输入命令。用户与计算机的这种临时的交互，称为一次”会话”（session） 会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完 一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。 为了解决这个问题，会话与窗口可以”解绑”：窗口关闭时，会话并不终止，继续运行，等到以后需要的时候，再让会话”绑定” 其他窗口终端复用器软件就是会话与窗口的”解绑”工具，将它们彻底分离。 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口”接入”已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。 2.11.1 screen工具有一些长时间的操作，或者做备份的时候，可以通过screen新建一个会话窗口，在新的会话窗口里面执行操作，这样可以避免因为xshell突然崩溃，网络崩溃或者不小心关掉了窗口而停止程序运行 利用screen 可以实现会话管理,如：新建会话,共享会话等 注意：CentOS7 来自于base源，CentOS8 来自于epel源 1234567891011121314151617181920212223#CentOS7 安装screen[root@centos7 ~]#yum -y install screen#CentOS8 安装screen[root@centos8 ~]#dnf -y install epel-release[root@centos8 ~]#dnf -y install screen#创建新screen会话screen –S [SESSION]#加入screen会话screen –x [SESSION]#退出并关闭screen会话exit#剥离当前screen会话Ctrl+a,d#显示所有已经打开的screen会话screen -ls#恢复某screen会话screen -r [SESSION] 2.11.2 tmuxTmux 是一个终端复用器（terminal multiplexer），类似 screen，但是更易用，也更强大，它将会话与窗口”解绑”，将它们彻底分离，功能如下 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口”接入”已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分 123456#安装yum install tmux#启动与退出tmuxexit tmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是 Ctrl+b ，即先按下Ctrl+b ，快捷键才会生效。帮助命令的快捷键是 Ctrl+b ? 然后，按下 q 键，就可以退出帮助 新建会话第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0号会话、1 号会话。使用编号区分会话，不太直观，更好的方法是为会话起名。下面命令新建一个指定名称的会话。 给会话窗口命名 1tmux new -s &lt;session-name&gt; 查看当前所有的 Tmux 会话 121 tmux ls2 tmux list-session 分离会话 121 tmux ls2 tmux list-session 接入对话 12tmux attach -t &lt;session-name&gt;tmux attach -t 0 杀死会话 1tmux kill-session -t &lt;session-name&gt; 切换会话 1tmux switch -t &lt;session-name&gt; 上下分窗格 121 tmux split-window2 ctrl+b,&quot; 左右分窗格 121 tmux split-window -h2 ctrl+b,% 窗格快捷键 123456789101112131415Ctrl+b %：划分左右两个窗格Ctrl+b &quot;：划分上下两个窗格Ctrl+b &lt;arrow key&gt;：光标切换到其他窗格。&lt;arrow key&gt;是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓Ctrl+b ;：光标切换到上一个窗格Ctrl+b o：光标切换到下一个窗格。Ctrl+b &#123;：当前窗格左移Ctrl+b &#125;：当前窗格右移Ctrl+b Ctrl+o：当前窗格上移Ctrl+b Alt+o：当前窗格下移Ctrl+b x：关闭当前窗格Ctrl+b !：将当前窗格拆分为一个独立窗口Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小Ctrl+b Ctrl+&lt;arrow key&gt;：按箭头方向调整窗格大小Ctrl+b q：显示窗格编号 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口新建窗口 创建新窗口 1tmux new-window 新建一个指定名称的窗口 1tmux new-window -n &lt;window-name&gt; 切换到指定编号的窗口 1tmux select-window -t &lt;window-number&gt; 切换到指定名称的窗口 1tmux select-window -t &lt;window-name&gt; 窗口快捷键 123456Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。Ctrl+b n：切换到下一个窗口。Ctrl+b &lt;number&gt;：切换到指定编号的窗口，其中的&lt;number&gt;是状态栏上的窗口编号Ctrl+b w：从列表中选择窗口Ctrl+b ,：窗口重命名 列出所有快捷键，及其对应的 Tmux 命令 1tmux list-keys 列出所有 Tmux 命令及其参数 1tmux list-commands 2.12 输出信息echo语法 12345echo [-neE][字符串]-E （默认）不支持 \\ 解释功能-n 不自动换行-e 启用 \\ 字符的解释功能 显示变量 12echo &quot;$VAR_NAME” #用变量值替换，弱引用echo &#x27;$VAR_NAME’ #变量不会替换，强引用 启用命令选项-e，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出 12345678910\\a 发出警告声\\b 退格键\\c 最后不加上换行符号\\e escape，相当于\\033\\n 换行且光标移至行首\\r 回车，即光标移至行首，但不换行\\t 插入tab\\\\ 插入\\字符\\0nnn 插入nnn（八进制）所代表的ASCII字符\\xHH插入HH（十六进制）所代表的ASCII数字（man 7 ascii） 在终端中，ANSI定义了用于屏幕显示的Escape屏幕控制码，可以显示具有颜色的字符，其格式如下 123456789101112131415161718192021222324&quot;\\033[字符背景颜色;字体颜色m字符串\\033[0m&quot;\\033[30m -- \\033[37m 设置前景色\\033[40m -- \\033[47m 设置背景色#字符背景颜色范围: 40--47 40:黑 41:红 42:绿 43:黄 44:蓝 45:紫 46:深绿 47:白色 #字体颜色: 30--3730: 黑31: 红32: 绿33: 黄34: 蓝35: 紫36: 深绿37: 白色 加颜色只是以下控制码中的一种，下面是常见的一些ANSI控制码 123456789101112131415161718\\033[0m 关闭所有属性 \\033[1m 设置高亮度 \\033[4m 下划线 \\033[5m 闪烁 \\033[7m 反显 \\033[8m 消隐 \\033[nA 光标上移n行 \\033[nB 光标下移n行 \\033[nC 光标右移n列 \\033[nD 光标左移n列 \\033[x;yH 设置光标位置x行y列 \\033[2J 清屏 \\033[K 清除从光标到行尾的内容 \\033[s 保存光标位置 \\033[u 恢复光标位置 \\033[?25l 隐藏光标 \\033[?25h 显示光标\\033[2J\\033[0;0H 清屏且将光标置顶 2.13 语言环境默认系统为英文环境，可以修改为中文环境，从而查看帮助或提示可以变为中文 范例：临时修改LANG变量实现中文语言提示 12345678910[root@centos7 ~]#echo $LANGen_US.UTF-8[root@centos7 ~]#magedu-bash: magedu: command not found[root@centos7 ~]#LANG=zh_CN.UTF-8[root@centos7 ~]#echo $LANGzh_CN.UTF-8[root@centos7 ~]#magedu-bash: magedu: 未找到命令 范例: Rocky 8 修改语言环境为中文 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@rocky8 ~]#localectl status System Locale: LANG=en_US.UTF-8 VC Keymap: us X11 Layout: us [root@rocky8 ~]#echo $LANGen_US.UTF-8[root@rocky8 ~]#localectl list-localesC.utf8en_AGen_AUen_AU.utf8en_BWen_BW.utf8en_CAen_CA.utf8....[root@rocky8 ~]#yum list lang*[root@rocky8 ~]#yum -y install langpacks-zh_CN.noarch[root@rocky8 ~]#localectl list-localesC.utf8en_AGen_AU.......zh_CNzh_CN.gb18030zh_CN.gbkzh_CN.utf8zh_HKzh_HK.utf8....#通用方法[root@rocky8 ~]#localectl set-locale LANG=zh_CN.utf8#或者下面方式,CentOS8支持,但ubuntu和Centos7不支持,不建议使用[root@rocky8 ~]#localectl set-locale zh_CN.utf8[root@rocky8 ~]#localectl status System Locale: LANG=zh_CN.utf8 VC Keymap: us X11 Layout: us [root@rocky8 ~]#echo $LANGzh_CN.utf8#重新登录后可以看到中文环境[root@rocky8 ~]#exit 范例: Ubuntu 修改语言环境为中文 123456789101112131415[root@ubuntu2204 ~]#localectl status System Locale: LANG=en_US.UTF-8 VC Keymap: n/a X11 Layout: us X11 Model: pc105 [root@ubuntu2204 ~]#apt install language-pack-zh-hans -y[root@ubuntu2204 ~]#localectl list-localesC.UTF-8en_US.UTF-8zh_CN.UTF-8zh_SG.UTF-8[root@ubuntu2204 ~]#localectl set-locale LANG=zh_CN.utf8[root@ubuntu2204 ~]#exit 2.14 命令行历史2.14.1 查看命令行历史当执行命令后，系统默认会在内存记录执行过的命令 当用户正常退出时，会将内存的命令历史存放对应历史文件中，默认是 ~/.bash_history 登录shell时，会读取命令历史文件中记录下的命令加载到内存中 登录进shell后新执行的命令只会记录在内存的缓存区中；这些命令会用户正常退出时“追加”至命令历史文件中 利用命令历史。可以用它来重复执行命令，提高输入效率 1234567891011historyCtrl R可以在命令行历史中查找所需命令-c: 清空命令历史-d offset: 删除历史中指定的第offset个命令n: 显示最近的n条历史-a: 追加本次会话新执行的命令历史列表至历史文件-r: 读历史文件附加到历史列表-w: 保存历史列表到指定的历史文件-n: 读历史文件中未读过的行到历史列表-p: 展开历史参数成多行，但不存在历史列表中-s: 展开历史参数成一行，附加在历史列表后 命令历史相关环境变量 1234567891011HISTSIZE #命令历史记录的条数HISTFILE #指定历史文件，默认为~/.bash_historyHISTFILESIZE #命令历史文件记录历史的条数HISTTIMEFORMAT=&quot;%F %T `whoami` &quot; #显示时间和用户HISTIGNORE=&quot;str1:str2*:…&quot; #忽略str1命令，str2开头的历史HISTCONTROL=ignoredups|ignorespace|ignoreboth|erasedups #控制命令历史的记录方式ignoredups #是默认值，可忽略重复的命令，连续且相同为“重复”ignorespace #忽略所有以空白开头的命令ignoreboth #相当于ignoredups, ignorespace的组合erasedups #删除重复命令 持久保存变量，以上变量可以 export 变量名=&quot;值&quot; 形式存放在 &#x2F;etc&#x2F;profile 或 ~&#x2F;.bash_profile 范例： 1234567891011[root@centos8 ~]#cat .bash_profileexport PATHexport HISTCONTROL=ignorebothexport HISTTIMEFORMAT=&quot;%F %T &quot;[root@centos8 ~]#history 1 2019-12-13 08:39:05 ls /data 2 2019-12-13 08:39:05 date 3 2019-12-13 08:39:05 vie0 4 2019-12-13 08:39:05 nano .bash_profile 5 2019-12-13 08:39:05 exit 2.14.2 调用命令行历史123456789101112131415161718192021222324252627282930313233343536373839404142434445#重复前一个命令方法重复前一个命令使用上方向键，并回车执行按 !! 并回车执行输入!-1 并回车执行按 Ctrl+p 并回车执行!:0 #执行前一条命令（去除参数）!n #执行history命令输出对应序号n的命令!-n #执行history历史中倒数第n个命令!string #重复前一个以“string”开头的命令!?string #重复前一个包含string的命令!string:p #仅打印命令历史，而不执行!$:p #打印输出 !$ （上一条命令的最后一个参数）的内容!*:p #打印输出 !*（上一条命令的所有参数）的内容^string #删除上一条命令中的第一个string^string1^string2 #将上一条命令中的第一个string1替换为string2!:gs/string1/string2 #将上一条命令中所有的string1都替换为 string2使用up（向上）和down（向下）键来上下浏览从前输入的命令ctrl-r来在命令历史中搜索命令（reverse-i-search）`’：Ctrl+g：从历史搜索模式退出#要重新调用前一个命令中最后一个参数!$ #表示前一个命令中最后一个参数Esc, . #点击Esc键后松开，然后点击 . 键Alt+ . #按住Alt键的同时点击 . 键command !^ #利用上一个命令的第一个参数做command的参数command !$ #利用上一个命令的最后一个参数做command的参数command !* #利用上一个命令的全部参数做command的参数command !:n #利用上一个命令的第n个参数做command的参数command !n:^ #调用第n条命令的第一个参数command !n:$ #调用第n条命令的最后一个参数command !n:m #调用第n条命令的第m个参数command !n:* #调用第n条命令的所有参数command !string:^ #从命令历史中搜索以 string 开头的命令，并获取它的第一个参数command !string:$ #从命令历史中搜索以 string 开头的命令,并获取它的最后一个参数command !string:n #从命令历史中搜索以 string 开头的命令，并获取它的第n个参数command !string:* #从命令历史中搜索以 string 开头的命令，并获取它的所有参数 3 符号用法与快捷键3.1 反向单引号 &#96;&#96;&#96;&#96;里面一定是可执行的命令，变量和命令都可识别 一个命令CMD1想调用另一个命令CMD2的执行结果，就需要将CMD2放在反向引号中 CMD2 $()与&#96;&#96;等价 1234567[root@centos7 ~]#touch `date +%F`.log[root@centos7 ~]#ls2023-10-22.log anaconda-ks.cfg touch是创建文件的命令，用``将date +%F括起来后，先执行date +%F这个命令，后执行touch命令#思维例如今天是2023-7-31，执行touch `date +%F`.log后，便可创建2023-7-31.log这个文件，明天是2023-8-1，再执行touch `date +%F`.log，便可创建2023-8-1.log这个文件。就不可能说每天查一下今天日期多少，然后再执行touch 2023-7-31.log才可以创建2023-7-31.log这个文件，这样子效率太慢。 3.2 单引号’’变量和命令都不能识别 12[root@centos7 ~]#echo &#x27;echo $PATH&#x27;echo $PATH 3.3 双引号””只能识别变量，不能识别命令 1234[root@centos7 ~]#echo &quot;echo $PATH&quot;echo /apps/tree/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@centos7 ~]#echo $PATH/apps/tree/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin 3.4 花括号{}实现打印重复字符串的简化形式 {元素1..元素2..元素3} 12345678910111213141516171819202122[root@centos7 ~]#echo &#123;1..10&#125;1 2 3 4 5 6 7 8 9 10[root@centos7 ~]#echo &#123;1..10..2&#125;1 3 5 7 9[root@centos7 ~]#echo &#123;a..z..3&#125;a d g j m p s v y[root@centos7 ~]#echo &#123;20..10..2&#125;20 18 16 14 12 10[root@centos7 ~]#echo &#123;a b c&#125;&#123;a b c&#125;[root@centos7 ~]#echo &#123;a,b,c&#125;a b c[root@centos7 ~]#echo &#123;a,b,c&#125;.&#123;txt,log&#125;a.txt a.log b.txt b.log c.txt c.log[root@centos7 ~]#echo file&#123;1..5&#125;.&#123;txt,log&#125;file1.txt file1.log file2.txt file2.log file3.txt file3.log file4.txt file4.log file5.txt file5.log[root@centos7 ~]#echo /data/mysql/&#123;txt,log,pid&#125;/data/mysql/txt /data/mysql/log /data/mysql/pid[root@centos7 ~]#echo file&#123; ,bak&#125;file&#123; ,bak&#125;[root@centos7 ~]#echo file&#123;,bak&#125;file filebak 3.5 bash快捷键12345678910111213141516171819202122232425262728293031Ctrl + l #清屏，相当于clear命令Ctrl + o #执行当前命令，并重新显示本命令Ctrl + s #阻止屏幕输出，锁定Ctrl + q #允许屏幕输出，解锁Ctrl + c #终止命令Ctrl + z #挂起命令Ctrl + a #光标移到命令行首，相当于HomeCtrl + e #光标移到命令行尾，相当于EndCtrl + f #光标向右移动一个字符Ctrl + b #光标向左移动一个字符Ctrl + xx #光标在命令行首和光标之间移动ctrl+ &gt;(方向键) #光标向右移动一个单词尾，相当于 Alt + fctrl+ &lt;(方向键) #光标向左移动一个单词首，相当于 Alt + bCtrl + u #从光标处删除至命令行首Ctrl + k #从光标处删除至命令行尾Alt + r #删除当前整行Ctrl + w #从光标处向左删除至单词首Alt + d #从光标处向右删除至单词尾Alt + Backspace #删除左边单词Ctrl + d #删除光标处的一个字符Ctrl + h #删除光标前的一个字符Ctrl + y #将删除的字符粘贴至光标后Alt + c #从光标处开始向右更改为首字母大写的单词Alt + u #从光标处开始，将右边一个单词更改为大写Alt + l #从光标处开始，将右边一个单词更改为小写Ctrl + t #交换光标处和之前的字符位置Alt + t #交换光标处和之前的单词位置Alt + # #提示输入指定字符后，重复显示该字符#次 注意：Alt 组合快捷键经常和其它软件冲突 范例：xshell中启动 alt 键 4 字符集和编码及语言环境许多场合下，字符集与编码这两个概念常被混为一谈，但两者是有差别的。字符集与字符集编码是两个不同层面的概念 charset是character set的简写，即字符集，即二进制和字符的对应关系，不关注最终的存储形式 encoding是charset encoding的简写，即字符集编码，简称编码，实现如何将字符转化为实际的二进制进行存储或相反，编码决定了空间的使用的大小 4.1 ASCII码计算机内部，所有信息最终都是一个二进制值。上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定，即ASCII（American Standard Code for InformationInterchange） 码ASCII 码一共规定了128个字符的编码，占用了一个字节的后面7位，最前面的一位统一规定为 0 Oct 8进制 Dec 10进制 ascii 编码 Hex 16进制 Bin 2进制 Char 字符 范例：查看 ascii 表 12[root@centos8 ~]#dnf -y install man-pages[root@centos8 ~]#man ascii 4.2 Unicode由于计算机是美国人发明的，因此，最早只有128个字符被编码到计算机里，即ASCII编码，但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。 全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码 为了表示世界上所有语言中的所有字符。每一个符号都给予一个独一无二的编码数字，Unicode 是一个很大的集合，现在的规模可以容纳100多万个符号。Unicode 仅仅只是一个字符集，规定了每个字符对应的二进制代码，至于这个二进制代码如何存储则没有规定 Unicode编码方案： UTF-8： 变长，1到4个字节 UTF-16：变长，2或4个字节 UTF-32：固定长度，4个字节 UTF-8 是目前互联网上使用最广泛的一种 Unicode 编码方式，可变长存储。使用 1- 4 个字节表示一个字符，根据字符的不同变换长度。编码规则如下：对于单个字节的字符，第一位设为 0，后面的 7 位对应这个字符的 Unicode 码。因此，对于英文中的 0 127 号字符，与 ASCII 码完全相同。这意味着 ASCII 码的文档可用 UTF-8 编码打开对于需要使用 N 个字节来表示的字符（N &gt; 1），第一个字节的前 N 位都设为 1，第 N + 1 位设为0，剩余的 N - 1 个字节的前两位都设为 10，剩下的二进制位则使用这个字符的 Unicode 码来填充 编码转换和查询参考链接： 1234567https://home.unicode.org/https://unicode.yunser.com/unicodehttp://www.chi2ko.com/tool/CJK.htmhttps://www.bejson.com/convert/unicode_chinese/https://javawind.net/tools/native2ascii.jsp?action=transformhttp://tool.oschina.net/encodehttp://web.chacuo.net/charsetescape 5 环境变量5.1 配置文件说明profile类文件：设定环境变量, 登陆前运行的脚本和命令。 bashrc类文件：设定本地变量, 定义命令别名。 5.2 环境变量配置方法5.2.1 export PATH使用export命令直接修改PATH的值，配置MySQL进入环境变量的方法: 1234export PATH=/home/uusama/mysql/bin:PATH#或者把PATH放在前面 export PATH=PATH:/home/uusama/mysql/bin 注意事项： 生效时间：立即生效 生效期限：当前终端有效，窗口关闭后无效 生效范围：仅对当前用户有效 配置的环境变量中不要忘了加上原来的配置，即$PATH部分，避免覆盖原来配置 5.2.2 vim ~&#x2F;.bashrc通过修改用户目录下的~&#x2F;.bashrc文件进行配置： 1234vim ~/.bashrc#在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~&#x2F;.bashrc生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果有后续的环境变量加载文件覆盖了PATH定义，则可能不生效 5.2.3 vim ~&#x2F;.bash_profile和修改~&#x2F;.bashrc文件类似，也是要在文件最后加上新的路径即可： 1234vim ~/.bash_profile#在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~&#x2F;.bash_profile生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果没有&#x2F;.bash_profile文件，则可以编辑&#x2F;.profile文件或者新建一个 5.2.4 vim &#x2F;etc&#x2F;bashrc该方法是修改系统配置，需要管理员权限（如root）或者对该文件的写入权限： 1234567#如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/bashrcvim /etc/bashrc#在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source &#x2F;etc&#x2F;bashrc生效 生效期限：永久有效 生效范围：对所有用户有效 5.2.5 vim &#x2F;etc&#x2F;profile该方法修改系统配置，需要管理员权限或者对该文件的写入权限，和vim &#x2F;etc&#x2F;bashrc类似： 1234567#如果/etc/profile文件不可编辑，需要修改为可编辑chmod -v u+w /etc/profilevim /etc/profile#在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source &#x2F;etc&#x2F;profile生效 生效期限：永久有效 生效范围：对所有用户有效 5.2.6 vim &#x2F;etc&#x2F;environment该方法是修改系统环境配置文件，需要管理员权限或者对该文件的写入权限： 1234567#如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/environmentvim /etc/profile#在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source &#x2F;etc&#x2F;environment生效 生效期限：永久有效 生效范围：对所有用户有效 5.3 读取环境变量读取环境变量的方法： export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值 其中PATH变量定义了运行命令的查找路径，以冒号:分割不同的路径，使用export定义的时候可加双引号也可不加。 5.4 环境变量加载顺序环境变量可以简单的分成用户自定义的环境变量以及系统级别的环境变量。 用户级别环境变量定义文件：&#x2F;.bashrc、&#x2F;.profile（部分系统为：~&#x2F;.bash_profile） 系统级别环境变量定义文件：&#x2F;etc&#x2F;bashrc、&#x2F;etc&#x2F;profile(部分系统为：&#x2F;etc&#x2F;bash_profile）、&#x2F;etc&#x2F;environment Linux加载环境变量的顺序如下：系统环境变量 -&gt; 用户自定义环境变量 /etc/environment -&gt; /etc/profile -&gt; ~/.profile 另外在用户级别环境变量中，系统会首先读取&#x2F;.bash_profile（或者&#x2F;.profile）文件，如果没有该文件则读取&#x2F;.bash_login，根据这些文件中内容再去读取&#x2F;.bashrc。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"监控","slug":"monitor","permalink":"https://aquapluto.github.io/categories/monitor/"},{"name":"Linux","slug":"Linux","permalink":"https://aquapluto.github.io/categories/Linux/"},{"name":"计算机基础","slug":"计算机基础","permalink":"https://aquapluto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"https://aquapluto.github.io/tags/Grafana/"},{"name":"Alertmanager","slug":"Alertmanager","permalink":"https://aquapluto.github.io/tags/Alertmanager/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://aquapluto.github.io/tags/Prometheus/"},{"name":"linux基础","slug":"linux基础","permalink":"https://aquapluto.github.io/tags/linux%E5%9F%BA%E7%A1%80/"},{"name":"加密和安全","slug":"加密和安全","permalink":"https://aquapluto.github.io/tags/%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8/"},{"name":"防火墙","slug":"防火墙","permalink":"https://aquapluto.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"服务管理","slug":"服务管理","permalink":"https://aquapluto.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"},{"name":"网络管理","slug":"网络管理","permalink":"https://aquapluto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"},{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://aquapluto.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"name":"进程管理","slug":"进程管理","permalink":"https://aquapluto.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"软件包管理","slug":"软件包管理","permalink":"https://aquapluto.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"https://aquapluto.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"https://aquapluto.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"shell编程","slug":"shell编程","permalink":"https://aquapluto.github.io/tags/shell%E7%BC%96%E7%A8%8B/"},{"name":"系统优化","slug":"系统优化","permalink":"https://aquapluto.github.io/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"}]}